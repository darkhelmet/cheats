{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Cheat Sheets Collection Welcome to the cheat sheets collection - a comprehensive set of quick reference guides for various programming languages, frameworks, and tools. Getting Started README - Overview and contribution guidelines Available Cheat Sheets Python Inquirer - Interactive command-line prompts and user interfaces Keras - High-level neural networks API with multi-backend support LangChain - Framework for building LLM-powered applications LangExtract - Google's language detection and information extraction Matplotlib - Core plotting and data visualization library NLTK - Natural Language Toolkit for text processing and analysis NumPy - Numerical computing basics and advanced operations Pandas - Data manipulation and analysis fundamentals Pillow - Python Image Library for image processing Polars - Blazingly fast DataFrame library with lazy evaluation and powerful expressions Python - Core Python language syntax, data structures, and built-in features PyTorch - Deep learning framework for tensors, neural networks, and training Scikit-learn - Machine learning workflows, algorithms, and model evaluation SciPy - Scientific computing algorithms and mathematical functions Seaborn - Statistical data visualization with elegant defaults Sentence-Transformers - Semantic similarity and text embeddings TensorFlow - Machine learning platform with Keras integration TorchVision - Computer vision utilities and pre-trained models Transformers - Hugging Face transformers for modern NLP JavaScript & Frameworks React - Component-based UI library with hooks, state management, and modern patterns Next.js - Full-stack React framework with App Router, SSR/SSG, and API routes Machine Learning & Data Science Machine Learning Algorithms - Comprehensive guide to ML algorithms, their use cases, and selection criteria GPU Computing CUDA - Comprehensive CUDA C/C++ programming reference for GPU computing Operating Systems Bottlerocket OS - Container-optimized Linux OS with AWS SSM, containerd management, and security best practices Tools & Editors Protocol Buffers - Schema definition and code generation with protoc compiler ripgrep - Fast text search tool with regex support Vim/Neovim with LazyVim - Text editing with Vim motions and LazyVim enhancements Contributing We welcome contributions! Please see the README for guidelines on adding new cheat sheets or improving existing ones. Each cheat sheet should include: - Basic syntax and common patterns - Frequently used operations - Advanced but commonly needed functionality - Practical examples with clear explanations Organization Cheat sheets are organized by topic: - python/ - Python-related libraries and tools - javascript/ - JavaScript frameworks and libraries - machine-learning-algorithms.md - General machine learning and data science concepts - gpu/ - GPU computing and parallel programming - os/ - Operating systems and system administration - tools/ - Development tools and editors - Additional directories can be added for other languages/topics as needed This documentation is built with MkDocs. For more information about MkDocs, visit mkdocs.org .","title":"Cheat Sheets Collection"},{"location":"#cheat-sheets-collection","text":"Welcome to the cheat sheets collection - a comprehensive set of quick reference guides for various programming languages, frameworks, and tools.","title":"Cheat Sheets Collection"},{"location":"#getting-started","text":"README - Overview and contribution guidelines","title":"Getting Started"},{"location":"#available-cheat-sheets","text":"","title":"Available Cheat Sheets"},{"location":"#python","text":"Inquirer - Interactive command-line prompts and user interfaces Keras - High-level neural networks API with multi-backend support LangChain - Framework for building LLM-powered applications LangExtract - Google's language detection and information extraction Matplotlib - Core plotting and data visualization library NLTK - Natural Language Toolkit for text processing and analysis NumPy - Numerical computing basics and advanced operations Pandas - Data manipulation and analysis fundamentals Pillow - Python Image Library for image processing Polars - Blazingly fast DataFrame library with lazy evaluation and powerful expressions Python - Core Python language syntax, data structures, and built-in features PyTorch - Deep learning framework for tensors, neural networks, and training Scikit-learn - Machine learning workflows, algorithms, and model evaluation SciPy - Scientific computing algorithms and mathematical functions Seaborn - Statistical data visualization with elegant defaults Sentence-Transformers - Semantic similarity and text embeddings TensorFlow - Machine learning platform with Keras integration TorchVision - Computer vision utilities and pre-trained models Transformers - Hugging Face transformers for modern NLP","title":"Python"},{"location":"#javascript-frameworks","text":"React - Component-based UI library with hooks, state management, and modern patterns Next.js - Full-stack React framework with App Router, SSR/SSG, and API routes","title":"JavaScript &amp; Frameworks"},{"location":"#machine-learning-data-science","text":"Machine Learning Algorithms - Comprehensive guide to ML algorithms, their use cases, and selection criteria","title":"Machine Learning &amp; Data Science"},{"location":"#gpu-computing","text":"CUDA - Comprehensive CUDA C/C++ programming reference for GPU computing","title":"GPU Computing"},{"location":"#operating-systems","text":"Bottlerocket OS - Container-optimized Linux OS with AWS SSM, containerd management, and security best practices","title":"Operating Systems"},{"location":"#tools-editors","text":"Protocol Buffers - Schema definition and code generation with protoc compiler ripgrep - Fast text search tool with regex support Vim/Neovim with LazyVim - Text editing with Vim motions and LazyVim enhancements","title":"Tools &amp; Editors"},{"location":"#contributing","text":"We welcome contributions! Please see the README for guidelines on adding new cheat sheets or improving existing ones. Each cheat sheet should include: - Basic syntax and common patterns - Frequently used operations - Advanced but commonly needed functionality - Practical examples with clear explanations","title":"Contributing"},{"location":"#organization","text":"Cheat sheets are organized by topic: - python/ - Python-related libraries and tools - javascript/ - JavaScript frameworks and libraries - machine-learning-algorithms.md - General machine learning and data science concepts - gpu/ - GPU computing and parallel programming - os/ - Operating systems and system administration - tools/ - Development tools and editors - Additional directories can be added for other languages/topics as needed This documentation is built with MkDocs. For more information about MkDocs, visit mkdocs.org .","title":"Organization"},{"location":"machine-learning-algorithms/","text":"Machine Learning Algorithms A comprehensive guide to fundamental machine learning algorithms, their applications, strengths, weaknesses, and when to use each approach. Quick Algorithm Selection Guide By Problem Type Regression : Linear Regression, Random Forest, SVM, Neural Networks Classification : Logistic Regression, Decision Trees, Random Forest, SVM, k-NN, Naive Bayes Clustering : k-Means, Hierarchical Clustering, DBSCAN Dimensionality Reduction : PCA, t-SNE, UMAP Anomaly Detection : Isolation Forest, One-Class SVM, Local Outlier Factor By Data Size Small datasets (< 1K samples) : k-NN, Naive Bayes, Decision Trees, AdaBoost Medium datasets (1K-100K) : SVM, Random Forest, XGBoost, LightGBM, CatBoost Large datasets (> 100K) : Linear models, Neural Networks, LightGBM, SGD variants By Interpretability High : Linear Regression, Decision Trees, Naive Bayes Medium : Random Forest, k-NN, AdaBoost Low : SVM (with RBF kernel), Neural Networks, XGBoost, LightGBM, CatBoost Supervised Learning Algorithms Linear Regression Purpose : Predict continuous target variable using linear relationship Mathematical Formula : y = \u03b2\u2080 + \u03b2\u2081x\u2081 + \u03b2\u2082x\u2082 + ... + \u03b2\u2099x\u2099 + \u03b5 Cost Function: J(\u03b8) = 1/(2m) \u03a3(h\u03b8(x\u207d\u2071\u207e) - y\u207d\u2071\u207e)\u00b2 Key Parameters : - fit_intercept : Whether to calculate intercept (default: True) - normalize : Normalize features before fitting (deprecated, use StandardScaler) - solver : Algorithm for optimization ('auto', 'svd', 'cholesky', 'lsqr', 'sparse_cg', 'sag', 'saga') When to Use : - \u2705 Linear relationship between features and target - \u2705 Need interpretable results - \u2705 Fast training and prediction required - \u2705 Baseline model for comparison Strengths : - Fast training and prediction - No hyperparameter tuning needed - Provides feature importance (coefficients) - Works well with linearly separable data - Memory efficient Weaknesses : - Assumes linear relationship - Sensitive to outliers - Requires feature scaling - Poor performance with non-linear patterns Preprocessing : - Scale features (StandardScaler, MinMaxScaler) - Handle outliers - Feature engineering for non-linear relationships Logistic Regression Purpose : Binary or multi-class classification using logistic function Mathematical Formula : Sigmoid: \u03c3(z) = 1 / (1 + e^(-z)) Probability: P(y=1|x) = \u03c3(\u03b8\u1d40x) Cost Function: J(\u03b8) = -1/m \u03a3[y\u207d\u2071\u207elog(h\u03b8(x\u207d\u2071\u207e)) + (1-y\u207d\u2071\u207e)log(1-h\u03b8(x\u207d\u2071\u207e))] Key Parameters : - C : Inverse of regularization strength (default: 1.0) - penalty : Regularization type ('l1', 'l2', 'elasticnet', 'none') - solver : Algorithm ('liblinear', 'newton-cg', 'lbfgs', 'sag', 'saga') - max_iter : Maximum iterations (default: 100) When to Use : - \u2705 Binary or multi-class classification - \u2705 Need probability estimates - \u2705 Linear decision boundary is appropriate - \u2705 Fast training required Strengths : - Outputs probability estimates - Less prone to overfitting than complex models - Fast training - Interpretable coefficients Weaknesses : - Assumes linear relationship between features and log-odds - Sensitive to outliers - Requires feature scaling - Can struggle with complex relationships Decision Trees Purpose : Classification or regression using tree-like model of decisions Key Concepts : Information Gain = Entropy(parent) - Weighted_Avg(Entropy(children)) Gini Impurity = 1 - \u03a3(p\u1d62)\u00b2 MSE (regression) = 1/n \u03a3(y\u1d62 - \u0177)\u00b2 Key Parameters : - criterion : Split quality measure ('gini', 'entropy', 'log_loss' for classification; 'squared_error', 'absolute_error' for regression) - max_depth : Maximum tree depth (default: None) - min_samples_split : Minimum samples to split node (default: 2) - min_samples_leaf : Minimum samples in leaf node (default: 1) - max_features : Number of features for best split (default: None) When to Use : - \u2705 Need interpretable model - \u2705 Non-linear relationships exist - \u2705 Mixed data types (numerical and categorical) - \u2705 Feature interactions are important Strengths : - Highly interpretable - Handles both numerical and categorical data - No need for feature scaling - Automatically handles feature interactions - Fast prediction Weaknesses : - Prone to overfitting - Unstable (small data changes \u2192 different trees) - Biased toward features with more levels - Cannot capture linear relationships efficiently Hyperparameter Tuning : # Prevent overfitting max_depth = [3, 5, 7, 10, None] min_samples_split = [2, 5, 10, 20] min_samples_leaf = [1, 2, 4, 8] Random Forest Purpose : Ensemble of decision trees for improved accuracy and reduced overfitting Key Concepts : Final Prediction = Average/Majority Vote of all trees Out-of-Bag Error: Error rate using samples not used in training each tree Feature Importance: Average decrease in impurity when feature is used for splits Key Parameters : - n_estimators : Number of trees (default: 100) - max_depth : Maximum depth of trees (default: None) - min_samples_split : Minimum samples to split (default: 2) - min_samples_leaf : Minimum samples in leaf (default: 1) - max_features : Features to consider for splits (default: 'sqrt') - bootstrap : Whether to bootstrap samples (default: True) When to Use : - \u2705 Need robust, accurate model - \u2705 Have mixed data types - \u2705 Want feature importance rankings - \u2705 Can tolerate longer training time Strengths : - Reduces overfitting compared to single trees - Provides feature importance - Handles missing values - Works well out-of-the-box - Robust to outliers Weaknesses : - Less interpretable than single tree - Can overfit with very noisy data - Biased toward categorical features with many categories - Memory intensive Hyperparameter Tuning : # Key parameters to tune n_estimators = [100, 200, 300, 500] max_depth = [3, 5, 7, 10, None] min_samples_split = [2, 5, 10] max_features = ['sqrt', 'log2', None] Gradient Boosting Purpose : Sequential ensemble method that builds models iteratively, each correcting errors of previous models Key Concepts : Sequential Learning: F_m(x) = F_(m-1)(x) + h_m(x) Gradient Descent: h_m = argmin \u03a3 L(y_i, F_(m-1)(x_i) + h(x_i)) Loss Function: Optimize differentiable loss functions Weak Learners: Typically shallow decision trees (stumps) Shrinkage: F_m(x) = F_(m-1)(x) + \u03bd * h_m(x) where \u03bd is learning rate Mathematical Framework : 1. Initialize: F_0(x) = argmin_\u03b3 \u03a3 L(y_i, \u03b3) 2. For m = 1 to M: a. Compute residuals: r_im = -\u2202L(y_i, F_(m-1)(x_i))/\u2202F_(m-1)(x_i) b. Fit weak learner: h_m(x) to predict residuals r_im c. Find optimal step size: \u03b3_m = argmin_\u03b3 \u03a3 L(y_i, F_(m-1)(x_i) + \u03b3h_m(x_i)) d. Update: F_m(x) = F_(m-1)(x) + \u03b3_m * h_m(x) 3. Output: F_M(x) Popular Algorithms : XGBoost (eXtreme Gradient Boosting) : - Strengths : High performance, handles missing values, built-in regularization, parallel processing - Best for : Structured/tabular data, competitions, high accuracy requirements - Key Parameters : - n_estimators : Number of boosting rounds (100-1000) - max_depth : Maximum tree depth (3-10) - learning_rate : Step size shrinkage (0.01-0.3) - subsample : Fraction of samples (0.8-1.0) - colsample_bytree : Fraction of features (0.8-1.0) - reg_alpha : L1 regularization (0-10) - reg_lambda : L2 regularization (1-10) # XGBoost Example import xgboost as xgb from sklearn.model_selection import GridSearchCV # Basic usage xgb_model = xgb.XGBClassifier( n_estimators=100, max_depth=6, learning_rate=0.1, random_state=42 ) xgb_model.fit(X_train, y_train) # Hyperparameter tuning param_grid = { 'n_estimators': [100, 200, 300], 'max_depth': [3, 5, 7], 'learning_rate': [0.01, 0.1, 0.2], 'subsample': [0.8, 0.9, 1.0] } LightGBM (Light Gradient Boosting Machine) : - Strengths : Fast training, low memory usage, high accuracy, handles categorical features - Best for : Large datasets, fast training requirements, limited memory - Key Parameters : - num_leaves : Maximum leaves in one tree (31-300) - learning_rate : Shrinkage rate (0.01-0.3) - feature_fraction : Fraction of features (0.8-1.0) - bagging_fraction : Fraction of data (0.8-1.0) - min_data_in_leaf : Minimum samples in leaf (20-100) - lambda_l1 , lambda_l2 : Regularization terms # LightGBM Example import lightgbm as lgb # Basic usage lgb_model = lgb.LGBMClassifier( num_leaves=31, learning_rate=0.1, n_estimators=100, random_state=42 ) lgb_model.fit(X_train, y_train) # Advanced configuration lgb_train = lgb.Dataset(X_train, y_train) params = { 'objective': 'binary', 'metric': 'binary_logloss', 'num_leaves': 31, 'learning_rate': 0.1, 'feature_fraction': 0.9 } model = lgb.train(params, lgb_train, num_boost_round=100) CatBoost (Categorical Boosting) : - Strengths : Handles categorical features automatically, robust to overfitting, good default parameters - Best for : Datasets with many categorical features, minimal preprocessing - Key Parameters : - iterations : Number of boosting iterations (100-1000) - learning_rate : Learning rate (0.01-0.3) - depth : Tree depth (4-10) - l2_leaf_reg : L2 regularization (1-10) - border_count : Number of splits for numerical features (32-255) # CatBoost Example from catboost import CatBoostClassifier # Basic usage (handles categorical features automatically) cat_model = CatBoostClassifier( iterations=100, learning_rate=0.1, depth=6, verbose=False ) cat_model.fit(X_train, y_train, cat_features=['category_col1', 'category_col2']) # With categorical feature indices cat_features = [0, 1, 5] # Column indices of categorical features cat_model.fit(X_train, y_train, cat_features=cat_features) AdaBoost (Adaptive Boosting) : - Strengths : Simple algorithm, good for binary classification, less prone to overfitting - Best for : Small datasets, when interpretability is important - Key Parameters : - n_estimators : Number of weak learners (50-500) - learning_rate : Weight applied to each classifier (0.1-2.0) - algorithm : SAMME or SAMME.R for multi-class # AdaBoost Example from sklearn.ensemble import AdaBoostClassifier from sklearn.tree import DecisionTreeClassifier # Note: The 'estimator' parameter was named 'base_estimator' in scikit-learn < 1.2 ada_model = AdaBoostClassifier( estimator=DecisionTreeClassifier(max_depth=1), n_estimators=100, learning_rate=1.0, random_state=42 ) ada_model.fit(X_train, y_train) When to Use Gradient Boosting : - \u2705 Tabular/structured data with mixed feature types - \u2705 High accuracy is priority over interpretability - \u2705 Medium to large datasets (1K+ samples) - \u2705 Complex non-linear relationships exist - \u2705 Have time for hyperparameter tuning - \u2705 Competition or benchmark scenarios Advantages : - High predictive accuracy - Handles mixed data types well - Built-in feature selection - Robust to outliers and missing values - No need for feature scaling - Provides feature importance - Can optimize various loss functions Disadvantages : - Prone to overfitting (especially with small datasets) - Computationally expensive - Many hyperparameters to tune - Sequential training (harder to parallelize base algorithm) - Less interpretable than single trees - Sensitive to noisy data Hyperparameter Tuning Strategy : # 1. Start with learning rate and number of estimators learning_rates = [0.01, 0.1, 0.2] n_estimators = [100, 300, 500] # 2. Tune tree-specific parameters max_depths = [3, 5, 7, 10] min_samples_splits = [2, 5, 10] # 3. Add regularization reg_alphas = [0, 0.1, 1, 10] # L1 reg_lambdas = [1, 5, 10] # L2 # 4. Fine-tune sampling parameters subsamples = [0.8, 0.9, 1.0] colsample_bytrees = [0.8, 0.9, 1.0] Common Loss Functions : - Regression : Squared error, absolute error, Huber, Quantile - Classification : Logistic loss, exponential loss, Hinge loss - Ranking : Pairwise ranking, LambdaRank, NDCG Best Practices : 1. Start simple : Begin with default parameters and small learning rate 2. Cross-validation : Use CV for reliable performance estimates 3. Early stopping : Monitor validation loss to prevent overfitting 4. Feature engineering : Create meaningful features before boosting 5. Regularization : Use L1/L2 regularization and sampling techniques 6. Ensemble stacking : Combine multiple boosting models 7. Monitor overfitting : Track training vs validation metrics Performance Comparison : | Algorithm | Training Speed | Memory Usage | Categorical Handling | Accuracy | Interpretability | |-----------|---------------|--------------|---------------------|----------|------------------| | XGBoost | \u26a1\u26a1 | \u26a1\u26a1 | \u26a1 | \u2b50\u2b50\u2b50 | \u2b50 | | LightGBM | \u26a1\u26a1\u26a1 | \u26a1\u26a1\u26a1 | \u26a1\u26a1 | \u2b50\u2b50\u2b50 | \u2b50 | | CatBoost | \u26a1\u26a1 | \u26a1\u26a1 | \u2b50\u2b50\u2b50 | \u2b50\u2b50\u2b50 | \u2b50 | | AdaBoost | \u26a1 | \u26a1\u26a1\u26a1 | \u26a1 | \u2b50\u2b50 | \u2b50\u2b50 | Support Vector Machine (SVM) Purpose : Classification or regression by finding optimal hyperplane Mathematical Formula : Objective: minimize 1/2||w||\u00b2 subject to y\u1d62(w\u1d40x\u1d62 + b) \u2265 1 Kernel Trick: K(x, x') maps input space to higher dimensional space RBF Kernel: K(x, x') = exp(-\u03b3||x - x'||\u00b2) Key Parameters : - C : Regularization parameter (default: 1.0) - kernel : Kernel type ('linear', 'poly', 'rbf', 'sigmoid') - gamma : Kernel coefficient for 'rbf', 'poly', 'sigmoid' ('scale', 'auto', or float) - degree : Degree for polynomial kernel (default: 3) When to Use : - \u2705 High-dimensional data - \u2705 Clear margin of separation - \u2705 Memory efficient solution needed - \u2705 Versatile (different kernels) Strengths : - Effective in high dimensions - Memory efficient - Versatile (different kernel functions) - Works well with clear separation margin Weaknesses : - Poor performance on large datasets - Sensitive to feature scaling - No probabilistic output - Choice of kernel and parameters is crucial Hyperparameter Tuning : # Grid search parameters C = [0.1, 1, 10, 100] gamma = ['scale', 'auto', 0.001, 0.01, 0.1, 1] kernel = ['linear', 'rbf', 'poly'] k-Nearest Neighbors (k-NN) Purpose : Classification or regression based on k closest training examples Mathematical Formula : Distance Metrics: - Euclidean: d(x,y) = \u221a\u03a3(x\u1d62 - y\u1d62)\u00b2 - Manhattan: d(x,y) = \u03a3|x\u1d62 - y\u1d62| - Minkowski: d(x,y) = (\u03a3|x\u1d62 - y\u1d62|\u1d56)^(1/p) Classification: Majority vote of k neighbors Regression: Average of k neighbors Key Parameters : - n_neighbors : Number of neighbors (default: 5) - weights : Weight function ('uniform', 'distance', or callable) - algorithm : Algorithm to compute neighbors ('auto', 'ball_tree', 'kd_tree', 'brute') - metric : Distance metric ('euclidean', 'manhattan', 'minkowski') - p : Power parameter for Minkowski metric (default: 2) When to Use : - \u2705 Simple, non-parametric approach needed - \u2705 Local patterns in data are important - \u2705 Irregular decision boundaries - \u2705 Small to medium datasets Strengths : - Simple to understand and implement - No assumptions about data distribution - Works well with small datasets - Naturally handles multi-class problems Weaknesses : - Computationally expensive for large datasets - Sensitive to irrelevant features (curse of dimensionality) - Sensitive to local structure of data - Memory intensive Hyperparameter Tuning : # Key parameters n_neighbors = [3, 5, 7, 9, 11, 15] weights = ['uniform', 'distance'] metric = ['euclidean', 'manhattan', 'minkowski'] Naive Bayes Purpose : Classification based on Bayes' theorem with independence assumption Mathematical Formula : Bayes' Theorem: P(A|B) = P(B|A) * P(A) / P(B) Naive Bayes: P(y|x\u2081,...,x\u2099) = P(y) * \u220fP(x\u1d62|y) / P(x\u2081,...,x\u2099) Variants: - Gaussian: P(x\u1d62|y) = 1/\u221a(2\u03c0\u03c3\u1d67\u00b2) * exp(-(x\u1d62-\u03bc\u1d67)\u00b2/2\u03c3\u1d67\u00b2) - Multinomial: P(x\u1d62|y) = (count(x\u1d62,y) + \u03b1) / (count(y) + \u03b1*n) - Bernoulli: P(x\u1d62|y) = P(x\u1d62=1|y)^x\u1d62 * (1-P(x\u1d62=1|y))^(1-x\u1d62) Types & Parameters : - GaussianNB : For continuous features - MultinomialNB : For discrete counts (alpha for smoothing) - BernoulliNB : For binary features (alpha for smoothing) When to Use : - \u2705 Text classification - \u2705 Small datasets - \u2705 Need fast, simple baseline - \u2705 Features are relatively independent Strengths : - Fast training and prediction - Works well with small datasets - Handles multi-class naturally - Good baseline for text classification - Not sensitive to irrelevant features Weaknesses : - Strong independence assumption - Can be outperformed by more sophisticated methods - Requires smoothing for zero probabilities - Poor estimator for probability Neural Networks Purpose : Complex pattern recognition using interconnected nodes Mathematical Formula : Forward Pass: a\u02b2\u207d\u02e1\u207a\u00b9\u207e = \u03c3(W\u02b2\u02e1a\u02e1 + b\u02b2\u02e1) Loss Function: L = 1/m \u03a3 loss(\u0177\u207d\u2071\u207e, y\u207d\u2071\u207e) Backpropagation: \u2202L/\u2202W = \u2202L/\u2202a * \u2202a/\u2202z * \u2202z/\u2202W Common Activation Functions: - Sigmoid: \u03c3(x) = 1/(1+e\u207b\u02e3) - ReLU: f(x) = max(0,x) - Tanh: tanh(x) = (e\u02e3-e\u207b\u02e3)/(e\u02e3+e\u207b\u02e3) Key Parameters : - hidden_layer_sizes : Tuple of hidden layer sizes (default: (100,)) - activation : Activation function ('identity', 'logistic', 'tanh', 'relu') - solver : Weight optimization solver ('lbfgs', 'sgd', 'adam') - alpha : L2 penalty parameter (default: 0.0001) - learning_rate : Learning rate schedule ('constant', 'invscaling', 'adaptive') - max_iter : Maximum iterations (default: 200) When to Use : - \u2705 Complex, non-linear relationships - \u2705 Large datasets available - \u2705 High-dimensional problems - \u2705 Can afford longer training time Strengths : - Can model complex non-linear relationships - Universal function approximators - Flexible architecture - Good performance with large datasets Weaknesses : - Requires large datasets - Prone to overfitting - Many hyperparameters to tune - Black box (low interpretability) - Computationally intensive Unsupervised Learning Algorithms k-Means Clustering Purpose : Partition data into k clusters based on feature similarity Mathematical Formula : Objective: minimize \u03a3\u1d62\u208c\u2081\u1d4f \u03a3\u2093\u2208C\u1d62 ||x - \u03bc\u1d62||\u00b2 Where \u03bc\u1d62 is the centroid of cluster C\u1d62 Algorithm: 1. Initialize k centroids randomly 2. Assign points to nearest centroid 3. Update centroids to cluster mean 4. Repeat until convergence Key Parameters : - n_clusters : Number of clusters (default: 8) - init : Initialization method ('k-means++', 'random') - n_init : Number of random initializations (default: 10) - max_iter : Maximum iterations (default: 300) - tol : Tolerance for convergence (default: 1e-4) When to Use : - \u2705 Know approximate number of clusters - \u2705 Clusters are spherical and similar sized - \u2705 Need fast clustering algorithm - \u2705 Continuous features Strengths : - Simple and fast - Works well with spherical clusters - Scales well to large datasets - Guaranteed convergence Weaknesses : - Must specify number of clusters - Assumes spherical clusters - Sensitive to initialization and outliers - Struggles with clusters of different sizes/densities Choosing k : # Elbow method: plot WCSS vs k # Silhouette analysis: measure cluster cohesion # Gap statistic: compare to random data Hierarchical Clustering Purpose : Create tree of clusters showing nested grouping of data Types : - Agglomerative : Bottom-up (merge clusters) - Divisive : Top-down (split clusters) Linkage Criteria : Single: min(distance(a,b)) where a\u2208A, b\u2208B Complete: max(distance(a,b)) where a\u2208A, b\u2208B Average: mean(distance(a,b)) where a\u2208A, b\u2208B Ward: minimizes within-cluster variance Key Parameters : - n_clusters : Number of clusters to find (default: 2) - linkage : Linkage criterion ('ward', 'complete', 'average', 'single') - affinity : Distance metric ('euclidean', 'manhattan', 'cosine') When to Use : - \u2705 Don't know number of clusters beforehand - \u2705 Want to see cluster hierarchy - \u2705 Small to medium datasets - \u2705 Need deterministic results Strengths : - No need to specify number of clusters initially - Deterministic results - Creates hierarchy of clusters - Works with any distance metric Weaknesses : - O(n\u00b3) time complexity - Sensitive to noise and outliers - Difficult to handle large datasets - Cannot undo previous steps DBSCAN (Density-Based Spatial Clustering) Purpose : Group together points that are closely packed, marking outliers Key Concepts : Core Point: Point with at least MinPts neighbors within \u03b5 distance Border Point: Not core but within \u03b5 distance of core point Noise Point: Neither core nor border point Algorithm: 1. For each point, find neighbors within \u03b5 2. If point has \u2265 MinPts neighbors, mark as core 3. Form clusters by connecting core points 4. Add border points to nearby clusters Key Parameters : - eps : Maximum distance between two samples to be neighbors - min_samples : Minimum number of samples in neighborhood for core point - metric : Distance metric ('euclidean', 'manhattan', 'cosine') When to Use : - \u2705 Clusters have varying shapes and sizes - \u2705 Data contains noise/outliers - \u2705 Don't know number of clusters - \u2705 Density-based clusters expected Strengths : - Finds arbitrarily shaped clusters - Automatically determines number of clusters - Robust to outliers - Identifies outliers explicitly Weaknesses : - Sensitive to hyperparameters (eps, min_samples) - Struggles with varying densities - Memory intensive for large datasets - Difficult to use with high-dimensional data Principal Component Analysis (PCA) Purpose : Reduce dimensionality while preserving maximum variance Mathematical Formula : Covariance Matrix: C = 1/(n-1) * X\u1d40X Eigendecomposition: C = P\u039bP\u1d40 Principal Components: PC = X * P Explained Variance Ratio: \u03bb\u1d62 / \u03a3\u03bb\u2c7c Key Parameters : - n_components : Number of components to keep (int, float, 'mle', or None) - whiten : Whether to whiten the components (default: False) - svd_solver : SVD solver ('auto', 'full', 'arpack', 'randomized') When to Use : - \u2705 High-dimensional data - \u2705 Need dimensionality reduction - \u2705 Want to remove correlated features - \u2705 Visualization of high-dim data Strengths : - Reduces overfitting - Removes correlated features - Fast and simple - Interpretable components Weaknesses : - Linear transformation only - Components may not be interpretable - Sensitive to feature scaling - May lose important information Choosing Components : # Cumulative explained variance \u2265 95% # Scree plot: elbow in eigenvalue plot # Cross-validation performance t-SNE (t-Distributed Stochastic Neighbor Embedding) Purpose : Nonlinear dimensionality reduction for visualization Key Concepts : High-dimensional similarity: p\u2c7c|\u1d62 = exp(-||x\u1d62-x\u2c7c||\u00b2/2\u03c3\u1d62\u00b2) / \u03a3\u2096 exp(-||x\u1d62-x\u2096||\u00b2/2\u03c3\u1d62\u00b2) Low-dimensional similarity: q\u1d62\u2c7c = (1+||y\u1d62-y\u2c7c||\u00b2)\u207b\u00b9 / \u03a3\u2096\u2097(1+||y\u2096-y\u2097||\u00b2)\u207b\u00b9 Cost function: KL(P||Q) = \u03a3\u1d62\u2c7c p\u1d62\u2c7c log(p\u1d62\u2c7c/q\u1d62\u2c7c) Key Parameters : - n_components : Dimension of embedded space (default: 2) - perplexity : Number of nearest neighbors (default: 30) - learning_rate : Learning rate (default: 200) - n_iter : Maximum iterations (default: 1000) When to Use : - \u2705 Visualization of high-dimensional data - \u2705 Exploring cluster structure - \u2705 Non-linear relationships exist - \u2705 Small to medium datasets Strengths : - Excellent for visualization - Preserves local structure - Reveals cluster structure - Non-linear dimensionality reduction Weaknesses : - Computationally expensive - Non-deterministic results - Hyperparameter sensitive - Not suitable for new data projection Algorithm Selection Framework Data Characteristics Decision Tree Sample Size? \u251c\u2500\u2500 Small (< 1K) \u2502 \u251c\u2500\u2500 Classification \u2192 Naive Bayes, k-NN, Decision Tree \u2502 \u2514\u2500\u2500 Regression \u2192 Linear Regression, k-NN \u251c\u2500\u2500 Medium (1K-100K) \u2502 \u251c\u2500\u2500 Linear relationship \u2192 Linear/Logistic Regression \u2502 \u251c\u2500\u2500 Non-linear \u2192 Random Forest, SVM \u2502 \u2514\u2500\u2500 Complex patterns \u2192 Neural Networks \u2514\u2500\u2500 Large (> 100K) \u251c\u2500\u2500 Speed priority \u2192 Linear models, SGD \u251c\u2500\u2500 Accuracy priority \u2192 Random Forest, Gradient Boosting \u2514\u2500\u2500 Very complex \u2192 Neural Networks Interpretability needed? \u251c\u2500\u2500 Yes \u2192 Linear Regression, Decision Trees, Naive Bayes \u2514\u2500\u2500 No \u2192 Random Forest, SVM, Neural Networks Training Speed priority? \u251c\u2500\u2500 Yes \u2192 Naive Bayes, Linear Regression, k-NN \u2514\u2500\u2500 No \u2192 SVM, Random Forest, Neural Networks Performance Characteristics Algorithm Training Speed Prediction Speed Memory Usage Interpretability Linear Regression \u26a1\u26a1\u26a1 \u26a1\u26a1\u26a1 \u26a1\u26a1\u26a1 \u2b50\u2b50\u2b50 Logistic Regression \u26a1\u26a1\u26a1 \u26a1\u26a1\u26a1 \u26a1\u26a1\u26a1 \u2b50\u2b50\u2b50 Decision Tree \u26a1\u26a1 \u26a1\u26a1\u26a1 \u26a1\u26a1 \u2b50\u2b50\u2b50 Random Forest \u26a1 \u26a1\u26a1 \u26a1 \u2b50\u2b50 XGBoost \u26a1 \u26a1\u26a1 \u26a1\u26a1 \u2b50 LightGBM \u26a1\u26a1 \u26a1\u26a1\u26a1 \u26a1\u26a1\u26a1 \u2b50 CatBoost \u26a1 \u26a1\u26a1 \u26a1\u26a1 \u2b50 AdaBoost \u26a1 \u26a1\u26a1 \u26a1\u26a1 \u2b50\u2b50 SVM \u26a1 \u26a1\u26a1 \u26a1\u26a1 \u2b50 k-NN \u26a1\u26a1\u26a1 \u26a1 \u26a1 \u2b50\u2b50 Naive Bayes \u26a1\u26a1\u26a1 \u26a1\u26a1\u26a1 \u26a1\u26a1\u26a1 \u2b50\u2b50 Neural Networks \u26a1 \u26a1\u26a1 \u26a1 \u2b50 Evaluation Metrics Classification Metrics Accuracy : (TP + TN) / (TP + TN + FP + FN) - Use when: Balanced classes, all errors equally important Precision : TP / (TP + FP) - Use when: False positives are costly (spam detection) Recall (Sensitivity) : TP / (TP + FN) - Use when: False negatives are costly (disease detection) F1-Score : 2 * (Precision * Recall) / (Precision + Recall) - Use when: Balance between precision and recall needed ROC-AUC : Area under Receiver Operating Characteristic curve - Use when: Comparing models across different thresholds Regression Metrics Mean Absolute Error (MAE) : 1/n \u03a3|y\u1d62 - \u0177\u1d62| - Robust to outliers, interpretable in original units Mean Squared Error (MSE) : 1/n \u03a3(y\u1d62 - \u0177\u1d62)\u00b2 - Penalizes large errors more, sensitive to outliers Root Mean Squared Error (RMSE) : \u221a(1/n \u03a3(y\u1d62 - \u0177\u1d62)\u00b2) - Same units as target, interpretable R\u00b2 Score : 1 - SS_res/SS_tot - Proportion of variance explained, 0-1 scale Clustering Metrics Silhouette Score : Measures cluster cohesion and separation - Range: [-1, 1], higher is better Adjusted Rand Index : Measures similarity to true clustering - Range: [-1, 1], 1 = perfect match Inertia : Within-cluster sum of squares (k-means objective) - Lower is better, use with elbow method Common Preprocessing Steps Feature Scaling # Standardization (mean=0, std=1) StandardScaler() # For normal distribution # Normalization (min=0, max=1) MinMaxScaler() # For uniform distribution # Robust scaling (median=0, IQR=1) RobustScaler() # For data with outliers Feature Engineering Polynomial Features : Create interaction terms One-Hot Encoding : Convert categorical to binary Target Encoding : Use target statistics for categories Binning : Convert continuous to categorical Date Features : Extract year, month, day, weekday Missing Data Drop : Remove rows/columns with missing values Mean/Median/Mode : Fill with central tendency Forward/Backward Fill : Use adjacent values Interpolation : Estimate based on trends Model-based : Predict missing values Overfitting vs Underfitting Overfitting (High Variance) Symptoms : - High training accuracy, low validation accuracy - Complex model performs worse on new data Solutions : - More training data - Regularization (L1/L2) - Feature selection - Cross-validation - Early stopping - Ensemble methods Underfitting (High Bias) Symptoms : - Low training and validation accuracy - Model too simple for the problem Solutions : - More complex model - Add features - Reduce regularization - Increase model capacity - Feature engineering Model Selection Best Practices Start Simple : Begin with baseline models (linear, naive bayes) Cross-Validation : Use k-fold CV for reliable performance estimates Feature Engineering : Often more important than algorithm choice Ensemble Methods : Combine multiple models for better performance Hyperparameter Tuning : Use grid search or randomized search Monitor Overfitting : Track train vs validation performance Business Metrics : Optimize for what matters to the business Interpretability Trade-off : Balance accuracy with explainability Quick Reference Table Problem Type First Try If More Accuracy Needed If Interpretability Needed Binary Classification Logistic Regression XGBoost, LightGBM, CatBoost Decision Tree, Naive Bayes Multi-class Classification Logistic Regression XGBoost, LightGBM, CatBoost Decision Tree Regression Linear Regression XGBoost, LightGBM, CatBoost Linear Regression Clustering k-Means DBSCAN, Hierarchical k-Means with visualization Dimensionality Reduction PCA t-SNE, UMAP PCA Anomaly Detection Isolation Forest One-Class SVM Statistical methods This cheat sheet provides a foundation for understanding and applying machine learning algorithms. Always consider your specific problem context, data characteristics, and business requirements when selecting algorithms.","title":"Machine Learning Algorithms"},{"location":"machine-learning-algorithms/#machine-learning-algorithms","text":"A comprehensive guide to fundamental machine learning algorithms, their applications, strengths, weaknesses, and when to use each approach.","title":"Machine Learning Algorithms"},{"location":"machine-learning-algorithms/#quick-algorithm-selection-guide","text":"","title":"Quick Algorithm Selection Guide"},{"location":"machine-learning-algorithms/#by-problem-type","text":"Regression : Linear Regression, Random Forest, SVM, Neural Networks Classification : Logistic Regression, Decision Trees, Random Forest, SVM, k-NN, Naive Bayes Clustering : k-Means, Hierarchical Clustering, DBSCAN Dimensionality Reduction : PCA, t-SNE, UMAP Anomaly Detection : Isolation Forest, One-Class SVM, Local Outlier Factor","title":"By Problem Type"},{"location":"machine-learning-algorithms/#by-data-size","text":"Small datasets (< 1K samples) : k-NN, Naive Bayes, Decision Trees, AdaBoost Medium datasets (1K-100K) : SVM, Random Forest, XGBoost, LightGBM, CatBoost Large datasets (> 100K) : Linear models, Neural Networks, LightGBM, SGD variants","title":"By Data Size"},{"location":"machine-learning-algorithms/#by-interpretability","text":"High : Linear Regression, Decision Trees, Naive Bayes Medium : Random Forest, k-NN, AdaBoost Low : SVM (with RBF kernel), Neural Networks, XGBoost, LightGBM, CatBoost","title":"By Interpretability"},{"location":"machine-learning-algorithms/#supervised-learning-algorithms","text":"","title":"Supervised Learning Algorithms"},{"location":"machine-learning-algorithms/#linear-regression","text":"Purpose : Predict continuous target variable using linear relationship Mathematical Formula : y = \u03b2\u2080 + \u03b2\u2081x\u2081 + \u03b2\u2082x\u2082 + ... + \u03b2\u2099x\u2099 + \u03b5 Cost Function: J(\u03b8) = 1/(2m) \u03a3(h\u03b8(x\u207d\u2071\u207e) - y\u207d\u2071\u207e)\u00b2 Key Parameters : - fit_intercept : Whether to calculate intercept (default: True) - normalize : Normalize features before fitting (deprecated, use StandardScaler) - solver : Algorithm for optimization ('auto', 'svd', 'cholesky', 'lsqr', 'sparse_cg', 'sag', 'saga') When to Use : - \u2705 Linear relationship between features and target - \u2705 Need interpretable results - \u2705 Fast training and prediction required - \u2705 Baseline model for comparison Strengths : - Fast training and prediction - No hyperparameter tuning needed - Provides feature importance (coefficients) - Works well with linearly separable data - Memory efficient Weaknesses : - Assumes linear relationship - Sensitive to outliers - Requires feature scaling - Poor performance with non-linear patterns Preprocessing : - Scale features (StandardScaler, MinMaxScaler) - Handle outliers - Feature engineering for non-linear relationships","title":"Linear Regression"},{"location":"machine-learning-algorithms/#logistic-regression","text":"Purpose : Binary or multi-class classification using logistic function Mathematical Formula : Sigmoid: \u03c3(z) = 1 / (1 + e^(-z)) Probability: P(y=1|x) = \u03c3(\u03b8\u1d40x) Cost Function: J(\u03b8) = -1/m \u03a3[y\u207d\u2071\u207elog(h\u03b8(x\u207d\u2071\u207e)) + (1-y\u207d\u2071\u207e)log(1-h\u03b8(x\u207d\u2071\u207e))] Key Parameters : - C : Inverse of regularization strength (default: 1.0) - penalty : Regularization type ('l1', 'l2', 'elasticnet', 'none') - solver : Algorithm ('liblinear', 'newton-cg', 'lbfgs', 'sag', 'saga') - max_iter : Maximum iterations (default: 100) When to Use : - \u2705 Binary or multi-class classification - \u2705 Need probability estimates - \u2705 Linear decision boundary is appropriate - \u2705 Fast training required Strengths : - Outputs probability estimates - Less prone to overfitting than complex models - Fast training - Interpretable coefficients Weaknesses : - Assumes linear relationship between features and log-odds - Sensitive to outliers - Requires feature scaling - Can struggle with complex relationships","title":"Logistic Regression"},{"location":"machine-learning-algorithms/#decision-trees","text":"Purpose : Classification or regression using tree-like model of decisions Key Concepts : Information Gain = Entropy(parent) - Weighted_Avg(Entropy(children)) Gini Impurity = 1 - \u03a3(p\u1d62)\u00b2 MSE (regression) = 1/n \u03a3(y\u1d62 - \u0177)\u00b2 Key Parameters : - criterion : Split quality measure ('gini', 'entropy', 'log_loss' for classification; 'squared_error', 'absolute_error' for regression) - max_depth : Maximum tree depth (default: None) - min_samples_split : Minimum samples to split node (default: 2) - min_samples_leaf : Minimum samples in leaf node (default: 1) - max_features : Number of features for best split (default: None) When to Use : - \u2705 Need interpretable model - \u2705 Non-linear relationships exist - \u2705 Mixed data types (numerical and categorical) - \u2705 Feature interactions are important Strengths : - Highly interpretable - Handles both numerical and categorical data - No need for feature scaling - Automatically handles feature interactions - Fast prediction Weaknesses : - Prone to overfitting - Unstable (small data changes \u2192 different trees) - Biased toward features with more levels - Cannot capture linear relationships efficiently Hyperparameter Tuning : # Prevent overfitting max_depth = [3, 5, 7, 10, None] min_samples_split = [2, 5, 10, 20] min_samples_leaf = [1, 2, 4, 8]","title":"Decision Trees"},{"location":"machine-learning-algorithms/#random-forest","text":"Purpose : Ensemble of decision trees for improved accuracy and reduced overfitting Key Concepts : Final Prediction = Average/Majority Vote of all trees Out-of-Bag Error: Error rate using samples not used in training each tree Feature Importance: Average decrease in impurity when feature is used for splits Key Parameters : - n_estimators : Number of trees (default: 100) - max_depth : Maximum depth of trees (default: None) - min_samples_split : Minimum samples to split (default: 2) - min_samples_leaf : Minimum samples in leaf (default: 1) - max_features : Features to consider for splits (default: 'sqrt') - bootstrap : Whether to bootstrap samples (default: True) When to Use : - \u2705 Need robust, accurate model - \u2705 Have mixed data types - \u2705 Want feature importance rankings - \u2705 Can tolerate longer training time Strengths : - Reduces overfitting compared to single trees - Provides feature importance - Handles missing values - Works well out-of-the-box - Robust to outliers Weaknesses : - Less interpretable than single tree - Can overfit with very noisy data - Biased toward categorical features with many categories - Memory intensive Hyperparameter Tuning : # Key parameters to tune n_estimators = [100, 200, 300, 500] max_depth = [3, 5, 7, 10, None] min_samples_split = [2, 5, 10] max_features = ['sqrt', 'log2', None]","title":"Random Forest"},{"location":"machine-learning-algorithms/#gradient-boosting","text":"Purpose : Sequential ensemble method that builds models iteratively, each correcting errors of previous models Key Concepts : Sequential Learning: F_m(x) = F_(m-1)(x) + h_m(x) Gradient Descent: h_m = argmin \u03a3 L(y_i, F_(m-1)(x_i) + h(x_i)) Loss Function: Optimize differentiable loss functions Weak Learners: Typically shallow decision trees (stumps) Shrinkage: F_m(x) = F_(m-1)(x) + \u03bd * h_m(x) where \u03bd is learning rate Mathematical Framework : 1. Initialize: F_0(x) = argmin_\u03b3 \u03a3 L(y_i, \u03b3) 2. For m = 1 to M: a. Compute residuals: r_im = -\u2202L(y_i, F_(m-1)(x_i))/\u2202F_(m-1)(x_i) b. Fit weak learner: h_m(x) to predict residuals r_im c. Find optimal step size: \u03b3_m = argmin_\u03b3 \u03a3 L(y_i, F_(m-1)(x_i) + \u03b3h_m(x_i)) d. Update: F_m(x) = F_(m-1)(x) + \u03b3_m * h_m(x) 3. Output: F_M(x) Popular Algorithms : XGBoost (eXtreme Gradient Boosting) : - Strengths : High performance, handles missing values, built-in regularization, parallel processing - Best for : Structured/tabular data, competitions, high accuracy requirements - Key Parameters : - n_estimators : Number of boosting rounds (100-1000) - max_depth : Maximum tree depth (3-10) - learning_rate : Step size shrinkage (0.01-0.3) - subsample : Fraction of samples (0.8-1.0) - colsample_bytree : Fraction of features (0.8-1.0) - reg_alpha : L1 regularization (0-10) - reg_lambda : L2 regularization (1-10) # XGBoost Example import xgboost as xgb from sklearn.model_selection import GridSearchCV # Basic usage xgb_model = xgb.XGBClassifier( n_estimators=100, max_depth=6, learning_rate=0.1, random_state=42 ) xgb_model.fit(X_train, y_train) # Hyperparameter tuning param_grid = { 'n_estimators': [100, 200, 300], 'max_depth': [3, 5, 7], 'learning_rate': [0.01, 0.1, 0.2], 'subsample': [0.8, 0.9, 1.0] } LightGBM (Light Gradient Boosting Machine) : - Strengths : Fast training, low memory usage, high accuracy, handles categorical features - Best for : Large datasets, fast training requirements, limited memory - Key Parameters : - num_leaves : Maximum leaves in one tree (31-300) - learning_rate : Shrinkage rate (0.01-0.3) - feature_fraction : Fraction of features (0.8-1.0) - bagging_fraction : Fraction of data (0.8-1.0) - min_data_in_leaf : Minimum samples in leaf (20-100) - lambda_l1 , lambda_l2 : Regularization terms # LightGBM Example import lightgbm as lgb # Basic usage lgb_model = lgb.LGBMClassifier( num_leaves=31, learning_rate=0.1, n_estimators=100, random_state=42 ) lgb_model.fit(X_train, y_train) # Advanced configuration lgb_train = lgb.Dataset(X_train, y_train) params = { 'objective': 'binary', 'metric': 'binary_logloss', 'num_leaves': 31, 'learning_rate': 0.1, 'feature_fraction': 0.9 } model = lgb.train(params, lgb_train, num_boost_round=100) CatBoost (Categorical Boosting) : - Strengths : Handles categorical features automatically, robust to overfitting, good default parameters - Best for : Datasets with many categorical features, minimal preprocessing - Key Parameters : - iterations : Number of boosting iterations (100-1000) - learning_rate : Learning rate (0.01-0.3) - depth : Tree depth (4-10) - l2_leaf_reg : L2 regularization (1-10) - border_count : Number of splits for numerical features (32-255) # CatBoost Example from catboost import CatBoostClassifier # Basic usage (handles categorical features automatically) cat_model = CatBoostClassifier( iterations=100, learning_rate=0.1, depth=6, verbose=False ) cat_model.fit(X_train, y_train, cat_features=['category_col1', 'category_col2']) # With categorical feature indices cat_features = [0, 1, 5] # Column indices of categorical features cat_model.fit(X_train, y_train, cat_features=cat_features) AdaBoost (Adaptive Boosting) : - Strengths : Simple algorithm, good for binary classification, less prone to overfitting - Best for : Small datasets, when interpretability is important - Key Parameters : - n_estimators : Number of weak learners (50-500) - learning_rate : Weight applied to each classifier (0.1-2.0) - algorithm : SAMME or SAMME.R for multi-class # AdaBoost Example from sklearn.ensemble import AdaBoostClassifier from sklearn.tree import DecisionTreeClassifier # Note: The 'estimator' parameter was named 'base_estimator' in scikit-learn < 1.2 ada_model = AdaBoostClassifier( estimator=DecisionTreeClassifier(max_depth=1), n_estimators=100, learning_rate=1.0, random_state=42 ) ada_model.fit(X_train, y_train) When to Use Gradient Boosting : - \u2705 Tabular/structured data with mixed feature types - \u2705 High accuracy is priority over interpretability - \u2705 Medium to large datasets (1K+ samples) - \u2705 Complex non-linear relationships exist - \u2705 Have time for hyperparameter tuning - \u2705 Competition or benchmark scenarios Advantages : - High predictive accuracy - Handles mixed data types well - Built-in feature selection - Robust to outliers and missing values - No need for feature scaling - Provides feature importance - Can optimize various loss functions Disadvantages : - Prone to overfitting (especially with small datasets) - Computationally expensive - Many hyperparameters to tune - Sequential training (harder to parallelize base algorithm) - Less interpretable than single trees - Sensitive to noisy data Hyperparameter Tuning Strategy : # 1. Start with learning rate and number of estimators learning_rates = [0.01, 0.1, 0.2] n_estimators = [100, 300, 500] # 2. Tune tree-specific parameters max_depths = [3, 5, 7, 10] min_samples_splits = [2, 5, 10] # 3. Add regularization reg_alphas = [0, 0.1, 1, 10] # L1 reg_lambdas = [1, 5, 10] # L2 # 4. Fine-tune sampling parameters subsamples = [0.8, 0.9, 1.0] colsample_bytrees = [0.8, 0.9, 1.0] Common Loss Functions : - Regression : Squared error, absolute error, Huber, Quantile - Classification : Logistic loss, exponential loss, Hinge loss - Ranking : Pairwise ranking, LambdaRank, NDCG Best Practices : 1. Start simple : Begin with default parameters and small learning rate 2. Cross-validation : Use CV for reliable performance estimates 3. Early stopping : Monitor validation loss to prevent overfitting 4. Feature engineering : Create meaningful features before boosting 5. Regularization : Use L1/L2 regularization and sampling techniques 6. Ensemble stacking : Combine multiple boosting models 7. Monitor overfitting : Track training vs validation metrics Performance Comparison : | Algorithm | Training Speed | Memory Usage | Categorical Handling | Accuracy | Interpretability | |-----------|---------------|--------------|---------------------|----------|------------------| | XGBoost | \u26a1\u26a1 | \u26a1\u26a1 | \u26a1 | \u2b50\u2b50\u2b50 | \u2b50 | | LightGBM | \u26a1\u26a1\u26a1 | \u26a1\u26a1\u26a1 | \u26a1\u26a1 | \u2b50\u2b50\u2b50 | \u2b50 | | CatBoost | \u26a1\u26a1 | \u26a1\u26a1 | \u2b50\u2b50\u2b50 | \u2b50\u2b50\u2b50 | \u2b50 | | AdaBoost | \u26a1 | \u26a1\u26a1\u26a1 | \u26a1 | \u2b50\u2b50 | \u2b50\u2b50 |","title":"Gradient Boosting"},{"location":"machine-learning-algorithms/#support-vector-machine-svm","text":"Purpose : Classification or regression by finding optimal hyperplane Mathematical Formula : Objective: minimize 1/2||w||\u00b2 subject to y\u1d62(w\u1d40x\u1d62 + b) \u2265 1 Kernel Trick: K(x, x') maps input space to higher dimensional space RBF Kernel: K(x, x') = exp(-\u03b3||x - x'||\u00b2) Key Parameters : - C : Regularization parameter (default: 1.0) - kernel : Kernel type ('linear', 'poly', 'rbf', 'sigmoid') - gamma : Kernel coefficient for 'rbf', 'poly', 'sigmoid' ('scale', 'auto', or float) - degree : Degree for polynomial kernel (default: 3) When to Use : - \u2705 High-dimensional data - \u2705 Clear margin of separation - \u2705 Memory efficient solution needed - \u2705 Versatile (different kernels) Strengths : - Effective in high dimensions - Memory efficient - Versatile (different kernel functions) - Works well with clear separation margin Weaknesses : - Poor performance on large datasets - Sensitive to feature scaling - No probabilistic output - Choice of kernel and parameters is crucial Hyperparameter Tuning : # Grid search parameters C = [0.1, 1, 10, 100] gamma = ['scale', 'auto', 0.001, 0.01, 0.1, 1] kernel = ['linear', 'rbf', 'poly']","title":"Support Vector Machine (SVM)"},{"location":"machine-learning-algorithms/#k-nearest-neighbors-k-nn","text":"Purpose : Classification or regression based on k closest training examples Mathematical Formula : Distance Metrics: - Euclidean: d(x,y) = \u221a\u03a3(x\u1d62 - y\u1d62)\u00b2 - Manhattan: d(x,y) = \u03a3|x\u1d62 - y\u1d62| - Minkowski: d(x,y) = (\u03a3|x\u1d62 - y\u1d62|\u1d56)^(1/p) Classification: Majority vote of k neighbors Regression: Average of k neighbors Key Parameters : - n_neighbors : Number of neighbors (default: 5) - weights : Weight function ('uniform', 'distance', or callable) - algorithm : Algorithm to compute neighbors ('auto', 'ball_tree', 'kd_tree', 'brute') - metric : Distance metric ('euclidean', 'manhattan', 'minkowski') - p : Power parameter for Minkowski metric (default: 2) When to Use : - \u2705 Simple, non-parametric approach needed - \u2705 Local patterns in data are important - \u2705 Irregular decision boundaries - \u2705 Small to medium datasets Strengths : - Simple to understand and implement - No assumptions about data distribution - Works well with small datasets - Naturally handles multi-class problems Weaknesses : - Computationally expensive for large datasets - Sensitive to irrelevant features (curse of dimensionality) - Sensitive to local structure of data - Memory intensive Hyperparameter Tuning : # Key parameters n_neighbors = [3, 5, 7, 9, 11, 15] weights = ['uniform', 'distance'] metric = ['euclidean', 'manhattan', 'minkowski']","title":"k-Nearest Neighbors (k-NN)"},{"location":"machine-learning-algorithms/#naive-bayes","text":"Purpose : Classification based on Bayes' theorem with independence assumption Mathematical Formula : Bayes' Theorem: P(A|B) = P(B|A) * P(A) / P(B) Naive Bayes: P(y|x\u2081,...,x\u2099) = P(y) * \u220fP(x\u1d62|y) / P(x\u2081,...,x\u2099) Variants: - Gaussian: P(x\u1d62|y) = 1/\u221a(2\u03c0\u03c3\u1d67\u00b2) * exp(-(x\u1d62-\u03bc\u1d67)\u00b2/2\u03c3\u1d67\u00b2) - Multinomial: P(x\u1d62|y) = (count(x\u1d62,y) + \u03b1) / (count(y) + \u03b1*n) - Bernoulli: P(x\u1d62|y) = P(x\u1d62=1|y)^x\u1d62 * (1-P(x\u1d62=1|y))^(1-x\u1d62) Types & Parameters : - GaussianNB : For continuous features - MultinomialNB : For discrete counts (alpha for smoothing) - BernoulliNB : For binary features (alpha for smoothing) When to Use : - \u2705 Text classification - \u2705 Small datasets - \u2705 Need fast, simple baseline - \u2705 Features are relatively independent Strengths : - Fast training and prediction - Works well with small datasets - Handles multi-class naturally - Good baseline for text classification - Not sensitive to irrelevant features Weaknesses : - Strong independence assumption - Can be outperformed by more sophisticated methods - Requires smoothing for zero probabilities - Poor estimator for probability","title":"Naive Bayes"},{"location":"machine-learning-algorithms/#neural-networks","text":"Purpose : Complex pattern recognition using interconnected nodes Mathematical Formula : Forward Pass: a\u02b2\u207d\u02e1\u207a\u00b9\u207e = \u03c3(W\u02b2\u02e1a\u02e1 + b\u02b2\u02e1) Loss Function: L = 1/m \u03a3 loss(\u0177\u207d\u2071\u207e, y\u207d\u2071\u207e) Backpropagation: \u2202L/\u2202W = \u2202L/\u2202a * \u2202a/\u2202z * \u2202z/\u2202W Common Activation Functions: - Sigmoid: \u03c3(x) = 1/(1+e\u207b\u02e3) - ReLU: f(x) = max(0,x) - Tanh: tanh(x) = (e\u02e3-e\u207b\u02e3)/(e\u02e3+e\u207b\u02e3) Key Parameters : - hidden_layer_sizes : Tuple of hidden layer sizes (default: (100,)) - activation : Activation function ('identity', 'logistic', 'tanh', 'relu') - solver : Weight optimization solver ('lbfgs', 'sgd', 'adam') - alpha : L2 penalty parameter (default: 0.0001) - learning_rate : Learning rate schedule ('constant', 'invscaling', 'adaptive') - max_iter : Maximum iterations (default: 200) When to Use : - \u2705 Complex, non-linear relationships - \u2705 Large datasets available - \u2705 High-dimensional problems - \u2705 Can afford longer training time Strengths : - Can model complex non-linear relationships - Universal function approximators - Flexible architecture - Good performance with large datasets Weaknesses : - Requires large datasets - Prone to overfitting - Many hyperparameters to tune - Black box (low interpretability) - Computationally intensive","title":"Neural Networks"},{"location":"machine-learning-algorithms/#unsupervised-learning-algorithms","text":"","title":"Unsupervised Learning Algorithms"},{"location":"machine-learning-algorithms/#k-means-clustering","text":"Purpose : Partition data into k clusters based on feature similarity Mathematical Formula : Objective: minimize \u03a3\u1d62\u208c\u2081\u1d4f \u03a3\u2093\u2208C\u1d62 ||x - \u03bc\u1d62||\u00b2 Where \u03bc\u1d62 is the centroid of cluster C\u1d62 Algorithm: 1. Initialize k centroids randomly 2. Assign points to nearest centroid 3. Update centroids to cluster mean 4. Repeat until convergence Key Parameters : - n_clusters : Number of clusters (default: 8) - init : Initialization method ('k-means++', 'random') - n_init : Number of random initializations (default: 10) - max_iter : Maximum iterations (default: 300) - tol : Tolerance for convergence (default: 1e-4) When to Use : - \u2705 Know approximate number of clusters - \u2705 Clusters are spherical and similar sized - \u2705 Need fast clustering algorithm - \u2705 Continuous features Strengths : - Simple and fast - Works well with spherical clusters - Scales well to large datasets - Guaranteed convergence Weaknesses : - Must specify number of clusters - Assumes spherical clusters - Sensitive to initialization and outliers - Struggles with clusters of different sizes/densities Choosing k : # Elbow method: plot WCSS vs k # Silhouette analysis: measure cluster cohesion # Gap statistic: compare to random data","title":"k-Means Clustering"},{"location":"machine-learning-algorithms/#hierarchical-clustering","text":"Purpose : Create tree of clusters showing nested grouping of data Types : - Agglomerative : Bottom-up (merge clusters) - Divisive : Top-down (split clusters) Linkage Criteria : Single: min(distance(a,b)) where a\u2208A, b\u2208B Complete: max(distance(a,b)) where a\u2208A, b\u2208B Average: mean(distance(a,b)) where a\u2208A, b\u2208B Ward: minimizes within-cluster variance Key Parameters : - n_clusters : Number of clusters to find (default: 2) - linkage : Linkage criterion ('ward', 'complete', 'average', 'single') - affinity : Distance metric ('euclidean', 'manhattan', 'cosine') When to Use : - \u2705 Don't know number of clusters beforehand - \u2705 Want to see cluster hierarchy - \u2705 Small to medium datasets - \u2705 Need deterministic results Strengths : - No need to specify number of clusters initially - Deterministic results - Creates hierarchy of clusters - Works with any distance metric Weaknesses : - O(n\u00b3) time complexity - Sensitive to noise and outliers - Difficult to handle large datasets - Cannot undo previous steps","title":"Hierarchical Clustering"},{"location":"machine-learning-algorithms/#dbscan-density-based-spatial-clustering","text":"Purpose : Group together points that are closely packed, marking outliers Key Concepts : Core Point: Point with at least MinPts neighbors within \u03b5 distance Border Point: Not core but within \u03b5 distance of core point Noise Point: Neither core nor border point Algorithm: 1. For each point, find neighbors within \u03b5 2. If point has \u2265 MinPts neighbors, mark as core 3. Form clusters by connecting core points 4. Add border points to nearby clusters Key Parameters : - eps : Maximum distance between two samples to be neighbors - min_samples : Minimum number of samples in neighborhood for core point - metric : Distance metric ('euclidean', 'manhattan', 'cosine') When to Use : - \u2705 Clusters have varying shapes and sizes - \u2705 Data contains noise/outliers - \u2705 Don't know number of clusters - \u2705 Density-based clusters expected Strengths : - Finds arbitrarily shaped clusters - Automatically determines number of clusters - Robust to outliers - Identifies outliers explicitly Weaknesses : - Sensitive to hyperparameters (eps, min_samples) - Struggles with varying densities - Memory intensive for large datasets - Difficult to use with high-dimensional data","title":"DBSCAN (Density-Based Spatial Clustering)"},{"location":"machine-learning-algorithms/#principal-component-analysis-pca","text":"Purpose : Reduce dimensionality while preserving maximum variance Mathematical Formula : Covariance Matrix: C = 1/(n-1) * X\u1d40X Eigendecomposition: C = P\u039bP\u1d40 Principal Components: PC = X * P Explained Variance Ratio: \u03bb\u1d62 / \u03a3\u03bb\u2c7c Key Parameters : - n_components : Number of components to keep (int, float, 'mle', or None) - whiten : Whether to whiten the components (default: False) - svd_solver : SVD solver ('auto', 'full', 'arpack', 'randomized') When to Use : - \u2705 High-dimensional data - \u2705 Need dimensionality reduction - \u2705 Want to remove correlated features - \u2705 Visualization of high-dim data Strengths : - Reduces overfitting - Removes correlated features - Fast and simple - Interpretable components Weaknesses : - Linear transformation only - Components may not be interpretable - Sensitive to feature scaling - May lose important information Choosing Components : # Cumulative explained variance \u2265 95% # Scree plot: elbow in eigenvalue plot # Cross-validation performance","title":"Principal Component Analysis (PCA)"},{"location":"machine-learning-algorithms/#t-sne-t-distributed-stochastic-neighbor-embedding","text":"Purpose : Nonlinear dimensionality reduction for visualization Key Concepts : High-dimensional similarity: p\u2c7c|\u1d62 = exp(-||x\u1d62-x\u2c7c||\u00b2/2\u03c3\u1d62\u00b2) / \u03a3\u2096 exp(-||x\u1d62-x\u2096||\u00b2/2\u03c3\u1d62\u00b2) Low-dimensional similarity: q\u1d62\u2c7c = (1+||y\u1d62-y\u2c7c||\u00b2)\u207b\u00b9 / \u03a3\u2096\u2097(1+||y\u2096-y\u2097||\u00b2)\u207b\u00b9 Cost function: KL(P||Q) = \u03a3\u1d62\u2c7c p\u1d62\u2c7c log(p\u1d62\u2c7c/q\u1d62\u2c7c) Key Parameters : - n_components : Dimension of embedded space (default: 2) - perplexity : Number of nearest neighbors (default: 30) - learning_rate : Learning rate (default: 200) - n_iter : Maximum iterations (default: 1000) When to Use : - \u2705 Visualization of high-dimensional data - \u2705 Exploring cluster structure - \u2705 Non-linear relationships exist - \u2705 Small to medium datasets Strengths : - Excellent for visualization - Preserves local structure - Reveals cluster structure - Non-linear dimensionality reduction Weaknesses : - Computationally expensive - Non-deterministic results - Hyperparameter sensitive - Not suitable for new data projection","title":"t-SNE (t-Distributed Stochastic Neighbor Embedding)"},{"location":"machine-learning-algorithms/#algorithm-selection-framework","text":"","title":"Algorithm Selection Framework"},{"location":"machine-learning-algorithms/#data-characteristics-decision-tree","text":"Sample Size? \u251c\u2500\u2500 Small (< 1K) \u2502 \u251c\u2500\u2500 Classification \u2192 Naive Bayes, k-NN, Decision Tree \u2502 \u2514\u2500\u2500 Regression \u2192 Linear Regression, k-NN \u251c\u2500\u2500 Medium (1K-100K) \u2502 \u251c\u2500\u2500 Linear relationship \u2192 Linear/Logistic Regression \u2502 \u251c\u2500\u2500 Non-linear \u2192 Random Forest, SVM \u2502 \u2514\u2500\u2500 Complex patterns \u2192 Neural Networks \u2514\u2500\u2500 Large (> 100K) \u251c\u2500\u2500 Speed priority \u2192 Linear models, SGD \u251c\u2500\u2500 Accuracy priority \u2192 Random Forest, Gradient Boosting \u2514\u2500\u2500 Very complex \u2192 Neural Networks Interpretability needed? \u251c\u2500\u2500 Yes \u2192 Linear Regression, Decision Trees, Naive Bayes \u2514\u2500\u2500 No \u2192 Random Forest, SVM, Neural Networks Training Speed priority? \u251c\u2500\u2500 Yes \u2192 Naive Bayes, Linear Regression, k-NN \u2514\u2500\u2500 No \u2192 SVM, Random Forest, Neural Networks","title":"Data Characteristics Decision Tree"},{"location":"machine-learning-algorithms/#performance-characteristics","text":"Algorithm Training Speed Prediction Speed Memory Usage Interpretability Linear Regression \u26a1\u26a1\u26a1 \u26a1\u26a1\u26a1 \u26a1\u26a1\u26a1 \u2b50\u2b50\u2b50 Logistic Regression \u26a1\u26a1\u26a1 \u26a1\u26a1\u26a1 \u26a1\u26a1\u26a1 \u2b50\u2b50\u2b50 Decision Tree \u26a1\u26a1 \u26a1\u26a1\u26a1 \u26a1\u26a1 \u2b50\u2b50\u2b50 Random Forest \u26a1 \u26a1\u26a1 \u26a1 \u2b50\u2b50 XGBoost \u26a1 \u26a1\u26a1 \u26a1\u26a1 \u2b50 LightGBM \u26a1\u26a1 \u26a1\u26a1\u26a1 \u26a1\u26a1\u26a1 \u2b50 CatBoost \u26a1 \u26a1\u26a1 \u26a1\u26a1 \u2b50 AdaBoost \u26a1 \u26a1\u26a1 \u26a1\u26a1 \u2b50\u2b50 SVM \u26a1 \u26a1\u26a1 \u26a1\u26a1 \u2b50 k-NN \u26a1\u26a1\u26a1 \u26a1 \u26a1 \u2b50\u2b50 Naive Bayes \u26a1\u26a1\u26a1 \u26a1\u26a1\u26a1 \u26a1\u26a1\u26a1 \u2b50\u2b50 Neural Networks \u26a1 \u26a1\u26a1 \u26a1 \u2b50","title":"Performance Characteristics"},{"location":"machine-learning-algorithms/#evaluation-metrics","text":"","title":"Evaluation Metrics"},{"location":"machine-learning-algorithms/#classification-metrics","text":"Accuracy : (TP + TN) / (TP + TN + FP + FN) - Use when: Balanced classes, all errors equally important Precision : TP / (TP + FP) - Use when: False positives are costly (spam detection) Recall (Sensitivity) : TP / (TP + FN) - Use when: False negatives are costly (disease detection) F1-Score : 2 * (Precision * Recall) / (Precision + Recall) - Use when: Balance between precision and recall needed ROC-AUC : Area under Receiver Operating Characteristic curve - Use when: Comparing models across different thresholds","title":"Classification Metrics"},{"location":"machine-learning-algorithms/#regression-metrics","text":"Mean Absolute Error (MAE) : 1/n \u03a3|y\u1d62 - \u0177\u1d62| - Robust to outliers, interpretable in original units Mean Squared Error (MSE) : 1/n \u03a3(y\u1d62 - \u0177\u1d62)\u00b2 - Penalizes large errors more, sensitive to outliers Root Mean Squared Error (RMSE) : \u221a(1/n \u03a3(y\u1d62 - \u0177\u1d62)\u00b2) - Same units as target, interpretable R\u00b2 Score : 1 - SS_res/SS_tot - Proportion of variance explained, 0-1 scale","title":"Regression Metrics"},{"location":"machine-learning-algorithms/#clustering-metrics","text":"Silhouette Score : Measures cluster cohesion and separation - Range: [-1, 1], higher is better Adjusted Rand Index : Measures similarity to true clustering - Range: [-1, 1], 1 = perfect match Inertia : Within-cluster sum of squares (k-means objective) - Lower is better, use with elbow method","title":"Clustering Metrics"},{"location":"machine-learning-algorithms/#common-preprocessing-steps","text":"","title":"Common Preprocessing Steps"},{"location":"machine-learning-algorithms/#feature-scaling","text":"# Standardization (mean=0, std=1) StandardScaler() # For normal distribution # Normalization (min=0, max=1) MinMaxScaler() # For uniform distribution # Robust scaling (median=0, IQR=1) RobustScaler() # For data with outliers","title":"Feature Scaling"},{"location":"machine-learning-algorithms/#feature-engineering","text":"Polynomial Features : Create interaction terms One-Hot Encoding : Convert categorical to binary Target Encoding : Use target statistics for categories Binning : Convert continuous to categorical Date Features : Extract year, month, day, weekday","title":"Feature Engineering"},{"location":"machine-learning-algorithms/#missing-data","text":"Drop : Remove rows/columns with missing values Mean/Median/Mode : Fill with central tendency Forward/Backward Fill : Use adjacent values Interpolation : Estimate based on trends Model-based : Predict missing values","title":"Missing Data"},{"location":"machine-learning-algorithms/#overfitting-vs-underfitting","text":"","title":"Overfitting vs Underfitting"},{"location":"machine-learning-algorithms/#overfitting-high-variance","text":"Symptoms : - High training accuracy, low validation accuracy - Complex model performs worse on new data Solutions : - More training data - Regularization (L1/L2) - Feature selection - Cross-validation - Early stopping - Ensemble methods","title":"Overfitting (High Variance)"},{"location":"machine-learning-algorithms/#underfitting-high-bias","text":"Symptoms : - Low training and validation accuracy - Model too simple for the problem Solutions : - More complex model - Add features - Reduce regularization - Increase model capacity - Feature engineering","title":"Underfitting (High Bias)"},{"location":"machine-learning-algorithms/#model-selection-best-practices","text":"Start Simple : Begin with baseline models (linear, naive bayes) Cross-Validation : Use k-fold CV for reliable performance estimates Feature Engineering : Often more important than algorithm choice Ensemble Methods : Combine multiple models for better performance Hyperparameter Tuning : Use grid search or randomized search Monitor Overfitting : Track train vs validation performance Business Metrics : Optimize for what matters to the business Interpretability Trade-off : Balance accuracy with explainability","title":"Model Selection Best Practices"},{"location":"machine-learning-algorithms/#quick-reference-table","text":"Problem Type First Try If More Accuracy Needed If Interpretability Needed Binary Classification Logistic Regression XGBoost, LightGBM, CatBoost Decision Tree, Naive Bayes Multi-class Classification Logistic Regression XGBoost, LightGBM, CatBoost Decision Tree Regression Linear Regression XGBoost, LightGBM, CatBoost Linear Regression Clustering k-Means DBSCAN, Hierarchical k-Means with visualization Dimensionality Reduction PCA t-SNE, UMAP PCA Anomaly Detection Isolation Forest One-Class SVM Statistical methods This cheat sheet provides a foundation for understanding and applying machine learning algorithms. Always consider your specific problem context, data characteristics, and business requirements when selecting algorithms.","title":"Quick Reference Table"},{"location":"gpu/cuda/","text":"CUDA Programming A comprehensive reference for CUDA C/C++ GPU programming, covering kernels, memory management, synchronization, and optimization techniques. Quick Start Installation & Setup # Check CUDA installation nvcc --version nvidia-smi # Compile CUDA program nvcc program.cu -o program # Compile with debugging info nvcc -g -G program.cu -o program # Compile for specific architecture nvcc -arch=sm_80 program.cu -o program Basic Program Structure #include <cuda_runtime.h> #include <stdio.h> // Kernel function (runs on GPU) __global__ void myKernel(float* data, int n) { int idx = blockIdx.x * blockDim.x + threadIdx.x; if (idx < n) { data[idx] *= 2.0f; } } int main() { // Host code int n = 1024; size_t size = n * sizeof(float); // Allocate host memory float* h_data = (float*)malloc(size); // Allocate device memory float* d_data; cudaMalloc(&d_data, size); // Copy data to device cudaMemcpy(d_data, h_data, size, cudaMemcpyHostToDevice); // Launch kernel int blockSize = 256; int gridSize = (n + blockSize - 1) / blockSize; myKernel<<<gridSize, blockSize>>>(d_data, n); // Copy result back cudaMemcpy(h_data, d_data, size, cudaMemcpyDeviceToHost); // Cleanup cudaFree(d_data); free(h_data); return 0; } Core Concepts Execution Model // Grid -> Blocks -> Threads hierarchy __global__ void kernel() { // Thread indices int tid = threadIdx.x; // Thread within block int bid = blockIdx.x; // Block within grid int gid = bid * blockDim.x + tid; // Global thread index // Multi-dimensional indexing int row = blockIdx.y * blockDim.y + threadIdx.y; int col = blockIdx.x * blockDim.x + threadIdx.x; int idx = row * width + col; } // Launch configuration dim3 gridSize(16, 16); // 16x16 blocks dim3 blockSize(32, 32); // 32x32 threads per block kernel<<<gridSize, blockSize>>>(); Function Qualifiers __global__ void kernelFunction() { // Runs on GPU, called from host // Kernel code } __device__ void deviceFunction() { // Runs on GPU, called from GPU // Device function code } __host__ void hostFunction() { // Runs on CPU (default) // Host function code } __host__ __device__ void bothFunction() { // Can run on both // Code that works on both host and device } Variable Qualifiers __global__ void kernel() { __shared__ float sharedArray[256]; // Shared memory __constant__ float constValue; // Constant memory __device__ float deviceGlobal; // Global device memory int localVar; // Register/local memory } Memory Management Basic Memory Operations // Device memory allocation float* d_array; size_t size = n * sizeof(float); cudaError_t err = cudaMalloc(&d_array, size); // Memory copy operations cudaMemcpy(d_dst, h_src, size, cudaMemcpyHostToDevice); cudaMemcpy(h_dst, d_src, size, cudaMemcpyDeviceToHost); cudaMemcpy(d_dst, d_src, size, cudaMemcpyDeviceToDevice); // Memory initialization cudaMemset(d_array, 0, size); // Free memory cudaFree(d_array); Asynchronous Memory Operations // Create streams cudaStream_t stream1, stream2; cudaStreamCreate(&stream1); cudaStreamCreate(&stream2); // Asynchronous operations cudaMemcpyAsync(d_data, h_data, size, cudaMemcpyHostToDevice, stream1); kernel<<<grid, block, 0, stream1>>>(d_data); cudaMemcpyAsync(h_result, d_result, size, cudaMemcpyDeviceToHost, stream1); // Synchronization cudaStreamSynchronize(stream1); cudaDeviceSynchronize(); // Wait for all operations // Cleanup cudaStreamDestroy(stream1); cudaStreamDestroy(stream2); Pinned Memory // Allocate pinned memory (faster transfers) float* h_pinned; cudaHostAlloc(&h_pinned, size, cudaHostAllocDefault); // Or use cudaMallocHost cudaMallocHost(&h_pinned, size); // Free pinned memory cudaFreeHost(h_pinned); Unified Memory (Managed Memory) // Allocate unified memory float* unified_data; cudaMallocManaged(&unified_data, size); // Use directly in kernel kernel<<<grid, block>>>(unified_data); // Prefetch to device (optional optimization) cudaMemPrefetchAsync(unified_data, size, 0); // Device 0 // Free unified memory cudaFree(unified_data); Memory Types & Hierarchy Global Memory // Allocated with cudaMalloc // Accessible by all threads // Highest latency, largest capacity __global__ void kernel(float* global_mem) { int idx = blockIdx.x * blockDim.x + threadIdx.x; global_mem[idx] = idx; // Global memory access } Shared Memory __global__ void sharedMemoryExample(float* input, float* output) { __shared__ float tile[TILE_SIZE][TILE_SIZE]; // Static allocation // Dynamic shared memory (specified at kernel launch) extern __shared__ float dynamic_tile[]; int tid = threadIdx.x; // Load data to shared memory tile[threadIdx.y][threadIdx.x] = input[...]; // Synchronize threads in block __syncthreads(); // Use shared memory data float result = tile[threadIdx.y][threadIdx.x] * 2.0f; output[...] = result; } // Launch with dynamic shared memory int sharedMemSize = TILE_SIZE * TILE_SIZE * sizeof(float); kernel<<<grid, block, sharedMemSize>>>(input, output); Constant Memory // Declare constant memory (at file scope) __constant__ float const_array[1024]; // Copy to constant memory float host_array[1024]; cudaMemcpyToSymbol(const_array, host_array, sizeof(host_array)); __global__ void useConstant() { float value = const_array[threadIdx.x]; // Fast broadcast read } Texture Memory // Texture object (modern approach) texture<float, 2, cudaReadModeElementType> tex; __global__ void textureKernel() { float x = blockIdx.x * blockDim.x + threadIdx.x; float y = blockIdx.y * blockDim.y + threadIdx.y; // Read from texture (with interpolation) float value = tex2D(tex, x + 0.5f, y + 0.5f); } // Setup texture (host code) cudaArray* cuArray; cudaChannelFormatDesc channelDesc = cudaCreateChannelDesc<float>(); cudaMallocArray(&cuArray, &channelDesc, width, height); cudaBindTextureToArray(tex, cuArray, channelDesc); Kernel Launch & Configuration Launch Configuration // 1D configuration int blockSize = 256; int gridSize = (n + blockSize - 1) / blockSize; kernel<<<gridSize, blockSize>>>(data); // 2D configuration dim3 blockSize(16, 16); // 256 threads per block dim3 gridSize((width + 15) / 16, (height + 15) / 16); kernel2D<<<gridSize, blockSize>>>(data); // With shared memory int sharedMemSize = blockSize.x * blockSize.y * sizeof(float); kernel<<<gridSize, blockSize, sharedMemSize>>>(data); // With streams kernel<<<gridSize, blockSize, sharedMemSize, stream>>>(data); Dynamic Parallelism __global__ void parentKernel(float* data, int n) { int idx = blockIdx.x * blockDim.x + threadIdx.x; if (idx < n && needsProcessing(data[idx])) { // Launch child kernel from device childKernel<<<1, 32>>>(data, idx); // Synchronize child kernel cudaDeviceSynchronize(); } } __global__ void childKernel(float* data, int offset) { int idx = threadIdx.x; // Process data[offset + idx] } Occupancy Calculation int blockSize; // The launch configurator will suggest a block size int minGridSize; // The minimum grid size needed to achieve max occupancy int gridSize; // The actual grid size // Calculate optimal block size cudaOccupancyMaxPotentialBlockSize(&minGridSize, &blockSize, myKernel, 0, 0); // Round up according to array size gridSize = (n + blockSize - 1) / blockSize; myKernel<<<gridSize, blockSize>>>(data); Thread Synchronization Block-Level Synchronization __global__ void syncExample() { __shared__ float shared_data[256]; int tid = threadIdx.x; // Load data shared_data[tid] = input[blockIdx.x * blockDim.x + tid]; // Wait for all threads in block to finish loading __syncthreads(); // Now all threads can safely access shared_data float result = shared_data[255 - tid]; // Reverse access // Another sync before writing results __syncthreads(); output[blockIdx.x * blockDim.x + tid] = result; } Warp-Level Synchronization #include <cooperative_groups.h> __global__ void warpExample() { auto warp = cooperative_groups::tiled_partition<32>( cooperative_groups::this_thread_block()); int lane_id = warp.thread_rank(); int value = lane_id; // Warp-level reduction for (int delta = 16; delta > 0; delta /= 2) { value += warp.shfl_down_sync(0xffffffff, value, delta); } if (lane_id == 0) { // Thread 0 of each warp has the sum atomicAdd(result, value); } } Atomic Operations // Basic atomic operations __global__ void atomicsExample(int* counter, float* sum, int* histogram) { int idx = blockIdx.x * blockDim.x + threadIdx.x; // Atomic increment int old_val = atomicAdd(counter, 1); // Atomic floating point operations (CC >= 6.0) atomicAdd(sum, data[idx]); // Atomic compare and swap int expected = 0; int desired = idx; int old = atomicCAS(&flag, expected, desired); // Histogram example int bin = (int)(data[idx] * NUM_BINS); atomicAdd(&histogram[bin], 1); } // Custom atomic operations using CAS __device__ float atomicMaxFloat(float* address, float val) { int* address_as_int = (int*)address; int old = *address_as_int, assumed; do { assumed = old; old = atomicCAS(address_as_int, assumed, __float_as_int(fmaxf(val, __int_as_float(assumed)))); } while (assumed != old); return __int_as_float(old); } Cooperative Groups #include <cooperative_groups.h> using namespace cooperative_groups; __global__ void cooperativeKernel() { // Thread block group thread_block block = this_thread_block(); // Warp-sized tile auto tile32 = tiled_partition<32>(block); // Grid group (requires cooperative launch) grid_group grid = this_grid(); // Synchronize at different levels block.sync(); // Block-level sync tile32.sync(); // Warp-level sync grid.sync(); // Grid-level sync (cooperative kernels only) } // Launch cooperative kernel cudaLaunchCooperativeKernel((void*)cooperativeKernel, gridSize, blockSize, args); Error Handling Basic Error Checking #define CUDA_CHECK(call) \\ do { \\ cudaError_t err = call; \\ if (err != cudaSuccess) { \\ fprintf(stderr, \"CUDA error at %s:%d - %s\\n\", \\ __FILE__, __LINE__, cudaGetErrorString(err)); \\ exit(EXIT_FAILURE); \\ } \\ } while(0) // Usage CUDA_CHECK(cudaMalloc(&d_data, size)); CUDA_CHECK(cudaMemcpy(d_data, h_data, size, cudaMemcpyHostToDevice)); // Check kernel launch errors kernel<<<grid, block>>>(data); CUDA_CHECK(cudaGetLastError()); CUDA_CHECK(cudaDeviceSynchronize()); Advanced Error Handling // Error checking function void checkCudaErrors(cudaError_t result) { if (result != cudaSuccess) { fprintf(stderr, \"CUDA Runtime Error: %s\\n\", cudaGetErrorString(result)); assert(result == cudaSuccess); } } // Async error checking cudaError_t asyncCheckErrors() { cudaError_t err = cudaGetLastError(); if (err != cudaSuccess) { printf(\"Async kernel error: %s\\n\", cudaGetErrorString(err)); return err; } // Check for execution errors err = cudaDeviceSynchronize(); if (err != cudaSuccess) { printf(\"Sync error: %s\\n\", cudaGetErrorString(err)); return err; } return cudaSuccess; } Performance Optimization Memory Coalescing // Bad: Non-coalesced access __global__ void badAccess(float* data, int width) { int idx = blockIdx.x * blockDim.x + threadIdx.x; int row = idx / width; int col = idx % width; // Strided access pattern (bad) float value = data[col * width + row]; // Column-major access } // Good: Coalesced access __global__ void goodAccess(float* data, int width) { int row = blockIdx.y * blockDim.y + threadIdx.y; int col = blockIdx.x * blockDim.x + threadIdx.x; // Sequential access pattern (good) float value = data[row * width + col]; // Row-major access } Shared Memory Bank Conflicts // Bad: Bank conflicts __global__ void badSharedAccess() { __shared__ float shared[32][32]; int tid = threadIdx.x; // All threads access same bank (conflict) float value = shared[0][tid]; } // Good: No bank conflicts __global__ void goodSharedAccess() { __shared__ float shared[32][33]; // Padding to avoid conflicts int tid = threadIdx.x; // Diagonal access pattern float value = shared[tid][(tid + offset) % 32]; } Loop Unrolling // Manual unrolling for small, known loop counts __global__ void unrolledKernel(float* data) { int idx = blockIdx.x * blockDim.x + threadIdx.x; float sum = 0.0f; // Unroll small loops #pragma unroll 4 for (int i = 0; i < 4; i++) { sum += data[idx * 4 + i]; } data[idx] = sum; } Memory Bandwidth Optimization // Vectorized memory access __global__ void vectorizedAccess(float4* input, float4* output, int n) { int idx = blockIdx.x * blockDim.x + threadIdx.x; if (idx < n) { float4 data = input[idx]; // Load 4 floats at once // Process each component data.x *= 2.0f; data.y *= 2.0f; data.z *= 2.0f; data.w *= 2.0f; output[idx] = data; // Store 4 floats at once } } Instruction-Level Optimizations __global__ void optimizedKernel(float* data, int n) { int idx = blockIdx.x * blockDim.x + threadIdx.x; if (idx < n) { float x = data[idx]; // Use fast math functions float result = __sinf(x) + __cosf(x); // Fast sin/cos // Fast division (less accurate) result = __fdividef(result, 3.14159f); // Fast reciprocal square root result *= __frsqrt_rn(result); data[idx] = result; } } Common Patterns Reduction // Efficient block-level reduction __global__ void blockReduce(float* input, float* output, int n) { __shared__ float sdata[256]; int tid = threadIdx.x; int idx = blockIdx.x * blockDim.x + threadIdx.x; // Load data sdata[tid] = (idx < n) ? input[idx] : 0.0f; __syncthreads(); // Reduction in shared memory for (int s = blockDim.x / 2; s > 0; s >>= 1) { if (tid < s) { sdata[tid] += sdata[tid + s]; } __syncthreads(); } // Write result if (tid == 0) { output[blockIdx.x] = sdata[0]; } } Matrix Multiplication (Tiled) #define TILE_SIZE 16 __global__ void matmulTiled(float* A, float* B, float* C, int N) { __shared__ float As[TILE_SIZE][TILE_SIZE]; __shared__ float Bs[TILE_SIZE][TILE_SIZE]; int row = blockIdx.y * TILE_SIZE + threadIdx.y; int col = blockIdx.x * TILE_SIZE + threadIdx.x; float sum = 0.0f; for (int tile = 0; tile < (N + TILE_SIZE - 1) / TILE_SIZE; tile++) { // Load tiles into shared memory if (row < N && tile * TILE_SIZE + threadIdx.x < N) As[threadIdx.y][threadIdx.x] = A[row * N + tile * TILE_SIZE + threadIdx.x]; else As[threadIdx.y][threadIdx.x] = 0.0f; if (col < N && tile * TILE_SIZE + threadIdx.y < N) Bs[threadIdx.y][threadIdx.x] = B[(tile * TILE_SIZE + threadIdx.y) * N + col]; else Bs[threadIdx.y][threadIdx.x] = 0.0f; __syncthreads(); // Compute partial result for (int k = 0; k < TILE_SIZE; k++) { sum += As[threadIdx.y][k] * Bs[k][threadIdx.x]; } __syncthreads(); } // Write result if (row < N && col < N) { C[row * N + col] = sum; } } Scan (Prefix Sum) __global__ void scanBlock(float* input, float* output, int n) { __shared__ float temp[2 * BLOCK_SIZE]; int tid = threadIdx.x; int idx = blockIdx.x * blockDim.x + threadIdx.x; // Load data temp[2 * tid] = (2 * idx < n) ? input[2 * idx] : 0; temp[2 * tid + 1] = (2 * idx + 1 < n) ? input[2 * idx + 1] : 0; __syncthreads(); // Up-sweep phase for (int stride = 1; stride < 2 * BLOCK_SIZE; stride *= 2) { int index = (tid + 1) * stride * 2 - 1; if (index < 2 * BLOCK_SIZE) { temp[index] += temp[index - stride]; } __syncthreads(); } // Clear last element if (tid == 0) temp[2 * BLOCK_SIZE - 1] = 0; __syncthreads(); // Down-sweep phase for (int stride = BLOCK_SIZE; stride > 0; stride /= 2) { int index = (tid + 1) * stride * 2 - 1; if (index < 2 * BLOCK_SIZE) { float t = temp[index]; temp[index] += temp[index - stride]; temp[index - stride] = t; } __syncthreads(); } // Write results if (2 * idx < n) output[2 * idx] = temp[2 * tid]; if (2 * idx + 1 < n) output[2 * idx + 1] = temp[2 * tid + 1]; } Debugging & Profiling CUDA-GDB # Compile with debugging info nvcc -g -G -O0 program.cu -o program # Run with cuda-gdb cuda-gdb ./program # Common commands (cuda-gdb) break main (cuda-gdb) break kernel_name (cuda-gdb) run (cuda-gdb) cuda thread (0,0,0) # Switch to specific thread (cuda-gdb) cuda block (0,0) # Switch to specific block (cuda-gdb) print variable_name (cuda-gdb) continue Profiling with Nsight (nsys/ncu) # Nsight Systems (nsys) for system-wide performance analysis nsys profile --stats=true ./program # Nsight Compute (ncu) for detailed kernel analysis ncu --set full ./program # Legacy profiling (nvprof) - deprecated nvprof ./program Printf Debugging __global__ void debugKernel(float* data, int n) { int idx = blockIdx.x * blockDim.x + threadIdx.x; // Debug specific threads if (blockIdx.x == 0 && threadIdx.x < 5) { printf(\"Block %d, Thread %d: data[%d] = %f\\n\", blockIdx.x, threadIdx.x, idx, data[idx]); } // Conditional debugging if (data[idx] < 0) { printf(\"Negative value at index %d: %f\\n\", idx, data[idx]); } } Device Management Device Properties void queryDevice() { int deviceCount; cudaGetDeviceCount(&deviceCount); for (int dev = 0; dev < deviceCount; dev++) { cudaDeviceProp prop; cudaGetDeviceProperties(&prop, dev); printf(\"Device %d: %s\\n\", dev, prop.name); printf(\" Compute capability: %d.%d\\n\", prop.major, prop.minor); printf(\" Total global memory: %zu MB\\n\", prop.totalGlobalMem / (1024*1024)); printf(\" Shared memory per block: %zu KB\\n\", prop.sharedMemPerBlock / 1024); printf(\" Max threads per block: %d\\n\", prop.maxThreadsPerBlock); printf(\" Warp size: %d\\n\", prop.warpSize); printf(\" Memory bus width: %d bits\\n\", prop.memoryBusWidth); printf(\" Memory clock rate: %d MHz\\n\", prop.memoryClockRate / 1000); } } void setDevice() { int device = 0; // Use device 0 cudaSetDevice(device); // Verify device was set int currentDevice; cudaGetDevice(&currentDevice); printf(\"Using device %d\\n\", currentDevice); } Multi-GPU Programming void multiGPU() { int deviceCount; cudaGetDeviceCount(&deviceCount); // Allocate data on each device float** d_data = new float*[deviceCount]; cudaStream_t* streams = new cudaStream_t[deviceCount]; for (int dev = 0; dev < deviceCount; dev++) { cudaSetDevice(dev); cudaMalloc(&d_data[dev], dataSize); cudaStreamCreate(&streams[dev]); // Launch work on this device kernel<<<grid, block, 0, streams[dev]>>>(d_data[dev]); } // Synchronize all devices for (int dev = 0; dev < deviceCount; dev++) { cudaSetDevice(dev); cudaStreamSynchronize(streams[dev]); cudaFree(d_data[dev]); cudaStreamDestroy(streams[dev]); } } Quick Reference Memory Copy Directions cudaMemcpyHostToDevice // CPU \u2192 GPU cudaMemcpyDeviceToHost // GPU \u2192 CPU cudaMemcpyDeviceToDevice // GPU \u2192 GPU cudaMemcpyHostToHost // CPU \u2192 CPU (rarely used) Built-in Variables // Thread indexing threadIdx.x, threadIdx.y, threadIdx.z // Thread index within block blockIdx.x, blockIdx.y, blockIdx.z // Block index within grid blockDim.x, blockDim.y, blockDim.z // Block dimensions gridDim.x, gridDim.y, gridDim.z // Grid dimensions // Warp information warpSize // Usually 32 Mathematical Functions // Standard math functions (slower, double precision available) sin(), cos(), tan(), log(), exp(), sqrt(), pow() // Fast math functions (faster, single precision only) __sinf(), __cosf(), __tanf(), __logf(), __expf() __fsqrt_rn(), __fdividef() // Integer functions __clz() // Count leading zeros __popc() // Population count (number of set bits) __brev() // Bit reverse Warp Shuffle Operations // Warp shuffle functions (CC >= 3.0) __shfl_sync(mask, var, srcLane) // Direct lane access __shfl_up_sync(mask, var, delta) // Shift up __shfl_down_sync(mask, var, delta) // Shift down __shfl_xor_sync(mask, var, laneMask) // XOR-based shuffle // Example: Warp reduction int value = threadIdx.x; for (int offset = 16; offset > 0; offset /= 2) { value += __shfl_down_sync(0xffffffff, value, offset); } Common Gotchas & Best Practices Memory Access Patterns Always aim for coalesced memory access - threads in a warp should access consecutive memory addresses Use shared memory for repeated data access - 100x faster than global memory Avoid bank conflicts in shared memory - pad arrays or use different access patterns Prefer AoS over SoA for coalesced access in most cases Thread Management Choose block sizes that are multiples of warp size (32) for best efficiency Aim for high occupancy but not at all costs - sometimes fewer blocks with more shared memory is better Use __syncthreads() carefully - all threads in the block must reach it Avoid divergent branches within warps when possible Performance Tips Use fast math functions ( __sinf , __expf , etc.) when precision allows Minimize register usage to increase occupancy Use texture memory for spatial locality in read-only data Consider using unified memory for easier development, but profile performance Profile your code with nsys/ncu to identify bottlenecks Error Handling Always check CUDA API return values using error checking macros Use cudaGetLastError() after kernel launches to catch errors Synchronize before error checking for kernel execution errors Use CUDA-GDB for debugging device code when needed This cheat sheet covers the essential CUDA programming concepts and patterns. For the most current information, always refer to the official CUDA documentation .","title":"CUDA Programming"},{"location":"gpu/cuda/#cuda-programming","text":"A comprehensive reference for CUDA C/C++ GPU programming, covering kernels, memory management, synchronization, and optimization techniques.","title":"CUDA Programming"},{"location":"gpu/cuda/#quick-start","text":"","title":"Quick Start"},{"location":"gpu/cuda/#installation-setup","text":"# Check CUDA installation nvcc --version nvidia-smi # Compile CUDA program nvcc program.cu -o program # Compile with debugging info nvcc -g -G program.cu -o program # Compile for specific architecture nvcc -arch=sm_80 program.cu -o program","title":"Installation &amp; Setup"},{"location":"gpu/cuda/#basic-program-structure","text":"#include <cuda_runtime.h> #include <stdio.h> // Kernel function (runs on GPU) __global__ void myKernel(float* data, int n) { int idx = blockIdx.x * blockDim.x + threadIdx.x; if (idx < n) { data[idx] *= 2.0f; } } int main() { // Host code int n = 1024; size_t size = n * sizeof(float); // Allocate host memory float* h_data = (float*)malloc(size); // Allocate device memory float* d_data; cudaMalloc(&d_data, size); // Copy data to device cudaMemcpy(d_data, h_data, size, cudaMemcpyHostToDevice); // Launch kernel int blockSize = 256; int gridSize = (n + blockSize - 1) / blockSize; myKernel<<<gridSize, blockSize>>>(d_data, n); // Copy result back cudaMemcpy(h_data, d_data, size, cudaMemcpyDeviceToHost); // Cleanup cudaFree(d_data); free(h_data); return 0; }","title":"Basic Program Structure"},{"location":"gpu/cuda/#core-concepts","text":"","title":"Core Concepts"},{"location":"gpu/cuda/#execution-model","text":"// Grid -> Blocks -> Threads hierarchy __global__ void kernel() { // Thread indices int tid = threadIdx.x; // Thread within block int bid = blockIdx.x; // Block within grid int gid = bid * blockDim.x + tid; // Global thread index // Multi-dimensional indexing int row = blockIdx.y * blockDim.y + threadIdx.y; int col = blockIdx.x * blockDim.x + threadIdx.x; int idx = row * width + col; } // Launch configuration dim3 gridSize(16, 16); // 16x16 blocks dim3 blockSize(32, 32); // 32x32 threads per block kernel<<<gridSize, blockSize>>>();","title":"Execution Model"},{"location":"gpu/cuda/#function-qualifiers","text":"__global__ void kernelFunction() { // Runs on GPU, called from host // Kernel code } __device__ void deviceFunction() { // Runs on GPU, called from GPU // Device function code } __host__ void hostFunction() { // Runs on CPU (default) // Host function code } __host__ __device__ void bothFunction() { // Can run on both // Code that works on both host and device }","title":"Function Qualifiers"},{"location":"gpu/cuda/#variable-qualifiers","text":"__global__ void kernel() { __shared__ float sharedArray[256]; // Shared memory __constant__ float constValue; // Constant memory __device__ float deviceGlobal; // Global device memory int localVar; // Register/local memory }","title":"Variable Qualifiers"},{"location":"gpu/cuda/#memory-management","text":"","title":"Memory Management"},{"location":"gpu/cuda/#basic-memory-operations","text":"// Device memory allocation float* d_array; size_t size = n * sizeof(float); cudaError_t err = cudaMalloc(&d_array, size); // Memory copy operations cudaMemcpy(d_dst, h_src, size, cudaMemcpyHostToDevice); cudaMemcpy(h_dst, d_src, size, cudaMemcpyDeviceToHost); cudaMemcpy(d_dst, d_src, size, cudaMemcpyDeviceToDevice); // Memory initialization cudaMemset(d_array, 0, size); // Free memory cudaFree(d_array);","title":"Basic Memory Operations"},{"location":"gpu/cuda/#asynchronous-memory-operations","text":"// Create streams cudaStream_t stream1, stream2; cudaStreamCreate(&stream1); cudaStreamCreate(&stream2); // Asynchronous operations cudaMemcpyAsync(d_data, h_data, size, cudaMemcpyHostToDevice, stream1); kernel<<<grid, block, 0, stream1>>>(d_data); cudaMemcpyAsync(h_result, d_result, size, cudaMemcpyDeviceToHost, stream1); // Synchronization cudaStreamSynchronize(stream1); cudaDeviceSynchronize(); // Wait for all operations // Cleanup cudaStreamDestroy(stream1); cudaStreamDestroy(stream2);","title":"Asynchronous Memory Operations"},{"location":"gpu/cuda/#pinned-memory","text":"// Allocate pinned memory (faster transfers) float* h_pinned; cudaHostAlloc(&h_pinned, size, cudaHostAllocDefault); // Or use cudaMallocHost cudaMallocHost(&h_pinned, size); // Free pinned memory cudaFreeHost(h_pinned);","title":"Pinned Memory"},{"location":"gpu/cuda/#unified-memory-managed-memory","text":"// Allocate unified memory float* unified_data; cudaMallocManaged(&unified_data, size); // Use directly in kernel kernel<<<grid, block>>>(unified_data); // Prefetch to device (optional optimization) cudaMemPrefetchAsync(unified_data, size, 0); // Device 0 // Free unified memory cudaFree(unified_data);","title":"Unified Memory (Managed Memory)"},{"location":"gpu/cuda/#memory-types-hierarchy","text":"","title":"Memory Types &amp; Hierarchy"},{"location":"gpu/cuda/#global-memory","text":"// Allocated with cudaMalloc // Accessible by all threads // Highest latency, largest capacity __global__ void kernel(float* global_mem) { int idx = blockIdx.x * blockDim.x + threadIdx.x; global_mem[idx] = idx; // Global memory access }","title":"Global Memory"},{"location":"gpu/cuda/#shared-memory","text":"__global__ void sharedMemoryExample(float* input, float* output) { __shared__ float tile[TILE_SIZE][TILE_SIZE]; // Static allocation // Dynamic shared memory (specified at kernel launch) extern __shared__ float dynamic_tile[]; int tid = threadIdx.x; // Load data to shared memory tile[threadIdx.y][threadIdx.x] = input[...]; // Synchronize threads in block __syncthreads(); // Use shared memory data float result = tile[threadIdx.y][threadIdx.x] * 2.0f; output[...] = result; } // Launch with dynamic shared memory int sharedMemSize = TILE_SIZE * TILE_SIZE * sizeof(float); kernel<<<grid, block, sharedMemSize>>>(input, output);","title":"Shared Memory"},{"location":"gpu/cuda/#constant-memory","text":"// Declare constant memory (at file scope) __constant__ float const_array[1024]; // Copy to constant memory float host_array[1024]; cudaMemcpyToSymbol(const_array, host_array, sizeof(host_array)); __global__ void useConstant() { float value = const_array[threadIdx.x]; // Fast broadcast read }","title":"Constant Memory"},{"location":"gpu/cuda/#texture-memory","text":"// Texture object (modern approach) texture<float, 2, cudaReadModeElementType> tex; __global__ void textureKernel() { float x = blockIdx.x * blockDim.x + threadIdx.x; float y = blockIdx.y * blockDim.y + threadIdx.y; // Read from texture (with interpolation) float value = tex2D(tex, x + 0.5f, y + 0.5f); } // Setup texture (host code) cudaArray* cuArray; cudaChannelFormatDesc channelDesc = cudaCreateChannelDesc<float>(); cudaMallocArray(&cuArray, &channelDesc, width, height); cudaBindTextureToArray(tex, cuArray, channelDesc);","title":"Texture Memory"},{"location":"gpu/cuda/#kernel-launch-configuration","text":"","title":"Kernel Launch &amp; Configuration"},{"location":"gpu/cuda/#launch-configuration","text":"// 1D configuration int blockSize = 256; int gridSize = (n + blockSize - 1) / blockSize; kernel<<<gridSize, blockSize>>>(data); // 2D configuration dim3 blockSize(16, 16); // 256 threads per block dim3 gridSize((width + 15) / 16, (height + 15) / 16); kernel2D<<<gridSize, blockSize>>>(data); // With shared memory int sharedMemSize = blockSize.x * blockSize.y * sizeof(float); kernel<<<gridSize, blockSize, sharedMemSize>>>(data); // With streams kernel<<<gridSize, blockSize, sharedMemSize, stream>>>(data);","title":"Launch Configuration"},{"location":"gpu/cuda/#dynamic-parallelism","text":"__global__ void parentKernel(float* data, int n) { int idx = blockIdx.x * blockDim.x + threadIdx.x; if (idx < n && needsProcessing(data[idx])) { // Launch child kernel from device childKernel<<<1, 32>>>(data, idx); // Synchronize child kernel cudaDeviceSynchronize(); } } __global__ void childKernel(float* data, int offset) { int idx = threadIdx.x; // Process data[offset + idx] }","title":"Dynamic Parallelism"},{"location":"gpu/cuda/#occupancy-calculation","text":"int blockSize; // The launch configurator will suggest a block size int minGridSize; // The minimum grid size needed to achieve max occupancy int gridSize; // The actual grid size // Calculate optimal block size cudaOccupancyMaxPotentialBlockSize(&minGridSize, &blockSize, myKernel, 0, 0); // Round up according to array size gridSize = (n + blockSize - 1) / blockSize; myKernel<<<gridSize, blockSize>>>(data);","title":"Occupancy Calculation"},{"location":"gpu/cuda/#thread-synchronization","text":"","title":"Thread Synchronization"},{"location":"gpu/cuda/#block-level-synchronization","text":"__global__ void syncExample() { __shared__ float shared_data[256]; int tid = threadIdx.x; // Load data shared_data[tid] = input[blockIdx.x * blockDim.x + tid]; // Wait for all threads in block to finish loading __syncthreads(); // Now all threads can safely access shared_data float result = shared_data[255 - tid]; // Reverse access // Another sync before writing results __syncthreads(); output[blockIdx.x * blockDim.x + tid] = result; }","title":"Block-Level Synchronization"},{"location":"gpu/cuda/#warp-level-synchronization","text":"#include <cooperative_groups.h> __global__ void warpExample() { auto warp = cooperative_groups::tiled_partition<32>( cooperative_groups::this_thread_block()); int lane_id = warp.thread_rank(); int value = lane_id; // Warp-level reduction for (int delta = 16; delta > 0; delta /= 2) { value += warp.shfl_down_sync(0xffffffff, value, delta); } if (lane_id == 0) { // Thread 0 of each warp has the sum atomicAdd(result, value); } }","title":"Warp-Level Synchronization"},{"location":"gpu/cuda/#atomic-operations","text":"// Basic atomic operations __global__ void atomicsExample(int* counter, float* sum, int* histogram) { int idx = blockIdx.x * blockDim.x + threadIdx.x; // Atomic increment int old_val = atomicAdd(counter, 1); // Atomic floating point operations (CC >= 6.0) atomicAdd(sum, data[idx]); // Atomic compare and swap int expected = 0; int desired = idx; int old = atomicCAS(&flag, expected, desired); // Histogram example int bin = (int)(data[idx] * NUM_BINS); atomicAdd(&histogram[bin], 1); } // Custom atomic operations using CAS __device__ float atomicMaxFloat(float* address, float val) { int* address_as_int = (int*)address; int old = *address_as_int, assumed; do { assumed = old; old = atomicCAS(address_as_int, assumed, __float_as_int(fmaxf(val, __int_as_float(assumed)))); } while (assumed != old); return __int_as_float(old); }","title":"Atomic Operations"},{"location":"gpu/cuda/#cooperative-groups","text":"#include <cooperative_groups.h> using namespace cooperative_groups; __global__ void cooperativeKernel() { // Thread block group thread_block block = this_thread_block(); // Warp-sized tile auto tile32 = tiled_partition<32>(block); // Grid group (requires cooperative launch) grid_group grid = this_grid(); // Synchronize at different levels block.sync(); // Block-level sync tile32.sync(); // Warp-level sync grid.sync(); // Grid-level sync (cooperative kernels only) } // Launch cooperative kernel cudaLaunchCooperativeKernel((void*)cooperativeKernel, gridSize, blockSize, args);","title":"Cooperative Groups"},{"location":"gpu/cuda/#error-handling","text":"","title":"Error Handling"},{"location":"gpu/cuda/#basic-error-checking","text":"#define CUDA_CHECK(call) \\ do { \\ cudaError_t err = call; \\ if (err != cudaSuccess) { \\ fprintf(stderr, \"CUDA error at %s:%d - %s\\n\", \\ __FILE__, __LINE__, cudaGetErrorString(err)); \\ exit(EXIT_FAILURE); \\ } \\ } while(0) // Usage CUDA_CHECK(cudaMalloc(&d_data, size)); CUDA_CHECK(cudaMemcpy(d_data, h_data, size, cudaMemcpyHostToDevice)); // Check kernel launch errors kernel<<<grid, block>>>(data); CUDA_CHECK(cudaGetLastError()); CUDA_CHECK(cudaDeviceSynchronize());","title":"Basic Error Checking"},{"location":"gpu/cuda/#advanced-error-handling","text":"// Error checking function void checkCudaErrors(cudaError_t result) { if (result != cudaSuccess) { fprintf(stderr, \"CUDA Runtime Error: %s\\n\", cudaGetErrorString(result)); assert(result == cudaSuccess); } } // Async error checking cudaError_t asyncCheckErrors() { cudaError_t err = cudaGetLastError(); if (err != cudaSuccess) { printf(\"Async kernel error: %s\\n\", cudaGetErrorString(err)); return err; } // Check for execution errors err = cudaDeviceSynchronize(); if (err != cudaSuccess) { printf(\"Sync error: %s\\n\", cudaGetErrorString(err)); return err; } return cudaSuccess; }","title":"Advanced Error Handling"},{"location":"gpu/cuda/#performance-optimization","text":"","title":"Performance Optimization"},{"location":"gpu/cuda/#memory-coalescing","text":"// Bad: Non-coalesced access __global__ void badAccess(float* data, int width) { int idx = blockIdx.x * blockDim.x + threadIdx.x; int row = idx / width; int col = idx % width; // Strided access pattern (bad) float value = data[col * width + row]; // Column-major access } // Good: Coalesced access __global__ void goodAccess(float* data, int width) { int row = blockIdx.y * blockDim.y + threadIdx.y; int col = blockIdx.x * blockDim.x + threadIdx.x; // Sequential access pattern (good) float value = data[row * width + col]; // Row-major access }","title":"Memory Coalescing"},{"location":"gpu/cuda/#shared-memory-bank-conflicts","text":"// Bad: Bank conflicts __global__ void badSharedAccess() { __shared__ float shared[32][32]; int tid = threadIdx.x; // All threads access same bank (conflict) float value = shared[0][tid]; } // Good: No bank conflicts __global__ void goodSharedAccess() { __shared__ float shared[32][33]; // Padding to avoid conflicts int tid = threadIdx.x; // Diagonal access pattern float value = shared[tid][(tid + offset) % 32]; }","title":"Shared Memory Bank Conflicts"},{"location":"gpu/cuda/#loop-unrolling","text":"// Manual unrolling for small, known loop counts __global__ void unrolledKernel(float* data) { int idx = blockIdx.x * blockDim.x + threadIdx.x; float sum = 0.0f; // Unroll small loops #pragma unroll 4 for (int i = 0; i < 4; i++) { sum += data[idx * 4 + i]; } data[idx] = sum; }","title":"Loop Unrolling"},{"location":"gpu/cuda/#memory-bandwidth-optimization","text":"// Vectorized memory access __global__ void vectorizedAccess(float4* input, float4* output, int n) { int idx = blockIdx.x * blockDim.x + threadIdx.x; if (idx < n) { float4 data = input[idx]; // Load 4 floats at once // Process each component data.x *= 2.0f; data.y *= 2.0f; data.z *= 2.0f; data.w *= 2.0f; output[idx] = data; // Store 4 floats at once } }","title":"Memory Bandwidth Optimization"},{"location":"gpu/cuda/#instruction-level-optimizations","text":"__global__ void optimizedKernel(float* data, int n) { int idx = blockIdx.x * blockDim.x + threadIdx.x; if (idx < n) { float x = data[idx]; // Use fast math functions float result = __sinf(x) + __cosf(x); // Fast sin/cos // Fast division (less accurate) result = __fdividef(result, 3.14159f); // Fast reciprocal square root result *= __frsqrt_rn(result); data[idx] = result; } }","title":"Instruction-Level Optimizations"},{"location":"gpu/cuda/#common-patterns","text":"","title":"Common Patterns"},{"location":"gpu/cuda/#reduction","text":"// Efficient block-level reduction __global__ void blockReduce(float* input, float* output, int n) { __shared__ float sdata[256]; int tid = threadIdx.x; int idx = blockIdx.x * blockDim.x + threadIdx.x; // Load data sdata[tid] = (idx < n) ? input[idx] : 0.0f; __syncthreads(); // Reduction in shared memory for (int s = blockDim.x / 2; s > 0; s >>= 1) { if (tid < s) { sdata[tid] += sdata[tid + s]; } __syncthreads(); } // Write result if (tid == 0) { output[blockIdx.x] = sdata[0]; } }","title":"Reduction"},{"location":"gpu/cuda/#matrix-multiplication-tiled","text":"#define TILE_SIZE 16 __global__ void matmulTiled(float* A, float* B, float* C, int N) { __shared__ float As[TILE_SIZE][TILE_SIZE]; __shared__ float Bs[TILE_SIZE][TILE_SIZE]; int row = blockIdx.y * TILE_SIZE + threadIdx.y; int col = blockIdx.x * TILE_SIZE + threadIdx.x; float sum = 0.0f; for (int tile = 0; tile < (N + TILE_SIZE - 1) / TILE_SIZE; tile++) { // Load tiles into shared memory if (row < N && tile * TILE_SIZE + threadIdx.x < N) As[threadIdx.y][threadIdx.x] = A[row * N + tile * TILE_SIZE + threadIdx.x]; else As[threadIdx.y][threadIdx.x] = 0.0f; if (col < N && tile * TILE_SIZE + threadIdx.y < N) Bs[threadIdx.y][threadIdx.x] = B[(tile * TILE_SIZE + threadIdx.y) * N + col]; else Bs[threadIdx.y][threadIdx.x] = 0.0f; __syncthreads(); // Compute partial result for (int k = 0; k < TILE_SIZE; k++) { sum += As[threadIdx.y][k] * Bs[k][threadIdx.x]; } __syncthreads(); } // Write result if (row < N && col < N) { C[row * N + col] = sum; } }","title":"Matrix Multiplication (Tiled)"},{"location":"gpu/cuda/#scan-prefix-sum","text":"__global__ void scanBlock(float* input, float* output, int n) { __shared__ float temp[2 * BLOCK_SIZE]; int tid = threadIdx.x; int idx = blockIdx.x * blockDim.x + threadIdx.x; // Load data temp[2 * tid] = (2 * idx < n) ? input[2 * idx] : 0; temp[2 * tid + 1] = (2 * idx + 1 < n) ? input[2 * idx + 1] : 0; __syncthreads(); // Up-sweep phase for (int stride = 1; stride < 2 * BLOCK_SIZE; stride *= 2) { int index = (tid + 1) * stride * 2 - 1; if (index < 2 * BLOCK_SIZE) { temp[index] += temp[index - stride]; } __syncthreads(); } // Clear last element if (tid == 0) temp[2 * BLOCK_SIZE - 1] = 0; __syncthreads(); // Down-sweep phase for (int stride = BLOCK_SIZE; stride > 0; stride /= 2) { int index = (tid + 1) * stride * 2 - 1; if (index < 2 * BLOCK_SIZE) { float t = temp[index]; temp[index] += temp[index - stride]; temp[index - stride] = t; } __syncthreads(); } // Write results if (2 * idx < n) output[2 * idx] = temp[2 * tid]; if (2 * idx + 1 < n) output[2 * idx + 1] = temp[2 * tid + 1]; }","title":"Scan (Prefix Sum)"},{"location":"gpu/cuda/#debugging-profiling","text":"","title":"Debugging &amp; Profiling"},{"location":"gpu/cuda/#cuda-gdb","text":"# Compile with debugging info nvcc -g -G -O0 program.cu -o program # Run with cuda-gdb cuda-gdb ./program # Common commands (cuda-gdb) break main (cuda-gdb) break kernel_name (cuda-gdb) run (cuda-gdb) cuda thread (0,0,0) # Switch to specific thread (cuda-gdb) cuda block (0,0) # Switch to specific block (cuda-gdb) print variable_name (cuda-gdb) continue","title":"CUDA-GDB"},{"location":"gpu/cuda/#profiling-with-nsight-nsysncu","text":"# Nsight Systems (nsys) for system-wide performance analysis nsys profile --stats=true ./program # Nsight Compute (ncu) for detailed kernel analysis ncu --set full ./program # Legacy profiling (nvprof) - deprecated nvprof ./program","title":"Profiling with Nsight (nsys/ncu)"},{"location":"gpu/cuda/#printf-debugging","text":"__global__ void debugKernel(float* data, int n) { int idx = blockIdx.x * blockDim.x + threadIdx.x; // Debug specific threads if (blockIdx.x == 0 && threadIdx.x < 5) { printf(\"Block %d, Thread %d: data[%d] = %f\\n\", blockIdx.x, threadIdx.x, idx, data[idx]); } // Conditional debugging if (data[idx] < 0) { printf(\"Negative value at index %d: %f\\n\", idx, data[idx]); } }","title":"Printf Debugging"},{"location":"gpu/cuda/#device-management","text":"","title":"Device Management"},{"location":"gpu/cuda/#device-properties","text":"void queryDevice() { int deviceCount; cudaGetDeviceCount(&deviceCount); for (int dev = 0; dev < deviceCount; dev++) { cudaDeviceProp prop; cudaGetDeviceProperties(&prop, dev); printf(\"Device %d: %s\\n\", dev, prop.name); printf(\" Compute capability: %d.%d\\n\", prop.major, prop.minor); printf(\" Total global memory: %zu MB\\n\", prop.totalGlobalMem / (1024*1024)); printf(\" Shared memory per block: %zu KB\\n\", prop.sharedMemPerBlock / 1024); printf(\" Max threads per block: %d\\n\", prop.maxThreadsPerBlock); printf(\" Warp size: %d\\n\", prop.warpSize); printf(\" Memory bus width: %d bits\\n\", prop.memoryBusWidth); printf(\" Memory clock rate: %d MHz\\n\", prop.memoryClockRate / 1000); } } void setDevice() { int device = 0; // Use device 0 cudaSetDevice(device); // Verify device was set int currentDevice; cudaGetDevice(&currentDevice); printf(\"Using device %d\\n\", currentDevice); }","title":"Device Properties"},{"location":"gpu/cuda/#multi-gpu-programming","text":"void multiGPU() { int deviceCount; cudaGetDeviceCount(&deviceCount); // Allocate data on each device float** d_data = new float*[deviceCount]; cudaStream_t* streams = new cudaStream_t[deviceCount]; for (int dev = 0; dev < deviceCount; dev++) { cudaSetDevice(dev); cudaMalloc(&d_data[dev], dataSize); cudaStreamCreate(&streams[dev]); // Launch work on this device kernel<<<grid, block, 0, streams[dev]>>>(d_data[dev]); } // Synchronize all devices for (int dev = 0; dev < deviceCount; dev++) { cudaSetDevice(dev); cudaStreamSynchronize(streams[dev]); cudaFree(d_data[dev]); cudaStreamDestroy(streams[dev]); } }","title":"Multi-GPU Programming"},{"location":"gpu/cuda/#quick-reference","text":"","title":"Quick Reference"},{"location":"gpu/cuda/#memory-copy-directions","text":"cudaMemcpyHostToDevice // CPU \u2192 GPU cudaMemcpyDeviceToHost // GPU \u2192 CPU cudaMemcpyDeviceToDevice // GPU \u2192 GPU cudaMemcpyHostToHost // CPU \u2192 CPU (rarely used)","title":"Memory Copy Directions"},{"location":"gpu/cuda/#built-in-variables","text":"// Thread indexing threadIdx.x, threadIdx.y, threadIdx.z // Thread index within block blockIdx.x, blockIdx.y, blockIdx.z // Block index within grid blockDim.x, blockDim.y, blockDim.z // Block dimensions gridDim.x, gridDim.y, gridDim.z // Grid dimensions // Warp information warpSize // Usually 32","title":"Built-in Variables"},{"location":"gpu/cuda/#mathematical-functions","text":"// Standard math functions (slower, double precision available) sin(), cos(), tan(), log(), exp(), sqrt(), pow() // Fast math functions (faster, single precision only) __sinf(), __cosf(), __tanf(), __logf(), __expf() __fsqrt_rn(), __fdividef() // Integer functions __clz() // Count leading zeros __popc() // Population count (number of set bits) __brev() // Bit reverse","title":"Mathematical Functions"},{"location":"gpu/cuda/#warp-shuffle-operations","text":"// Warp shuffle functions (CC >= 3.0) __shfl_sync(mask, var, srcLane) // Direct lane access __shfl_up_sync(mask, var, delta) // Shift up __shfl_down_sync(mask, var, delta) // Shift down __shfl_xor_sync(mask, var, laneMask) // XOR-based shuffle // Example: Warp reduction int value = threadIdx.x; for (int offset = 16; offset > 0; offset /= 2) { value += __shfl_down_sync(0xffffffff, value, offset); }","title":"Warp Shuffle Operations"},{"location":"gpu/cuda/#common-gotchas-best-practices","text":"","title":"Common Gotchas &amp; Best Practices"},{"location":"gpu/cuda/#memory-access-patterns","text":"Always aim for coalesced memory access - threads in a warp should access consecutive memory addresses Use shared memory for repeated data access - 100x faster than global memory Avoid bank conflicts in shared memory - pad arrays or use different access patterns Prefer AoS over SoA for coalesced access in most cases","title":"Memory Access Patterns"},{"location":"gpu/cuda/#thread-management","text":"Choose block sizes that are multiples of warp size (32) for best efficiency Aim for high occupancy but not at all costs - sometimes fewer blocks with more shared memory is better Use __syncthreads() carefully - all threads in the block must reach it Avoid divergent branches within warps when possible","title":"Thread Management"},{"location":"gpu/cuda/#performance-tips","text":"Use fast math functions ( __sinf , __expf , etc.) when precision allows Minimize register usage to increase occupancy Use texture memory for spatial locality in read-only data Consider using unified memory for easier development, but profile performance Profile your code with nsys/ncu to identify bottlenecks","title":"Performance Tips"},{"location":"gpu/cuda/#error-handling_1","text":"Always check CUDA API return values using error checking macros Use cudaGetLastError() after kernel launches to catch errors Synchronize before error checking for kernel execution errors Use CUDA-GDB for debugging device code when needed This cheat sheet covers the essential CUDA programming concepts and patterns. For the most current information, always refer to the official CUDA documentation .","title":"Error Handling"},{"location":"javascript/nextjs/","text":"Next.js Next.js is a React framework for building full-stack web applications with built-in optimization, routing, and deployment features. This cheat sheet covers Next.js 13+ with App Router and modern patterns. Quick Start Installation and Setup # Create new Next.js app npx create-next-app@latest my-app cd my-app npm run dev # With specific options # Next.js Next.js is a React framework for building full-stack web applications with built-in optimization, routing, and deployment features. This cheat sheet covers Next.js 15+ with App Router and modern patterns. ## Quick Start ### Installation and Setup ```bash # Create new Next.js app (Next.js 15 requires React 19) npx create-next-app@latest my-app cd my-app npm run dev # Manual installation npm install next@latest react@latest react-dom@latest Basic Project Structure my-app/ \u251c\u2500\u2500 app/ # App Router \u2502 \u251c\u2500\u2500 globals.css # Global styles \u2502 \u251c\u2500\u2500 layout.tsx # Root layout \u2502 \u251c\u2500\u2500 page.tsx # Home page \u2502 \u2514\u2500\u2500 loading.tsx # Loading UI \u251c\u2500\u2500 public/ # Static assets \u251c\u2500\u2500 next.config.js # Next.js configuration \u2514\u2500\u2500 package.json Basic Configuration // next.config.js /** @type {import('next').NextConfig} */ const nextConfig = { images: { remotePatterns: [ { protocol: 'https', hostname: 'assets.example.com', }, ], }, env: { CUSTOM_KEY: process.env.CUSTOM_KEY, } } module.exports = nextConfig App Router (Next.js 15+) File-based Routing app/ \u251c\u2500\u2500 page.tsx # / (home) \u251c\u2500\u2500 about/page.tsx # /about \u251c\u2500\u2500 blog/ \u2502 \u251c\u2500\u2500 page.tsx # /blog \u2502 \u2514\u2500\u2500 [slug]/page.tsx # /blog/[slug] (dynamic) \u2514\u2500\u2500 (dashboard)/ # Route groups (no URL segment) \u251c\u2500\u2500 settings/page.tsx # /settings \u2514\u2500\u2500 profile/page.tsx # /profile Asynchronous Pages and Layouts In Next.js 15, params and searchParams are now Promises. // app/blog/[slug]/page.tsx - Dynamic Page type Params = Promise<{ slug: string }> type SearchParams = Promise<{ [key: string]: string | string[] | undefined }> export default async function BlogPost({ params, searchParams }: { params: Params, searchParams: SearchParams }) { const { slug } = await params; const search = await searchParams; return ( <div> <h1>Blog Post: {slug}</h1> <p>Search params: {JSON.stringify(search)}</p> </div> ) } Special Files // app/loading.tsx - Loading UI export default function Loading() { return <div className=\"spinner\">Loading...</div> } // app/error.tsx - Error UI 'use client' export default function Error({ error, reset, }: { error: Error & { digest?: string } reset: () => void }) { return ( <div> <h2>Something went wrong!</h2> <p>{error.message}</p> <button onClick={reset}>Try again</button> </div> ) } Data Fetching Server Components (Default) In Next.js 15, fetch is not cached by default . You must opt-in. // Server Component - runs on server async function getData() { // Opt-in to caching const res = await fetch('https://api.example.com/data', { cache: 'force-cache', }); // No caching (SSR) const dynamicRes = await fetch('https://api.example.com/data', { cache: 'no-store', }); // Incremental Static Regeneration (ISR) const isrRes = await fetch('https://api.example.com/data', { next: { revalidate: 60 } // Revalidate every 60 seconds }); if (!res.ok) { throw new Error('Failed to fetch data') } return res.json() } export default async function PostsPage() { const posts = await getData() return ( <div> <h1>Posts</h1> {posts.map((post: any) => ( <article key={post.id}> <h2>{post.title}</h2> </article> ))} </div> ) } Client Components 'use client' import { useState, useEffect } from 'react' export default function ClientDataFetching() { const [data, setData] = useState(null) useEffect(() => { fetch('/api/data') .then(res => res.json()) .then(setData) }, []) if (!data) return <div>Loading...</div> return <div>{/* Render data */}</div> } Static Site Generation (SSG) // app/posts/[slug]/page.tsx // Generate static params at build time export async function generateStaticParams() { const posts = await fetch('https://.../posts').then((res) => res.json()) return posts.map((post) => ({ slug: post.slug })) } // Page component export default async function PostPage({ params }: { params: Promise<{ slug: string }> }) { const { slug } = await params; const post = await fetch(`https://.../posts/${slug}`).then((res) => res.json()) return <div>{post.title}</div> } API Routes (Route Handlers) Basic API Routes // app/api/hello/route.ts import { NextRequest, NextResponse } from 'next/server' export async function GET() { return NextResponse.json({ message: 'Hello World' }) } Dynamic API Routes In Next.js 15, params in Route Handlers is a Promise. // app/api/users/[id]/route.ts import { NextRequest, NextResponse } from 'next/server' type Params = Promise<{ id: string }> export async function GET(request: NextRequest, { params }: { params: Params }) { const { id } = await params; const user = await getUserById(id); if (!user) { return new NextResponse('User not found', { status: 404 }) } return NextResponse.json(user) } Asynchronous Headers and Cookies // app/api/some-route/route.ts import { cookies, headers } from 'next/headers' import { NextRequest, NextResponse } from 'next/server' export async function GET(request: NextRequest) { const headersList = await headers() const userAgent = headersList.get('user-agent') const cookieStore = await cookies() const token = cookieStore.get('token') return NextResponse.json({ userAgent, token: token?.value }) } Navigation and Routing Link Component import Link from 'next/link' export default function Navigation() { return ( <nav> <Link href=\"/about\">About</Link> <Link href=\"/products\" className=\"nav-link\">Products</Link> <Link href={`/posts/${post.slug}`}>{post.title}</Link> </nav> ) } useRouter Hook 'use client' import { useRouter, usePathname, useSearchParams } from 'next/navigation' export default function ClientNavigation() { const router = useRouter() const pathname = usePathname() const searchParams = useSearchParams() const handleNavigation = () => { router.push('/dashboard') } return ( <div> <p>Current path: {pathname}</p> <button onClick={handleNavigation}>Go to Dashboard</button> </div> ) } Performance Optimization Partial Prerendering (PPR) Enable PPR in next.config.js for incremental static/dynamic rendering. // next.config.js /** @type {import('next').NextConfig} */ const nextConfig = { experimental: { ppr: 'incremental', }, } module.exports = nextConfig Caching Strategies fetch is no longer cached by default. // Default: No caching (SSR) const dynamicData = await fetch('https://api.example.com/dynamic-data') // Static caching (opt-in) const staticData = await fetch('https://api.example.com/static-data', { cache: 'force-cache' }) // Time-based revalidation (ISR) const revalidatedData = await fetch('https://api.example.com/data', { next: { revalidate: 60 } // Revalidate every 60 seconds }) // Set default caching for a layout or page export const fetchCache = 'default-cache' SEO and Metadata Dynamic Metadata params is now a Promise. import type { Metadata } from 'next' type Props = { params: Promise<{ slug: string }> } export async function generateMetadata({ params }: Props): Promise<Metadata> { const { slug } = await params; const post = await fetch(`https://.../posts/${slug}`).then((res) => res.json()) return { title: post.title, description: post.excerpt, } } export default async function PostPage({ params }: { params: Promise<{ slug:string }> }) { const { slug } = await params; const post = await fetch(`https://.../posts/${slug}`).then((res) => res.json()) return <div>{post.title}</div> } This comprehensive Next.js cheat sheet covers modern patterns, App Router features, and best practices for building production-ready applications with Next.js 15+. Focus on understanding the App Router paradigm, server/client component patterns, and data fetching strategies for effective Next.js development. Manual installation npm install next@latest react@latest react-dom@latest ### Basic Project Structure my-app/ \u251c\u2500\u2500 app/ # App Router (Next.js 13+) \u2502 \u251c\u2500\u2500 globals.css # Global styles \u2502 \u251c\u2500\u2500 layout.tsx # Root layout \u2502 \u251c\u2500\u2500 page.tsx # Home page \u2502 \u2514\u2500\u2500 loading.tsx # Loading UI \u251c\u2500\u2500 public/ # Static assets \u251c\u2500\u2500 next.config.js # Next.js configuration \u2514\u2500\u2500 package.json ### Basic Configuration ```javascript // next.config.js /** @type {import('next').NextConfig} */ const nextConfig = { images: { domains: ['example.com'], formats: ['image/webp', 'image/avif'], }, env: { CUSTOM_KEY: process.env.CUSTOM_KEY, } } module.exports = nextConfig App Router (Next.js 13+) File-based Routing app/ \u251c\u2500\u2500 page.tsx # / (home) \u251c\u2500\u2500 about/page.tsx # /about \u251c\u2500\u2500 blog/ \u2502 \u251c\u2500\u2500 page.tsx # /blog \u2502 \u2514\u2500\u2500 [slug]/page.tsx # /blog/[slug] (dynamic) \u251c\u2500\u2500 products/ \u2502 \u251c\u2500\u2500 page.tsx # /products \u2502 \u251c\u2500\u2500 [id]/page.tsx # /products/[id] \u2502 \u2514\u2500\u2500 [...slug]/page.tsx # /products/[...slug] (catch-all) \u2514\u2500\u2500 (dashboard)/ # Route groups (no URL segment) \u251c\u2500\u2500 settings/page.tsx # /settings \u2514\u2500\u2500 profile/page.tsx # /profile Layout Components // app/layout.tsx - Root Layout import type { Metadata } from 'next' export const metadata: Metadata = { title: 'My App', description: 'Generated by Next.js', } export default function RootLayout({ children, }: { children: React.ReactNode }) { return ( <html lang=\"en\"> <body> <header> <nav>{/* Navigation */}</nav> </header> <main>{children}</main> <footer>{/* Footer */}</footer> </body> </html> ) } // app/dashboard/layout.tsx - Nested Layout export default function DashboardLayout({ children, }: { children: React.ReactNode }) { return ( <div className=\"dashboard\"> <aside> {/* Sidebar */} </aside> <div className=\"content\"> {children} </div> </div> ) } Pages // app/page.tsx - Home Page export default function HomePage() { return ( <div> <h1>Welcome to Next.js</h1> <p>This is the home page</p> </div> ) } // app/about/page.tsx - About Page export default function AboutPage() { return ( <div> <h1>About Us</h1> <p>Learn more about our company</p> </div> ) } // app/blog/[slug]/page.tsx - Dynamic Page interface Props { params: { slug: string } searchParams: { [key: string]: string | string[] | undefined } } export default function BlogPost({ params, searchParams }: Props) { return ( <div> <h1>Blog Post: {params.slug}</h1> <p>Search params: {JSON.stringify(searchParams)}</p> </div> ) } Special Files // app/loading.tsx - Loading UI export default function Loading() { return <div className=\"spinner\">Loading...</div> } // app/error.tsx - Error UI 'use client' export default function Error({ error, reset, }: { error: Error & { digest?: string } reset: () => void }) { return ( <div> <h2>Something went wrong!</h2> <p>{error.message}</p> <button onClick={reset}>Try again</button> </div> ) } // app/not-found.tsx - 404 Page import Link from 'next/link' export default function NotFound() { return ( <div> <h2>Page Not Found</h2> <p>Could not find the requested page.</p> <Link href=\"/\">Return Home</Link> </div> ) } Data Fetching Server Components (Default) // Server Component - runs on server async function getData() { const res = await fetch('https://api.example.com/data', { cache: 'force-cache', // Default caching // cache: 'no-store', // No caching (SSR) // next: { revalidate: 60 } // Revalidate every 60 seconds }) if (!res.ok) { throw new Error('Failed to fetch data') } return res.json() } export default async function PostsPage() { const posts = await getData() return ( <div> <h1>Posts</h1> {posts.map((post: any) => ( <article key={post.id}> <h2>{post.title}</h2> <p>{post.content}</p> </article> ))} </div> ) } Client Components 'use client' import { useState, useEffect } from 'react' export default function ClientDataFetching() { const [data, setData] = useState(null) const [loading, setLoading] = useState(true) useEffect(() => { fetch('/api/data') .then(res => res.json()) .then(data => { setData(data) setLoading(false) }) }, []) if (loading) return <div>Loading...</div> return ( <div> <h1>Client-side Data</h1> <pre>{JSON.stringify(data, null, 2)}</pre> </div> ) } Static Site Generation (SSG) // app/posts/[slug]/page.tsx interface Post { id: string title: string content: string slug: string } // Generate static params at build time export async function generateStaticParams() { const posts = await fetch('https://api.example.com/posts').then(res => res.json()) return posts.map((post: Post) => ({ slug: post.slug, })) } // Generate metadata for each page export async function generateMetadata( { params }: { params: { slug: string } } ) { const post = await fetch(`https://api.example.com/posts/${params.slug}`) .then(res => res.json()) return { title: post.title, description: post.excerpt, } } // Page component export default async function PostPage({ params }: { params: { slug: string } }) { const post = await fetch(`https://api.example.com/posts/${params.slug}`) .then(res => res.json()) return ( <article> <h1>{post.title}</h1> <div dangerouslySetInnerHTML={{ __html: post.content }} /> </article> ) } Incremental Static Regeneration (ISR) async function getData() { const res = await fetch('https://api.example.com/posts', { next: { revalidate: 3600 } // Revalidate every hour }) return res.json() } export default async function PostsPage() { const posts = await getData() return ( <div> {posts.map((post: any) => ( <div key={post.id}>{post.title}</div> ))} </div> ) } API Routes Basic API Routes // app/api/hello/route.ts import { NextRequest, NextResponse } from 'next/server' export async function GET() { return NextResponse.json({ message: 'Hello World' }) } export async function POST(request: NextRequest) { const body = await request.json() return NextResponse.json({ message: 'Data received', data: body }) } Dynamic API Routes // app/api/users/[id]/route.ts import { NextRequest, NextResponse } from 'next/server' export async function GET( request: NextRequest, { params }: { params: { id: string } } ) { const id = params.id // Fetch user data const user = await getUserById(id) if (!user) { return new NextResponse('User not found', { status: 404 }) } return NextResponse.json(user) } export async function PUT( request: NextRequest, { params }: { params: { id: string } } ) { const id = params.id const body = await request.json() const updatedUser = await updateUser(id, body) return NextResponse.json(updatedUser) } export async function DELETE( request: NextRequest, { params }: { params: { id: string } } ) { const id = params.id await deleteUser(id) return new NextResponse(null, { status: 204 }) } Error Handling in API Routes // app/api/protected/route.ts import { NextRequest, NextResponse } from 'next/server' export async function GET(request: NextRequest) { try { // Check authentication const token = request.headers.get('authorization') if (!token) { return new NextResponse('Unauthorized', { status: 401 }) } // Validate token const user = await validateToken(token) if (!user) { return new NextResponse('Invalid token', { status: 401 }) } // Return protected data const data = await getProtectedData(user.id) return NextResponse.json(data) } catch (error) { console.error('API Error:', error) return new NextResponse('Internal Server Error', { status: 500 }) } } Middleware // middleware.ts (in root directory) import { NextResponse } from 'next/server' import type { NextRequest } from 'next/server' export function middleware(request: NextRequest) { // Check if user is authenticated const token = request.cookies.get('auth-token') if (!token && request.nextUrl.pathname.startsWith('/dashboard')) { return NextResponse.redirect(new URL('/login', request.url)) } // Add custom headers const response = NextResponse.next() response.headers.set('x-custom-header', 'my-value') return response } export const config = { matcher: ['/dashboard/:path*', '/api/:path*'] } Navigation and Routing Link Component import Link from 'next/link' export default function Navigation() { return ( <nav> {/* Basic link */} <Link href=\"/about\">About</Link> {/* Link with custom styling */} <Link href=\"/products\" className=\"nav-link\"> Products </Link> {/* Dynamic link */} <Link href={`/posts/${post.slug}`}> {post.title} </Link> {/* External link */} <Link href=\"https://example.com\" target=\"_blank\"> External Link </Link> {/* Link with query parameters */} <Link href={{ pathname: '/search', query: { q: 'nextjs' } }} > Search </Link> </nav> ) } useRouter Hook 'use client' import { useRouter, usePathname, useSearchParams } from 'next/navigation' export default function ClientNavigation() { const router = useRouter() const pathname = usePathname() const searchParams = useSearchParams() const handleNavigation = () => { // Programmatic navigation router.push('/dashboard') // router.replace('/dashboard') // Replace current entry // router.back() // Go back // router.forward() // Go forward } const handleSearch = (term: string) => { // Update URL with search params const params = new URLSearchParams(searchParams) params.set('q', term) router.push(`${pathname}?${params.toString()}`) } return ( <div> <p>Current path: {pathname}</p> <p>Search: {searchParams.get('q')}</p> <button onClick={handleNavigation}>Go to Dashboard</button> <input type=\"text\" onChange={(e) => handleSearch(e.target.value)} placeholder=\"Search...\" /> </div> ) } Styling CSS Modules // components/Button.module.css .button { padding: 0.5rem 1rem; border: none; border-radius: 4px; background-color: #0070f3; color: white; cursor: pointer; } .button:hover { background-color: #0051a2; } .primary { background-color: #0070f3; } .secondary { background-color: #666; } // components/Button.tsx import styles from './Button.module.css' interface ButtonProps { children: React.ReactNode variant?: 'primary' | 'secondary' onClick?: () => void } export default function Button({ children, variant = 'primary', onClick }: ButtonProps) { return ( <button className={`${styles.button} ${styles[variant]}`} onClick={onClick} > {children} </button> ) } Global Styles /* app/globals.css */ * { box-sizing: border-box; padding: 0; margin: 0; } html, body { max-width: 100vw; overflow-x: hidden; } body { color: rgb(var(--foreground-rgb)); background: linear-gradient( to bottom, transparent, rgb(var(--background-end-rgb)) ) rgb(var(--background-start-rgb)); } Tailwind CSS Integration // Install: npm install -D tailwindcss postcss autoprefixer // Initialize: npx tailwindcss init -p // tailwind.config.js /** @type {import('tailwindcss').Config} */ module.exports = { content: [ './app/**/*.{js,ts,jsx,tsx,mdx}', './components/**/*.{js,ts,jsx,tsx,mdx}', ], theme: { extend: {}, }, plugins: [], } // Component with Tailwind classes export default function Card({ children }: { children: React.ReactNode }) { return ( <div className=\"max-w-sm mx-auto bg-white rounded-xl shadow-md overflow-hidden\"> <div className=\"p-6\"> {children} </div> </div> ) } Image Optimization Next.js Image Component import Image from 'next/image' export default function Gallery() { return ( <div> {/* Local image */} <Image src=\"/hero-image.jpg\" alt=\"Hero\" width={800} height={600} priority // Load immediately /> {/* Remote image */} <Image src=\"https://example.com/image.jpg\" alt=\"Remote image\" width={400} height={300} placeholder=\"blur\" blurDataURL=\"data:image/jpeg;base64,...\" // Base64 blur placeholder /> {/* Responsive image */} <Image src=\"/responsive-image.jpg\" alt=\"Responsive\" fill style={{ objectFit: 'cover' }} /> {/* Image with custom loader */} <Image src=\"image-key\" alt=\"Custom loader\" width={300} height={200} loader={({ src, width, quality }) => { return `https://cdn.example.com/${src}?w=${width}&q=${quality || 75}` }} /> </div> ) } Image Configuration // next.config.js /** @type {import('next').NextConfig} */ const nextConfig = { images: { domains: ['example.com', 'cdn.example.com'], deviceSizes: [640, 750, 828, 1080, 1200, 1920, 2048, 3840], imageSizes: [16, 32, 48, 64, 96, 128, 256, 384], formats: ['image/webp', 'image/avif'], minimumCacheTTL: 60, dangerouslyAllowSVG: true, contentDispositionType: 'attachment', }, } module.exports = nextConfig Authentication Patterns Session-based Authentication // app/api/auth/login/route.ts import { NextRequest, NextResponse } from 'next/server' import { cookies } from 'next/headers' import jwt from 'jsonwebtoken' export async function POST(request: NextRequest) { const { email, password } = await request.json() // Validate credentials const user = await validateUser(email, password) if (!user) { return new NextResponse('Invalid credentials', { status: 401 }) } // Create JWT token const token = jwt.sign( { userId: user.id, email: user.email }, process.env.JWT_SECRET!, { expiresIn: '7d' } ) // Set cookie cookies().set('auth-token', token, { httpOnly: true, secure: process.env.NODE_ENV === 'production', sameSite: 'strict', maxAge: 60 * 60 * 24 * 7, // 7 days }) return NextResponse.json({ user: { id: user.id, email: user.email } }) } Protected Routes // app/dashboard/page.tsx import { cookies } from 'next/headers' import { redirect } from 'next/navigation' import jwt from 'jsonwebtoken' async function getCurrentUser() { const token = cookies().get('auth-token')?.value if (!token) { return null } try { const decoded = jwt.verify(token, process.env.JWT_SECRET!) as any return await getUserById(decoded.userId) } catch { return null } } export default async function DashboardPage() { const user = await getCurrentUser() if (!user) { redirect('/login') } return ( <div> <h1>Welcome, {user.name}!</h1> <p>This is your dashboard</p> </div> ) } Environment Variables Environment Configuration # .env.local (not committed to Git) DATABASE_URL=postgresql://... JWT_SECRET=your-secret-key API_KEY=your-api-key # .env (committed to Git - public variables only) NEXT_PUBLIC_APP_NAME=My App NEXT_PUBLIC_API_URL=https://api.example.com // lib/env.ts - Type-safe environment variables export const env = { DATABASE_URL: process.env.DATABASE_URL!, JWT_SECRET: process.env.JWT_SECRET!, // Public variables (available in browser) NEXT_PUBLIC_APP_NAME: process.env.NEXT_PUBLIC_APP_NAME!, NEXT_PUBLIC_API_URL: process.env.NEXT_PUBLIC_API_URL!, } // Usage in components export default function Header() { return ( <header> <h1>{env.NEXT_PUBLIC_APP_NAME}</h1> </header> ) } Database Integration Prisma Setup # Install Prisma npm install prisma @prisma/client npx prisma init # Generate client after schema changes npx prisma generate # Run migrations npx prisma migrate dev --name init // lib/prisma.ts import { PrismaClient } from '@prisma/client' const globalForPrisma = globalThis as unknown as { prisma: PrismaClient | undefined } export const prisma = globalForPrisma.prisma ?? new PrismaClient() if (process.env.NODE_ENV !== 'production') globalForPrisma.prisma = prisma // app/api/posts/route.ts import { NextResponse } from 'next/server' import { prisma } from '@/lib/prisma' export async function GET() { const posts = await prisma.post.findMany({ include: { author: { select: { name: true, email: true, }, }, }, orderBy: { createdAt: 'desc', }, }) return NextResponse.json(posts) } export async function POST(request: Request) { const { title, content, authorId } = await request.json() const post = await prisma.post.create({ data: { title, content, authorId, }, }) return NextResponse.json(post, { status: 201 }) } Performance Optimization Code Splitting and Lazy Loading import { lazy, Suspense } from 'react' import dynamic from 'next/dynamic' // React.lazy (client-side only) const LazyComponent = lazy(() => import('../components/ExpensiveComponent')) // Next.js dynamic imports const DynamicComponent = dynamic(() => import('../components/DynamicComponent'), { loading: () => <p>Loading...</p>, ssr: false, // Disable SSR for this component }) // Dynamic import with named export const DynamicChart = dynamic( () => import('../components/Chart').then(mod => mod.Chart), { ssr: false } ) export default function Page() { return ( <div> <h1>My Page</h1> <Suspense fallback={<div>Loading lazy component...</div>}> <LazyComponent /> </Suspense> <DynamicComponent /> <DynamicChart data={chartData} /> </div> ) } Caching Strategies // Static caching (default) const staticData = await fetch('https://api.example.com/static-data') // No caching (SSR) const dynamicData = await fetch('https://api.example.com/dynamic-data', { cache: 'no-store' }) // Time-based revalidation (ISR) const revalidatedData = await fetch('https://api.example.com/data', { next: { revalidate: 60 } // Revalidate every 60 seconds }) // Tag-based revalidation const taggedData = await fetch('https://api.example.com/data', { next: { tags: ['posts'] } }) // Manual revalidation import { revalidateTag, revalidatePath } from 'next/cache' // In API route or server action revalidateTag('posts') // Revalidate all requests with 'posts' tag revalidatePath('/posts') // Revalidate specific path SEO and Metadata Dynamic Metadata import type { Metadata } from 'next' interface Props { params: { slug: string } } export async function generateMetadata({ params }: Props): Promise<Metadata> { const post = await fetch(`https://api.example.com/posts/${params.slug}`) .then(res => res.json()) return { title: post.title, description: post.excerpt, openGraph: { title: post.title, description: post.excerpt, images: [ { url: post.featuredImage, width: 1200, height: 630, alt: post.title, }, ], }, twitter: { card: 'summary_large_image', title: post.title, description: post.excerpt, images: [post.featuredImage], }, } } export default async function PostPage({ params }: Props) { const post = await fetch(`https://api.example.com/posts/${params.slug}`) .then(res => res.json()) return ( <article> <h1>{post.title}</h1> <div dangerouslySetInnerHTML={{ __html: post.content }} /> </article> ) } Sitemap Generation // app/sitemap.ts import type { MetadataRoute } from 'next' export default function sitemap(): MetadataRoute.Sitemap { return [ { url: 'https://example.com', lastModified: new Date(), changeFrequency: 'yearly', priority: 1, }, { url: 'https://example.com/about', lastModified: new Date(), changeFrequency: 'monthly', priority: 0.8, }, { url: 'https://example.com/blog', lastModified: new Date(), changeFrequency: 'weekly', priority: 0.5, }, ] } Robots.txt // app/robots.ts import type { MetadataRoute } from 'next' export default function robots(): MetadataRoute.Robots { return { rules: { userAgent: '*', allow: '/', disallow: '/private/', }, sitemap: 'https://example.com/sitemap.xml', } } Testing Jest Setup // jest.config.js /** @type {import('jest').Config} */ const config = { testEnvironment: 'jsdom', setupFilesAfterEnv: ['<rootDir>/jest.setup.js'], moduleNameMapping: { '^@/(.*)$': '<rootDir>/$1', }, transform: { '^.+\\\\.(js|jsx|ts|tsx)$': ['babel-jest', { presets: ['next/babel'] }], }, } module.exports = config // jest.setup.js import '@testing-library/jest-dom' Component Testing // __tests__/components/Button.test.tsx import { render, screen, fireEvent } from '@testing-library/react' import Button from '@/components/Button' describe('Button', () => { test('renders with correct text', () => { render(<Button>Click me</Button>) expect(screen.getByText('Click me')).toBeInTheDocument() }) test('calls onClick when clicked', () => { const handleClick = jest.fn() render(<Button onClick={handleClick}>Click me</Button>) fireEvent.click(screen.getByText('Click me')) expect(handleClick).toHaveBeenCalledTimes(1) }) }) API Route Testing // __tests__/api/users.test.ts import { GET } from '@/app/api/users/route' // Adjust path as needed import { NextRequest } from 'next/server' describe('/api/users route', () => { it('returns a successful response with a list of users', async () => { // Mock the request object const request = new NextRequest('http://localhost/api/users') // Call the route handler const response = await GET(request) const body = await response.json() // Assertions expect(response.status).toBe(200) expect(body).toHaveProperty('users') expect(Array.isArray(body.users)).toBe(true) }) }) Deployment Vercel Deployment # Install Vercel CLI npm i -g vercel # Deploy vercel # Deploy to production vercel --prod Docker Deployment # Dockerfile FROM node:18-alpine AS base FROM base AS deps RUN apk add --no-cache libc6-compat WORKDIR /app COPY package.json yarn.lock* package-lock.json* pnpm-lock.yaml* ./ RUN \\ if [ -f yarn.lock ]; then yarn --frozen-lockfile; \\ elif [ -f package-lock.json ]; then npm ci; \\ elif [ -f pnpm-lock.yaml ]; then yarn global add pnpm && pnpm i --frozen-lockfile; \\ else echo \"Lockfile not found.\" && exit 1; \\ fi FROM base AS builder WORKDIR /app COPY --from=deps /app/node_modules ./node_modules COPY . . RUN yarn build FROM base AS runner WORKDIR /app ENV NODE_ENV production RUN addgroup --system --gid 1001 nodejs RUN adduser --system --uid 1001 nextjs COPY --from=builder /app/public ./public RUN mkdir .next RUN chown nextjs:nodejs .next COPY --from=builder --chown=nextjs:nodejs /app/.next/standalone ./ COPY --from=builder --chown=nextjs:nodejs /app/.next/static ./.next/static USER nextjs EXPOSE 3000 ENV PORT 3000 CMD [\"node\", \"server.js\"] Environment Variables for Production # .env.production NEXT_PUBLIC_API_URL=https://api.production.com DATABASE_URL=postgresql://prod-db... JWT_SECRET=production-secret-key Common Patterns and Best Practices Error Handling // Global error boundary 'use client' import { useEffect } from 'react' export default function GlobalError({ error, reset, }: { error: Error & { digest?: string } reset: () => void }) { useEffect(() => { console.error(error) }, [error]) return ( <html> <body> <h2>Something went wrong!</h2> <button onClick={() => reset()}>Try again</button> </body> </html> ) } Loading States // app/dashboard/loading.tsx export default function DashboardLoading() { return ( <div className=\"animate-pulse\"> <div className=\"h-8 bg-gray-200 rounded mb-4\"></div> <div className=\"h-4 bg-gray-200 rounded mb-2\"></div> <div className=\"h-4 bg-gray-200 rounded mb-2\"></div> <div className=\"h-4 bg-gray-200 rounded w-3/4\"></div> </div> ) } Form Handling with Server Actions // app/contact/page.tsx import { redirect } from 'next/navigation' async function createContact(formData: FormData) { 'use server' const name = formData.get('name') as string const email = formData.get('email') as string const message = formData.get('message') as string // Save to database await saveContact({ name, email, message }) redirect('/contact/success') } export default function ContactPage() { return ( <form action={createContact}> <input type=\"text\" name=\"name\" placeholder=\"Name\" required /> <input type=\"email\" name=\"email\" placeholder=\"Email\" required /> <textarea name=\"message\" placeholder=\"Message\" required /> <button type=\"submit\">Send Message</button> </form> ) } TypeScript Configuration // tsconfig.json { \"compilerOptions\": { \"lib\": [\"dom\", \"dom.iterable\", \"es6\"], \"allowJs\": true, \"skipLibCheck\": true, \"strict\": true, \"noEmit\": true, \"esModuleInterop\": true, \"module\": \"esnext\", \"moduleResolution\": \"bundler\", \"resolveJsonModule\": true, \"isolatedModules\": true, \"jsx\": \"preserve\", \"incremental\": true, \"plugins\": [ { \"name\": \"next\" } ], \"baseUrl\": \".\", \"paths\": { \"@/*\": [\"./*\"], \"@/components/*\": [\"./components/*\"], \"@/lib/*\": [\"./lib/*\"] } }, \"include\": [\"next-env.d.ts\", \"**/*.ts\", \"**/*.tsx\", \".next/types/**/*.ts\"], \"exclude\": [\"node_modules\"] } This comprehensive Next.js cheat sheet covers modern patterns, App Router features, and best practices for building production-ready applications with Next.js 13+. Focus on understanding the App Router paradigm, server/client component patterns, and data fetching strategies for effective Next.js development.","title":"Next.js"},{"location":"javascript/nextjs/#nextjs","text":"Next.js is a React framework for building full-stack web applications with built-in optimization, routing, and deployment features. This cheat sheet covers Next.js 13+ with App Router and modern patterns.","title":"Next.js"},{"location":"javascript/nextjs/#quick-start","text":"","title":"Quick Start"},{"location":"javascript/nextjs/#installation-and-setup","text":"# Create new Next.js app npx create-next-app@latest my-app cd my-app npm run dev # With specific options # Next.js Next.js is a React framework for building full-stack web applications with built-in optimization, routing, and deployment features. This cheat sheet covers Next.js 15+ with App Router and modern patterns. ## Quick Start ### Installation and Setup ```bash # Create new Next.js app (Next.js 15 requires React 19) npx create-next-app@latest my-app cd my-app npm run dev # Manual installation npm install next@latest react@latest react-dom@latest","title":"Installation and Setup"},{"location":"javascript/nextjs/#basic-project-structure","text":"my-app/ \u251c\u2500\u2500 app/ # App Router \u2502 \u251c\u2500\u2500 globals.css # Global styles \u2502 \u251c\u2500\u2500 layout.tsx # Root layout \u2502 \u251c\u2500\u2500 page.tsx # Home page \u2502 \u2514\u2500\u2500 loading.tsx # Loading UI \u251c\u2500\u2500 public/ # Static assets \u251c\u2500\u2500 next.config.js # Next.js configuration \u2514\u2500\u2500 package.json","title":"Basic Project Structure"},{"location":"javascript/nextjs/#basic-configuration","text":"// next.config.js /** @type {import('next').NextConfig} */ const nextConfig = { images: { remotePatterns: [ { protocol: 'https', hostname: 'assets.example.com', }, ], }, env: { CUSTOM_KEY: process.env.CUSTOM_KEY, } } module.exports = nextConfig","title":"Basic Configuration"},{"location":"javascript/nextjs/#app-router-nextjs-15","text":"","title":"App Router (Next.js 15+)"},{"location":"javascript/nextjs/#file-based-routing","text":"app/ \u251c\u2500\u2500 page.tsx # / (home) \u251c\u2500\u2500 about/page.tsx # /about \u251c\u2500\u2500 blog/ \u2502 \u251c\u2500\u2500 page.tsx # /blog \u2502 \u2514\u2500\u2500 [slug]/page.tsx # /blog/[slug] (dynamic) \u2514\u2500\u2500 (dashboard)/ # Route groups (no URL segment) \u251c\u2500\u2500 settings/page.tsx # /settings \u2514\u2500\u2500 profile/page.tsx # /profile","title":"File-based Routing"},{"location":"javascript/nextjs/#asynchronous-pages-and-layouts","text":"In Next.js 15, params and searchParams are now Promises. // app/blog/[slug]/page.tsx - Dynamic Page type Params = Promise<{ slug: string }> type SearchParams = Promise<{ [key: string]: string | string[] | undefined }> export default async function BlogPost({ params, searchParams }: { params: Params, searchParams: SearchParams }) { const { slug } = await params; const search = await searchParams; return ( <div> <h1>Blog Post: {slug}</h1> <p>Search params: {JSON.stringify(search)}</p> </div> ) }","title":"Asynchronous Pages and Layouts"},{"location":"javascript/nextjs/#special-files","text":"// app/loading.tsx - Loading UI export default function Loading() { return <div className=\"spinner\">Loading...</div> } // app/error.tsx - Error UI 'use client' export default function Error({ error, reset, }: { error: Error & { digest?: string } reset: () => void }) { return ( <div> <h2>Something went wrong!</h2> <p>{error.message}</p> <button onClick={reset}>Try again</button> </div> ) }","title":"Special Files"},{"location":"javascript/nextjs/#data-fetching","text":"","title":"Data Fetching"},{"location":"javascript/nextjs/#server-components-default","text":"In Next.js 15, fetch is not cached by default . You must opt-in. // Server Component - runs on server async function getData() { // Opt-in to caching const res = await fetch('https://api.example.com/data', { cache: 'force-cache', }); // No caching (SSR) const dynamicRes = await fetch('https://api.example.com/data', { cache: 'no-store', }); // Incremental Static Regeneration (ISR) const isrRes = await fetch('https://api.example.com/data', { next: { revalidate: 60 } // Revalidate every 60 seconds }); if (!res.ok) { throw new Error('Failed to fetch data') } return res.json() } export default async function PostsPage() { const posts = await getData() return ( <div> <h1>Posts</h1> {posts.map((post: any) => ( <article key={post.id}> <h2>{post.title}</h2> </article> ))} </div> ) }","title":"Server Components (Default)"},{"location":"javascript/nextjs/#client-components","text":"'use client' import { useState, useEffect } from 'react' export default function ClientDataFetching() { const [data, setData] = useState(null) useEffect(() => { fetch('/api/data') .then(res => res.json()) .then(setData) }, []) if (!data) return <div>Loading...</div> return <div>{/* Render data */}</div> }","title":"Client Components"},{"location":"javascript/nextjs/#static-site-generation-ssg","text":"// app/posts/[slug]/page.tsx // Generate static params at build time export async function generateStaticParams() { const posts = await fetch('https://.../posts').then((res) => res.json()) return posts.map((post) => ({ slug: post.slug })) } // Page component export default async function PostPage({ params }: { params: Promise<{ slug: string }> }) { const { slug } = await params; const post = await fetch(`https://.../posts/${slug}`).then((res) => res.json()) return <div>{post.title}</div> }","title":"Static Site Generation (SSG)"},{"location":"javascript/nextjs/#api-routes-route-handlers","text":"","title":"API Routes (Route Handlers)"},{"location":"javascript/nextjs/#basic-api-routes","text":"// app/api/hello/route.ts import { NextRequest, NextResponse } from 'next/server' export async function GET() { return NextResponse.json({ message: 'Hello World' }) }","title":"Basic API Routes"},{"location":"javascript/nextjs/#dynamic-api-routes","text":"In Next.js 15, params in Route Handlers is a Promise. // app/api/users/[id]/route.ts import { NextRequest, NextResponse } from 'next/server' type Params = Promise<{ id: string }> export async function GET(request: NextRequest, { params }: { params: Params }) { const { id } = await params; const user = await getUserById(id); if (!user) { return new NextResponse('User not found', { status: 404 }) } return NextResponse.json(user) }","title":"Dynamic API Routes"},{"location":"javascript/nextjs/#asynchronous-headers-and-cookies","text":"// app/api/some-route/route.ts import { cookies, headers } from 'next/headers' import { NextRequest, NextResponse } from 'next/server' export async function GET(request: NextRequest) { const headersList = await headers() const userAgent = headersList.get('user-agent') const cookieStore = await cookies() const token = cookieStore.get('token') return NextResponse.json({ userAgent, token: token?.value }) }","title":"Asynchronous Headers and Cookies"},{"location":"javascript/nextjs/#navigation-and-routing","text":"","title":"Navigation and Routing"},{"location":"javascript/nextjs/#link-component","text":"import Link from 'next/link' export default function Navigation() { return ( <nav> <Link href=\"/about\">About</Link> <Link href=\"/products\" className=\"nav-link\">Products</Link> <Link href={`/posts/${post.slug}`}>{post.title}</Link> </nav> ) }","title":"Link Component"},{"location":"javascript/nextjs/#userouter-hook","text":"'use client' import { useRouter, usePathname, useSearchParams } from 'next/navigation' export default function ClientNavigation() { const router = useRouter() const pathname = usePathname() const searchParams = useSearchParams() const handleNavigation = () => { router.push('/dashboard') } return ( <div> <p>Current path: {pathname}</p> <button onClick={handleNavigation}>Go to Dashboard</button> </div> ) }","title":"useRouter Hook"},{"location":"javascript/nextjs/#performance-optimization","text":"","title":"Performance Optimization"},{"location":"javascript/nextjs/#partial-prerendering-ppr","text":"Enable PPR in next.config.js for incremental static/dynamic rendering. // next.config.js /** @type {import('next').NextConfig} */ const nextConfig = { experimental: { ppr: 'incremental', }, } module.exports = nextConfig","title":"Partial Prerendering (PPR)"},{"location":"javascript/nextjs/#caching-strategies","text":"fetch is no longer cached by default. // Default: No caching (SSR) const dynamicData = await fetch('https://api.example.com/dynamic-data') // Static caching (opt-in) const staticData = await fetch('https://api.example.com/static-data', { cache: 'force-cache' }) // Time-based revalidation (ISR) const revalidatedData = await fetch('https://api.example.com/data', { next: { revalidate: 60 } // Revalidate every 60 seconds }) // Set default caching for a layout or page export const fetchCache = 'default-cache'","title":"Caching Strategies"},{"location":"javascript/nextjs/#seo-and-metadata","text":"","title":"SEO and Metadata"},{"location":"javascript/nextjs/#dynamic-metadata","text":"params is now a Promise. import type { Metadata } from 'next' type Props = { params: Promise<{ slug: string }> } export async function generateMetadata({ params }: Props): Promise<Metadata> { const { slug } = await params; const post = await fetch(`https://.../posts/${slug}`).then((res) => res.json()) return { title: post.title, description: post.excerpt, } } export default async function PostPage({ params }: { params: Promise<{ slug:string }> }) { const { slug } = await params; const post = await fetch(`https://.../posts/${slug}`).then((res) => res.json()) return <div>{post.title}</div> } This comprehensive Next.js cheat sheet covers modern patterns, App Router features, and best practices for building production-ready applications with Next.js 15+. Focus on understanding the App Router paradigm, server/client component patterns, and data fetching strategies for effective Next.js development.","title":"Dynamic Metadata"},{"location":"javascript/nextjs/#manual-installation","text":"npm install next@latest react@latest react-dom@latest ### Basic Project Structure my-app/ \u251c\u2500\u2500 app/ # App Router (Next.js 13+) \u2502 \u251c\u2500\u2500 globals.css # Global styles \u2502 \u251c\u2500\u2500 layout.tsx # Root layout \u2502 \u251c\u2500\u2500 page.tsx # Home page \u2502 \u2514\u2500\u2500 loading.tsx # Loading UI \u251c\u2500\u2500 public/ # Static assets \u251c\u2500\u2500 next.config.js # Next.js configuration \u2514\u2500\u2500 package.json ### Basic Configuration ```javascript // next.config.js /** @type {import('next').NextConfig} */ const nextConfig = { images: { domains: ['example.com'], formats: ['image/webp', 'image/avif'], }, env: { CUSTOM_KEY: process.env.CUSTOM_KEY, } } module.exports = nextConfig","title":"Manual installation"},{"location":"javascript/nextjs/#app-router-nextjs-13","text":"","title":"App Router (Next.js 13+)"},{"location":"javascript/nextjs/#file-based-routing_1","text":"app/ \u251c\u2500\u2500 page.tsx # / (home) \u251c\u2500\u2500 about/page.tsx # /about \u251c\u2500\u2500 blog/ \u2502 \u251c\u2500\u2500 page.tsx # /blog \u2502 \u2514\u2500\u2500 [slug]/page.tsx # /blog/[slug] (dynamic) \u251c\u2500\u2500 products/ \u2502 \u251c\u2500\u2500 page.tsx # /products \u2502 \u251c\u2500\u2500 [id]/page.tsx # /products/[id] \u2502 \u2514\u2500\u2500 [...slug]/page.tsx # /products/[...slug] (catch-all) \u2514\u2500\u2500 (dashboard)/ # Route groups (no URL segment) \u251c\u2500\u2500 settings/page.tsx # /settings \u2514\u2500\u2500 profile/page.tsx # /profile","title":"File-based Routing"},{"location":"javascript/nextjs/#layout-components","text":"// app/layout.tsx - Root Layout import type { Metadata } from 'next' export const metadata: Metadata = { title: 'My App', description: 'Generated by Next.js', } export default function RootLayout({ children, }: { children: React.ReactNode }) { return ( <html lang=\"en\"> <body> <header> <nav>{/* Navigation */}</nav> </header> <main>{children}</main> <footer>{/* Footer */}</footer> </body> </html> ) } // app/dashboard/layout.tsx - Nested Layout export default function DashboardLayout({ children, }: { children: React.ReactNode }) { return ( <div className=\"dashboard\"> <aside> {/* Sidebar */} </aside> <div className=\"content\"> {children} </div> </div> ) }","title":"Layout Components"},{"location":"javascript/nextjs/#pages","text":"// app/page.tsx - Home Page export default function HomePage() { return ( <div> <h1>Welcome to Next.js</h1> <p>This is the home page</p> </div> ) } // app/about/page.tsx - About Page export default function AboutPage() { return ( <div> <h1>About Us</h1> <p>Learn more about our company</p> </div> ) } // app/blog/[slug]/page.tsx - Dynamic Page interface Props { params: { slug: string } searchParams: { [key: string]: string | string[] | undefined } } export default function BlogPost({ params, searchParams }: Props) { return ( <div> <h1>Blog Post: {params.slug}</h1> <p>Search params: {JSON.stringify(searchParams)}</p> </div> ) }","title":"Pages"},{"location":"javascript/nextjs/#special-files_1","text":"// app/loading.tsx - Loading UI export default function Loading() { return <div className=\"spinner\">Loading...</div> } // app/error.tsx - Error UI 'use client' export default function Error({ error, reset, }: { error: Error & { digest?: string } reset: () => void }) { return ( <div> <h2>Something went wrong!</h2> <p>{error.message}</p> <button onClick={reset}>Try again</button> </div> ) } // app/not-found.tsx - 404 Page import Link from 'next/link' export default function NotFound() { return ( <div> <h2>Page Not Found</h2> <p>Could not find the requested page.</p> <Link href=\"/\">Return Home</Link> </div> ) }","title":"Special Files"},{"location":"javascript/nextjs/#data-fetching_1","text":"","title":"Data Fetching"},{"location":"javascript/nextjs/#server-components-default_1","text":"// Server Component - runs on server async function getData() { const res = await fetch('https://api.example.com/data', { cache: 'force-cache', // Default caching // cache: 'no-store', // No caching (SSR) // next: { revalidate: 60 } // Revalidate every 60 seconds }) if (!res.ok) { throw new Error('Failed to fetch data') } return res.json() } export default async function PostsPage() { const posts = await getData() return ( <div> <h1>Posts</h1> {posts.map((post: any) => ( <article key={post.id}> <h2>{post.title}</h2> <p>{post.content}</p> </article> ))} </div> ) }","title":"Server Components (Default)"},{"location":"javascript/nextjs/#client-components_1","text":"'use client' import { useState, useEffect } from 'react' export default function ClientDataFetching() { const [data, setData] = useState(null) const [loading, setLoading] = useState(true) useEffect(() => { fetch('/api/data') .then(res => res.json()) .then(data => { setData(data) setLoading(false) }) }, []) if (loading) return <div>Loading...</div> return ( <div> <h1>Client-side Data</h1> <pre>{JSON.stringify(data, null, 2)}</pre> </div> ) }","title":"Client Components"},{"location":"javascript/nextjs/#static-site-generation-ssg_1","text":"// app/posts/[slug]/page.tsx interface Post { id: string title: string content: string slug: string } // Generate static params at build time export async function generateStaticParams() { const posts = await fetch('https://api.example.com/posts').then(res => res.json()) return posts.map((post: Post) => ({ slug: post.slug, })) } // Generate metadata for each page export async function generateMetadata( { params }: { params: { slug: string } } ) { const post = await fetch(`https://api.example.com/posts/${params.slug}`) .then(res => res.json()) return { title: post.title, description: post.excerpt, } } // Page component export default async function PostPage({ params }: { params: { slug: string } }) { const post = await fetch(`https://api.example.com/posts/${params.slug}`) .then(res => res.json()) return ( <article> <h1>{post.title}</h1> <div dangerouslySetInnerHTML={{ __html: post.content }} /> </article> ) }","title":"Static Site Generation (SSG)"},{"location":"javascript/nextjs/#incremental-static-regeneration-isr","text":"async function getData() { const res = await fetch('https://api.example.com/posts', { next: { revalidate: 3600 } // Revalidate every hour }) return res.json() } export default async function PostsPage() { const posts = await getData() return ( <div> {posts.map((post: any) => ( <div key={post.id}>{post.title}</div> ))} </div> ) }","title":"Incremental Static Regeneration (ISR)"},{"location":"javascript/nextjs/#api-routes","text":"","title":"API Routes"},{"location":"javascript/nextjs/#basic-api-routes_1","text":"// app/api/hello/route.ts import { NextRequest, NextResponse } from 'next/server' export async function GET() { return NextResponse.json({ message: 'Hello World' }) } export async function POST(request: NextRequest) { const body = await request.json() return NextResponse.json({ message: 'Data received', data: body }) }","title":"Basic API Routes"},{"location":"javascript/nextjs/#dynamic-api-routes_1","text":"// app/api/users/[id]/route.ts import { NextRequest, NextResponse } from 'next/server' export async function GET( request: NextRequest, { params }: { params: { id: string } } ) { const id = params.id // Fetch user data const user = await getUserById(id) if (!user) { return new NextResponse('User not found', { status: 404 }) } return NextResponse.json(user) } export async function PUT( request: NextRequest, { params }: { params: { id: string } } ) { const id = params.id const body = await request.json() const updatedUser = await updateUser(id, body) return NextResponse.json(updatedUser) } export async function DELETE( request: NextRequest, { params }: { params: { id: string } } ) { const id = params.id await deleteUser(id) return new NextResponse(null, { status: 204 }) }","title":"Dynamic API Routes"},{"location":"javascript/nextjs/#error-handling-in-api-routes","text":"// app/api/protected/route.ts import { NextRequest, NextResponse } from 'next/server' export async function GET(request: NextRequest) { try { // Check authentication const token = request.headers.get('authorization') if (!token) { return new NextResponse('Unauthorized', { status: 401 }) } // Validate token const user = await validateToken(token) if (!user) { return new NextResponse('Invalid token', { status: 401 }) } // Return protected data const data = await getProtectedData(user.id) return NextResponse.json(data) } catch (error) { console.error('API Error:', error) return new NextResponse('Internal Server Error', { status: 500 }) } }","title":"Error Handling in API Routes"},{"location":"javascript/nextjs/#middleware","text":"// middleware.ts (in root directory) import { NextResponse } from 'next/server' import type { NextRequest } from 'next/server' export function middleware(request: NextRequest) { // Check if user is authenticated const token = request.cookies.get('auth-token') if (!token && request.nextUrl.pathname.startsWith('/dashboard')) { return NextResponse.redirect(new URL('/login', request.url)) } // Add custom headers const response = NextResponse.next() response.headers.set('x-custom-header', 'my-value') return response } export const config = { matcher: ['/dashboard/:path*', '/api/:path*'] }","title":"Middleware"},{"location":"javascript/nextjs/#navigation-and-routing_1","text":"","title":"Navigation and Routing"},{"location":"javascript/nextjs/#link-component_1","text":"import Link from 'next/link' export default function Navigation() { return ( <nav> {/* Basic link */} <Link href=\"/about\">About</Link> {/* Link with custom styling */} <Link href=\"/products\" className=\"nav-link\"> Products </Link> {/* Dynamic link */} <Link href={`/posts/${post.slug}`}> {post.title} </Link> {/* External link */} <Link href=\"https://example.com\" target=\"_blank\"> External Link </Link> {/* Link with query parameters */} <Link href={{ pathname: '/search', query: { q: 'nextjs' } }} > Search </Link> </nav> ) }","title":"Link Component"},{"location":"javascript/nextjs/#userouter-hook_1","text":"'use client' import { useRouter, usePathname, useSearchParams } from 'next/navigation' export default function ClientNavigation() { const router = useRouter() const pathname = usePathname() const searchParams = useSearchParams() const handleNavigation = () => { // Programmatic navigation router.push('/dashboard') // router.replace('/dashboard') // Replace current entry // router.back() // Go back // router.forward() // Go forward } const handleSearch = (term: string) => { // Update URL with search params const params = new URLSearchParams(searchParams) params.set('q', term) router.push(`${pathname}?${params.toString()}`) } return ( <div> <p>Current path: {pathname}</p> <p>Search: {searchParams.get('q')}</p> <button onClick={handleNavigation}>Go to Dashboard</button> <input type=\"text\" onChange={(e) => handleSearch(e.target.value)} placeholder=\"Search...\" /> </div> ) }","title":"useRouter Hook"},{"location":"javascript/nextjs/#styling","text":"","title":"Styling"},{"location":"javascript/nextjs/#css-modules","text":"// components/Button.module.css .button { padding: 0.5rem 1rem; border: none; border-radius: 4px; background-color: #0070f3; color: white; cursor: pointer; } .button:hover { background-color: #0051a2; } .primary { background-color: #0070f3; } .secondary { background-color: #666; } // components/Button.tsx import styles from './Button.module.css' interface ButtonProps { children: React.ReactNode variant?: 'primary' | 'secondary' onClick?: () => void } export default function Button({ children, variant = 'primary', onClick }: ButtonProps) { return ( <button className={`${styles.button} ${styles[variant]}`} onClick={onClick} > {children} </button> ) }","title":"CSS Modules"},{"location":"javascript/nextjs/#global-styles","text":"/* app/globals.css */ * { box-sizing: border-box; padding: 0; margin: 0; } html, body { max-width: 100vw; overflow-x: hidden; } body { color: rgb(var(--foreground-rgb)); background: linear-gradient( to bottom, transparent, rgb(var(--background-end-rgb)) ) rgb(var(--background-start-rgb)); }","title":"Global Styles"},{"location":"javascript/nextjs/#tailwind-css-integration","text":"// Install: npm install -D tailwindcss postcss autoprefixer // Initialize: npx tailwindcss init -p // tailwind.config.js /** @type {import('tailwindcss').Config} */ module.exports = { content: [ './app/**/*.{js,ts,jsx,tsx,mdx}', './components/**/*.{js,ts,jsx,tsx,mdx}', ], theme: { extend: {}, }, plugins: [], } // Component with Tailwind classes export default function Card({ children }: { children: React.ReactNode }) { return ( <div className=\"max-w-sm mx-auto bg-white rounded-xl shadow-md overflow-hidden\"> <div className=\"p-6\"> {children} </div> </div> ) }","title":"Tailwind CSS Integration"},{"location":"javascript/nextjs/#image-optimization","text":"","title":"Image Optimization"},{"location":"javascript/nextjs/#nextjs-image-component","text":"import Image from 'next/image' export default function Gallery() { return ( <div> {/* Local image */} <Image src=\"/hero-image.jpg\" alt=\"Hero\" width={800} height={600} priority // Load immediately /> {/* Remote image */} <Image src=\"https://example.com/image.jpg\" alt=\"Remote image\" width={400} height={300} placeholder=\"blur\" blurDataURL=\"data:image/jpeg;base64,...\" // Base64 blur placeholder /> {/* Responsive image */} <Image src=\"/responsive-image.jpg\" alt=\"Responsive\" fill style={{ objectFit: 'cover' }} /> {/* Image with custom loader */} <Image src=\"image-key\" alt=\"Custom loader\" width={300} height={200} loader={({ src, width, quality }) => { return `https://cdn.example.com/${src}?w=${width}&q=${quality || 75}` }} /> </div> ) }","title":"Next.js Image Component"},{"location":"javascript/nextjs/#image-configuration","text":"// next.config.js /** @type {import('next').NextConfig} */ const nextConfig = { images: { domains: ['example.com', 'cdn.example.com'], deviceSizes: [640, 750, 828, 1080, 1200, 1920, 2048, 3840], imageSizes: [16, 32, 48, 64, 96, 128, 256, 384], formats: ['image/webp', 'image/avif'], minimumCacheTTL: 60, dangerouslyAllowSVG: true, contentDispositionType: 'attachment', }, } module.exports = nextConfig","title":"Image Configuration"},{"location":"javascript/nextjs/#authentication-patterns","text":"","title":"Authentication Patterns"},{"location":"javascript/nextjs/#session-based-authentication","text":"// app/api/auth/login/route.ts import { NextRequest, NextResponse } from 'next/server' import { cookies } from 'next/headers' import jwt from 'jsonwebtoken' export async function POST(request: NextRequest) { const { email, password } = await request.json() // Validate credentials const user = await validateUser(email, password) if (!user) { return new NextResponse('Invalid credentials', { status: 401 }) } // Create JWT token const token = jwt.sign( { userId: user.id, email: user.email }, process.env.JWT_SECRET!, { expiresIn: '7d' } ) // Set cookie cookies().set('auth-token', token, { httpOnly: true, secure: process.env.NODE_ENV === 'production', sameSite: 'strict', maxAge: 60 * 60 * 24 * 7, // 7 days }) return NextResponse.json({ user: { id: user.id, email: user.email } }) }","title":"Session-based Authentication"},{"location":"javascript/nextjs/#protected-routes","text":"// app/dashboard/page.tsx import { cookies } from 'next/headers' import { redirect } from 'next/navigation' import jwt from 'jsonwebtoken' async function getCurrentUser() { const token = cookies().get('auth-token')?.value if (!token) { return null } try { const decoded = jwt.verify(token, process.env.JWT_SECRET!) as any return await getUserById(decoded.userId) } catch { return null } } export default async function DashboardPage() { const user = await getCurrentUser() if (!user) { redirect('/login') } return ( <div> <h1>Welcome, {user.name}!</h1> <p>This is your dashboard</p> </div> ) }","title":"Protected Routes"},{"location":"javascript/nextjs/#environment-variables","text":"","title":"Environment Variables"},{"location":"javascript/nextjs/#environment-configuration","text":"# .env.local (not committed to Git) DATABASE_URL=postgresql://... JWT_SECRET=your-secret-key API_KEY=your-api-key # .env (committed to Git - public variables only) NEXT_PUBLIC_APP_NAME=My App NEXT_PUBLIC_API_URL=https://api.example.com // lib/env.ts - Type-safe environment variables export const env = { DATABASE_URL: process.env.DATABASE_URL!, JWT_SECRET: process.env.JWT_SECRET!, // Public variables (available in browser) NEXT_PUBLIC_APP_NAME: process.env.NEXT_PUBLIC_APP_NAME!, NEXT_PUBLIC_API_URL: process.env.NEXT_PUBLIC_API_URL!, } // Usage in components export default function Header() { return ( <header> <h1>{env.NEXT_PUBLIC_APP_NAME}</h1> </header> ) }","title":"Environment Configuration"},{"location":"javascript/nextjs/#database-integration","text":"","title":"Database Integration"},{"location":"javascript/nextjs/#prisma-setup","text":"# Install Prisma npm install prisma @prisma/client npx prisma init # Generate client after schema changes npx prisma generate # Run migrations npx prisma migrate dev --name init // lib/prisma.ts import { PrismaClient } from '@prisma/client' const globalForPrisma = globalThis as unknown as { prisma: PrismaClient | undefined } export const prisma = globalForPrisma.prisma ?? new PrismaClient() if (process.env.NODE_ENV !== 'production') globalForPrisma.prisma = prisma // app/api/posts/route.ts import { NextResponse } from 'next/server' import { prisma } from '@/lib/prisma' export async function GET() { const posts = await prisma.post.findMany({ include: { author: { select: { name: true, email: true, }, }, }, orderBy: { createdAt: 'desc', }, }) return NextResponse.json(posts) } export async function POST(request: Request) { const { title, content, authorId } = await request.json() const post = await prisma.post.create({ data: { title, content, authorId, }, }) return NextResponse.json(post, { status: 201 }) }","title":"Prisma Setup"},{"location":"javascript/nextjs/#performance-optimization_1","text":"","title":"Performance Optimization"},{"location":"javascript/nextjs/#code-splitting-and-lazy-loading","text":"import { lazy, Suspense } from 'react' import dynamic from 'next/dynamic' // React.lazy (client-side only) const LazyComponent = lazy(() => import('../components/ExpensiveComponent')) // Next.js dynamic imports const DynamicComponent = dynamic(() => import('../components/DynamicComponent'), { loading: () => <p>Loading...</p>, ssr: false, // Disable SSR for this component }) // Dynamic import with named export const DynamicChart = dynamic( () => import('../components/Chart').then(mod => mod.Chart), { ssr: false } ) export default function Page() { return ( <div> <h1>My Page</h1> <Suspense fallback={<div>Loading lazy component...</div>}> <LazyComponent /> </Suspense> <DynamicComponent /> <DynamicChart data={chartData} /> </div> ) }","title":"Code Splitting and Lazy Loading"},{"location":"javascript/nextjs/#caching-strategies_1","text":"// Static caching (default) const staticData = await fetch('https://api.example.com/static-data') // No caching (SSR) const dynamicData = await fetch('https://api.example.com/dynamic-data', { cache: 'no-store' }) // Time-based revalidation (ISR) const revalidatedData = await fetch('https://api.example.com/data', { next: { revalidate: 60 } // Revalidate every 60 seconds }) // Tag-based revalidation const taggedData = await fetch('https://api.example.com/data', { next: { tags: ['posts'] } }) // Manual revalidation import { revalidateTag, revalidatePath } from 'next/cache' // In API route or server action revalidateTag('posts') // Revalidate all requests with 'posts' tag revalidatePath('/posts') // Revalidate specific path","title":"Caching Strategies"},{"location":"javascript/nextjs/#seo-and-metadata_1","text":"","title":"SEO and Metadata"},{"location":"javascript/nextjs/#dynamic-metadata_1","text":"import type { Metadata } from 'next' interface Props { params: { slug: string } } export async function generateMetadata({ params }: Props): Promise<Metadata> { const post = await fetch(`https://api.example.com/posts/${params.slug}`) .then(res => res.json()) return { title: post.title, description: post.excerpt, openGraph: { title: post.title, description: post.excerpt, images: [ { url: post.featuredImage, width: 1200, height: 630, alt: post.title, }, ], }, twitter: { card: 'summary_large_image', title: post.title, description: post.excerpt, images: [post.featuredImage], }, } } export default async function PostPage({ params }: Props) { const post = await fetch(`https://api.example.com/posts/${params.slug}`) .then(res => res.json()) return ( <article> <h1>{post.title}</h1> <div dangerouslySetInnerHTML={{ __html: post.content }} /> </article> ) }","title":"Dynamic Metadata"},{"location":"javascript/nextjs/#sitemap-generation","text":"// app/sitemap.ts import type { MetadataRoute } from 'next' export default function sitemap(): MetadataRoute.Sitemap { return [ { url: 'https://example.com', lastModified: new Date(), changeFrequency: 'yearly', priority: 1, }, { url: 'https://example.com/about', lastModified: new Date(), changeFrequency: 'monthly', priority: 0.8, }, { url: 'https://example.com/blog', lastModified: new Date(), changeFrequency: 'weekly', priority: 0.5, }, ] }","title":"Sitemap Generation"},{"location":"javascript/nextjs/#robotstxt","text":"// app/robots.ts import type { MetadataRoute } from 'next' export default function robots(): MetadataRoute.Robots { return { rules: { userAgent: '*', allow: '/', disallow: '/private/', }, sitemap: 'https://example.com/sitemap.xml', } }","title":"Robots.txt"},{"location":"javascript/nextjs/#testing","text":"","title":"Testing"},{"location":"javascript/nextjs/#jest-setup","text":"// jest.config.js /** @type {import('jest').Config} */ const config = { testEnvironment: 'jsdom', setupFilesAfterEnv: ['<rootDir>/jest.setup.js'], moduleNameMapping: { '^@/(.*)$': '<rootDir>/$1', }, transform: { '^.+\\\\.(js|jsx|ts|tsx)$': ['babel-jest', { presets: ['next/babel'] }], }, } module.exports = config // jest.setup.js import '@testing-library/jest-dom'","title":"Jest Setup"},{"location":"javascript/nextjs/#component-testing","text":"// __tests__/components/Button.test.tsx import { render, screen, fireEvent } from '@testing-library/react' import Button from '@/components/Button' describe('Button', () => { test('renders with correct text', () => { render(<Button>Click me</Button>) expect(screen.getByText('Click me')).toBeInTheDocument() }) test('calls onClick when clicked', () => { const handleClick = jest.fn() render(<Button onClick={handleClick}>Click me</Button>) fireEvent.click(screen.getByText('Click me')) expect(handleClick).toHaveBeenCalledTimes(1) }) })","title":"Component Testing"},{"location":"javascript/nextjs/#api-route-testing","text":"// __tests__/api/users.test.ts import { GET } from '@/app/api/users/route' // Adjust path as needed import { NextRequest } from 'next/server' describe('/api/users route', () => { it('returns a successful response with a list of users', async () => { // Mock the request object const request = new NextRequest('http://localhost/api/users') // Call the route handler const response = await GET(request) const body = await response.json() // Assertions expect(response.status).toBe(200) expect(body).toHaveProperty('users') expect(Array.isArray(body.users)).toBe(true) }) })","title":"API Route Testing"},{"location":"javascript/nextjs/#deployment","text":"","title":"Deployment"},{"location":"javascript/nextjs/#vercel-deployment","text":"# Install Vercel CLI npm i -g vercel # Deploy vercel # Deploy to production vercel --prod","title":"Vercel Deployment"},{"location":"javascript/nextjs/#docker-deployment","text":"# Dockerfile FROM node:18-alpine AS base FROM base AS deps RUN apk add --no-cache libc6-compat WORKDIR /app COPY package.json yarn.lock* package-lock.json* pnpm-lock.yaml* ./ RUN \\ if [ -f yarn.lock ]; then yarn --frozen-lockfile; \\ elif [ -f package-lock.json ]; then npm ci; \\ elif [ -f pnpm-lock.yaml ]; then yarn global add pnpm && pnpm i --frozen-lockfile; \\ else echo \"Lockfile not found.\" && exit 1; \\ fi FROM base AS builder WORKDIR /app COPY --from=deps /app/node_modules ./node_modules COPY . . RUN yarn build FROM base AS runner WORKDIR /app ENV NODE_ENV production RUN addgroup --system --gid 1001 nodejs RUN adduser --system --uid 1001 nextjs COPY --from=builder /app/public ./public RUN mkdir .next RUN chown nextjs:nodejs .next COPY --from=builder --chown=nextjs:nodejs /app/.next/standalone ./ COPY --from=builder --chown=nextjs:nodejs /app/.next/static ./.next/static USER nextjs EXPOSE 3000 ENV PORT 3000 CMD [\"node\", \"server.js\"]","title":"Docker Deployment"},{"location":"javascript/nextjs/#environment-variables-for-production","text":"# .env.production NEXT_PUBLIC_API_URL=https://api.production.com DATABASE_URL=postgresql://prod-db... JWT_SECRET=production-secret-key","title":"Environment Variables for Production"},{"location":"javascript/nextjs/#common-patterns-and-best-practices","text":"","title":"Common Patterns and Best Practices"},{"location":"javascript/nextjs/#error-handling","text":"// Global error boundary 'use client' import { useEffect } from 'react' export default function GlobalError({ error, reset, }: { error: Error & { digest?: string } reset: () => void }) { useEffect(() => { console.error(error) }, [error]) return ( <html> <body> <h2>Something went wrong!</h2> <button onClick={() => reset()}>Try again</button> </body> </html> ) }","title":"Error Handling"},{"location":"javascript/nextjs/#loading-states","text":"// app/dashboard/loading.tsx export default function DashboardLoading() { return ( <div className=\"animate-pulse\"> <div className=\"h-8 bg-gray-200 rounded mb-4\"></div> <div className=\"h-4 bg-gray-200 rounded mb-2\"></div> <div className=\"h-4 bg-gray-200 rounded mb-2\"></div> <div className=\"h-4 bg-gray-200 rounded w-3/4\"></div> </div> ) }","title":"Loading States"},{"location":"javascript/nextjs/#form-handling-with-server-actions","text":"// app/contact/page.tsx import { redirect } from 'next/navigation' async function createContact(formData: FormData) { 'use server' const name = formData.get('name') as string const email = formData.get('email') as string const message = formData.get('message') as string // Save to database await saveContact({ name, email, message }) redirect('/contact/success') } export default function ContactPage() { return ( <form action={createContact}> <input type=\"text\" name=\"name\" placeholder=\"Name\" required /> <input type=\"email\" name=\"email\" placeholder=\"Email\" required /> <textarea name=\"message\" placeholder=\"Message\" required /> <button type=\"submit\">Send Message</button> </form> ) }","title":"Form Handling with Server Actions"},{"location":"javascript/nextjs/#typescript-configuration","text":"// tsconfig.json { \"compilerOptions\": { \"lib\": [\"dom\", \"dom.iterable\", \"es6\"], \"allowJs\": true, \"skipLibCheck\": true, \"strict\": true, \"noEmit\": true, \"esModuleInterop\": true, \"module\": \"esnext\", \"moduleResolution\": \"bundler\", \"resolveJsonModule\": true, \"isolatedModules\": true, \"jsx\": \"preserve\", \"incremental\": true, \"plugins\": [ { \"name\": \"next\" } ], \"baseUrl\": \".\", \"paths\": { \"@/*\": [\"./*\"], \"@/components/*\": [\"./components/*\"], \"@/lib/*\": [\"./lib/*\"] } }, \"include\": [\"next-env.d.ts\", \"**/*.ts\", \"**/*.tsx\", \".next/types/**/*.ts\"], \"exclude\": [\"node_modules\"] } This comprehensive Next.js cheat sheet covers modern patterns, App Router features, and best practices for building production-ready applications with Next.js 13+. Focus on understanding the App Router paradigm, server/client component patterns, and data fetching strategies for effective Next.js development.","title":"TypeScript Configuration"},{"location":"javascript/react/","text":"React React is a JavaScript library for building user interfaces through reusable components. This cheat sheet covers React 18+ with modern hooks, patterns, and best practices. Quick Start Installation # Create new React app with Vite (recommended) npm create vite@latest my-app -- --template react cd my-app npm install npm run dev # Create React App (Legacy) npx create-react-app my-app # Add React to existing project npm install react react-dom Basic Setup // index.js - Entry point import React from 'react'; import ReactDOM from 'react-dom/client'; import App from './App'; const root = ReactDOM.createRoot(document.getElementById('root')); root.render(<App />); Core Concepts JSX Fundamentals // JSX allows HTML-like syntax in JavaScript function Welcome({ name }) { return ( <div> <h1>Hello, {name}!</h1> <p>Welcome to React</p> </div> ); } // JSX expressions const user = { name: 'Alice', age: 30 }; const element = ( <div> <p>Name: {user.name}</p> <p>Age: {user.age}</p> <p>Status: {user.age >= 18 ? 'Adult' : 'Minor'}</p> </div> ); // JSX attributes const imageUrl = 'https://example.com/image.jpg'; const image = <img src={imageUrl} alt=\"Description\" className=\"image-style\" />; Components Function Components (Recommended) // Basic function component function Greeting({ name }) { return <h1>Hello, {name}!</h1>; } // Arrow function component const Greeting = ({ name }) => { return <h1>Hello, {name}!</h1>; }; // Component with multiple props function UserCard({ user, showEmail = false }) { return ( <div className=\"user-card\"> <h2>{user.name}</h2> <p>Age: {user.age}</p> {showEmail && <p>Email: {user.email}</p>} </div> ); } Class Components (Legacy) import React, { Component } from 'react'; class Welcome extends Component { render() { return <h1>Hello, {this.props.name}!</h1>; } } State Management useState Hook import { useState } from 'react'; function Counter() { const [count, setCount] = useState(0); const increment = () => setCount(count + 1); const decrement = () => setCount(prev => prev - 1); // Functional update return ( <div> <p>Count: {count}</p> <button onClick={increment}>+</button> <button onClick={decrement}>-</button> </div> ); } // Multiple state variables function UserProfile() { const [name, setName] = useState(''); const [email, setEmail] = useState(''); const [isLoading, setIsLoading] = useState(false); return ( <form> <input value={name} onChange={(e) => setName(e.target.value)} placeholder=\"Name\" /> <input value={email} onChange={(e) => setEmail(e.target.value)} placeholder=\"Email\" /> </form> ); } // Object state function UserSettings() { const [settings, setSettings] = useState({ theme: 'light', notifications: true, language: 'en' }); const updateTheme = (theme) => { setSettings(prev => ({ ...prev, theme })); }; return ( <div> <button onClick={() => updateTheme('dark')}>Dark Theme</button> <button onClick={() => updateTheme('light')}>Light Theme</button> </div> ); } useReducer Hook import { useReducer } from 'react'; // Reducer function function counterReducer(state, action) { switch (action.type) { case 'INCREMENT': return { count: state.count + 1 }; case 'DECREMENT': return { count: state.count - 1 }; case 'RESET': return { count: 0 }; default: throw new Error(`Unknown action: ${action.type}`); } } function Counter() { const [state, dispatch] = useReducer(counterReducer, { count: 0 }); return ( <div> <p>Count: {state.count}</p> <button onClick={() => dispatch({ type: 'INCREMENT' })}>+</button> <button onClick={() => dispatch({ type: 'DECREMENT' })}>-</button> <button onClick={() => dispatch({ type: 'RESET' })}>Reset</button> </div> ); } // Complex state management const todoReducer = (state, action) => { switch (action.type) { case 'ADD_TODO': return [...state, { id: Date.now(), text: action.text, done: false }]; case 'TOGGLE_TODO': return state.map(todo => todo.id === action.id ? { ...todo, done: !todo.done } : todo ); case 'DELETE_TODO': return state.filter(todo => todo.id !== action.id); default: return state; } }; Effects and Side Effects useEffect Hook import { useEffect, useState } from 'react'; // Basic effect (runs after every render) function Example() { const [count, setCount] = useState(0); useEffect(() => { document.title = `Count: ${count}`; }); return <div>Count: {count}</div>; } // Effect with dependency array function UserProfile({ userId }) { const [user, setUser] = useState(null); useEffect(() => { fetchUser(userId).then(setUser); }, [userId]); // Only re-run when userId changes return user ? <div>{user.name}</div> : <div>Loading...</div>; } // Effect with cleanup function Timer() { const [seconds, setSeconds] = useState(0); useEffect(() => { const interval = setInterval(() => { setSeconds(prev => prev + 1); }, 1000); // Cleanup function return () => clearInterval(interval); }, []); // Empty dependency array = run once return <div>Seconds: {seconds}</div>; } // Multiple effects function ChatRoom({ roomId }) { const [messages, setMessages] = useState([]); const [isConnected, setIsConnected] = useState(false); // Effect for connection useEffect(() => { const connection = createConnection(roomId); connection.connect(); setIsConnected(true); return () => { connection.disconnect(); setIsConnected(false); }; }, [roomId]); // Effect for messages useEffect(() => { if (isConnected) { const unsubscribe = subscribeToMessages(roomId, setMessages); return unsubscribe; } }, [roomId, isConnected]); } Event Handling Common Event Patterns function Form() { const [formData, setFormData] = useState({ name: '', email: '', message: '' }); // Handle input changes const handleChange = (e) => { const { name, value } = e.target; setFormData(prev => ({ ...prev, [name]: value })); }; // Handle form submission const handleSubmit = (e) => { e.preventDefault(); console.log('Form submitted:', formData); // Reset form setFormData({ name: '', email: '', message: '' }); }; // Handle button clicks const handleButtonClick = (e) => { console.log('Button clicked', e.target); }; return ( <form onSubmit={handleSubmit}> <input type=\"text\" name=\"name\" value={formData.name} onChange={handleChange} placeholder=\"Name\" /> <input type=\"email\" name=\"email\" value={formData.email} onChange={handleChange} placeholder=\"Email\" /> <textarea name=\"message\" value={formData.message} onChange={handleChange} placeholder=\"Message\" /> <button type=\"submit\">Submit</button> <button type=\"button\" onClick={handleButtonClick}>Cancel</button> </form> ); } // Event delegation and synthetic events function ItemList({ items }) { const handleItemClick = (e, itemId) => { e.stopPropagation(); // Prevent event bubbling console.log(`Clicked item ${itemId}`); }; return ( <ul> {items.map(item => ( <li key={item.id} onClick={(e) => handleItemClick(e, item.id)}> {item.name} </li> ))} </ul> ); } Props and Communication Props Patterns // Basic props function Greeting({ name, age = 0 }) { // Default props return <p>Hello {name}, age {age}</p>; } // Destructuring props function UserCard({ user: { name, email, avatar } }) { return ( <div> <img src={avatar} alt={name} /> <h3>{name}</h3> <p>{email}</p> </div> ); } // Spread props function Button({ children, ...props }) { return ( <button {...props} className={`btn ${props.className || ''}`}> {children} </button> ); } // Render props pattern function DataFetcher({ render, url }) { const [data, setData] = useState(null); const [loading, setLoading] = useState(true); useEffect(() => { fetch(url) .then(res => res.json()) .then(data => { setData(data); setLoading(false); }); }, [url]); return render({ data, loading }); } // Usage <DataFetcher url=\"/api/users\" render={({ data, loading }) => loading ? <div>Loading...</div> : <UserList users={data} /> } /> // Children prop patterns function Card({ children, title, footer }) { return ( <div className=\"card\"> <h2>{title}</h2> <div className=\"card-content\">{children}</div> {footer && <div className=\"card-footer\">{footer}</div>} </div> ); } // Higher-Order Component pattern function withLoading(WrappedComponent) { return function WithLoadingComponent({ isLoading, ...props }) { if (isLoading) return <div>Loading...</div>; return <WrappedComponent {...props} />; }; } Lifting State Up function ParentComponent() { const [sharedState, setSharedState] = useState(''); return ( <div> <ChildA value={sharedState} onChange={setSharedState} /> <ChildB value={sharedState} /> </div> ); } function ChildA({ value, onChange }) { return ( <input value={value} onChange={(e) => onChange(e.target.value)} /> ); } function ChildB({ value }) { return <p>Current value: {value}</p>; } Context API Creating and Using Context import { createContext, useContext, useState } from 'react'; // Create context const ThemeContext = createContext(); // Provider component function ThemeProvider({ children }) { const [theme, setTheme] = useState('light'); const toggleTheme = () => { setTheme(prev => prev === 'light' ? 'dark' : 'light'); }; return ( <ThemeContext.Provider value={{ theme, toggleTheme }}> {children} </ThemeContext.Provider> ); } // Custom hook for using context function useTheme() { const context = useContext(ThemeContext); if (!context) { throw new Error('useTheme must be used within ThemeProvider'); } return context; } // Using context in components function ThemedButton() { const { theme, toggleTheme } = useTheme(); return ( <button className={`btn btn-${theme}`} onClick={toggleTheme} > Toggle Theme </button> ); } // App with context function App() { return ( <ThemeProvider> <div className=\"app\"> <ThemedButton /> </div> </ThemeProvider> ); } Complex Context with Reducer // Auth context with reducer const AuthContext = createContext(); const authReducer = (state, action) => { switch (action.type) { case 'LOGIN': return { ...state, user: action.user, isAuthenticated: true }; case 'LOGOUT': return { ...state, user: null, isAuthenticated: false }; case 'SET_LOADING': return { ...state, isLoading: action.isLoading }; default: return state; } }; function AuthProvider({ children }) { const [state, dispatch] = useReducer(authReducer, { user: null, isAuthenticated: false, isLoading: true }); const login = async (credentials) => { dispatch({ type: 'SET_LOADING', isLoading: true }); try { const user = await authService.login(credentials); dispatch({ type: 'LOGIN', user }); } catch (error) { console.error('Login failed:', error); } finally { dispatch({ type: 'SET_LOADING', isLoading: false }); } }; return ( <AuthContext.Provider value={{ ...state, login, dispatch }}> {children} </AuthContext.Provider> ); } Custom Hooks Creating Custom Hooks // Custom hook for API calls function useApi(url) { const [data, setData] = useState(null); const [loading, setLoading] = useState(true); const [error, setError] = useState(null); useEffect(() => { const fetchData = async () => { try { setLoading(true); const response = await fetch(url); const result = await response.json(); setData(result); } catch (err) { setError(err); } finally { setLoading(false); } }; fetchData(); }, [url]); return { data, loading, error }; } // Custom hook for local storage function useLocalStorage(key, initialValue) { const [storedValue, setStoredValue] = useState(() => { try { const item = window.localStorage.getItem(key); return item ? JSON.parse(item) : initialValue; } catch (error) { return initialValue; } }); const setValue = (value) => { try { setStoredValue(value); window.localStorage.setItem(key, JSON.stringify(value)); } catch (error) { console.error(error); } }; return [storedValue, setValue]; } // Custom hook for form handling function useForm(initialValues) { const [values, setValues] = useState(initialValues); const [errors, setErrors] = useState({}); const handleChange = (e) => { const { name, value } = e.target; setValues(prev => ({ ...prev, [name]: value })); }; const handleSubmit = (callback) => (e) => { e.preventDefault(); callback(values); }; const reset = () => { setValues(initialValues); setErrors({}); }; return { values, errors, handleChange, handleSubmit, reset, setErrors }; } // Usage function ContactForm() { const { values, handleChange, handleSubmit, reset } = useForm({ name: '', email: '', message: '' }); const onSubmit = (formData) => { console.log('Submitting:', formData); reset(); }; return ( <form onSubmit={handleSubmit(onSubmit)}> <input name=\"name\" value={values.name} onChange={handleChange} placeholder=\"Name\" /> {/* ... other inputs */} </form> ); } Performance Optimization React.memo import { memo } from 'react'; // Memoized component - only re-renders if props change const ExpensiveComponent = memo(function ExpensiveComponent({ data, onUpdate }) { return ( <div> {data.map(item => ( <div key={item.id}> <span>{item.name}</span> <button onClick={() => onUpdate(item.id)}>Update</button> </div> ))} </div> ); }); // Custom comparison function const OptimizedComponent = memo(function OptimizedComponent({ user, settings }) { return <div>{user.name} - {settings.theme}</div>; }, (prevProps, nextProps) => { return prevProps.user.id === nextProps.user.id && prevProps.settings.theme === nextProps.settings.theme; }); useMemo and useCallback import { useMemo, useCallback, useState } from 'react'; function ExpensiveList({ items, filter }) { // Memoize expensive calculations const filteredItems = useMemo(() => { return items.filter(item => item.name.includes(filter)); }, [items, filter]); const expensiveValue = useMemo(() => { return items.reduce((sum, item) => sum + item.price, 0); }, [items]); // Memoize callback functions const handleItemClick = useCallback((itemId) => { console.log(`Clicked item ${itemId}`); }, []); const handleSort = useCallback((sortBy) => { // Sort logic here }, []); return ( <div> <p>Total: ${expensiveValue}</p> {filteredItems.map(item => ( <ItemCard key={item.id} item={item} onClick={handleItemClick} /> ))} </div> ); } Conditional Rendering Conditional Patterns function ConditionalExample({ user, isLoggedIn, items = [] }) { return ( <div> {/* Simple conditional */} {isLoggedIn && <p>Welcome, {user.name}!</p>} {/* Ternary operator */} {isLoggedIn ? ( <UserDashboard user={user} /> ) : ( <LoginForm /> )} {/* Complex conditions */} {isLoggedIn && user.role === 'admin' && ( <AdminPanel /> )} {/* Conditional with function */} {(() => { if (!isLoggedIn) return <LoginPrompt />; if (user.role === 'admin') return <AdminDashboard />; return <UserDashboard />; })()} {/* List rendering with conditions */} {items.length > 0 ? ( <ul> {items.map(item => ( <li key={item.id}> {item.name} {item.isNew && <span className=\"badge\">New</span>} </li> ))} </ul> ) : ( <p>No items found</p> )} </div> ); } Lists and Keys Rendering Lists function ItemList({ items, onDelete, onEdit }) { return ( <div> {items.map(item => ( <div key={item.id} className=\"item\"> <h3>{item.title}</h3> <p>{item.description}</p> <button onClick={() => onEdit(item)}>Edit</button> <button onClick={() => onDelete(item.id)}>Delete</button> </div> ))} </div> ); } // Dynamic list with state function TodoList() { const [todos, setTodos] = useState([]); const [newTodo, setNewTodo] = useState(''); const addTodo = () => { if (newTodo.trim()) { setTodos(prev => [...prev, { id: Date.now(), text: newTodo, completed: false }]); setNewTodo(''); } }; const toggleTodo = (id) => { setTodos(prev => prev.map(todo => todo.id === id ? { ...todo, completed: !todo.completed } : todo )); }; return ( <div> <div> <input value={newTodo} onChange={(e) => setNewTodo(e.target.value)} placeholder=\"Add todo...\" /> <button onClick={addTodo}>Add</button> </div> <ul> {todos.map(todo => ( <li key={todo.id}> <span style={{ textDecoration: todo.completed ? 'line-through' : 'none' }} onClick={() => toggleTodo(todo.id)} > {todo.text} </span> </li> ))} </ul> </div> ); } Forms and Validation Controlled Components function ContactForm() { const [formData, setFormData] = useState({ name: '', email: '', category: 'general', message: '', subscribe: false }); const [errors, setErrors] = useState({}); const handleInputChange = (e) => { const { name, value, type, checked } = e.target; setFormData(prev => ({ ...prev, [name]: type === 'checkbox' ? checked : value })); }; const validateForm = () => { const newErrors = {}; if (!formData.name.trim()) { newErrors.name = 'Name is required'; } if (!formData.email.trim()) { newErrors.email = 'Email is required'; } else if (!/\\S+@\\S+\\.\\S+/.test(formData.email)) { newErrors.email = 'Email is invalid'; } if (!formData.message.trim()) { newErrors.message = 'Message is required'; } setErrors(newErrors); return Object.keys(newErrors).length === 0; }; const handleSubmit = (e) => { e.preventDefault(); if (validateForm()) { console.log('Form submitted:', formData); // Reset form setFormData({ name: '', email: '', category: 'general', message: '', subscribe: false }); } }; return ( <form onSubmit={handleSubmit}> <div> <label> Name: <input type=\"text\" name=\"name\" value={formData.name} onChange={handleInputChange} /> </label> {errors.name && <span className=\"error\">{errors.name}</span>} </div> <div> <label> Email: <input type=\"email\" name=\"email\" value={formData.email} onChange={handleInputChange} /> </label> {errors.email && <span className=\"error\">{errors.email}</span>} </div> <div> <label> Category: <select name=\"category\" value={formData.category} onChange={handleInputChange} > <option value=\"general\">General</option> <option value=\"support\">Support</option> <option value=\"billing\">Billing</option> </select> </label> </div> <div> <label> <input type=\"checkbox\" name=\"subscribe\" checked={formData.subscribe} onChange={handleInputChange} /> Subscribe to newsletter </label> </div> <div> <label> Message: <textarea name=\"message\" value={formData.message} onChange={handleInputChange} rows={4} /> </label> {errors.message && <span className=\"error\">{errors.message}</span>} </div> <button type=\"submit\">Submit</button> </form> ); } Error Boundaries Error Boundary Component import { Component } from 'react'; class ErrorBoundary extends Component { constructor(props) { super(props); this.state = { hasError: false, error: null, errorInfo: null }; } static getDerivedStateFromError(error) { return { hasError: true }; } componentDidCatch(error, errorInfo) { this.setState({ error: error, errorInfo: errorInfo }); } render() { if (this.state.hasError) { return ( <div className=\"error-boundary\"> <h2>Something went wrong</h2> <details> {this.state.error && this.state.error.toString()} <br /> {this.state.errorInfo.componentStack} </details> </div> ); } return this.props.children; } } // Usage function App() { return ( <ErrorBoundary> <Header /> <MainContent /> <Footer /> </ErrorBoundary> ); } Refs and DOM Access useRef Hook import { useRef, useEffect } from 'react'; function FocusInput() { const inputRef = useRef(null); useEffect(() => { // Focus input when component mounts inputRef.current.focus(); }, []); const handleFocus = () => { inputRef.current.focus(); }; return ( <div> <input ref={inputRef} type=\"text\" /> <button onClick={handleFocus}>Focus Input</button> </div> ); } // Refs with state function VideoPlayer({ src }) { const videoRef = useRef(null); const [isPlaying, setIsPlaying] = useState(false); const togglePlayPause = () => { const video = videoRef.current; if (isPlaying) { video.pause(); } else { video.play(); } setIsPlaying(!isPlaying); }; return ( <div> <video ref={videoRef} src={src} /> <button onClick={togglePlayPause}> {isPlaying ? 'Pause' : 'Play'} </button> </div> ); } // Forwarding refs import { forwardRef } from 'react'; const CustomInput = forwardRef(function CustomInput(props, ref) { return <input {...props} ref={ref} className=\"custom-input\" />; }); // Usage of forwarded ref function Parent() { const inputRef = useRef(null); const focusInput = () => { inputRef.current.focus(); }; return ( <div> <CustomInput ref={inputRef} /> <button onClick={focusInput}>Focus</button> </div> ); } Common Patterns and Best Practices Component Composition // Composition over inheritance function Layout({ children }) { return ( <div className=\"layout\"> <Header /> <main>{children}</main> <Footer /> </div> ); } // Compound components function Tabs({ children, defaultTab = 0 }) { const [activeTab, setActiveTab] = useState(defaultTab); return ( <div className=\"tabs\"> {React.Children.map(children, (child, index) => React.cloneElement(child, { activeTab, setActiveTab, index }) )} </div> ); } function TabList({ children, activeTab, setActiveTab }) { return ( <div className=\"tab-list\"> {React.Children.map(children, (child, index) => React.cloneElement(child, { isActive: activeTab === index, onClick: () => setActiveTab(index) }) )} </div> ); } // Usage <Tabs defaultTab={0}> <TabList> <Tab>Tab 1</Tab> <Tab>Tab 2</Tab> </TabList> <TabPanels> <TabPanel>Content 1</TabPanel> <TabPanel>Content 2</TabPanel> </TabPanels> </Tabs> Data Fetching Patterns // Custom hook for data fetching with loading states function useAsyncData(asyncFunction, dependencies = []) { const [data, setData] = useState(null); const [loading, setLoading] = useState(true); const [error, setError] = useState(null); useEffect(() => { let isCancelled = false; const fetchData = async () => { try { setLoading(true); setError(null); const result = await asyncFunction(); if (!isCancelled) { setData(result); } } catch (err) { if (!isCancelled) { setError(err); } } finally { if (!isCancelled) { setLoading(false); } } }; fetchData(); return () => { isCancelled = true; }; }, dependencies); return { data, loading, error }; } // Usage function UserProfile({ userId }) { const { data: user, loading, error } = useAsyncData( () => fetchUser(userId), [userId] ); if (loading) return <div>Loading...</div>; if (error) return <div>Error: {error.message}</div>; if (!user) return <div>User not found</div>; return ( <div> <h1>{user.name}</h1> <p>{user.email}</p> </div> ); } Testing Patterns Component Testing Setup // Example test with React Testing Library import { render, screen, fireEvent, waitFor } from '@testing-library/react'; import '@testing-library/jest-dom'; import Counter from './Counter'; test('renders counter and increments on click', async () => { render(<Counter />); // Find elements const countElement = screen.getByText(/count: 0/i); const incrementButton = screen.getByText(/increment/i); expect(countElement).toBeInTheDocument(); // Simulate user interaction fireEvent.click(incrementButton); // Assert changes await waitFor(() => { expect(screen.getByText(/count: 1/i)).toBeInTheDocument(); }); }); // Testing with context test('uses theme context correctly', () => { render( <ThemeProvider> <ThemedButton /> </ThemeProvider> ); const button = screen.getByRole('button'); expect(button).toHaveClass('btn-light'); fireEvent.click(button); expect(button).toHaveClass('btn-dark'); }); Common Gotchas and Best Practices Key Best Practices // \u2705 Good: Stable keys for list items items.map(item => <Item key={item.id} data={item} />) // \u274c Bad: Using array index as key items.map((item, index) => <Item key={index} data={item} />) // \u2705 Good: Functional state updates setCount(prev => prev + 1); // \u274c Bad: Direct state mutation const newItems = items; newItems.push(newItem); setItems(newItems); // \u2705 Good: Immutable state updates setItems(prev => [...prev, newItem]); // \u2705 Good: Effect cleanup useEffect(() => { const subscription = subscribe(); return () => subscription.unsubscribe(); }, []); // \u2705 Good: Dependency arrays useEffect(() => { fetchData(userId); }, [userId]); // Include all dependencies // \u274c Bad: Missing dependencies useEffect(() => { fetchData(userId); }, []); // Missing userId dependency Performance Tips // Use React.memo for expensive components const ExpensiveComponent = memo(({ data }) => { // Expensive rendering logic return <div>{/* Complex UI */}</div>; }); // Use useMemo for expensive calculations const expensiveValue = useMemo(() => { return data.reduce((acc, item) => acc + item.value, 0); }, [data]); // Use useCallback for stable function references const handleClick = useCallback((id) => { onItemClick(id); }, [onItemClick]); // Lazy loading with React.lazy const LazyComponent = lazy(() => import('./LazyComponent')); function App() { return ( <Suspense fallback={<div>Loading...</div>}> <LazyComponent /> </Suspense> ); } This cheat sheet covers the essential React concepts, patterns, and best practices for building modern React applications. Focus on understanding hooks, component patterns, and state management for effective React development.","title":"React"},{"location":"javascript/react/#react","text":"React is a JavaScript library for building user interfaces through reusable components. This cheat sheet covers React 18+ with modern hooks, patterns, and best practices.","title":"React"},{"location":"javascript/react/#quick-start","text":"","title":"Quick Start"},{"location":"javascript/react/#installation","text":"# Create new React app with Vite (recommended) npm create vite@latest my-app -- --template react cd my-app npm install npm run dev # Create React App (Legacy) npx create-react-app my-app # Add React to existing project npm install react react-dom","title":"Installation"},{"location":"javascript/react/#basic-setup","text":"// index.js - Entry point import React from 'react'; import ReactDOM from 'react-dom/client'; import App from './App'; const root = ReactDOM.createRoot(document.getElementById('root')); root.render(<App />);","title":"Basic Setup"},{"location":"javascript/react/#core-concepts","text":"","title":"Core Concepts"},{"location":"javascript/react/#jsx-fundamentals","text":"// JSX allows HTML-like syntax in JavaScript function Welcome({ name }) { return ( <div> <h1>Hello, {name}!</h1> <p>Welcome to React</p> </div> ); } // JSX expressions const user = { name: 'Alice', age: 30 }; const element = ( <div> <p>Name: {user.name}</p> <p>Age: {user.age}</p> <p>Status: {user.age >= 18 ? 'Adult' : 'Minor'}</p> </div> ); // JSX attributes const imageUrl = 'https://example.com/image.jpg'; const image = <img src={imageUrl} alt=\"Description\" className=\"image-style\" />;","title":"JSX Fundamentals"},{"location":"javascript/react/#components","text":"","title":"Components"},{"location":"javascript/react/#function-components-recommended","text":"// Basic function component function Greeting({ name }) { return <h1>Hello, {name}!</h1>; } // Arrow function component const Greeting = ({ name }) => { return <h1>Hello, {name}!</h1>; }; // Component with multiple props function UserCard({ user, showEmail = false }) { return ( <div className=\"user-card\"> <h2>{user.name}</h2> <p>Age: {user.age}</p> {showEmail && <p>Email: {user.email}</p>} </div> ); }","title":"Function Components (Recommended)"},{"location":"javascript/react/#class-components-legacy","text":"import React, { Component } from 'react'; class Welcome extends Component { render() { return <h1>Hello, {this.props.name}!</h1>; } }","title":"Class Components (Legacy)"},{"location":"javascript/react/#state-management","text":"","title":"State Management"},{"location":"javascript/react/#usestate-hook","text":"import { useState } from 'react'; function Counter() { const [count, setCount] = useState(0); const increment = () => setCount(count + 1); const decrement = () => setCount(prev => prev - 1); // Functional update return ( <div> <p>Count: {count}</p> <button onClick={increment}>+</button> <button onClick={decrement}>-</button> </div> ); } // Multiple state variables function UserProfile() { const [name, setName] = useState(''); const [email, setEmail] = useState(''); const [isLoading, setIsLoading] = useState(false); return ( <form> <input value={name} onChange={(e) => setName(e.target.value)} placeholder=\"Name\" /> <input value={email} onChange={(e) => setEmail(e.target.value)} placeholder=\"Email\" /> </form> ); } // Object state function UserSettings() { const [settings, setSettings] = useState({ theme: 'light', notifications: true, language: 'en' }); const updateTheme = (theme) => { setSettings(prev => ({ ...prev, theme })); }; return ( <div> <button onClick={() => updateTheme('dark')}>Dark Theme</button> <button onClick={() => updateTheme('light')}>Light Theme</button> </div> ); }","title":"useState Hook"},{"location":"javascript/react/#usereducer-hook","text":"import { useReducer } from 'react'; // Reducer function function counterReducer(state, action) { switch (action.type) { case 'INCREMENT': return { count: state.count + 1 }; case 'DECREMENT': return { count: state.count - 1 }; case 'RESET': return { count: 0 }; default: throw new Error(`Unknown action: ${action.type}`); } } function Counter() { const [state, dispatch] = useReducer(counterReducer, { count: 0 }); return ( <div> <p>Count: {state.count}</p> <button onClick={() => dispatch({ type: 'INCREMENT' })}>+</button> <button onClick={() => dispatch({ type: 'DECREMENT' })}>-</button> <button onClick={() => dispatch({ type: 'RESET' })}>Reset</button> </div> ); } // Complex state management const todoReducer = (state, action) => { switch (action.type) { case 'ADD_TODO': return [...state, { id: Date.now(), text: action.text, done: false }]; case 'TOGGLE_TODO': return state.map(todo => todo.id === action.id ? { ...todo, done: !todo.done } : todo ); case 'DELETE_TODO': return state.filter(todo => todo.id !== action.id); default: return state; } };","title":"useReducer Hook"},{"location":"javascript/react/#effects-and-side-effects","text":"","title":"Effects and Side Effects"},{"location":"javascript/react/#useeffect-hook","text":"import { useEffect, useState } from 'react'; // Basic effect (runs after every render) function Example() { const [count, setCount] = useState(0); useEffect(() => { document.title = `Count: ${count}`; }); return <div>Count: {count}</div>; } // Effect with dependency array function UserProfile({ userId }) { const [user, setUser] = useState(null); useEffect(() => { fetchUser(userId).then(setUser); }, [userId]); // Only re-run when userId changes return user ? <div>{user.name}</div> : <div>Loading...</div>; } // Effect with cleanup function Timer() { const [seconds, setSeconds] = useState(0); useEffect(() => { const interval = setInterval(() => { setSeconds(prev => prev + 1); }, 1000); // Cleanup function return () => clearInterval(interval); }, []); // Empty dependency array = run once return <div>Seconds: {seconds}</div>; } // Multiple effects function ChatRoom({ roomId }) { const [messages, setMessages] = useState([]); const [isConnected, setIsConnected] = useState(false); // Effect for connection useEffect(() => { const connection = createConnection(roomId); connection.connect(); setIsConnected(true); return () => { connection.disconnect(); setIsConnected(false); }; }, [roomId]); // Effect for messages useEffect(() => { if (isConnected) { const unsubscribe = subscribeToMessages(roomId, setMessages); return unsubscribe; } }, [roomId, isConnected]); }","title":"useEffect Hook"},{"location":"javascript/react/#event-handling","text":"","title":"Event Handling"},{"location":"javascript/react/#common-event-patterns","text":"function Form() { const [formData, setFormData] = useState({ name: '', email: '', message: '' }); // Handle input changes const handleChange = (e) => { const { name, value } = e.target; setFormData(prev => ({ ...prev, [name]: value })); }; // Handle form submission const handleSubmit = (e) => { e.preventDefault(); console.log('Form submitted:', formData); // Reset form setFormData({ name: '', email: '', message: '' }); }; // Handle button clicks const handleButtonClick = (e) => { console.log('Button clicked', e.target); }; return ( <form onSubmit={handleSubmit}> <input type=\"text\" name=\"name\" value={formData.name} onChange={handleChange} placeholder=\"Name\" /> <input type=\"email\" name=\"email\" value={formData.email} onChange={handleChange} placeholder=\"Email\" /> <textarea name=\"message\" value={formData.message} onChange={handleChange} placeholder=\"Message\" /> <button type=\"submit\">Submit</button> <button type=\"button\" onClick={handleButtonClick}>Cancel</button> </form> ); } // Event delegation and synthetic events function ItemList({ items }) { const handleItemClick = (e, itemId) => { e.stopPropagation(); // Prevent event bubbling console.log(`Clicked item ${itemId}`); }; return ( <ul> {items.map(item => ( <li key={item.id} onClick={(e) => handleItemClick(e, item.id)}> {item.name} </li> ))} </ul> ); }","title":"Common Event Patterns"},{"location":"javascript/react/#props-and-communication","text":"","title":"Props and Communication"},{"location":"javascript/react/#props-patterns","text":"// Basic props function Greeting({ name, age = 0 }) { // Default props return <p>Hello {name}, age {age}</p>; } // Destructuring props function UserCard({ user: { name, email, avatar } }) { return ( <div> <img src={avatar} alt={name} /> <h3>{name}</h3> <p>{email}</p> </div> ); } // Spread props function Button({ children, ...props }) { return ( <button {...props} className={`btn ${props.className || ''}`}> {children} </button> ); } // Render props pattern function DataFetcher({ render, url }) { const [data, setData] = useState(null); const [loading, setLoading] = useState(true); useEffect(() => { fetch(url) .then(res => res.json()) .then(data => { setData(data); setLoading(false); }); }, [url]); return render({ data, loading }); } // Usage <DataFetcher url=\"/api/users\" render={({ data, loading }) => loading ? <div>Loading...</div> : <UserList users={data} /> } /> // Children prop patterns function Card({ children, title, footer }) { return ( <div className=\"card\"> <h2>{title}</h2> <div className=\"card-content\">{children}</div> {footer && <div className=\"card-footer\">{footer}</div>} </div> ); } // Higher-Order Component pattern function withLoading(WrappedComponent) { return function WithLoadingComponent({ isLoading, ...props }) { if (isLoading) return <div>Loading...</div>; return <WrappedComponent {...props} />; }; }","title":"Props Patterns"},{"location":"javascript/react/#lifting-state-up","text":"function ParentComponent() { const [sharedState, setSharedState] = useState(''); return ( <div> <ChildA value={sharedState} onChange={setSharedState} /> <ChildB value={sharedState} /> </div> ); } function ChildA({ value, onChange }) { return ( <input value={value} onChange={(e) => onChange(e.target.value)} /> ); } function ChildB({ value }) { return <p>Current value: {value}</p>; }","title":"Lifting State Up"},{"location":"javascript/react/#context-api","text":"","title":"Context API"},{"location":"javascript/react/#creating-and-using-context","text":"import { createContext, useContext, useState } from 'react'; // Create context const ThemeContext = createContext(); // Provider component function ThemeProvider({ children }) { const [theme, setTheme] = useState('light'); const toggleTheme = () => { setTheme(prev => prev === 'light' ? 'dark' : 'light'); }; return ( <ThemeContext.Provider value={{ theme, toggleTheme }}> {children} </ThemeContext.Provider> ); } // Custom hook for using context function useTheme() { const context = useContext(ThemeContext); if (!context) { throw new Error('useTheme must be used within ThemeProvider'); } return context; } // Using context in components function ThemedButton() { const { theme, toggleTheme } = useTheme(); return ( <button className={`btn btn-${theme}`} onClick={toggleTheme} > Toggle Theme </button> ); } // App with context function App() { return ( <ThemeProvider> <div className=\"app\"> <ThemedButton /> </div> </ThemeProvider> ); }","title":"Creating and Using Context"},{"location":"javascript/react/#complex-context-with-reducer","text":"// Auth context with reducer const AuthContext = createContext(); const authReducer = (state, action) => { switch (action.type) { case 'LOGIN': return { ...state, user: action.user, isAuthenticated: true }; case 'LOGOUT': return { ...state, user: null, isAuthenticated: false }; case 'SET_LOADING': return { ...state, isLoading: action.isLoading }; default: return state; } }; function AuthProvider({ children }) { const [state, dispatch] = useReducer(authReducer, { user: null, isAuthenticated: false, isLoading: true }); const login = async (credentials) => { dispatch({ type: 'SET_LOADING', isLoading: true }); try { const user = await authService.login(credentials); dispatch({ type: 'LOGIN', user }); } catch (error) { console.error('Login failed:', error); } finally { dispatch({ type: 'SET_LOADING', isLoading: false }); } }; return ( <AuthContext.Provider value={{ ...state, login, dispatch }}> {children} </AuthContext.Provider> ); }","title":"Complex Context with Reducer"},{"location":"javascript/react/#custom-hooks","text":"","title":"Custom Hooks"},{"location":"javascript/react/#creating-custom-hooks","text":"// Custom hook for API calls function useApi(url) { const [data, setData] = useState(null); const [loading, setLoading] = useState(true); const [error, setError] = useState(null); useEffect(() => { const fetchData = async () => { try { setLoading(true); const response = await fetch(url); const result = await response.json(); setData(result); } catch (err) { setError(err); } finally { setLoading(false); } }; fetchData(); }, [url]); return { data, loading, error }; } // Custom hook for local storage function useLocalStorage(key, initialValue) { const [storedValue, setStoredValue] = useState(() => { try { const item = window.localStorage.getItem(key); return item ? JSON.parse(item) : initialValue; } catch (error) { return initialValue; } }); const setValue = (value) => { try { setStoredValue(value); window.localStorage.setItem(key, JSON.stringify(value)); } catch (error) { console.error(error); } }; return [storedValue, setValue]; } // Custom hook for form handling function useForm(initialValues) { const [values, setValues] = useState(initialValues); const [errors, setErrors] = useState({}); const handleChange = (e) => { const { name, value } = e.target; setValues(prev => ({ ...prev, [name]: value })); }; const handleSubmit = (callback) => (e) => { e.preventDefault(); callback(values); }; const reset = () => { setValues(initialValues); setErrors({}); }; return { values, errors, handleChange, handleSubmit, reset, setErrors }; } // Usage function ContactForm() { const { values, handleChange, handleSubmit, reset } = useForm({ name: '', email: '', message: '' }); const onSubmit = (formData) => { console.log('Submitting:', formData); reset(); }; return ( <form onSubmit={handleSubmit(onSubmit)}> <input name=\"name\" value={values.name} onChange={handleChange} placeholder=\"Name\" /> {/* ... other inputs */} </form> ); }","title":"Creating Custom Hooks"},{"location":"javascript/react/#performance-optimization","text":"","title":"Performance Optimization"},{"location":"javascript/react/#reactmemo","text":"import { memo } from 'react'; // Memoized component - only re-renders if props change const ExpensiveComponent = memo(function ExpensiveComponent({ data, onUpdate }) { return ( <div> {data.map(item => ( <div key={item.id}> <span>{item.name}</span> <button onClick={() => onUpdate(item.id)}>Update</button> </div> ))} </div> ); }); // Custom comparison function const OptimizedComponent = memo(function OptimizedComponent({ user, settings }) { return <div>{user.name} - {settings.theme}</div>; }, (prevProps, nextProps) => { return prevProps.user.id === nextProps.user.id && prevProps.settings.theme === nextProps.settings.theme; });","title":"React.memo"},{"location":"javascript/react/#usememo-and-usecallback","text":"import { useMemo, useCallback, useState } from 'react'; function ExpensiveList({ items, filter }) { // Memoize expensive calculations const filteredItems = useMemo(() => { return items.filter(item => item.name.includes(filter)); }, [items, filter]); const expensiveValue = useMemo(() => { return items.reduce((sum, item) => sum + item.price, 0); }, [items]); // Memoize callback functions const handleItemClick = useCallback((itemId) => { console.log(`Clicked item ${itemId}`); }, []); const handleSort = useCallback((sortBy) => { // Sort logic here }, []); return ( <div> <p>Total: ${expensiveValue}</p> {filteredItems.map(item => ( <ItemCard key={item.id} item={item} onClick={handleItemClick} /> ))} </div> ); }","title":"useMemo and useCallback"},{"location":"javascript/react/#conditional-rendering","text":"","title":"Conditional Rendering"},{"location":"javascript/react/#conditional-patterns","text":"function ConditionalExample({ user, isLoggedIn, items = [] }) { return ( <div> {/* Simple conditional */} {isLoggedIn && <p>Welcome, {user.name}!</p>} {/* Ternary operator */} {isLoggedIn ? ( <UserDashboard user={user} /> ) : ( <LoginForm /> )} {/* Complex conditions */} {isLoggedIn && user.role === 'admin' && ( <AdminPanel /> )} {/* Conditional with function */} {(() => { if (!isLoggedIn) return <LoginPrompt />; if (user.role === 'admin') return <AdminDashboard />; return <UserDashboard />; })()} {/* List rendering with conditions */} {items.length > 0 ? ( <ul> {items.map(item => ( <li key={item.id}> {item.name} {item.isNew && <span className=\"badge\">New</span>} </li> ))} </ul> ) : ( <p>No items found</p> )} </div> ); }","title":"Conditional Patterns"},{"location":"javascript/react/#lists-and-keys","text":"","title":"Lists and Keys"},{"location":"javascript/react/#rendering-lists","text":"function ItemList({ items, onDelete, onEdit }) { return ( <div> {items.map(item => ( <div key={item.id} className=\"item\"> <h3>{item.title}</h3> <p>{item.description}</p> <button onClick={() => onEdit(item)}>Edit</button> <button onClick={() => onDelete(item.id)}>Delete</button> </div> ))} </div> ); } // Dynamic list with state function TodoList() { const [todos, setTodos] = useState([]); const [newTodo, setNewTodo] = useState(''); const addTodo = () => { if (newTodo.trim()) { setTodos(prev => [...prev, { id: Date.now(), text: newTodo, completed: false }]); setNewTodo(''); } }; const toggleTodo = (id) => { setTodos(prev => prev.map(todo => todo.id === id ? { ...todo, completed: !todo.completed } : todo )); }; return ( <div> <div> <input value={newTodo} onChange={(e) => setNewTodo(e.target.value)} placeholder=\"Add todo...\" /> <button onClick={addTodo}>Add</button> </div> <ul> {todos.map(todo => ( <li key={todo.id}> <span style={{ textDecoration: todo.completed ? 'line-through' : 'none' }} onClick={() => toggleTodo(todo.id)} > {todo.text} </span> </li> ))} </ul> </div> ); }","title":"Rendering Lists"},{"location":"javascript/react/#forms-and-validation","text":"","title":"Forms and Validation"},{"location":"javascript/react/#controlled-components","text":"function ContactForm() { const [formData, setFormData] = useState({ name: '', email: '', category: 'general', message: '', subscribe: false }); const [errors, setErrors] = useState({}); const handleInputChange = (e) => { const { name, value, type, checked } = e.target; setFormData(prev => ({ ...prev, [name]: type === 'checkbox' ? checked : value })); }; const validateForm = () => { const newErrors = {}; if (!formData.name.trim()) { newErrors.name = 'Name is required'; } if (!formData.email.trim()) { newErrors.email = 'Email is required'; } else if (!/\\S+@\\S+\\.\\S+/.test(formData.email)) { newErrors.email = 'Email is invalid'; } if (!formData.message.trim()) { newErrors.message = 'Message is required'; } setErrors(newErrors); return Object.keys(newErrors).length === 0; }; const handleSubmit = (e) => { e.preventDefault(); if (validateForm()) { console.log('Form submitted:', formData); // Reset form setFormData({ name: '', email: '', category: 'general', message: '', subscribe: false }); } }; return ( <form onSubmit={handleSubmit}> <div> <label> Name: <input type=\"text\" name=\"name\" value={formData.name} onChange={handleInputChange} /> </label> {errors.name && <span className=\"error\">{errors.name}</span>} </div> <div> <label> Email: <input type=\"email\" name=\"email\" value={formData.email} onChange={handleInputChange} /> </label> {errors.email && <span className=\"error\">{errors.email}</span>} </div> <div> <label> Category: <select name=\"category\" value={formData.category} onChange={handleInputChange} > <option value=\"general\">General</option> <option value=\"support\">Support</option> <option value=\"billing\">Billing</option> </select> </label> </div> <div> <label> <input type=\"checkbox\" name=\"subscribe\" checked={formData.subscribe} onChange={handleInputChange} /> Subscribe to newsletter </label> </div> <div> <label> Message: <textarea name=\"message\" value={formData.message} onChange={handleInputChange} rows={4} /> </label> {errors.message && <span className=\"error\">{errors.message}</span>} </div> <button type=\"submit\">Submit</button> </form> ); }","title":"Controlled Components"},{"location":"javascript/react/#error-boundaries","text":"","title":"Error Boundaries"},{"location":"javascript/react/#error-boundary-component","text":"import { Component } from 'react'; class ErrorBoundary extends Component { constructor(props) { super(props); this.state = { hasError: false, error: null, errorInfo: null }; } static getDerivedStateFromError(error) { return { hasError: true }; } componentDidCatch(error, errorInfo) { this.setState({ error: error, errorInfo: errorInfo }); } render() { if (this.state.hasError) { return ( <div className=\"error-boundary\"> <h2>Something went wrong</h2> <details> {this.state.error && this.state.error.toString()} <br /> {this.state.errorInfo.componentStack} </details> </div> ); } return this.props.children; } } // Usage function App() { return ( <ErrorBoundary> <Header /> <MainContent /> <Footer /> </ErrorBoundary> ); }","title":"Error Boundary Component"},{"location":"javascript/react/#refs-and-dom-access","text":"","title":"Refs and DOM Access"},{"location":"javascript/react/#useref-hook","text":"import { useRef, useEffect } from 'react'; function FocusInput() { const inputRef = useRef(null); useEffect(() => { // Focus input when component mounts inputRef.current.focus(); }, []); const handleFocus = () => { inputRef.current.focus(); }; return ( <div> <input ref={inputRef} type=\"text\" /> <button onClick={handleFocus}>Focus Input</button> </div> ); } // Refs with state function VideoPlayer({ src }) { const videoRef = useRef(null); const [isPlaying, setIsPlaying] = useState(false); const togglePlayPause = () => { const video = videoRef.current; if (isPlaying) { video.pause(); } else { video.play(); } setIsPlaying(!isPlaying); }; return ( <div> <video ref={videoRef} src={src} /> <button onClick={togglePlayPause}> {isPlaying ? 'Pause' : 'Play'} </button> </div> ); } // Forwarding refs import { forwardRef } from 'react'; const CustomInput = forwardRef(function CustomInput(props, ref) { return <input {...props} ref={ref} className=\"custom-input\" />; }); // Usage of forwarded ref function Parent() { const inputRef = useRef(null); const focusInput = () => { inputRef.current.focus(); }; return ( <div> <CustomInput ref={inputRef} /> <button onClick={focusInput}>Focus</button> </div> ); }","title":"useRef Hook"},{"location":"javascript/react/#common-patterns-and-best-practices","text":"","title":"Common Patterns and Best Practices"},{"location":"javascript/react/#component-composition","text":"// Composition over inheritance function Layout({ children }) { return ( <div className=\"layout\"> <Header /> <main>{children}</main> <Footer /> </div> ); } // Compound components function Tabs({ children, defaultTab = 0 }) { const [activeTab, setActiveTab] = useState(defaultTab); return ( <div className=\"tabs\"> {React.Children.map(children, (child, index) => React.cloneElement(child, { activeTab, setActiveTab, index }) )} </div> ); } function TabList({ children, activeTab, setActiveTab }) { return ( <div className=\"tab-list\"> {React.Children.map(children, (child, index) => React.cloneElement(child, { isActive: activeTab === index, onClick: () => setActiveTab(index) }) )} </div> ); } // Usage <Tabs defaultTab={0}> <TabList> <Tab>Tab 1</Tab> <Tab>Tab 2</Tab> </TabList> <TabPanels> <TabPanel>Content 1</TabPanel> <TabPanel>Content 2</TabPanel> </TabPanels> </Tabs>","title":"Component Composition"},{"location":"javascript/react/#data-fetching-patterns","text":"// Custom hook for data fetching with loading states function useAsyncData(asyncFunction, dependencies = []) { const [data, setData] = useState(null); const [loading, setLoading] = useState(true); const [error, setError] = useState(null); useEffect(() => { let isCancelled = false; const fetchData = async () => { try { setLoading(true); setError(null); const result = await asyncFunction(); if (!isCancelled) { setData(result); } } catch (err) { if (!isCancelled) { setError(err); } } finally { if (!isCancelled) { setLoading(false); } } }; fetchData(); return () => { isCancelled = true; }; }, dependencies); return { data, loading, error }; } // Usage function UserProfile({ userId }) { const { data: user, loading, error } = useAsyncData( () => fetchUser(userId), [userId] ); if (loading) return <div>Loading...</div>; if (error) return <div>Error: {error.message}</div>; if (!user) return <div>User not found</div>; return ( <div> <h1>{user.name}</h1> <p>{user.email}</p> </div> ); }","title":"Data Fetching Patterns"},{"location":"javascript/react/#testing-patterns","text":"","title":"Testing Patterns"},{"location":"javascript/react/#component-testing-setup","text":"// Example test with React Testing Library import { render, screen, fireEvent, waitFor } from '@testing-library/react'; import '@testing-library/jest-dom'; import Counter from './Counter'; test('renders counter and increments on click', async () => { render(<Counter />); // Find elements const countElement = screen.getByText(/count: 0/i); const incrementButton = screen.getByText(/increment/i); expect(countElement).toBeInTheDocument(); // Simulate user interaction fireEvent.click(incrementButton); // Assert changes await waitFor(() => { expect(screen.getByText(/count: 1/i)).toBeInTheDocument(); }); }); // Testing with context test('uses theme context correctly', () => { render( <ThemeProvider> <ThemedButton /> </ThemeProvider> ); const button = screen.getByRole('button'); expect(button).toHaveClass('btn-light'); fireEvent.click(button); expect(button).toHaveClass('btn-dark'); });","title":"Component Testing Setup"},{"location":"javascript/react/#common-gotchas-and-best-practices","text":"","title":"Common Gotchas and Best Practices"},{"location":"javascript/react/#key-best-practices","text":"// \u2705 Good: Stable keys for list items items.map(item => <Item key={item.id} data={item} />) // \u274c Bad: Using array index as key items.map((item, index) => <Item key={index} data={item} />) // \u2705 Good: Functional state updates setCount(prev => prev + 1); // \u274c Bad: Direct state mutation const newItems = items; newItems.push(newItem); setItems(newItems); // \u2705 Good: Immutable state updates setItems(prev => [...prev, newItem]); // \u2705 Good: Effect cleanup useEffect(() => { const subscription = subscribe(); return () => subscription.unsubscribe(); }, []); // \u2705 Good: Dependency arrays useEffect(() => { fetchData(userId); }, [userId]); // Include all dependencies // \u274c Bad: Missing dependencies useEffect(() => { fetchData(userId); }, []); // Missing userId dependency","title":"Key Best Practices"},{"location":"javascript/react/#performance-tips","text":"// Use React.memo for expensive components const ExpensiveComponent = memo(({ data }) => { // Expensive rendering logic return <div>{/* Complex UI */}</div>; }); // Use useMemo for expensive calculations const expensiveValue = useMemo(() => { return data.reduce((acc, item) => acc + item.value, 0); }, [data]); // Use useCallback for stable function references const handleClick = useCallback((id) => { onItemClick(id); }, [onItemClick]); // Lazy loading with React.lazy const LazyComponent = lazy(() => import('./LazyComponent')); function App() { return ( <Suspense fallback={<div>Loading...</div>}> <LazyComponent /> </Suspense> ); } This cheat sheet covers the essential React concepts, patterns, and best practices for building modern React applications. Focus on understanding hooks, component patterns, and state management for effective React development.","title":"Performance Tips"},{"location":"os/bottlerocket/","text":"Bottlerocket OS Administration A comprehensive guide to managing Bottlerocket OS instances with AWS Systems Manager Session Manager, containerd, and essential administration tasks. Quick Start Prerequisites AWS CLI configured with appropriate IAM permissions Session Manager plugin installed Instance with SSMServiceRole and AmazonSSMManagedInstanceCore policy Bottlerocket instance with control container enabled Essential Setup Commands For instructions on installing the Session Manager plugin on your operating system, please refer to the official AWS documentation: Install the Session Manager plugin for the AWS CLI . After installation, you can verify it and connect to an instance. # Verify installation session-manager-plugin # Connect to instance aws ssm start-session --target $INSTANCE_ID --region $REGION Core Concepts Container Architecture Control Container : Provides SSM access and API management (enabled by default) Admin Container : Privileged access for debugging (disabled by default) Host Containers : Out-of-band access to host OS with configurable privileges Workload Containers : Application containers managed by orchestrators Security Model dm-verity : Read-only root filesystem with cryptographic integrity checking SELinux : Enforcing mode with process labels (container_t, control_t, super_t) Immutable OS : Updates via complete image replacement, not package managers Minimal Attack Surface : No SSH, shell, or package manager by default AWS SSM Session Manager Basic Connection # Connect to instance via SSM aws ssm start-session --target i-1234567890abcdef0 --region us-west-2 # Connect with specific profile aws ssm start-session --target $INSTANCE_ID --region $REGION --profile myprofile # List managed instances aws ssm describe-instance-information --region us-west-2 Setting Up SSM Access 1. Create IAM Service Role # Create trust policy cat <<EOF > ssmservice-trust.json { \"Version\": \"2012-10-17\", \"Statement\": { \"Effect\": \"Allow\", \"Principal\": { \"Service\": \"ssm.amazonaws.com\" }, \"Action\": \"sts:AssumeRole\" } } EOF # Create the role aws iam create-role \\ --role-name SSMServiceRole \\ --assume-role-policy-document file://ssmservice-trust.json # Attach SSM policy aws iam attach-role-policy \\ --role-name SSMServiceRole \\ --policy-arn arn:aws:iam::aws:policy/AmazonSSMManagedInstanceCore 2. Configure Control Container # Create SSM activation export SSM_ACTIVATION=\"$(aws ssm create-activation \\ --iam-role SSMServiceRole \\ --registration-limit 100 \\ --region us-west-2 \\ --output json)\" # Extract activation details SSM_ACTIVATION_ID=\"$(jq -r '.ActivationId' <<< ${SSM_ACTIVATION})\" SSM_ACTIVATION_CODE=\"$(jq -r '.ActivationCode' <<< ${SSM_ACTIVATION})\" # Create user data for control container CONTROL_USER_DATA=\"$(echo '{\"ssm\":{\"activation-id\":\"'${SSM_ACTIVATION_ID}'\",\"activation-code\":\"'${SSM_ACTIVATION_CODE}'\",\"region\":\"us-west-2\"}}' | base64 -w0)\" # Add to user-data.toml cat <<EOF >>user-data.toml [settings.host-containers.control] enabled = true user-data = \"${CONTROL_USER_DATA}\" # Note: Replace vX.Y.Z with the latest version from the ECR Public Gallery # https://gallery.ecr.aws/bottlerocket/bottlerocket-control source = \"public.ecr.aws/bottlerocket/bottlerocket-control:vX.Y.Z\" EOF 3. Enable Admin Container (if needed) Note: The container versions below are examples. Always check the Amazon ECR Public Gallery for the latest version tags for the bottlerocket-control and bottlerocket-admin containers before use. # Via user data (during launch) PUBKEY_FILE=\"${HOME}/.ssh/id_rsa.pub\" PUBKEY=$(< \"${PUBKEY_FILE}\") ADMIN_USER_DATA=\"$(echo '{\"ssh\": {\"authorized-keys\": [\"'${PUBKEY}'\"]}}' | base64 -w 0)\" cat <<EOF >>user-data.toml [settings.host-containers.admin] enabled = true superpowered = true user-data = \"${ADMIN_USER_DATA}\" # Note: Replace vX.Y.Z with the latest version from the ECR Public Gallery # https://gallery.ecr.aws/bottlerocket/bottlerocket-admin source = \"public.ecr.aws/bottlerocket/bottlerocket-admin:vX.Y.Z\" EOF Session Management # Start interactive session aws ssm start-session --target $INSTANCE_ID # Run single command aws ssm send-command \\ --instance-ids $INSTANCE_ID \\ --document-name \"AWS-RunShellScript\" \\ --parameters 'commands=[\"uptime\"]' # Get command output aws ssm get-command-invocation \\ --command-id $COMMAND_ID \\ --instance-id $INSTANCE_ID Container Management with ctr Container Runtime Access # Access the host containerd socket sudo ctr --address /run/host-containerd/host-containerd.sock # Common namespaces ctr namespaces list # k8s.io (Kubernetes) # moby (Docker/ECS) # default Image Management # List images ctr --namespace k8s.io images list ctr --namespace moby images list # Pull image ctr --namespace k8s.io images pull docker.io/nginx:latest # Remove image ctr --namespace k8s.io images remove docker.io/nginx:latest # Import image from tar ctr --namespace k8s.io images import image.tar # Export image to tar ctr --namespace k8s.io images export image.tar docker.io/nginx:latest # Tag image ctr --namespace k8s.io images tag docker.io/nginx:latest my-registry/nginx:v1 Container Operations # List containers ctr --namespace k8s.io containers list ctr --namespace moby containers list # List running tasks ctr --namespace k8s.io tasks list # View container info ctr --namespace k8s.io containers info $CONTAINER_ID # Execute command in running container ctr --namespace k8s.io tasks exec --exec-id $EXEC_ID $CONTAINER_ID sh # Kill task ctr --namespace k8s.io tasks kill $CONTAINER_ID # Remove container ctr --namespace k8s.io containers remove $CONTAINER_ID Advanced Operations # Create container (without starting) ctr --namespace k8s.io containers create docker.io/nginx:latest nginx-test # Start container as task ctr --namespace k8s.io tasks start nginx-test # Attach to running container ctr --namespace k8s.io tasks attach nginx-test # Get container metrics ctr --namespace k8s.io tasks metrics $CONTAINER_ID # Create snapshot ctr --namespace k8s.io snapshots prepare snapshot-name $CONTAINER_ID # List snapshots ctr --namespace k8s.io snapshots list Administration Tasks Host Container Management From Control Container # Enable admin container enable-admin-container # Enter admin container enter-admin-container # Check admin container status apiclient get host-containers.admin From Admin Container # Access privileged host namespace sudo sheltie # Run single command with elevated privileges sudo sheltie -c \"command_here\" # Common privileged operations sudo sheltie -c \"systemctl status kubelet\" sudo sheltie -c \"journalctl -u kubelet --no-pager\" sudo sheltie -c \"crictl ps\" API Client Operations # Set configuration apiclient set host-containers.admin.enabled=true apiclient set settings.kubernetes.cluster-name=my-cluster # Get configuration apiclient get settings apiclient get host-containers # Execute in container apiclient exec admin bash apiclient exec control enable-admin-container # Apply settings from file apiclient apply --from-file settings.json # Generate configuration apiclient generate-settings > current-settings.json System Information # OS version and build info apiclient get os cat /etc/os-release # Kernel information uname -a apiclient get kernel # Container runtime info ctr version apiclient get container-runtime # Network configuration apiclient get network ip addr show # Storage information df -h lsblk apiclient get storage Service Management # From admin container with sheltie sudo sheltie -c \"systemctl status containerd\" sudo sheltie -c \"systemctl status kubelet\" sudo sheltie -c \"systemctl status ecs\" sudo sheltie -c \"systemctl restart containerd\" # View service logs sudo sheltie -c \"journalctl -u containerd --no-pager\" sudo sheltie -c \"journalctl -u kubelet -f\" sudo sheltie -c \"journalctl --boot --no-pager\" Troubleshooting Log Collection # Generate comprehensive log archive sudo sheltie logdog # Fetch logs via SSH ssh -i YOUR_KEY_FILE ec2-user@YOUR_HOST \\ \"cat /.bottlerocket/support/bottlerocket-logs.tar.gz\" > bottlerocket-logs.tar.gz # Fetch logs via kubectl (for Kubernetes) kubectl get --raw \\ \"/api/v1/nodes/NODE_NAME/proxy/logs/support/bottlerocket-logs.tar.gz\" > bottlerocket-logs.tar.gz Common Issues and Solutions 1. Container Runtime Issues # Check containerd status sudo sheltie -c \"systemctl status containerd\" # Restart containerd sudo sheltie -c \"systemctl restart containerd\" # Check containerd configuration sudo sheltie -c \"cat /etc/containerd/config.toml\" # View containerd logs sudo sheltie -c \"journalctl -u containerd --no-pager -n 100\" 2. Kubernetes Node Issues # Check kubelet status sudo sheltie -c \"systemctl status kubelet\" # View kubelet configuration apiclient get settings.kubernetes # Check node readiness kubectl get nodes kubectl describe node $NODE_NAME # Restart kubelet sudo sheltie -c \"systemctl restart kubelet\" 3. Network Connectivity # Check network interfaces ip addr show ip route show # Test DNS resolution nslookup kubernetes.default.svc.cluster.local # Check iptables rules (from admin container) sudo sheltie -c \"iptables -L\" sudo sheltie -c \"iptables -t nat -L\" # Test container network ctr --namespace k8s.io tasks exec --exec-id test nginx-test ping 8.8.8.8 4. Storage Issues # Check disk usage df -h lsblk # Check mount points mount | grep bottlerocket # EBS volume attachment (AWS) aws ec2 describe-volumes --volume-ids $VOLUME_ID # Container storage usage ctr --namespace k8s.io images list -q | xargs ctr --namespace k8s.io images usage 5. SSM Connection Problems # Check SSM agent status sudo sheltie -c \"systemctl status amazon-ssm-agent\" # Restart SSM agent sudo sheltie -c \"systemctl restart amazon-ssm-agent\" # Verify instance registration aws ssm describe-instance-information --filters \"Key=InstanceIds,Values=$INSTANCE_ID\" # Check IAM permissions aws sts get-caller-identity aws iam list-attached-role-policies --role-name $ROLE_NAME Performance Monitoring # CPU and memory usage top htop (if available) apiclient get metrics # Container resource usage ctr --namespace k8s.io tasks metrics crictl stats (from admin container) # System resource limits apiclient get settings.oci-defaults # Network statistics ss -tuln netstat -i # I/O statistics iostat iotop (if available) Security Best Practices Container Security # Disable privileged containers (ECS) apiclient set settings.ecs.allow-privileged-containers=false # Configure SELinux labels for containers apiclient set settings.oci-defaults.capabilities=[] apiclient set settings.container-runtime.selinux-label=\"system_u:system_r:container_t:s0\" Host Container Hardening # Disable admin container when not needed apiclient set host-containers.admin.enabled=false # Disable control container (careful - may lose remote access) apiclient set host-containers.control.enabled=false # Limit superpowered containers # Avoid: superpowered = true unless absolutely necessary Network Security # Configure proxy settings if required apiclient set settings.network.proxy.http-proxy=\"http://proxy:8080\" apiclient set settings.network.proxy.https-proxy=\"https://proxy:8080\" apiclient set settings.network.proxy.no-proxy=\"localhost,127.0.0.1,.internal\" # Review iptables rules sudo sheltie -c \"iptables -L -n\" Access Control with Pod Security Admission Pod Security Policies (PSPs) were deprecated in Kubernetes v1.21 and removed entirely in v1.25. Security for pods is now enforced using Pod Security Admission (PSA) , which applies security standards at the namespace level. You can enforce privileged , baseline , or restricted policies by labeling your namespaces. # Example: Label a namespace to enforce the baseline policy kubectl label --overwrite ns YOUR_NAMESPACE pod-security.kubernetes.io/enforce=baseline # Example: Label a namespace to warn on violations of the restricted policy kubectl label --overwrite ns YOUR_NAMESPACE pod-security.kubernetes.io/warn=restricted Updates and Maintenance OS Updates # Check current version apiclient get os.version-id apiclient get os.build-id # Configure automatic updates # Note: Replace aws-k8s-1.XX with your desired and supported Kubernetes version. apiclient set settings.updates.metadata-base-url=\"https://updates.bottlerocket.aws/2020-07-07/aws-k8s-1.XX/x86_64/\" apiclient set settings.updates.targets-base-url=\"https://updates.bottlerocket.aws/2020-07-07/aws-k8s-1.XX/x86_64/\" # Check for available updates apiclient check-update # Apply updates apiclient update apply # Rollback if needed apiclient update rollback # Reboot to new image apiclient reboot Container Image Management # Clean up unused images ctr --namespace k8s.io images prune ctr --namespace moby images prune # Check image sizes ctr --namespace k8s.io images list -q | xargs -I {} ctr --namespace k8s.io images usage {} # Update container runtime settings apiclient set settings.container-runtime.max-container-log-line-size=\"16384\" apiclient set settings.container-runtime.max-concurrent-downloads=\"6\" AMI Management Finding Bottlerocket AMIs Note: The Kubernetes version 1.27 used below is an example. You should find the latest supported version for your use case. # List all available Bottlerocket variants to find the latest K8s version aws ssm get-parameters-by-path \\ --path \"/aws/service/bottlerocket\" \\ --query \"Parameters[].Name\" --output text | sort | uniq # Get latest AMI ID from SSM for a specific K8s version aws ssm get-parameter \\ --region us-west-2 \\ --name \"/aws/service/bottlerocket/aws-k8s-1.27/x86_64/latest/image_id\" \\ --query Parameter.Value --output text # Get AMI details for a specific K8s version aws ssm get-parameters --region us-west-2 \\ --names \"/aws/service/bottlerocket/aws-k8s-1.27/x86_64/latest/image_id\" \\ \"/aws/service/bottlerocket/aws-k8s-1.27/x86_64/latest/image_version\" \\ --output json | jq -r '.Parameters | .[] | \"\\(.Name): \\(.Value)\"' # List all available variants (alternative) aws ssm get-parameters-by-path \\ --path \"/aws/service/bottlerocket\" \\ --recursive --region us-west-2 | jq -r '.Parameters[].Name' | sort Instance Launch # Launch with user data aws ec2 run-instances \\ --image-id $AMI_ID \\ --count 1 \\ --instance-type m5.large \\ --key-name my-key \\ --security-group-ids sg-12345678 \\ --subnet-id subnet-12345678 \\ --iam-instance-profile Name=BottlerocketInstanceProfile \\ --user-data file://user-data.toml Quick Reference Essential Commands Task Command Connect via SSM aws ssm start-session --target $INSTANCE_ID Enable admin container enable-admin-container (from control) Access admin container enter-admin-container (from control) Privileged shell sudo sheltie (from admin) List containers ctr --namespace k8s.io containers list Generate logs logdog (from admin with sheltie) Get OS info apiclient get os Set configuration apiclient set key=value Apply updates apiclient update apply Container Namespaces Namespace Purpose k8s.io Kubernetes containers and images moby Docker/ECS containers and images default Default containerd namespace Important File Locations Path Description /run/host-containerd/host-containerd.sock Host containerd socket /run/containerd/containerd.sock Container containerd socket /etc/containerd/config.toml Containerd configuration /.bottlerocket/support/ Log and debug files /etc/os-release OS version information SELinux Labels Label Usage Privileges container_t Regular containers Limited control_t Privileged containers API socket access super_t Superpowered containers Full host access Production Recommendations Security Keep admin container disabled unless actively debugging Use least-privilege IAM roles Implement Pod Security Admission standards Regular security updates Monitoring Set up CloudWatch for system metrics Monitor container resource usage Alert on update failures Track SSM session activity Maintenance Schedule regular OS updates Clean up unused container images Monitor disk usage Backup important configurations Access Control Limit SSH key distribution Use SSM for remote access Implement proper IAM policies Regular access reviews Troubleshooting Preparedness Document common procedures Maintain debug tooling access Regular log collection tests Incident response procedures","title":"Bottlerocket OS Administration"},{"location":"os/bottlerocket/#bottlerocket-os-administration","text":"A comprehensive guide to managing Bottlerocket OS instances with AWS Systems Manager Session Manager, containerd, and essential administration tasks.","title":"Bottlerocket OS Administration"},{"location":"os/bottlerocket/#quick-start","text":"","title":"Quick Start"},{"location":"os/bottlerocket/#prerequisites","text":"AWS CLI configured with appropriate IAM permissions Session Manager plugin installed Instance with SSMServiceRole and AmazonSSMManagedInstanceCore policy Bottlerocket instance with control container enabled","title":"Prerequisites"},{"location":"os/bottlerocket/#essential-setup-commands","text":"For instructions on installing the Session Manager plugin on your operating system, please refer to the official AWS documentation: Install the Session Manager plugin for the AWS CLI . After installation, you can verify it and connect to an instance. # Verify installation session-manager-plugin # Connect to instance aws ssm start-session --target $INSTANCE_ID --region $REGION","title":"Essential Setup Commands"},{"location":"os/bottlerocket/#core-concepts","text":"","title":"Core Concepts"},{"location":"os/bottlerocket/#container-architecture","text":"Control Container : Provides SSM access and API management (enabled by default) Admin Container : Privileged access for debugging (disabled by default) Host Containers : Out-of-band access to host OS with configurable privileges Workload Containers : Application containers managed by orchestrators","title":"Container Architecture"},{"location":"os/bottlerocket/#security-model","text":"dm-verity : Read-only root filesystem with cryptographic integrity checking SELinux : Enforcing mode with process labels (container_t, control_t, super_t) Immutable OS : Updates via complete image replacement, not package managers Minimal Attack Surface : No SSH, shell, or package manager by default","title":"Security Model"},{"location":"os/bottlerocket/#aws-ssm-session-manager","text":"","title":"AWS SSM Session Manager"},{"location":"os/bottlerocket/#basic-connection","text":"# Connect to instance via SSM aws ssm start-session --target i-1234567890abcdef0 --region us-west-2 # Connect with specific profile aws ssm start-session --target $INSTANCE_ID --region $REGION --profile myprofile # List managed instances aws ssm describe-instance-information --region us-west-2","title":"Basic Connection"},{"location":"os/bottlerocket/#setting-up-ssm-access","text":"","title":"Setting Up SSM Access"},{"location":"os/bottlerocket/#1-create-iam-service-role","text":"# Create trust policy cat <<EOF > ssmservice-trust.json { \"Version\": \"2012-10-17\", \"Statement\": { \"Effect\": \"Allow\", \"Principal\": { \"Service\": \"ssm.amazonaws.com\" }, \"Action\": \"sts:AssumeRole\" } } EOF # Create the role aws iam create-role \\ --role-name SSMServiceRole \\ --assume-role-policy-document file://ssmservice-trust.json # Attach SSM policy aws iam attach-role-policy \\ --role-name SSMServiceRole \\ --policy-arn arn:aws:iam::aws:policy/AmazonSSMManagedInstanceCore","title":"1. Create IAM Service Role"},{"location":"os/bottlerocket/#2-configure-control-container","text":"# Create SSM activation export SSM_ACTIVATION=\"$(aws ssm create-activation \\ --iam-role SSMServiceRole \\ --registration-limit 100 \\ --region us-west-2 \\ --output json)\" # Extract activation details SSM_ACTIVATION_ID=\"$(jq -r '.ActivationId' <<< ${SSM_ACTIVATION})\" SSM_ACTIVATION_CODE=\"$(jq -r '.ActivationCode' <<< ${SSM_ACTIVATION})\" # Create user data for control container CONTROL_USER_DATA=\"$(echo '{\"ssm\":{\"activation-id\":\"'${SSM_ACTIVATION_ID}'\",\"activation-code\":\"'${SSM_ACTIVATION_CODE}'\",\"region\":\"us-west-2\"}}' | base64 -w0)\" # Add to user-data.toml cat <<EOF >>user-data.toml [settings.host-containers.control] enabled = true user-data = \"${CONTROL_USER_DATA}\" # Note: Replace vX.Y.Z with the latest version from the ECR Public Gallery # https://gallery.ecr.aws/bottlerocket/bottlerocket-control source = \"public.ecr.aws/bottlerocket/bottlerocket-control:vX.Y.Z\" EOF","title":"2. Configure Control Container"},{"location":"os/bottlerocket/#3-enable-admin-container-if-needed","text":"Note: The container versions below are examples. Always check the Amazon ECR Public Gallery for the latest version tags for the bottlerocket-control and bottlerocket-admin containers before use. # Via user data (during launch) PUBKEY_FILE=\"${HOME}/.ssh/id_rsa.pub\" PUBKEY=$(< \"${PUBKEY_FILE}\") ADMIN_USER_DATA=\"$(echo '{\"ssh\": {\"authorized-keys\": [\"'${PUBKEY}'\"]}}' | base64 -w 0)\" cat <<EOF >>user-data.toml [settings.host-containers.admin] enabled = true superpowered = true user-data = \"${ADMIN_USER_DATA}\" # Note: Replace vX.Y.Z with the latest version from the ECR Public Gallery # https://gallery.ecr.aws/bottlerocket/bottlerocket-admin source = \"public.ecr.aws/bottlerocket/bottlerocket-admin:vX.Y.Z\" EOF","title":"3. Enable Admin Container (if needed)"},{"location":"os/bottlerocket/#session-management","text":"# Start interactive session aws ssm start-session --target $INSTANCE_ID # Run single command aws ssm send-command \\ --instance-ids $INSTANCE_ID \\ --document-name \"AWS-RunShellScript\" \\ --parameters 'commands=[\"uptime\"]' # Get command output aws ssm get-command-invocation \\ --command-id $COMMAND_ID \\ --instance-id $INSTANCE_ID","title":"Session Management"},{"location":"os/bottlerocket/#container-management-with-ctr","text":"","title":"Container Management with ctr"},{"location":"os/bottlerocket/#container-runtime-access","text":"# Access the host containerd socket sudo ctr --address /run/host-containerd/host-containerd.sock # Common namespaces ctr namespaces list # k8s.io (Kubernetes) # moby (Docker/ECS) # default","title":"Container Runtime Access"},{"location":"os/bottlerocket/#image-management","text":"# List images ctr --namespace k8s.io images list ctr --namespace moby images list # Pull image ctr --namespace k8s.io images pull docker.io/nginx:latest # Remove image ctr --namespace k8s.io images remove docker.io/nginx:latest # Import image from tar ctr --namespace k8s.io images import image.tar # Export image to tar ctr --namespace k8s.io images export image.tar docker.io/nginx:latest # Tag image ctr --namespace k8s.io images tag docker.io/nginx:latest my-registry/nginx:v1","title":"Image Management"},{"location":"os/bottlerocket/#container-operations","text":"# List containers ctr --namespace k8s.io containers list ctr --namespace moby containers list # List running tasks ctr --namespace k8s.io tasks list # View container info ctr --namespace k8s.io containers info $CONTAINER_ID # Execute command in running container ctr --namespace k8s.io tasks exec --exec-id $EXEC_ID $CONTAINER_ID sh # Kill task ctr --namespace k8s.io tasks kill $CONTAINER_ID # Remove container ctr --namespace k8s.io containers remove $CONTAINER_ID","title":"Container Operations"},{"location":"os/bottlerocket/#advanced-operations","text":"# Create container (without starting) ctr --namespace k8s.io containers create docker.io/nginx:latest nginx-test # Start container as task ctr --namespace k8s.io tasks start nginx-test # Attach to running container ctr --namespace k8s.io tasks attach nginx-test # Get container metrics ctr --namespace k8s.io tasks metrics $CONTAINER_ID # Create snapshot ctr --namespace k8s.io snapshots prepare snapshot-name $CONTAINER_ID # List snapshots ctr --namespace k8s.io snapshots list","title":"Advanced Operations"},{"location":"os/bottlerocket/#administration-tasks","text":"","title":"Administration Tasks"},{"location":"os/bottlerocket/#host-container-management","text":"","title":"Host Container Management"},{"location":"os/bottlerocket/#from-control-container","text":"# Enable admin container enable-admin-container # Enter admin container enter-admin-container # Check admin container status apiclient get host-containers.admin","title":"From Control Container"},{"location":"os/bottlerocket/#from-admin-container","text":"# Access privileged host namespace sudo sheltie # Run single command with elevated privileges sudo sheltie -c \"command_here\" # Common privileged operations sudo sheltie -c \"systemctl status kubelet\" sudo sheltie -c \"journalctl -u kubelet --no-pager\" sudo sheltie -c \"crictl ps\"","title":"From Admin Container"},{"location":"os/bottlerocket/#api-client-operations","text":"# Set configuration apiclient set host-containers.admin.enabled=true apiclient set settings.kubernetes.cluster-name=my-cluster # Get configuration apiclient get settings apiclient get host-containers # Execute in container apiclient exec admin bash apiclient exec control enable-admin-container # Apply settings from file apiclient apply --from-file settings.json # Generate configuration apiclient generate-settings > current-settings.json","title":"API Client Operations"},{"location":"os/bottlerocket/#system-information","text":"# OS version and build info apiclient get os cat /etc/os-release # Kernel information uname -a apiclient get kernel # Container runtime info ctr version apiclient get container-runtime # Network configuration apiclient get network ip addr show # Storage information df -h lsblk apiclient get storage","title":"System Information"},{"location":"os/bottlerocket/#service-management","text":"# From admin container with sheltie sudo sheltie -c \"systemctl status containerd\" sudo sheltie -c \"systemctl status kubelet\" sudo sheltie -c \"systemctl status ecs\" sudo sheltie -c \"systemctl restart containerd\" # View service logs sudo sheltie -c \"journalctl -u containerd --no-pager\" sudo sheltie -c \"journalctl -u kubelet -f\" sudo sheltie -c \"journalctl --boot --no-pager\"","title":"Service Management"},{"location":"os/bottlerocket/#troubleshooting","text":"","title":"Troubleshooting"},{"location":"os/bottlerocket/#log-collection","text":"# Generate comprehensive log archive sudo sheltie logdog # Fetch logs via SSH ssh -i YOUR_KEY_FILE ec2-user@YOUR_HOST \\ \"cat /.bottlerocket/support/bottlerocket-logs.tar.gz\" > bottlerocket-logs.tar.gz # Fetch logs via kubectl (for Kubernetes) kubectl get --raw \\ \"/api/v1/nodes/NODE_NAME/proxy/logs/support/bottlerocket-logs.tar.gz\" > bottlerocket-logs.tar.gz","title":"Log Collection"},{"location":"os/bottlerocket/#common-issues-and-solutions","text":"","title":"Common Issues and Solutions"},{"location":"os/bottlerocket/#1-container-runtime-issues","text":"# Check containerd status sudo sheltie -c \"systemctl status containerd\" # Restart containerd sudo sheltie -c \"systemctl restart containerd\" # Check containerd configuration sudo sheltie -c \"cat /etc/containerd/config.toml\" # View containerd logs sudo sheltie -c \"journalctl -u containerd --no-pager -n 100\"","title":"1. Container Runtime Issues"},{"location":"os/bottlerocket/#2-kubernetes-node-issues","text":"# Check kubelet status sudo sheltie -c \"systemctl status kubelet\" # View kubelet configuration apiclient get settings.kubernetes # Check node readiness kubectl get nodes kubectl describe node $NODE_NAME # Restart kubelet sudo sheltie -c \"systemctl restart kubelet\"","title":"2. Kubernetes Node Issues"},{"location":"os/bottlerocket/#3-network-connectivity","text":"# Check network interfaces ip addr show ip route show # Test DNS resolution nslookup kubernetes.default.svc.cluster.local # Check iptables rules (from admin container) sudo sheltie -c \"iptables -L\" sudo sheltie -c \"iptables -t nat -L\" # Test container network ctr --namespace k8s.io tasks exec --exec-id test nginx-test ping 8.8.8.8","title":"3. Network Connectivity"},{"location":"os/bottlerocket/#4-storage-issues","text":"# Check disk usage df -h lsblk # Check mount points mount | grep bottlerocket # EBS volume attachment (AWS) aws ec2 describe-volumes --volume-ids $VOLUME_ID # Container storage usage ctr --namespace k8s.io images list -q | xargs ctr --namespace k8s.io images usage","title":"4. Storage Issues"},{"location":"os/bottlerocket/#5-ssm-connection-problems","text":"# Check SSM agent status sudo sheltie -c \"systemctl status amazon-ssm-agent\" # Restart SSM agent sudo sheltie -c \"systemctl restart amazon-ssm-agent\" # Verify instance registration aws ssm describe-instance-information --filters \"Key=InstanceIds,Values=$INSTANCE_ID\" # Check IAM permissions aws sts get-caller-identity aws iam list-attached-role-policies --role-name $ROLE_NAME","title":"5. SSM Connection Problems"},{"location":"os/bottlerocket/#performance-monitoring","text":"# CPU and memory usage top htop (if available) apiclient get metrics # Container resource usage ctr --namespace k8s.io tasks metrics crictl stats (from admin container) # System resource limits apiclient get settings.oci-defaults # Network statistics ss -tuln netstat -i # I/O statistics iostat iotop (if available)","title":"Performance Monitoring"},{"location":"os/bottlerocket/#security-best-practices","text":"","title":"Security Best Practices"},{"location":"os/bottlerocket/#container-security","text":"# Disable privileged containers (ECS) apiclient set settings.ecs.allow-privileged-containers=false # Configure SELinux labels for containers apiclient set settings.oci-defaults.capabilities=[] apiclient set settings.container-runtime.selinux-label=\"system_u:system_r:container_t:s0\"","title":"Container Security"},{"location":"os/bottlerocket/#host-container-hardening","text":"# Disable admin container when not needed apiclient set host-containers.admin.enabled=false # Disable control container (careful - may lose remote access) apiclient set host-containers.control.enabled=false # Limit superpowered containers # Avoid: superpowered = true unless absolutely necessary","title":"Host Container Hardening"},{"location":"os/bottlerocket/#network-security","text":"# Configure proxy settings if required apiclient set settings.network.proxy.http-proxy=\"http://proxy:8080\" apiclient set settings.network.proxy.https-proxy=\"https://proxy:8080\" apiclient set settings.network.proxy.no-proxy=\"localhost,127.0.0.1,.internal\" # Review iptables rules sudo sheltie -c \"iptables -L -n\"","title":"Network Security"},{"location":"os/bottlerocket/#access-control-with-pod-security-admission","text":"Pod Security Policies (PSPs) were deprecated in Kubernetes v1.21 and removed entirely in v1.25. Security for pods is now enforced using Pod Security Admission (PSA) , which applies security standards at the namespace level. You can enforce privileged , baseline , or restricted policies by labeling your namespaces. # Example: Label a namespace to enforce the baseline policy kubectl label --overwrite ns YOUR_NAMESPACE pod-security.kubernetes.io/enforce=baseline # Example: Label a namespace to warn on violations of the restricted policy kubectl label --overwrite ns YOUR_NAMESPACE pod-security.kubernetes.io/warn=restricted","title":"Access Control with Pod Security Admission"},{"location":"os/bottlerocket/#updates-and-maintenance","text":"","title":"Updates and Maintenance"},{"location":"os/bottlerocket/#os-updates","text":"# Check current version apiclient get os.version-id apiclient get os.build-id # Configure automatic updates # Note: Replace aws-k8s-1.XX with your desired and supported Kubernetes version. apiclient set settings.updates.metadata-base-url=\"https://updates.bottlerocket.aws/2020-07-07/aws-k8s-1.XX/x86_64/\" apiclient set settings.updates.targets-base-url=\"https://updates.bottlerocket.aws/2020-07-07/aws-k8s-1.XX/x86_64/\" # Check for available updates apiclient check-update # Apply updates apiclient update apply # Rollback if needed apiclient update rollback # Reboot to new image apiclient reboot","title":"OS Updates"},{"location":"os/bottlerocket/#container-image-management","text":"# Clean up unused images ctr --namespace k8s.io images prune ctr --namespace moby images prune # Check image sizes ctr --namespace k8s.io images list -q | xargs -I {} ctr --namespace k8s.io images usage {} # Update container runtime settings apiclient set settings.container-runtime.max-container-log-line-size=\"16384\" apiclient set settings.container-runtime.max-concurrent-downloads=\"6\"","title":"Container Image Management"},{"location":"os/bottlerocket/#ami-management","text":"","title":"AMI Management"},{"location":"os/bottlerocket/#finding-bottlerocket-amis","text":"Note: The Kubernetes version 1.27 used below is an example. You should find the latest supported version for your use case. # List all available Bottlerocket variants to find the latest K8s version aws ssm get-parameters-by-path \\ --path \"/aws/service/bottlerocket\" \\ --query \"Parameters[].Name\" --output text | sort | uniq # Get latest AMI ID from SSM for a specific K8s version aws ssm get-parameter \\ --region us-west-2 \\ --name \"/aws/service/bottlerocket/aws-k8s-1.27/x86_64/latest/image_id\" \\ --query Parameter.Value --output text # Get AMI details for a specific K8s version aws ssm get-parameters --region us-west-2 \\ --names \"/aws/service/bottlerocket/aws-k8s-1.27/x86_64/latest/image_id\" \\ \"/aws/service/bottlerocket/aws-k8s-1.27/x86_64/latest/image_version\" \\ --output json | jq -r '.Parameters | .[] | \"\\(.Name): \\(.Value)\"' # List all available variants (alternative) aws ssm get-parameters-by-path \\ --path \"/aws/service/bottlerocket\" \\ --recursive --region us-west-2 | jq -r '.Parameters[].Name' | sort","title":"Finding Bottlerocket AMIs"},{"location":"os/bottlerocket/#instance-launch","text":"# Launch with user data aws ec2 run-instances \\ --image-id $AMI_ID \\ --count 1 \\ --instance-type m5.large \\ --key-name my-key \\ --security-group-ids sg-12345678 \\ --subnet-id subnet-12345678 \\ --iam-instance-profile Name=BottlerocketInstanceProfile \\ --user-data file://user-data.toml","title":"Instance Launch"},{"location":"os/bottlerocket/#quick-reference","text":"","title":"Quick Reference"},{"location":"os/bottlerocket/#essential-commands","text":"Task Command Connect via SSM aws ssm start-session --target $INSTANCE_ID Enable admin container enable-admin-container (from control) Access admin container enter-admin-container (from control) Privileged shell sudo sheltie (from admin) List containers ctr --namespace k8s.io containers list Generate logs logdog (from admin with sheltie) Get OS info apiclient get os Set configuration apiclient set key=value Apply updates apiclient update apply","title":"Essential Commands"},{"location":"os/bottlerocket/#container-namespaces","text":"Namespace Purpose k8s.io Kubernetes containers and images moby Docker/ECS containers and images default Default containerd namespace","title":"Container Namespaces"},{"location":"os/bottlerocket/#important-file-locations","text":"Path Description /run/host-containerd/host-containerd.sock Host containerd socket /run/containerd/containerd.sock Container containerd socket /etc/containerd/config.toml Containerd configuration /.bottlerocket/support/ Log and debug files /etc/os-release OS version information","title":"Important File Locations"},{"location":"os/bottlerocket/#selinux-labels","text":"Label Usage Privileges container_t Regular containers Limited control_t Privileged containers API socket access super_t Superpowered containers Full host access","title":"SELinux Labels"},{"location":"os/bottlerocket/#production-recommendations","text":"Security Keep admin container disabled unless actively debugging Use least-privilege IAM roles Implement Pod Security Admission standards Regular security updates Monitoring Set up CloudWatch for system metrics Monitor container resource usage Alert on update failures Track SSM session activity Maintenance Schedule regular OS updates Clean up unused container images Monitor disk usage Backup important configurations Access Control Limit SSH key distribution Use SSM for remote access Implement proper IAM policies Regular access reviews Troubleshooting Preparedness Document common procedures Maintain debug tooling access Regular log collection tests Incident response procedures","title":"Production Recommendations"},{"location":"python/inquirer/","text":"Python Inquirer A comprehensive reference for building interactive command-line interfaces with Python's inquirer libraries. This covers both the original python-inquirer and the modern InquirerPy libraries for creating engaging CLI prompts. Quick Start Installation # Original python-inquirer (stable, simple) pip install inquirer # InquirerPy (modern, feature-rich) pip install inquirerpy # Both libraries can coexist pip install inquirer inquirerpy Basic Usage Comparison # python-inquirer (classic) import inquirer questions = [ inquirer.Text('name', message=\"What's your name?\"), inquirer.List('color', message=\"Favorite color?\", choices=['Red', 'Blue', 'Green']) ] answers = inquirer.prompt(questions) # InquirerPy (modern - classic syntax) from InquirerPy import prompt questions = [ {\"type\": \"input\", \"message\": \"What's your name?\", \"name\": \"name\"}, {\"type\": \"list\", \"message\": \"Favorite color?\", \"choices\": [\"Red\", \"Blue\", \"Green\"]} ] answers = prompt(questions) # InquirerPy (modern - alternate syntax) from InquirerPy import inquirer name = inquirer.text(message=\"What's your name?\").execute() color = inquirer.select(message=\"Favorite color?\", choices=[\"Red\", \"Blue\", \"Green\"]).execute() Core Prompt Types Text Input python-inquirer import inquirer # Basic text input questions = [ inquirer.Text('username', message=\"Enter username\"), inquirer.Text('email', message=\"Enter email\", validate=lambda _, x: '@' in x), ] answers = inquirer.prompt(questions) InquirerPy # Classic syntax from InquirerPy import prompt questions = [ { \"type\": \"input\", \"message\": \"Username:\", \"name\": \"username\", \"validate\": lambda result: len(result) > 0, \"invalid_message\": \"Username cannot be empty\" } ] result = prompt(questions) # Alternate syntax from InquirerPy import inquirer username = inquirer.text( message=\"Username:\", validate=lambda result: len(result) > 0, invalid_message=\"Username cannot be empty\" ).execute() Password Input python-inquirer import inquirer questions = [ inquirer.Password('password', message=\"Enter password\") ] answers = inquirer.prompt(questions) InquirerPy # Classic syntax from InquirerPy import prompt from InquirerPy.validator import PasswordValidator questions = [ { \"type\": \"secret\", \"message\": \"Password:\", \"validate\": PasswordValidator( length=8, cap=True, special=True, number=True ) } ] result = prompt(questions) # Alternate syntax password = inquirer.secret( message=\"Password:\", validate=PasswordValidator(length=8, cap=True, special=True, number=True) ).execute() Single Choice Lists python-inquirer import inquirer questions = [ inquirer.List('size', message=\"What size?\", choices=['Small', 'Medium', 'Large'], carousel=True # Circular navigation ) ] answers = inquirer.prompt(questions) InquirerPy # Classic syntax questions = [ { \"type\": \"list\", \"message\": \"What size?\", \"choices\": [\"Small\", \"Medium\", \"Large\"], \"default\": \"Medium\" } ] result = prompt(questions) # Alternate syntax size = inquirer.select( message=\"What size?\", choices=[\"Small\", \"Medium\", \"Large\"], default=\"Medium\" ).execute() Multiple Choice (Checkboxes) python-inquirer import inquirer questions = [ inquirer.Checkbox('interests', message=\"Select interests\", choices=['Music', 'Sports', 'Reading', 'Gaming'], ) ] answers = inquirer.prompt(questions) InquirerPy # With validation for minimum selections from InquirerPy import inquirer interests = inquirer.checkbox( message=\"Select interests:\", choices=[\"Music\", \"Sports\", \"Reading\", \"Gaming\"], validate=lambda selection: len(selection) >= 2, invalid_message=\"Select at least 2 interests\" ).execute() Confirmation Prompts python-inquirer import inquirer questions = [ inquirer.Confirm('proceed', message=\"Continue?\", default=True) ] answers = inquirer.prompt(questions) InquirerPy # Custom confirmation letters (localization) from InquirerPy import inquirer confirm = inquirer.confirm( message=\"Proceed?\", default=True, confirm_letter=\"s\", # 's' for 'Sim' (Yes in Portuguese) reject_letter=\"n\", # 'n' for 'N\u00e3o' (No in Portuguese) transformer=lambda result: \"Sim\" if result else \"N\u00e3o\" ).execute() File Path Selection python-inquirer import inquirer questions = [ inquirer.Path('config_file', message=\"Config file location?\", path_type=inquirer.Path.FILE, exists=True ) ] answers = inquirer.prompt(questions) InquirerPy from InquirerPy import inquirer from InquirerPy.validator import PathValidator filepath = inquirer.filepath( message=\"Select file:\", validate=PathValidator(\"Path must be valid\") ).execute() Advanced Features Dynamic Questions (Conditional Logic) python-inquirer import inquirer questions = [ inquirer.Confirm('married', message=\"Are you married?\"), inquirer.Text('spouse_name', message=\"Spouse name?\", ignore=lambda x: not x['married'] # Skip if not married ) ] answers = inquirer.prompt(questions) InquirerPy from InquirerPy import prompt questions = [ {\"type\": \"confirm\", \"message\": \"Are you married?\", \"name\": \"married\"}, { \"type\": \"input\", \"message\": \"Spouse name?\", \"name\": \"spouse_name\", \"when\": lambda result: result[\"married\"] # Show only if married } ] result = prompt(questions) Choice Objects and Separators InquirerPy Advanced Choices from InquirerPy import inquirer from InquirerPy.base.control import Choice from InquirerPy.separator import Separator # Advanced choice configuration choices = [ Choice(\"aws-east-1\", name=\"AWS East (Virginia)\", enabled=True), Choice(\"aws-west-1\", name=\"AWS West (California)\", enabled=False), Separator(), \"gcp-us-central\", \"azure-eastus\" ] region = inquirer.select( message=\"Select cloud region:\", choices=choices, multiselect=True, transformer=lambda result: f\"{len(result)} region(s) selected\" ).execute() Custom Validation python-inquirer import inquirer import re def phone_validator(answers, current): if not re.match(r'^\\+?\\d[\\d ]+\\d$', current): raise inquirer.errors.ValidationError('', reason='Invalid phone format') return True questions = [ inquirer.Text('phone', message=\"Phone number\", validate=phone_validator) ] answers = inquirer.prompt(questions) InquirerPy from InquirerPy import inquirer from InquirerPy.validator import NumberValidator, EmptyInputValidator import re # Built-in validators age = inquirer.text( message=\"Age:\", validate=NumberValidator(float_allowed=False), filter=lambda result: int(result) # Convert to integer ).execute() # Custom validator function def email_validator(email): pattern = r'^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}$' return re.match(pattern, email) is not None email = inquirer.text( message=\"Email:\", validate=email_validator, invalid_message=\"Please enter a valid email address\" ).execute() # Custom validator class from prompt_toolkit.validation import ValidationError, Validator class CustomEmailValidator(Validator): def validate(self, document): if '@' not in document.text: raise ValidationError( message=\"Email must contain @ symbol\", cursor_position=len(document.text) ) email = inquirer.text( message=\"Email:\", validate=CustomEmailValidator() ).execute() Styling and Theming InquirerPy Styling from InquirerPy import prompt from InquirerPy.utils import color_print # Custom style dictionary custom_style = { \"questionmark\": \"#ff9d00 bold\", \"answer\": \"#61afef\", \"input\": \"#98c379\", \"question\": \"\", \"answered_question\": \"\", \"instruction\": \"#abb2bf\", \"pointer\": \"#61afef\", \"checkbox\": \"#98c379\", \"separator\": \"\", \"skipped\": \"#5c6370\", \"validator\": \"#e06c75\", \"marker\": \"#e5c07b\", } result = prompt( {\"type\": \"input\", \"message\": \"Styled prompt:\"}, style=custom_style, vi_mode=True # Enable vim keybindings ) # Environment variable styling import os os.environ[\"INQUIRERPY_STYLE_QUESTIONMARK\"] = \"#ff9d00 bold\" os.environ[\"INQUIRERPY_STYLE_ANSWER\"] = \"#61afef\" # Color printing utility color_print([(\"#e5c07b\", \"Hello \"), (\"#61afef\", \"World!\")]) Default InquirerPy Theme # Based on onedark color palette default_style = { \"questionmark\": \"#e5c07b\", # Yellow \"answermark\": \"#e5c07b\", # Yellow \"answer\": \"#61afef\", # Blue \"input\": \"#98c379\", # Green \"question\": \"\", # Default \"answered_question\": \"\", # Default \"instruction\": \"#abb2bf\", # Light gray \"long_instruction\": \"#abb2bf\", # Light gray \"pointer\": \"#61afef\", # Blue \"checkbox\": \"#98c379\", # Green \"separator\": \"\", # Default \"skipped\": \"#5c6370\", # Dark gray \"validator\": \"\", # Default \"marker\": \"#e5c07b\", # Yellow \"fuzzy_prompt\": \"#c678dd\", # Purple \"fuzzy_info\": \"#abb2bf\", # Light gray \"fuzzy_border\": \"#4b5263\", # Dark blue \"fuzzy_match\": \"#c678dd\", # Purple \"spinner_pattern\": \"#e5c07b\", # Yellow \"spinner_text\": \"\", # Default } Advanced InquirerPy Features Fuzzy Search from InquirerPy import inquirer # Large list with fuzzy search frameworks = [ \"React\", \"Vue\", \"Angular\", \"Svelte\", \"Next.js\", \"Django\", \"Flask\", \"FastAPI\", \"Express\", \"Koa\", \"Spring Boot\", \"Laravel\", \"Ruby on Rails\" ] framework = inquirer.fuzzy( message=\"Select framework:\", choices=frameworks, max_height=\"70%\", # 70% of terminal height match_exact=True, # Enable exact substring matching exact_symbol=\" E\" # Indicator for exact matches ).execute() Expand Choices from InquirerPy import inquirer from InquirerPy.prompts.expand import ExpandChoice, ExpandHelp # Expand prompt for quick selection choices = [ ExpandChoice(\"create\", key=\"c\", name=\"Create new project\"), ExpandChoice(\"open\", key=\"o\", name=\"Open existing project\"), ExpandChoice(\"delete\", key=\"d\", name=\"Delete project\"), ExpandChoice(\"quit\", key=\"q\", name=\"Quit application\") ] action = inquirer.expand( message=\"What would you like to do?\", choices=choices, expand_help=ExpandHelp(key=\"h\", message=\"Show help\") ).execute() Number Input from InquirerPy import inquirer from InquirerPy.validator import NumberValidator # Number input with validation age = inquirer.number( message=\"Enter your age:\", min_allowed=0, max_allowed=150, validate=NumberValidator(), replace_mode=True # Replace entire input on type ).execute() Custom Keybindings from InquirerPy import inquirer # Custom keybindings keybindings = { \"skip\": [{\"key\": \"c-c\"}], # Ctrl+C to skip \"interrupt\": [{\"key\": \"c-d\"}], # Ctrl+D to interrupt \"toggle-all\": [{\"key\": [\"c-a\", \"space\"]}] # Ctrl+A then Space } result = inquirer.select( message=\"Select options:\", choices=[\"Option 1\", \"Option 2\", \"Option 3\", \"Option 4\"], multiselect=True, keybindings=keybindings, vi_mode=True # Enable vim mode ).execute() Height Control from InquirerPy import inquirer # Control prompt height result = inquirer.select( message=\"Select from long list:\", choices=[f\"Item {i}\" for i in range(100)], height=10, # Fixed height of 10 lines max_height=\"50%\", # Max 50% of terminal height instruction=\"Use j/k to navigate\" ).execute() Practical Examples User Registration Form from InquirerPy import inquirer from InquirerPy.validator import EmptyInputValidator, PasswordValidator import re def email_validator(email): pattern = r'^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}$' if not re.match(pattern, email): return False return True def register_user(): print(\"=== User Registration ===\") # Collect user information username = inquirer.text( message=\"Username:\", validate=EmptyInputValidator(\"Username is required\"), instruction=\"Letters, numbers, and underscores only\" ).execute() email = inquirer.text( message=\"Email address:\", validate=email_validator, invalid_message=\"Please enter a valid email address\" ).execute() password = inquirer.secret( message=\"Password:\", validate=PasswordValidator( length=8, cap=True, special=True, number=True, message=\"Password must be 8+ chars with uppercase, number, and special character\" ) ).execute() # Confirm password confirm_password = inquirer.secret( message=\"Confirm password:\", validate=lambda pwd: pwd == password, invalid_message=\"Passwords do not match\" ).execute() # Additional preferences newsletter = inquirer.confirm( message=\"Subscribe to newsletter?\", default=False ).execute() interests = inquirer.checkbox( message=\"Select interests:\", choices=[ \"Technology\", \"Sports\", \"Music\", \"Travel\", \"Food\", \"Books\", \"Movies\", \"Gaming\" ], validate=lambda selection: len(selection) > 0, invalid_message=\"Please select at least one interest\" ).execute() # Summary print(f\"\\n\u2705 Registration successful!\") print(f\"Username: {username}\") print(f\"Email: {email}\") print(f\"Newsletter: {'Yes' if newsletter else 'No'}\") print(f\"Interests: {', '.join(interests)}\") return { 'username': username, 'email': email, 'password': password, 'newsletter': newsletter, 'interests': interests } # Run registration user_data = register_user() Project Setup Wizard from InquirerPy import inquirer from InquirerPy.base.control import Choice from InquirerPy.separator import Separator import os def project_setup(): print(\"\ud83d\ude80 Project Setup Wizard\") # Project type selection project_type = inquirer.select( message=\"What type of project?\", choices=[ Choice(\"web\", name=\"\ud83c\udf10 Web Application\"), Choice(\"api\", name=\"\ud83d\udd17 REST API\"), Choice(\"desktop\", name=\"\ud83d\udda5\ufe0f Desktop Application\"), Choice(\"cli\", name=\"\u26a1 Command Line Tool\"), Choice(\"library\", name=\"\ud83d\udcda Library/Package\") ] ).execute() # Programming language language = inquirer.select( message=\"Programming language:\", choices=[ \"Python\", \"JavaScript\", \"TypeScript\", \"Java\", \"Go\", \"Rust\", \"C++\", \"C#\" ] ).execute() # Framework selection (conditional) framework = None if project_type == \"web\": if language == \"Python\": framework = inquirer.select( message=\"Web framework:\", choices=[\"Django\", \"Flask\", \"FastAPI\", \"Tornado\"] ).execute() elif language in [\"JavaScript\", \"TypeScript\"]: framework = inquirer.select( message=\"Web framework:\", choices=[\"React\", \"Vue\", \"Angular\", \"Next.js\", \"Express\"] ).execute() # Features features = inquirer.checkbox( message=\"Select features to include:\", choices=[ \"Database integration\", \"Authentication\", \"Testing setup\", \"Docker support\", \"CI/CD pipeline\", \"Documentation\", \"Logging\", \"Configuration management\" ] ).execute() # Project name and location project_name = inquirer.text( message=\"Project name:\", validate=lambda name: len(name) > 0 and name.replace('-', '').replace('_', '').isalnum(), invalid_message=\"Project name must contain only letters, numbers, hyphens, and underscores\" ).execute() default_path = os.path.join(os.path.expanduser(\"~\"), \"projects\", project_name) project_path = inquirer.text( message=\"Project location:\", default=default_path ).execute() # Confirmation print(f\"\\n\ud83d\udccb Project Summary:\") print(f\"Type: {project_type}\") print(f\"Language: {language}\") if framework: print(f\"Framework: {framework}\") print(f\"Features: {', '.join(features)}\") print(f\"Name: {project_name}\") print(f\"Location: {project_path}\") proceed = inquirer.confirm( message=\"Create project with these settings?\", default=True ).execute() if proceed: print(\"\u2705 Project created successfully!\") # Here you would create the actual project structure return { 'type': project_type, 'language': language, 'framework': framework, 'features': features, 'name': project_name, 'path': project_path } else: print(\"\u274c Project creation cancelled.\") return None # Run project setup project_config = project_setup() Configuration Manager from InquirerPy import inquirer from InquirerPy.validator import NumberValidator import json import os def manage_config(): config_file = \"app_config.json\" # Load existing config if os.path.exists(config_file): with open(config_file, 'r') as f: config = json.load(f) print(\"\ud83d\udcc2 Loaded existing configuration\") else: config = {} print(\"\ud83c\udd95 Creating new configuration\") # Menu system while True: action = inquirer.select( message=\"Configuration Manager:\", choices=[ Choice(\"view\", name=\"\ud83d\udc40 View current config\"), Choice(\"edit\", name=\"\u270f\ufe0f Edit settings\"), Choice(\"add\", name=\"\u2795 Add new setting\"), Choice(\"delete\", name=\"\ud83d\uddd1\ufe0f Delete setting\"), Choice(\"save\", name=\"\ud83d\udcbe Save and exit\"), Choice(\"exit\", name=\"\ud83d\udeaa Exit without saving\") ] ).execute() if action == \"view\": if config: print(\"\\n\ud83d\udccb Current Configuration:\") for key, value in config.items(): print(f\" {key}: {value}\") else: print(\"\u26a0\ufe0f Configuration is empty\") elif action == \"edit\": if not config: print(\"\u26a0\ufe0f No settings to edit\") continue setting = inquirer.select( message=\"Select setting to edit:\", choices=list(config.keys()) ).execute() current_value = config[setting] data_type = inquirer.select( message=f\"Data type for '{setting}':\", choices=[\"String\", \"Number\", \"Boolean\"], default=\"String\" ).execute() if data_type == \"String\": new_value = inquirer.text( message=f\"New value for '{setting}':\", default=str(current_value) ).execute() elif data_type == \"Number\": new_value = inquirer.number( message=f\"New value for '{setting}':\", default=float(current_value) if isinstance(current_value, (int, float)) else 0 ).execute() elif data_type == \"Boolean\": new_value = inquirer.confirm( message=f\"Enable '{setting}'?\", default=bool(current_value) ).execute() config[setting] = new_value print(f\"\u2705 Updated {setting} = {new_value}\") elif action == \"add\": key = inquirer.text( message=\"Setting name:\", validate=lambda k: len(k) > 0 and k not in config, invalid_message=\"Setting name must be unique and non-empty\" ).execute() data_type = inquirer.select( message=\"Data type:\", choices=[\"String\", \"Number\", \"Boolean\"] ).execute() if data_type == \"String\": value = inquirer.text(message=\"Value:\").execute() elif data_type == \"Number\": value = inquirer.number(message=\"Value:\").execute() elif data_type == \"Boolean\": value = inquirer.confirm(message=\"Enable?\").execute() config[key] = value print(f\"\u2705 Added {key} = {value}\") elif action == \"delete\": if not config: print(\"\u26a0\ufe0f No settings to delete\") continue setting = inquirer.select( message=\"Select setting to delete:\", choices=list(config.keys()) ).execute() confirm = inquirer.confirm( message=f\"Delete '{setting}'?\", default=False ).execute() if confirm: del config[setting] print(f\"\u2705 Deleted {setting}\") elif action == \"save\": with open(config_file, 'w') as f: json.dump(config, f, indent=2) print(f\"\u2705 Configuration saved to {config_file}\") break elif action == \"exit\": save_changes = inquirer.confirm( message=\"Save changes before exiting?\", default=True ).execute() if save_changes: with open(config_file, 'w') as f: json.dump(config, f, indent=2) print(f\"\u2705 Configuration saved to {config_file}\") break # Run configuration manager manage_config() Testing Interactive Prompts Unit Testing with Mock import unittest from unittest.mock import patch from InquirerPy import prompt def get_user_info(): questions = [ {\"type\": \"input\", \"message\": \"Name:\", \"name\": \"name\"}, {\"type\": \"confirm\", \"message\": \"Subscribe?\", \"name\": \"subscribe\"} ] return prompt(questions) class TestPrompts(unittest.TestCase): @patch('your_module.prompt') def test_get_user_info(self, mock_prompt): # Mock the prompt response mock_prompt.return_value = {\"name\": \"John\", \"subscribe\": True} result = get_user_info() self.assertEqual(result[\"name\"], \"John\") self.assertTrue(result[\"subscribe\"]) mock_prompt.assert_called_once() if __name__ == '__main__': unittest.main() Performance and Best Practices 1. Choose the Right Library python-inquirer : Simple, stable, fewer dependencies InquirerPy : Modern, feature-rich, better styling, async support 2. Validation Best Practices # Good: Clear, specific error messages def validate_email(email): if not email: return \"Email is required\" if '@' not in email: return \"Email must contain @ symbol\" if not email.endswith(('.com', '.org', '.net')): return \"Email must end with .com, .org, or .net\" return True # Good: Use built-in validators when possible from InquirerPy.validator import EmptyInputValidator, NumberValidator, PathValidator # Good: Combine validation with filtering age = inquirer.text( message=\"Age:\", validate=NumberValidator(float_allowed=False), filter=lambda x: int(x) # Convert to integer ).execute() 3. User Experience Tips # Use clear, action-oriented messages message=\"Select deployment environment:\" # Good message=\"Environment?\" # Poor # Provide helpful instructions instruction=\"Use arrow keys to navigate, Enter to select\" # Set sensible defaults default=\"production\" if is_prod_deploy else \"development\" # Use separators to group related options choices=[ \"Development servers\", Separator(), \"dev-01\", \"dev-02\", \"dev-03\", Separator(), \"Production servers\", Separator(), \"prod-01\", \"prod-02\" ] # Transform output for better UX transformer=lambda result: f\"{len(result)} items selected\" 4. Error Handling from InquirerPy import inquirer from InquirerPy.exceptions import InvalidArgument try: result = inquirer.select( message=\"Select option:\", choices=[\"A\", \"B\", \"C\"] ).execute() except KeyboardInterrupt: print(\"\\n\u274c Operation cancelled by user\") exit(1) except InvalidArgument as e: print(f\"\u274c Configuration error: {e}\") exit(1) except Exception as e: print(f\"\u274c Unexpected error: {e}\") exit(1) 5. Async Support (InquirerPy) import asyncio from InquirerPy import prompt_async async def async_prompts(): questions = [ {\"type\": \"input\", \"message\": \"Name:\"}, {\"type\": \"confirm\", \"message\": \"Continue?\"} ] result = await prompt_async(questions) return result # Run async prompts result = asyncio.run(async_prompts()) This cheat sheet covers both libraries comprehensively, providing you with the tools to create engaging, interactive command-line interfaces. Start with simple prompts and gradually incorporate advanced features like validation, styling, and dynamic behavior as your applications grow in complexity.","title":"Python Inquirer"},{"location":"python/inquirer/#python-inquirer","text":"A comprehensive reference for building interactive command-line interfaces with Python's inquirer libraries. This covers both the original python-inquirer and the modern InquirerPy libraries for creating engaging CLI prompts.","title":"Python Inquirer"},{"location":"python/inquirer/#quick-start","text":"","title":"Quick Start"},{"location":"python/inquirer/#installation","text":"# Original python-inquirer (stable, simple) pip install inquirer # InquirerPy (modern, feature-rich) pip install inquirerpy # Both libraries can coexist pip install inquirer inquirerpy","title":"Installation"},{"location":"python/inquirer/#basic-usage-comparison","text":"# python-inquirer (classic) import inquirer questions = [ inquirer.Text('name', message=\"What's your name?\"), inquirer.List('color', message=\"Favorite color?\", choices=['Red', 'Blue', 'Green']) ] answers = inquirer.prompt(questions) # InquirerPy (modern - classic syntax) from InquirerPy import prompt questions = [ {\"type\": \"input\", \"message\": \"What's your name?\", \"name\": \"name\"}, {\"type\": \"list\", \"message\": \"Favorite color?\", \"choices\": [\"Red\", \"Blue\", \"Green\"]} ] answers = prompt(questions) # InquirerPy (modern - alternate syntax) from InquirerPy import inquirer name = inquirer.text(message=\"What's your name?\").execute() color = inquirer.select(message=\"Favorite color?\", choices=[\"Red\", \"Blue\", \"Green\"]).execute()","title":"Basic Usage Comparison"},{"location":"python/inquirer/#core-prompt-types","text":"","title":"Core Prompt Types"},{"location":"python/inquirer/#text-input","text":"","title":"Text Input"},{"location":"python/inquirer/#python-inquirer_1","text":"import inquirer # Basic text input questions = [ inquirer.Text('username', message=\"Enter username\"), inquirer.Text('email', message=\"Enter email\", validate=lambda _, x: '@' in x), ] answers = inquirer.prompt(questions)","title":"python-inquirer"},{"location":"python/inquirer/#inquirerpy","text":"# Classic syntax from InquirerPy import prompt questions = [ { \"type\": \"input\", \"message\": \"Username:\", \"name\": \"username\", \"validate\": lambda result: len(result) > 0, \"invalid_message\": \"Username cannot be empty\" } ] result = prompt(questions) # Alternate syntax from InquirerPy import inquirer username = inquirer.text( message=\"Username:\", validate=lambda result: len(result) > 0, invalid_message=\"Username cannot be empty\" ).execute()","title":"InquirerPy"},{"location":"python/inquirer/#password-input","text":"","title":"Password Input"},{"location":"python/inquirer/#python-inquirer_2","text":"import inquirer questions = [ inquirer.Password('password', message=\"Enter password\") ] answers = inquirer.prompt(questions)","title":"python-inquirer"},{"location":"python/inquirer/#inquirerpy_1","text":"# Classic syntax from InquirerPy import prompt from InquirerPy.validator import PasswordValidator questions = [ { \"type\": \"secret\", \"message\": \"Password:\", \"validate\": PasswordValidator( length=8, cap=True, special=True, number=True ) } ] result = prompt(questions) # Alternate syntax password = inquirer.secret( message=\"Password:\", validate=PasswordValidator(length=8, cap=True, special=True, number=True) ).execute()","title":"InquirerPy"},{"location":"python/inquirer/#single-choice-lists","text":"","title":"Single Choice Lists"},{"location":"python/inquirer/#python-inquirer_3","text":"import inquirer questions = [ inquirer.List('size', message=\"What size?\", choices=['Small', 'Medium', 'Large'], carousel=True # Circular navigation ) ] answers = inquirer.prompt(questions)","title":"python-inquirer"},{"location":"python/inquirer/#inquirerpy_2","text":"# Classic syntax questions = [ { \"type\": \"list\", \"message\": \"What size?\", \"choices\": [\"Small\", \"Medium\", \"Large\"], \"default\": \"Medium\" } ] result = prompt(questions) # Alternate syntax size = inquirer.select( message=\"What size?\", choices=[\"Small\", \"Medium\", \"Large\"], default=\"Medium\" ).execute()","title":"InquirerPy"},{"location":"python/inquirer/#multiple-choice-checkboxes","text":"","title":"Multiple Choice (Checkboxes)"},{"location":"python/inquirer/#python-inquirer_4","text":"import inquirer questions = [ inquirer.Checkbox('interests', message=\"Select interests\", choices=['Music', 'Sports', 'Reading', 'Gaming'], ) ] answers = inquirer.prompt(questions)","title":"python-inquirer"},{"location":"python/inquirer/#inquirerpy_3","text":"# With validation for minimum selections from InquirerPy import inquirer interests = inquirer.checkbox( message=\"Select interests:\", choices=[\"Music\", \"Sports\", \"Reading\", \"Gaming\"], validate=lambda selection: len(selection) >= 2, invalid_message=\"Select at least 2 interests\" ).execute()","title":"InquirerPy"},{"location":"python/inquirer/#confirmation-prompts","text":"","title":"Confirmation Prompts"},{"location":"python/inquirer/#python-inquirer_5","text":"import inquirer questions = [ inquirer.Confirm('proceed', message=\"Continue?\", default=True) ] answers = inquirer.prompt(questions)","title":"python-inquirer"},{"location":"python/inquirer/#inquirerpy_4","text":"# Custom confirmation letters (localization) from InquirerPy import inquirer confirm = inquirer.confirm( message=\"Proceed?\", default=True, confirm_letter=\"s\", # 's' for 'Sim' (Yes in Portuguese) reject_letter=\"n\", # 'n' for 'N\u00e3o' (No in Portuguese) transformer=lambda result: \"Sim\" if result else \"N\u00e3o\" ).execute()","title":"InquirerPy"},{"location":"python/inquirer/#file-path-selection","text":"","title":"File Path Selection"},{"location":"python/inquirer/#python-inquirer_6","text":"import inquirer questions = [ inquirer.Path('config_file', message=\"Config file location?\", path_type=inquirer.Path.FILE, exists=True ) ] answers = inquirer.prompt(questions)","title":"python-inquirer"},{"location":"python/inquirer/#inquirerpy_5","text":"from InquirerPy import inquirer from InquirerPy.validator import PathValidator filepath = inquirer.filepath( message=\"Select file:\", validate=PathValidator(\"Path must be valid\") ).execute()","title":"InquirerPy"},{"location":"python/inquirer/#advanced-features","text":"","title":"Advanced Features"},{"location":"python/inquirer/#dynamic-questions-conditional-logic","text":"","title":"Dynamic Questions (Conditional Logic)"},{"location":"python/inquirer/#python-inquirer_7","text":"import inquirer questions = [ inquirer.Confirm('married', message=\"Are you married?\"), inquirer.Text('spouse_name', message=\"Spouse name?\", ignore=lambda x: not x['married'] # Skip if not married ) ] answers = inquirer.prompt(questions)","title":"python-inquirer"},{"location":"python/inquirer/#inquirerpy_6","text":"from InquirerPy import prompt questions = [ {\"type\": \"confirm\", \"message\": \"Are you married?\", \"name\": \"married\"}, { \"type\": \"input\", \"message\": \"Spouse name?\", \"name\": \"spouse_name\", \"when\": lambda result: result[\"married\"] # Show only if married } ] result = prompt(questions)","title":"InquirerPy"},{"location":"python/inquirer/#choice-objects-and-separators","text":"","title":"Choice Objects and Separators"},{"location":"python/inquirer/#inquirerpy-advanced-choices","text":"from InquirerPy import inquirer from InquirerPy.base.control import Choice from InquirerPy.separator import Separator # Advanced choice configuration choices = [ Choice(\"aws-east-1\", name=\"AWS East (Virginia)\", enabled=True), Choice(\"aws-west-1\", name=\"AWS West (California)\", enabled=False), Separator(), \"gcp-us-central\", \"azure-eastus\" ] region = inquirer.select( message=\"Select cloud region:\", choices=choices, multiselect=True, transformer=lambda result: f\"{len(result)} region(s) selected\" ).execute()","title":"InquirerPy Advanced Choices"},{"location":"python/inquirer/#custom-validation","text":"","title":"Custom Validation"},{"location":"python/inquirer/#python-inquirer_8","text":"import inquirer import re def phone_validator(answers, current): if not re.match(r'^\\+?\\d[\\d ]+\\d$', current): raise inquirer.errors.ValidationError('', reason='Invalid phone format') return True questions = [ inquirer.Text('phone', message=\"Phone number\", validate=phone_validator) ] answers = inquirer.prompt(questions)","title":"python-inquirer"},{"location":"python/inquirer/#inquirerpy_7","text":"from InquirerPy import inquirer from InquirerPy.validator import NumberValidator, EmptyInputValidator import re # Built-in validators age = inquirer.text( message=\"Age:\", validate=NumberValidator(float_allowed=False), filter=lambda result: int(result) # Convert to integer ).execute() # Custom validator function def email_validator(email): pattern = r'^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}$' return re.match(pattern, email) is not None email = inquirer.text( message=\"Email:\", validate=email_validator, invalid_message=\"Please enter a valid email address\" ).execute() # Custom validator class from prompt_toolkit.validation import ValidationError, Validator class CustomEmailValidator(Validator): def validate(self, document): if '@' not in document.text: raise ValidationError( message=\"Email must contain @ symbol\", cursor_position=len(document.text) ) email = inquirer.text( message=\"Email:\", validate=CustomEmailValidator() ).execute()","title":"InquirerPy"},{"location":"python/inquirer/#styling-and-theming","text":"","title":"Styling and Theming"},{"location":"python/inquirer/#inquirerpy-styling","text":"from InquirerPy import prompt from InquirerPy.utils import color_print # Custom style dictionary custom_style = { \"questionmark\": \"#ff9d00 bold\", \"answer\": \"#61afef\", \"input\": \"#98c379\", \"question\": \"\", \"answered_question\": \"\", \"instruction\": \"#abb2bf\", \"pointer\": \"#61afef\", \"checkbox\": \"#98c379\", \"separator\": \"\", \"skipped\": \"#5c6370\", \"validator\": \"#e06c75\", \"marker\": \"#e5c07b\", } result = prompt( {\"type\": \"input\", \"message\": \"Styled prompt:\"}, style=custom_style, vi_mode=True # Enable vim keybindings ) # Environment variable styling import os os.environ[\"INQUIRERPY_STYLE_QUESTIONMARK\"] = \"#ff9d00 bold\" os.environ[\"INQUIRERPY_STYLE_ANSWER\"] = \"#61afef\" # Color printing utility color_print([(\"#e5c07b\", \"Hello \"), (\"#61afef\", \"World!\")])","title":"InquirerPy Styling"},{"location":"python/inquirer/#default-inquirerpy-theme","text":"# Based on onedark color palette default_style = { \"questionmark\": \"#e5c07b\", # Yellow \"answermark\": \"#e5c07b\", # Yellow \"answer\": \"#61afef\", # Blue \"input\": \"#98c379\", # Green \"question\": \"\", # Default \"answered_question\": \"\", # Default \"instruction\": \"#abb2bf\", # Light gray \"long_instruction\": \"#abb2bf\", # Light gray \"pointer\": \"#61afef\", # Blue \"checkbox\": \"#98c379\", # Green \"separator\": \"\", # Default \"skipped\": \"#5c6370\", # Dark gray \"validator\": \"\", # Default \"marker\": \"#e5c07b\", # Yellow \"fuzzy_prompt\": \"#c678dd\", # Purple \"fuzzy_info\": \"#abb2bf\", # Light gray \"fuzzy_border\": \"#4b5263\", # Dark blue \"fuzzy_match\": \"#c678dd\", # Purple \"spinner_pattern\": \"#e5c07b\", # Yellow \"spinner_text\": \"\", # Default }","title":"Default InquirerPy Theme"},{"location":"python/inquirer/#advanced-inquirerpy-features","text":"","title":"Advanced InquirerPy Features"},{"location":"python/inquirer/#fuzzy-search","text":"from InquirerPy import inquirer # Large list with fuzzy search frameworks = [ \"React\", \"Vue\", \"Angular\", \"Svelte\", \"Next.js\", \"Django\", \"Flask\", \"FastAPI\", \"Express\", \"Koa\", \"Spring Boot\", \"Laravel\", \"Ruby on Rails\" ] framework = inquirer.fuzzy( message=\"Select framework:\", choices=frameworks, max_height=\"70%\", # 70% of terminal height match_exact=True, # Enable exact substring matching exact_symbol=\" E\" # Indicator for exact matches ).execute()","title":"Fuzzy Search"},{"location":"python/inquirer/#expand-choices","text":"from InquirerPy import inquirer from InquirerPy.prompts.expand import ExpandChoice, ExpandHelp # Expand prompt for quick selection choices = [ ExpandChoice(\"create\", key=\"c\", name=\"Create new project\"), ExpandChoice(\"open\", key=\"o\", name=\"Open existing project\"), ExpandChoice(\"delete\", key=\"d\", name=\"Delete project\"), ExpandChoice(\"quit\", key=\"q\", name=\"Quit application\") ] action = inquirer.expand( message=\"What would you like to do?\", choices=choices, expand_help=ExpandHelp(key=\"h\", message=\"Show help\") ).execute()","title":"Expand Choices"},{"location":"python/inquirer/#number-input","text":"from InquirerPy import inquirer from InquirerPy.validator import NumberValidator # Number input with validation age = inquirer.number( message=\"Enter your age:\", min_allowed=0, max_allowed=150, validate=NumberValidator(), replace_mode=True # Replace entire input on type ).execute()","title":"Number Input"},{"location":"python/inquirer/#custom-keybindings","text":"from InquirerPy import inquirer # Custom keybindings keybindings = { \"skip\": [{\"key\": \"c-c\"}], # Ctrl+C to skip \"interrupt\": [{\"key\": \"c-d\"}], # Ctrl+D to interrupt \"toggle-all\": [{\"key\": [\"c-a\", \"space\"]}] # Ctrl+A then Space } result = inquirer.select( message=\"Select options:\", choices=[\"Option 1\", \"Option 2\", \"Option 3\", \"Option 4\"], multiselect=True, keybindings=keybindings, vi_mode=True # Enable vim mode ).execute()","title":"Custom Keybindings"},{"location":"python/inquirer/#height-control","text":"from InquirerPy import inquirer # Control prompt height result = inquirer.select( message=\"Select from long list:\", choices=[f\"Item {i}\" for i in range(100)], height=10, # Fixed height of 10 lines max_height=\"50%\", # Max 50% of terminal height instruction=\"Use j/k to navigate\" ).execute()","title":"Height Control"},{"location":"python/inquirer/#practical-examples","text":"","title":"Practical Examples"},{"location":"python/inquirer/#user-registration-form","text":"from InquirerPy import inquirer from InquirerPy.validator import EmptyInputValidator, PasswordValidator import re def email_validator(email): pattern = r'^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}$' if not re.match(pattern, email): return False return True def register_user(): print(\"=== User Registration ===\") # Collect user information username = inquirer.text( message=\"Username:\", validate=EmptyInputValidator(\"Username is required\"), instruction=\"Letters, numbers, and underscores only\" ).execute() email = inquirer.text( message=\"Email address:\", validate=email_validator, invalid_message=\"Please enter a valid email address\" ).execute() password = inquirer.secret( message=\"Password:\", validate=PasswordValidator( length=8, cap=True, special=True, number=True, message=\"Password must be 8+ chars with uppercase, number, and special character\" ) ).execute() # Confirm password confirm_password = inquirer.secret( message=\"Confirm password:\", validate=lambda pwd: pwd == password, invalid_message=\"Passwords do not match\" ).execute() # Additional preferences newsletter = inquirer.confirm( message=\"Subscribe to newsletter?\", default=False ).execute() interests = inquirer.checkbox( message=\"Select interests:\", choices=[ \"Technology\", \"Sports\", \"Music\", \"Travel\", \"Food\", \"Books\", \"Movies\", \"Gaming\" ], validate=lambda selection: len(selection) > 0, invalid_message=\"Please select at least one interest\" ).execute() # Summary print(f\"\\n\u2705 Registration successful!\") print(f\"Username: {username}\") print(f\"Email: {email}\") print(f\"Newsletter: {'Yes' if newsletter else 'No'}\") print(f\"Interests: {', '.join(interests)}\") return { 'username': username, 'email': email, 'password': password, 'newsletter': newsletter, 'interests': interests } # Run registration user_data = register_user()","title":"User Registration Form"},{"location":"python/inquirer/#project-setup-wizard","text":"from InquirerPy import inquirer from InquirerPy.base.control import Choice from InquirerPy.separator import Separator import os def project_setup(): print(\"\ud83d\ude80 Project Setup Wizard\") # Project type selection project_type = inquirer.select( message=\"What type of project?\", choices=[ Choice(\"web\", name=\"\ud83c\udf10 Web Application\"), Choice(\"api\", name=\"\ud83d\udd17 REST API\"), Choice(\"desktop\", name=\"\ud83d\udda5\ufe0f Desktop Application\"), Choice(\"cli\", name=\"\u26a1 Command Line Tool\"), Choice(\"library\", name=\"\ud83d\udcda Library/Package\") ] ).execute() # Programming language language = inquirer.select( message=\"Programming language:\", choices=[ \"Python\", \"JavaScript\", \"TypeScript\", \"Java\", \"Go\", \"Rust\", \"C++\", \"C#\" ] ).execute() # Framework selection (conditional) framework = None if project_type == \"web\": if language == \"Python\": framework = inquirer.select( message=\"Web framework:\", choices=[\"Django\", \"Flask\", \"FastAPI\", \"Tornado\"] ).execute() elif language in [\"JavaScript\", \"TypeScript\"]: framework = inquirer.select( message=\"Web framework:\", choices=[\"React\", \"Vue\", \"Angular\", \"Next.js\", \"Express\"] ).execute() # Features features = inquirer.checkbox( message=\"Select features to include:\", choices=[ \"Database integration\", \"Authentication\", \"Testing setup\", \"Docker support\", \"CI/CD pipeline\", \"Documentation\", \"Logging\", \"Configuration management\" ] ).execute() # Project name and location project_name = inquirer.text( message=\"Project name:\", validate=lambda name: len(name) > 0 and name.replace('-', '').replace('_', '').isalnum(), invalid_message=\"Project name must contain only letters, numbers, hyphens, and underscores\" ).execute() default_path = os.path.join(os.path.expanduser(\"~\"), \"projects\", project_name) project_path = inquirer.text( message=\"Project location:\", default=default_path ).execute() # Confirmation print(f\"\\n\ud83d\udccb Project Summary:\") print(f\"Type: {project_type}\") print(f\"Language: {language}\") if framework: print(f\"Framework: {framework}\") print(f\"Features: {', '.join(features)}\") print(f\"Name: {project_name}\") print(f\"Location: {project_path}\") proceed = inquirer.confirm( message=\"Create project with these settings?\", default=True ).execute() if proceed: print(\"\u2705 Project created successfully!\") # Here you would create the actual project structure return { 'type': project_type, 'language': language, 'framework': framework, 'features': features, 'name': project_name, 'path': project_path } else: print(\"\u274c Project creation cancelled.\") return None # Run project setup project_config = project_setup()","title":"Project Setup Wizard"},{"location":"python/inquirer/#configuration-manager","text":"from InquirerPy import inquirer from InquirerPy.validator import NumberValidator import json import os def manage_config(): config_file = \"app_config.json\" # Load existing config if os.path.exists(config_file): with open(config_file, 'r') as f: config = json.load(f) print(\"\ud83d\udcc2 Loaded existing configuration\") else: config = {} print(\"\ud83c\udd95 Creating new configuration\") # Menu system while True: action = inquirer.select( message=\"Configuration Manager:\", choices=[ Choice(\"view\", name=\"\ud83d\udc40 View current config\"), Choice(\"edit\", name=\"\u270f\ufe0f Edit settings\"), Choice(\"add\", name=\"\u2795 Add new setting\"), Choice(\"delete\", name=\"\ud83d\uddd1\ufe0f Delete setting\"), Choice(\"save\", name=\"\ud83d\udcbe Save and exit\"), Choice(\"exit\", name=\"\ud83d\udeaa Exit without saving\") ] ).execute() if action == \"view\": if config: print(\"\\n\ud83d\udccb Current Configuration:\") for key, value in config.items(): print(f\" {key}: {value}\") else: print(\"\u26a0\ufe0f Configuration is empty\") elif action == \"edit\": if not config: print(\"\u26a0\ufe0f No settings to edit\") continue setting = inquirer.select( message=\"Select setting to edit:\", choices=list(config.keys()) ).execute() current_value = config[setting] data_type = inquirer.select( message=f\"Data type for '{setting}':\", choices=[\"String\", \"Number\", \"Boolean\"], default=\"String\" ).execute() if data_type == \"String\": new_value = inquirer.text( message=f\"New value for '{setting}':\", default=str(current_value) ).execute() elif data_type == \"Number\": new_value = inquirer.number( message=f\"New value for '{setting}':\", default=float(current_value) if isinstance(current_value, (int, float)) else 0 ).execute() elif data_type == \"Boolean\": new_value = inquirer.confirm( message=f\"Enable '{setting}'?\", default=bool(current_value) ).execute() config[setting] = new_value print(f\"\u2705 Updated {setting} = {new_value}\") elif action == \"add\": key = inquirer.text( message=\"Setting name:\", validate=lambda k: len(k) > 0 and k not in config, invalid_message=\"Setting name must be unique and non-empty\" ).execute() data_type = inquirer.select( message=\"Data type:\", choices=[\"String\", \"Number\", \"Boolean\"] ).execute() if data_type == \"String\": value = inquirer.text(message=\"Value:\").execute() elif data_type == \"Number\": value = inquirer.number(message=\"Value:\").execute() elif data_type == \"Boolean\": value = inquirer.confirm(message=\"Enable?\").execute() config[key] = value print(f\"\u2705 Added {key} = {value}\") elif action == \"delete\": if not config: print(\"\u26a0\ufe0f No settings to delete\") continue setting = inquirer.select( message=\"Select setting to delete:\", choices=list(config.keys()) ).execute() confirm = inquirer.confirm( message=f\"Delete '{setting}'?\", default=False ).execute() if confirm: del config[setting] print(f\"\u2705 Deleted {setting}\") elif action == \"save\": with open(config_file, 'w') as f: json.dump(config, f, indent=2) print(f\"\u2705 Configuration saved to {config_file}\") break elif action == \"exit\": save_changes = inquirer.confirm( message=\"Save changes before exiting?\", default=True ).execute() if save_changes: with open(config_file, 'w') as f: json.dump(config, f, indent=2) print(f\"\u2705 Configuration saved to {config_file}\") break # Run configuration manager manage_config()","title":"Configuration Manager"},{"location":"python/inquirer/#testing-interactive-prompts","text":"","title":"Testing Interactive Prompts"},{"location":"python/inquirer/#unit-testing-with-mock","text":"import unittest from unittest.mock import patch from InquirerPy import prompt def get_user_info(): questions = [ {\"type\": \"input\", \"message\": \"Name:\", \"name\": \"name\"}, {\"type\": \"confirm\", \"message\": \"Subscribe?\", \"name\": \"subscribe\"} ] return prompt(questions) class TestPrompts(unittest.TestCase): @patch('your_module.prompt') def test_get_user_info(self, mock_prompt): # Mock the prompt response mock_prompt.return_value = {\"name\": \"John\", \"subscribe\": True} result = get_user_info() self.assertEqual(result[\"name\"], \"John\") self.assertTrue(result[\"subscribe\"]) mock_prompt.assert_called_once() if __name__ == '__main__': unittest.main()","title":"Unit Testing with Mock"},{"location":"python/inquirer/#performance-and-best-practices","text":"","title":"Performance and Best Practices"},{"location":"python/inquirer/#1-choose-the-right-library","text":"python-inquirer : Simple, stable, fewer dependencies InquirerPy : Modern, feature-rich, better styling, async support","title":"1. Choose the Right Library"},{"location":"python/inquirer/#2-validation-best-practices","text":"# Good: Clear, specific error messages def validate_email(email): if not email: return \"Email is required\" if '@' not in email: return \"Email must contain @ symbol\" if not email.endswith(('.com', '.org', '.net')): return \"Email must end with .com, .org, or .net\" return True # Good: Use built-in validators when possible from InquirerPy.validator import EmptyInputValidator, NumberValidator, PathValidator # Good: Combine validation with filtering age = inquirer.text( message=\"Age:\", validate=NumberValidator(float_allowed=False), filter=lambda x: int(x) # Convert to integer ).execute()","title":"2. Validation Best Practices"},{"location":"python/inquirer/#3-user-experience-tips","text":"# Use clear, action-oriented messages message=\"Select deployment environment:\" # Good message=\"Environment?\" # Poor # Provide helpful instructions instruction=\"Use arrow keys to navigate, Enter to select\" # Set sensible defaults default=\"production\" if is_prod_deploy else \"development\" # Use separators to group related options choices=[ \"Development servers\", Separator(), \"dev-01\", \"dev-02\", \"dev-03\", Separator(), \"Production servers\", Separator(), \"prod-01\", \"prod-02\" ] # Transform output for better UX transformer=lambda result: f\"{len(result)} items selected\"","title":"3. User Experience Tips"},{"location":"python/inquirer/#4-error-handling","text":"from InquirerPy import inquirer from InquirerPy.exceptions import InvalidArgument try: result = inquirer.select( message=\"Select option:\", choices=[\"A\", \"B\", \"C\"] ).execute() except KeyboardInterrupt: print(\"\\n\u274c Operation cancelled by user\") exit(1) except InvalidArgument as e: print(f\"\u274c Configuration error: {e}\") exit(1) except Exception as e: print(f\"\u274c Unexpected error: {e}\") exit(1)","title":"4. Error Handling"},{"location":"python/inquirer/#5-async-support-inquirerpy","text":"import asyncio from InquirerPy import prompt_async async def async_prompts(): questions = [ {\"type\": \"input\", \"message\": \"Name:\"}, {\"type\": \"confirm\", \"message\": \"Continue?\"} ] result = await prompt_async(questions) return result # Run async prompts result = asyncio.run(async_prompts()) This cheat sheet covers both libraries comprehensively, providing you with the tools to create engaging, interactive command-line interfaces. Start with simple prompts and gradually incorporate advanced features like validation, styling, and dynamic behavior as your applications grow in complexity.","title":"5. Async Support (InquirerPy)"},{"location":"python/keras/","text":"Keras Installation # Keras 3 (multi-backend) pip install --upgrade keras # With specific backend dependencies pip install --upgrade keras-cv keras-hub keras # For computer vision and NLP pip install --upgrade jax[cpu] # For JAX backend pip install --upgrade tensorflow # For TensorFlow backend pip install --upgrade torch # For PyTorch backend # Check version python -c \"import keras; print(keras.__version__)\" Backend Configuration # Set backend before importing Keras (method 1) import os os.environ[\"KERAS_BACKEND\"] = \"tensorflow\" # or \"jax\", \"torch\" # Or via environment variable (method 2) export KERAS_BACKEND=\"jax\" # Or in Colab/Jupyter import os os.environ[\"KERAS_BACKEND\"] = \"jax\" import keras # Check current backend print(keras.config.backend()) Import Essentials import keras from keras import layers, models, utils, optimizers, losses, metrics from keras import ops # Backend-agnostic operations import numpy as np import matplotlib.pyplot as plt Models Sequential Model # Method 1: List of layers model = keras.Sequential([ layers.Dense(64, activation='relu', input_shape=(784,)), layers.Dropout(0.2), layers.Dense(10, activation='softmax') ]) # Method 2: Add layers incrementally model = keras.Sequential() model.add(layers.Dense(64, activation='relu', input_shape=(784,))) model.add(layers.Dropout(0.2)) model.add(layers.Dense(10, activation='softmax')) Functional API inputs = layers.Input(shape=(784,)) x = layers.Dense(64, activation='relu')(inputs) x = layers.Dropout(0.2)(x) outputs = layers.Dense(10, activation='softmax')(x) model = keras.Model(inputs=inputs, outputs=outputs) # Multi-input/output example input1 = layers.Input(shape=(10,), name='input1') input2 = layers.Input(shape=(5,), name='input2') x1 = layers.Dense(64, activation='relu')(input1) x2 = layers.Dense(32, activation='relu')(input2) concatenated = layers.Concatenate()([x1, x2]) output1 = layers.Dense(1, activation='sigmoid', name='output1')(concatenated) output2 = layers.Dense(3, activation='softmax', name='output2')(concatenated) model = keras.Model(inputs=[input1, input2], outputs=[output1, output2]) Model Subclassing class MyModel(keras.Model): def __init__(self, num_classes=10): super().__init__() self.dense1 = layers.Dense(64, activation='relu') self.dropout = layers.Dropout(0.2) self.dense2 = layers.Dense(num_classes, activation='softmax') def call(self, inputs, training=None): x = self.dense1(inputs) x = self.dropout(x, training=training) return self.dense2(x) def get_config(self): return {\"num_classes\": self.dense2.units} model = MyModel(num_classes=10) Layers Dense (Fully Connected) layers.Dense(64, activation='relu') layers.Dense(10, activation='softmax', use_bias=False) layers.Dense(32, kernel_regularizer=keras.regularizers.l2(0.01)) Convolutional Layers # 2D Convolution layers.Conv2D(32, (3, 3), activation='relu', padding='same') layers.Conv2D(64, 3, strides=2, activation='relu') # Depthwise Separable layers.SeparableConv2D(64, (3, 3), activation='relu') # Transposed Convolution (Deconvolution) layers.Conv2DTranspose(32, (3, 3), strides=2, padding='same') # 1D and 3D variants layers.Conv1D(32, 3, activation='relu') layers.Conv3D(32, (3, 3, 3), activation='relu') Pooling Layers layers.MaxPooling2D((2, 2)) layers.AveragePooling2D((2, 2), strides=2) layers.GlobalMaxPooling2D() layers.GlobalAveragePooling2D() Recurrent Layers layers.LSTM(64, return_sequences=True) layers.GRU(32, dropout=0.2, recurrent_dropout=0.2) layers.SimpleRNN(32) # Bidirectional layers.Bidirectional(layers.LSTM(64)) # Stacked RNNs layers.LSTM(64, return_sequences=True) layers.LSTM(32) Attention and Transformer Layers # Multi-head attention layers.MultiHeadAttention(num_heads=8, key_dim=64) # Self-attention layers.Attention() # Add & Normalize layers.LayerNormalization() layers.Add() Normalization Layers layers.BatchNormalization() layers.LayerNormalization() layers.GroupNormalization(groups=32) layers.UnitNormalization() Regularization layers.Dropout(0.2) layers.AlphaDropout(0.1) # For SELU activation layers.SpatialDropout2D(0.2) # For convolutional layers layers.GaussianDropout(0.1) layers.GaussianNoise(0.1) Activation Layers layers.ReLU() layers.LeakyReLU(negative_slope=0.3) layers.ELU(alpha=1.0) layers.Softmax(axis=-1) layers.Activation('tanh') # Advanced activations layers.PReLU() layers.ThresholdedReLU(theta=1.0) layers.Softplus() Utility Layers layers.Flatten() layers.Reshape((3, 4)) layers.Permute((2, 1)) layers.RepeatVector(3) layers.Lambda(lambda x: x ** 2) layers.Cropping2D(cropping=((1, 1), (2, 2))) layers.ZeroPadding2D(padding=(1, 1)) Model Compilation Basic Compilation model.compile( optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'] ) Custom Configuration model.compile( optimizer=keras.optimizers.Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999), loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True), metrics=[ keras.metrics.SparseCategoricalAccuracy(), keras.metrics.TopKCategoricalAccuracy(k=5) ] ) Multiple Losses (Multi-output) model.compile( optimizer='adam', loss={ 'output1': 'binary_crossentropy', 'output2': 'categorical_crossentropy' }, loss_weights={'output1': 1.0, 'output2': 0.2}, metrics={ 'output1': ['accuracy'], 'output2': ['accuracy', 'top_k_categorical_accuracy'] } ) Optimizers # SGD with momentum keras.optimizers.SGD(learning_rate=0.01, momentum=0.9, nesterov=True) # Adam variants keras.optimizers.Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999) keras.optimizers.AdamW(learning_rate=0.001, weight_decay=0.01) keras.optimizers.Adamax(learning_rate=0.002) # Other optimizers keras.optimizers.RMSprop(learning_rate=0.001, rho=0.9) keras.optimizers.Adagrad(learning_rate=0.01) keras.optimizers.Adadelta(learning_rate=1.0, rho=0.95) Learning Rate Schedules # Exponential decay lr_schedule = keras.optimizers.schedules.ExponentialDecay( initial_learning_rate=0.1, decay_steps=10000, decay_rate=0.9 ) # Cosine decay lr_schedule = keras.optimizers.schedules.CosineDecay( initial_learning_rate=0.1, decay_steps=1000 ) # Piecewise constant lr_schedule = keras.optimizers.schedules.PiecewiseConstantDecay( boundaries=[100000, 110000], values=[1.0, 0.5, 0.1] ) optimizer = keras.optimizers.Adam(learning_rate=lr_schedule) Loss Functions Classification keras.losses.BinaryCrossentropy() keras.losses.BinaryFocalCrossentropy(alpha=0.25, gamma=2.0) keras.losses.CategoricalCrossentropy() keras.losses.SparseCategoricalCrossentropy() keras.losses.KLDivergence() Regression keras.losses.MeanSquaredError() keras.losses.MeanAbsoluteError() keras.losses.MeanAbsolutePercentageError() keras.losses.MeanSquaredLogarithmicError() keras.losses.Huber(delta=1.0) Custom Loss def custom_loss(y_true, y_pred): return ops.mean(ops.square(y_true - y_pred)) # Or as a class class CustomLoss(keras.losses.Loss): def __init__(self, name=\"custom_loss\"): super().__init__(name=name) def call(self, y_true, y_pred): return ops.mean(ops.square(y_true - y_pred)) model.compile(optimizer='adam', loss=CustomLoss()) Training Basic Training history = model.fit( x_train, y_train, batch_size=32, epochs=10, validation_data=(x_val, y_val), verbose=1 ) Advanced Training with Callbacks callbacks = [ keras.callbacks.EarlyStopping( monitor='val_loss', patience=3, restore_best_weights=True ), keras.callbacks.ReduceLROnPlateau( monitor='val_loss', factor=0.2, patience=2, min_lr=0.001 ), keras.callbacks.ModelCheckpoint( filepath='best_model.keras', monitor='val_accuracy', save_best_only=True, verbose=1 ), keras.callbacks.TensorBoard( log_dir='./logs', histogram_freq=1, write_graph=True ) ] history = model.fit( x_train, y_train, validation_data=(x_val, y_val), epochs=50, callbacks=callbacks, verbose=1 ) Custom Training Step class CustomModel(keras.Model): def train_step(self, data): x, y = data with keras.backends.gradienttape() as tape: y_pred = self(x, training=True) loss = self.compute_loss(x, y, y_pred) trainable_vars = self.trainable_variables gradients = tape.gradient(loss, trainable_vars) self.optimizer.apply_gradients(zip(gradients, trainable_vars)) for metric in self.metrics: if metric.name == \"loss\": metric.update_state(loss) else: metric.update_state(y, y_pred) return {m.name: m.result() for m in self.metrics} Data Processing Image Data Loading and Augmentation # Create a dataset from a directory of images train_ds = keras.utils.image_dataset_from_directory( directory='train_directory', labels='inferred', label_mode='categorical', batch_size=32, image_size=(224, 224) ) # Define data augmentation layers data_augmentation = keras.Sequential([ layers.RandomFlip(\"horizontal\"), layers.RandomRotation(0.1), layers.RandomZoom(0.1), ]) # Apply augmentation to the dataset train_ds = train_ds.map(lambda x, y: (data_augmentation(x), y)) # Prefetch for performance train_ds = train_ds.prefetch(buffer_size=tf.data.AUTOTUNE) # Fit with the dataset model.fit(train_ds, epochs=10, validation_data=val_ds) tf.data Integration # Using tf.data with Keras import tensorflow as tf def preprocess(image, label): image = tf.cast(image, tf.float32) / 255.0 return image, label train_ds = tf.data.Dataset.from_tensor_slices((x_train, y_train)) train_ds = train_ds.map(preprocess).batch(32).prefetch(tf.data.AUTOTUNE) model.fit(train_ds, epochs=10) Evaluation and Prediction Model Evaluation # Evaluate on test set test_loss, test_accuracy = model.evaluate(x_test, y_test, verbose=0) print(f\"Test accuracy: {test_accuracy:.4f}\") # Detailed evaluation with multiple metrics results = model.evaluate( x_test, y_test, batch_size=32, return_dict=True, verbose=1 ) Predictions # Predictions predictions = model.predict(x_test) predicted_classes = np.argmax(predictions, axis=1) # Single prediction single_pred = model.predict(np.expand_dims(single_sample, axis=0)) # Prediction with custom batch size predictions = model.predict(x_test, batch_size=64, verbose=1) Model Persistence Save/Load Model # Save entire model model.save('my_model.keras') # Recommended format model.save('my_model.h5') # Legacy format # Load model loaded_model = keras.models.load_model('my_model.keras') # Save/load weights only model.save_weights('weights.weights.h5') model.load_weights('weights.weights.h5') Export to Different Formats # SavedModel format (for TensorFlow Serving) model.export('saved_model_dir') # Load exported model imported_model = keras.models.load_model('saved_model_dir') Callbacks Built-in Callbacks # Early stopping keras.callbacks.EarlyStopping( monitor='val_loss', patience=5, restore_best_weights=True, verbose=1 ) # Learning rate scheduling keras.callbacks.LearningRateScheduler( lambda epoch: 0.1 * 0.95 ** epoch ) # CSV logger keras.callbacks.CSVLogger('training.log') # Model checkpointing keras.callbacks.ModelCheckpoint( 'model_{epoch:02d}_{val_loss:.2f}.keras', save_best_only=True, monitor='val_loss', mode='min' ) Custom Callbacks class CustomCallback(keras.callbacks.Callback): def on_epoch_begin(self, epoch, logs=None): print(f\"Starting epoch {epoch}\") def on_epoch_end(self, epoch, logs=None): if logs.get('val_accuracy') > 0.95: print(\"Reached 95% accuracy, stopping training!\") self.model.stop_training = True def on_batch_end(self, batch, logs=None): if batch % 100 == 0: print(f\"Finished batch {batch}\") model.fit(x_train, y_train, callbacks=[CustomCallback()]) Metrics Built-in Metrics # Classification metrics keras.metrics.Accuracy() keras.metrics.BinaryAccuracy() keras.metrics.CategoricalAccuracy() keras.metrics.SparseCategoricalAccuracy() keras.metrics.TopKCategoricalAccuracy(k=5) keras.metrics.Precision() keras.metrics.Recall() keras.metrics.F1Score() keras.metrics.AUC() # Regression metrics keras.metrics.MeanSquaredError() keras.metrics.MeanAbsoluteError() keras.metrics.RootMeanSquaredError() keras.metrics.MeanAbsolutePercentageError() Custom Metrics class F1Score(keras.metrics.Metric): def __init__(self, name='f1_score', **kwargs): super().__init__(name=name, **kwargs) self.precision = keras.metrics.Precision() self.recall = keras.metrics.Recall() def update_state(self, y_true, y_pred, sample_weight=None): self.precision.update_state(y_true, y_pred, sample_weight) self.recall.update_state(y_true, y_pred, sample_weight) def result(self): p = self.precision.result() r = self.recall.result() return 2 * ((p * r) / (p + r + keras.backend.epsilon())) def reset_state(self): self.precision.reset_state() self.recall.reset_state() Transfer Learning Using Pre-trained Models # Load pre-trained model without top layers base_model = keras.applications.VGG16( weights='imagenet', include_top=False, input_shape=(224, 224, 3) ) # Freeze base model base_model.trainable = False # Add custom head inputs = keras.Input(shape=(224, 224, 3)) x = base_model(inputs, training=False) x = layers.GlobalAveragePooling2D()(x) x = layers.Dense(128, activation='relu')(x) outputs = layers.Dense(num_classes, activation='softmax')(x) model = keras.Model(inputs, outputs) # Fine-tuning: unfreeze some layers base_model.trainable = True for layer in base_model.layers[:-4]: layer.trainable = False Advanced Features Mixed Precision Training # Enable mixed precision keras.mixed_precision.set_global_policy('mixed_float16') # Custom model with loss scaling class MixedPrecisionModel(keras.Model): def __init__(self, *args, **kwargs): super().__init__(*args, **kwargs) self.loss_tracker = keras.metrics.Mean(name=\"loss\") def train_step(self, data): x, y = data with keras.backend.gradienttape() as tape: y_pred = self(x, training=True) loss = self.compute_loss(x, y, y_pred) # Scale loss for mixed precision scaled_loss = self.optimizer.get_scaled_loss(loss) scaled_gradients = tape.gradient(scaled_loss, self.trainable_variables) gradients = self.optimizer.get_unscaled_gradients(scaled_gradients) self.optimizer.apply_gradients(zip(gradients, self.trainable_variables)) self.loss_tracker.update_state(loss) return {\"loss\": self.loss_tracker.result()} Custom Layers class CustomDense(layers.Layer): def __init__(self, units=32, **kwargs): super().__init__(**kwargs) self.units = units def build(self, input_shape): self.w = self.add_weight( shape=(input_shape[-1], self.units), initializer='random_normal', trainable=True, name='kernel' ) self.b = self.add_weight( shape=(self.units,), initializer='zeros', trainable=True, name='bias' ) super().build(input_shape) def call(self, inputs): return ops.matmul(inputs, self.w) + self.b def get_config(self): config = super().get_config() config.update({\"units\": self.units}) return config Model Visualization # Plot model architecture keras.utils.plot_model( model, to_file='model.png', show_shapes=True, show_layer_names=True, rankdir='TB', dpi=96 ) # Model summary model.summary() # Layer-wise summary for i, layer in enumerate(model.layers): print(f\"Layer {i}: {layer.name} ({layer.__class__.__name__})\") print(f\" Input shape: {layer.input_shape}\") print(f\" Output shape: {layer.output_shape}\") print(f\" Parameters: {layer.count_params()}\") Hyperparameter Tuning with KerasTuner # Install: pip install keras-tuner import keras_tuner def build_model(hp): model = keras.Sequential([ layers.Dense( hp.Int('units_1', 32, 512, step=32), activation='relu' ), layers.Dropout(hp.Float('dropout_1', 0, 0.5, step=0.1)), layers.Dense( hp.Int('units_2', 32, 512, step=32), activation='relu' ), layers.Dense(10, activation='softmax') ]) model.compile( optimizer=keras.optimizers.Adam( hp.Float('learning_rate', 1e-4, 1e-2, sampling='log') ), loss='sparse_categorical_crossentropy', metrics=['accuracy'] ) return model tuner = keras_tuner.RandomSearch( build_model, objective='val_accuracy', max_trials=20 ) tuner.search(x_train, y_train, epochs=5, validation_data=(x_val, y_val)) best_model = tuner.get_best_models()[0] KerasHub and KerasCV KerasHub (NLP) # Install: pip install keras-hub import keras_hub # Text classification with BERT classifier = keras_hub.models.BertClassifier.from_preset( \"bert_base_en_uncased\", num_classes=2 ) # Text generation with GPT generator = keras_hub.models.GPT2CausalLM.from_preset(\"gpt2_base_en\") output = generator.generate(\"The weather today\", max_length=50) KerasCV (Computer Vision) # Install: pip install keras-cv import keras_cv # Data augmentation augment = keras_cv.layers.RandAugment( value_range=(0, 255), magnitude=0.5, augmentations_per_image=3 ) # Object detection detector = keras_cv.models.RetinaNet.from_preset( \"retinanet_resnet50_pascalvoc\" ) Debugging and Performance Debugging # Enable eager execution for debugging # tf.config.run_functions_eagerly(True) # For TensorFlow backend # Add debug prints in custom layers/models class DebugLayer(layers.Layer): def call(self, inputs): keras.utils.print_msg(f\"Input shape: {ops.shape(inputs)}\") return inputs # Check for NaN values def check_nan(tensor, name): if ops.any(ops.isnan(tensor)): print(f\"NaN detected in {name}\") return tensor Performance Optimization # Use mixed precision keras.mixed_precision.set_global_policy('mixed_float16') # Enable XLA compilation (TensorFlow backend) # model.compile(optimizer='adam', loss='mse', jit_compile=True) # Profile training # keras.utils.Progbar for custom progress bars # Use TensorBoard for performance profiling # Memory optimization keras.backend.clear_session() # Clear session to free memory Best Practices Model Design : Start simple, add complexity gradually Data : Normalize inputs, use data augmentation for images Training : Use callbacks for early stopping and learning rate scheduling Validation : Always use validation data to monitor overfitting Reproducibility : Set random seeds and use keras.utils.set_random_seed() Save Models : Use .keras format for better compatibility Backend Choice : JAX for research, TensorFlow for production, PyTorch for flexibility Memory Management : Use keras.backend.clear_session() to free memory Debugging : Use model summaries and visualization tools Performance : Use mixed precision and appropriate batch sizes","title":"Keras"},{"location":"python/keras/#keras","text":"","title":"Keras"},{"location":"python/keras/#installation","text":"# Keras 3 (multi-backend) pip install --upgrade keras # With specific backend dependencies pip install --upgrade keras-cv keras-hub keras # For computer vision and NLP pip install --upgrade jax[cpu] # For JAX backend pip install --upgrade tensorflow # For TensorFlow backend pip install --upgrade torch # For PyTorch backend # Check version python -c \"import keras; print(keras.__version__)\"","title":"Installation"},{"location":"python/keras/#backend-configuration","text":"# Set backend before importing Keras (method 1) import os os.environ[\"KERAS_BACKEND\"] = \"tensorflow\" # or \"jax\", \"torch\" # Or via environment variable (method 2) export KERAS_BACKEND=\"jax\" # Or in Colab/Jupyter import os os.environ[\"KERAS_BACKEND\"] = \"jax\" import keras # Check current backend print(keras.config.backend())","title":"Backend Configuration"},{"location":"python/keras/#import-essentials","text":"import keras from keras import layers, models, utils, optimizers, losses, metrics from keras import ops # Backend-agnostic operations import numpy as np import matplotlib.pyplot as plt","title":"Import Essentials"},{"location":"python/keras/#models","text":"","title":"Models"},{"location":"python/keras/#sequential-model","text":"# Method 1: List of layers model = keras.Sequential([ layers.Dense(64, activation='relu', input_shape=(784,)), layers.Dropout(0.2), layers.Dense(10, activation='softmax') ]) # Method 2: Add layers incrementally model = keras.Sequential() model.add(layers.Dense(64, activation='relu', input_shape=(784,))) model.add(layers.Dropout(0.2)) model.add(layers.Dense(10, activation='softmax'))","title":"Sequential Model"},{"location":"python/keras/#functional-api","text":"inputs = layers.Input(shape=(784,)) x = layers.Dense(64, activation='relu')(inputs) x = layers.Dropout(0.2)(x) outputs = layers.Dense(10, activation='softmax')(x) model = keras.Model(inputs=inputs, outputs=outputs) # Multi-input/output example input1 = layers.Input(shape=(10,), name='input1') input2 = layers.Input(shape=(5,), name='input2') x1 = layers.Dense(64, activation='relu')(input1) x2 = layers.Dense(32, activation='relu')(input2) concatenated = layers.Concatenate()([x1, x2]) output1 = layers.Dense(1, activation='sigmoid', name='output1')(concatenated) output2 = layers.Dense(3, activation='softmax', name='output2')(concatenated) model = keras.Model(inputs=[input1, input2], outputs=[output1, output2])","title":"Functional API"},{"location":"python/keras/#model-subclassing","text":"class MyModel(keras.Model): def __init__(self, num_classes=10): super().__init__() self.dense1 = layers.Dense(64, activation='relu') self.dropout = layers.Dropout(0.2) self.dense2 = layers.Dense(num_classes, activation='softmax') def call(self, inputs, training=None): x = self.dense1(inputs) x = self.dropout(x, training=training) return self.dense2(x) def get_config(self): return {\"num_classes\": self.dense2.units} model = MyModel(num_classes=10)","title":"Model Subclassing"},{"location":"python/keras/#layers","text":"","title":"Layers"},{"location":"python/keras/#dense-fully-connected","text":"layers.Dense(64, activation='relu') layers.Dense(10, activation='softmax', use_bias=False) layers.Dense(32, kernel_regularizer=keras.regularizers.l2(0.01))","title":"Dense (Fully Connected)"},{"location":"python/keras/#convolutional-layers","text":"# 2D Convolution layers.Conv2D(32, (3, 3), activation='relu', padding='same') layers.Conv2D(64, 3, strides=2, activation='relu') # Depthwise Separable layers.SeparableConv2D(64, (3, 3), activation='relu') # Transposed Convolution (Deconvolution) layers.Conv2DTranspose(32, (3, 3), strides=2, padding='same') # 1D and 3D variants layers.Conv1D(32, 3, activation='relu') layers.Conv3D(32, (3, 3, 3), activation='relu')","title":"Convolutional Layers"},{"location":"python/keras/#pooling-layers","text":"layers.MaxPooling2D((2, 2)) layers.AveragePooling2D((2, 2), strides=2) layers.GlobalMaxPooling2D() layers.GlobalAveragePooling2D()","title":"Pooling Layers"},{"location":"python/keras/#recurrent-layers","text":"layers.LSTM(64, return_sequences=True) layers.GRU(32, dropout=0.2, recurrent_dropout=0.2) layers.SimpleRNN(32) # Bidirectional layers.Bidirectional(layers.LSTM(64)) # Stacked RNNs layers.LSTM(64, return_sequences=True) layers.LSTM(32)","title":"Recurrent Layers"},{"location":"python/keras/#attention-and-transformer-layers","text":"# Multi-head attention layers.MultiHeadAttention(num_heads=8, key_dim=64) # Self-attention layers.Attention() # Add & Normalize layers.LayerNormalization() layers.Add()","title":"Attention and Transformer Layers"},{"location":"python/keras/#normalization-layers","text":"layers.BatchNormalization() layers.LayerNormalization() layers.GroupNormalization(groups=32) layers.UnitNormalization()","title":"Normalization Layers"},{"location":"python/keras/#regularization","text":"layers.Dropout(0.2) layers.AlphaDropout(0.1) # For SELU activation layers.SpatialDropout2D(0.2) # For convolutional layers layers.GaussianDropout(0.1) layers.GaussianNoise(0.1)","title":"Regularization"},{"location":"python/keras/#activation-layers","text":"layers.ReLU() layers.LeakyReLU(negative_slope=0.3) layers.ELU(alpha=1.0) layers.Softmax(axis=-1) layers.Activation('tanh') # Advanced activations layers.PReLU() layers.ThresholdedReLU(theta=1.0) layers.Softplus()","title":"Activation Layers"},{"location":"python/keras/#utility-layers","text":"layers.Flatten() layers.Reshape((3, 4)) layers.Permute((2, 1)) layers.RepeatVector(3) layers.Lambda(lambda x: x ** 2) layers.Cropping2D(cropping=((1, 1), (2, 2))) layers.ZeroPadding2D(padding=(1, 1))","title":"Utility Layers"},{"location":"python/keras/#model-compilation","text":"","title":"Model Compilation"},{"location":"python/keras/#basic-compilation","text":"model.compile( optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'] )","title":"Basic Compilation"},{"location":"python/keras/#custom-configuration","text":"model.compile( optimizer=keras.optimizers.Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999), loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True), metrics=[ keras.metrics.SparseCategoricalAccuracy(), keras.metrics.TopKCategoricalAccuracy(k=5) ] )","title":"Custom Configuration"},{"location":"python/keras/#multiple-losses-multi-output","text":"model.compile( optimizer='adam', loss={ 'output1': 'binary_crossentropy', 'output2': 'categorical_crossentropy' }, loss_weights={'output1': 1.0, 'output2': 0.2}, metrics={ 'output1': ['accuracy'], 'output2': ['accuracy', 'top_k_categorical_accuracy'] } )","title":"Multiple Losses (Multi-output)"},{"location":"python/keras/#optimizers","text":"# SGD with momentum keras.optimizers.SGD(learning_rate=0.01, momentum=0.9, nesterov=True) # Adam variants keras.optimizers.Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999) keras.optimizers.AdamW(learning_rate=0.001, weight_decay=0.01) keras.optimizers.Adamax(learning_rate=0.002) # Other optimizers keras.optimizers.RMSprop(learning_rate=0.001, rho=0.9) keras.optimizers.Adagrad(learning_rate=0.01) keras.optimizers.Adadelta(learning_rate=1.0, rho=0.95)","title":"Optimizers"},{"location":"python/keras/#learning-rate-schedules","text":"# Exponential decay lr_schedule = keras.optimizers.schedules.ExponentialDecay( initial_learning_rate=0.1, decay_steps=10000, decay_rate=0.9 ) # Cosine decay lr_schedule = keras.optimizers.schedules.CosineDecay( initial_learning_rate=0.1, decay_steps=1000 ) # Piecewise constant lr_schedule = keras.optimizers.schedules.PiecewiseConstantDecay( boundaries=[100000, 110000], values=[1.0, 0.5, 0.1] ) optimizer = keras.optimizers.Adam(learning_rate=lr_schedule)","title":"Learning Rate Schedules"},{"location":"python/keras/#loss-functions","text":"","title":"Loss Functions"},{"location":"python/keras/#classification","text":"keras.losses.BinaryCrossentropy() keras.losses.BinaryFocalCrossentropy(alpha=0.25, gamma=2.0) keras.losses.CategoricalCrossentropy() keras.losses.SparseCategoricalCrossentropy() keras.losses.KLDivergence()","title":"Classification"},{"location":"python/keras/#regression","text":"keras.losses.MeanSquaredError() keras.losses.MeanAbsoluteError() keras.losses.MeanAbsolutePercentageError() keras.losses.MeanSquaredLogarithmicError() keras.losses.Huber(delta=1.0)","title":"Regression"},{"location":"python/keras/#custom-loss","text":"def custom_loss(y_true, y_pred): return ops.mean(ops.square(y_true - y_pred)) # Or as a class class CustomLoss(keras.losses.Loss): def __init__(self, name=\"custom_loss\"): super().__init__(name=name) def call(self, y_true, y_pred): return ops.mean(ops.square(y_true - y_pred)) model.compile(optimizer='adam', loss=CustomLoss())","title":"Custom Loss"},{"location":"python/keras/#training","text":"","title":"Training"},{"location":"python/keras/#basic-training","text":"history = model.fit( x_train, y_train, batch_size=32, epochs=10, validation_data=(x_val, y_val), verbose=1 )","title":"Basic Training"},{"location":"python/keras/#advanced-training-with-callbacks","text":"callbacks = [ keras.callbacks.EarlyStopping( monitor='val_loss', patience=3, restore_best_weights=True ), keras.callbacks.ReduceLROnPlateau( monitor='val_loss', factor=0.2, patience=2, min_lr=0.001 ), keras.callbacks.ModelCheckpoint( filepath='best_model.keras', monitor='val_accuracy', save_best_only=True, verbose=1 ), keras.callbacks.TensorBoard( log_dir='./logs', histogram_freq=1, write_graph=True ) ] history = model.fit( x_train, y_train, validation_data=(x_val, y_val), epochs=50, callbacks=callbacks, verbose=1 )","title":"Advanced Training with Callbacks"},{"location":"python/keras/#custom-training-step","text":"class CustomModel(keras.Model): def train_step(self, data): x, y = data with keras.backends.gradienttape() as tape: y_pred = self(x, training=True) loss = self.compute_loss(x, y, y_pred) trainable_vars = self.trainable_variables gradients = tape.gradient(loss, trainable_vars) self.optimizer.apply_gradients(zip(gradients, trainable_vars)) for metric in self.metrics: if metric.name == \"loss\": metric.update_state(loss) else: metric.update_state(y, y_pred) return {m.name: m.result() for m in self.metrics}","title":"Custom Training Step"},{"location":"python/keras/#data-processing","text":"","title":"Data Processing"},{"location":"python/keras/#image-data-loading-and-augmentation","text":"# Create a dataset from a directory of images train_ds = keras.utils.image_dataset_from_directory( directory='train_directory', labels='inferred', label_mode='categorical', batch_size=32, image_size=(224, 224) ) # Define data augmentation layers data_augmentation = keras.Sequential([ layers.RandomFlip(\"horizontal\"), layers.RandomRotation(0.1), layers.RandomZoom(0.1), ]) # Apply augmentation to the dataset train_ds = train_ds.map(lambda x, y: (data_augmentation(x), y)) # Prefetch for performance train_ds = train_ds.prefetch(buffer_size=tf.data.AUTOTUNE) # Fit with the dataset model.fit(train_ds, epochs=10, validation_data=val_ds)","title":"Image Data Loading and Augmentation"},{"location":"python/keras/#tfdata-integration","text":"# Using tf.data with Keras import tensorflow as tf def preprocess(image, label): image = tf.cast(image, tf.float32) / 255.0 return image, label train_ds = tf.data.Dataset.from_tensor_slices((x_train, y_train)) train_ds = train_ds.map(preprocess).batch(32).prefetch(tf.data.AUTOTUNE) model.fit(train_ds, epochs=10)","title":"tf.data Integration"},{"location":"python/keras/#evaluation-and-prediction","text":"","title":"Evaluation and Prediction"},{"location":"python/keras/#model-evaluation","text":"# Evaluate on test set test_loss, test_accuracy = model.evaluate(x_test, y_test, verbose=0) print(f\"Test accuracy: {test_accuracy:.4f}\") # Detailed evaluation with multiple metrics results = model.evaluate( x_test, y_test, batch_size=32, return_dict=True, verbose=1 )","title":"Model Evaluation"},{"location":"python/keras/#predictions","text":"# Predictions predictions = model.predict(x_test) predicted_classes = np.argmax(predictions, axis=1) # Single prediction single_pred = model.predict(np.expand_dims(single_sample, axis=0)) # Prediction with custom batch size predictions = model.predict(x_test, batch_size=64, verbose=1)","title":"Predictions"},{"location":"python/keras/#model-persistence","text":"","title":"Model Persistence"},{"location":"python/keras/#saveload-model","text":"# Save entire model model.save('my_model.keras') # Recommended format model.save('my_model.h5') # Legacy format # Load model loaded_model = keras.models.load_model('my_model.keras') # Save/load weights only model.save_weights('weights.weights.h5') model.load_weights('weights.weights.h5')","title":"Save/Load Model"},{"location":"python/keras/#export-to-different-formats","text":"# SavedModel format (for TensorFlow Serving) model.export('saved_model_dir') # Load exported model imported_model = keras.models.load_model('saved_model_dir')","title":"Export to Different Formats"},{"location":"python/keras/#callbacks","text":"","title":"Callbacks"},{"location":"python/keras/#built-in-callbacks","text":"# Early stopping keras.callbacks.EarlyStopping( monitor='val_loss', patience=5, restore_best_weights=True, verbose=1 ) # Learning rate scheduling keras.callbacks.LearningRateScheduler( lambda epoch: 0.1 * 0.95 ** epoch ) # CSV logger keras.callbacks.CSVLogger('training.log') # Model checkpointing keras.callbacks.ModelCheckpoint( 'model_{epoch:02d}_{val_loss:.2f}.keras', save_best_only=True, monitor='val_loss', mode='min' )","title":"Built-in Callbacks"},{"location":"python/keras/#custom-callbacks","text":"class CustomCallback(keras.callbacks.Callback): def on_epoch_begin(self, epoch, logs=None): print(f\"Starting epoch {epoch}\") def on_epoch_end(self, epoch, logs=None): if logs.get('val_accuracy') > 0.95: print(\"Reached 95% accuracy, stopping training!\") self.model.stop_training = True def on_batch_end(self, batch, logs=None): if batch % 100 == 0: print(f\"Finished batch {batch}\") model.fit(x_train, y_train, callbacks=[CustomCallback()])","title":"Custom Callbacks"},{"location":"python/keras/#metrics","text":"","title":"Metrics"},{"location":"python/keras/#built-in-metrics","text":"# Classification metrics keras.metrics.Accuracy() keras.metrics.BinaryAccuracy() keras.metrics.CategoricalAccuracy() keras.metrics.SparseCategoricalAccuracy() keras.metrics.TopKCategoricalAccuracy(k=5) keras.metrics.Precision() keras.metrics.Recall() keras.metrics.F1Score() keras.metrics.AUC() # Regression metrics keras.metrics.MeanSquaredError() keras.metrics.MeanAbsoluteError() keras.metrics.RootMeanSquaredError() keras.metrics.MeanAbsolutePercentageError()","title":"Built-in Metrics"},{"location":"python/keras/#custom-metrics","text":"class F1Score(keras.metrics.Metric): def __init__(self, name='f1_score', **kwargs): super().__init__(name=name, **kwargs) self.precision = keras.metrics.Precision() self.recall = keras.metrics.Recall() def update_state(self, y_true, y_pred, sample_weight=None): self.precision.update_state(y_true, y_pred, sample_weight) self.recall.update_state(y_true, y_pred, sample_weight) def result(self): p = self.precision.result() r = self.recall.result() return 2 * ((p * r) / (p + r + keras.backend.epsilon())) def reset_state(self): self.precision.reset_state() self.recall.reset_state()","title":"Custom Metrics"},{"location":"python/keras/#transfer-learning","text":"","title":"Transfer Learning"},{"location":"python/keras/#using-pre-trained-models","text":"# Load pre-trained model without top layers base_model = keras.applications.VGG16( weights='imagenet', include_top=False, input_shape=(224, 224, 3) ) # Freeze base model base_model.trainable = False # Add custom head inputs = keras.Input(shape=(224, 224, 3)) x = base_model(inputs, training=False) x = layers.GlobalAveragePooling2D()(x) x = layers.Dense(128, activation='relu')(x) outputs = layers.Dense(num_classes, activation='softmax')(x) model = keras.Model(inputs, outputs) # Fine-tuning: unfreeze some layers base_model.trainable = True for layer in base_model.layers[:-4]: layer.trainable = False","title":"Using Pre-trained Models"},{"location":"python/keras/#advanced-features","text":"","title":"Advanced Features"},{"location":"python/keras/#mixed-precision-training","text":"# Enable mixed precision keras.mixed_precision.set_global_policy('mixed_float16') # Custom model with loss scaling class MixedPrecisionModel(keras.Model): def __init__(self, *args, **kwargs): super().__init__(*args, **kwargs) self.loss_tracker = keras.metrics.Mean(name=\"loss\") def train_step(self, data): x, y = data with keras.backend.gradienttape() as tape: y_pred = self(x, training=True) loss = self.compute_loss(x, y, y_pred) # Scale loss for mixed precision scaled_loss = self.optimizer.get_scaled_loss(loss) scaled_gradients = tape.gradient(scaled_loss, self.trainable_variables) gradients = self.optimizer.get_unscaled_gradients(scaled_gradients) self.optimizer.apply_gradients(zip(gradients, self.trainable_variables)) self.loss_tracker.update_state(loss) return {\"loss\": self.loss_tracker.result()}","title":"Mixed Precision Training"},{"location":"python/keras/#custom-layers","text":"class CustomDense(layers.Layer): def __init__(self, units=32, **kwargs): super().__init__(**kwargs) self.units = units def build(self, input_shape): self.w = self.add_weight( shape=(input_shape[-1], self.units), initializer='random_normal', trainable=True, name='kernel' ) self.b = self.add_weight( shape=(self.units,), initializer='zeros', trainable=True, name='bias' ) super().build(input_shape) def call(self, inputs): return ops.matmul(inputs, self.w) + self.b def get_config(self): config = super().get_config() config.update({\"units\": self.units}) return config","title":"Custom Layers"},{"location":"python/keras/#model-visualization","text":"# Plot model architecture keras.utils.plot_model( model, to_file='model.png', show_shapes=True, show_layer_names=True, rankdir='TB', dpi=96 ) # Model summary model.summary() # Layer-wise summary for i, layer in enumerate(model.layers): print(f\"Layer {i}: {layer.name} ({layer.__class__.__name__})\") print(f\" Input shape: {layer.input_shape}\") print(f\" Output shape: {layer.output_shape}\") print(f\" Parameters: {layer.count_params()}\")","title":"Model Visualization"},{"location":"python/keras/#hyperparameter-tuning-with-kerastuner","text":"# Install: pip install keras-tuner import keras_tuner def build_model(hp): model = keras.Sequential([ layers.Dense( hp.Int('units_1', 32, 512, step=32), activation='relu' ), layers.Dropout(hp.Float('dropout_1', 0, 0.5, step=0.1)), layers.Dense( hp.Int('units_2', 32, 512, step=32), activation='relu' ), layers.Dense(10, activation='softmax') ]) model.compile( optimizer=keras.optimizers.Adam( hp.Float('learning_rate', 1e-4, 1e-2, sampling='log') ), loss='sparse_categorical_crossentropy', metrics=['accuracy'] ) return model tuner = keras_tuner.RandomSearch( build_model, objective='val_accuracy', max_trials=20 ) tuner.search(x_train, y_train, epochs=5, validation_data=(x_val, y_val)) best_model = tuner.get_best_models()[0]","title":"Hyperparameter Tuning with KerasTuner"},{"location":"python/keras/#kerashub-and-kerascv","text":"","title":"KerasHub and KerasCV"},{"location":"python/keras/#kerashub-nlp","text":"# Install: pip install keras-hub import keras_hub # Text classification with BERT classifier = keras_hub.models.BertClassifier.from_preset( \"bert_base_en_uncased\", num_classes=2 ) # Text generation with GPT generator = keras_hub.models.GPT2CausalLM.from_preset(\"gpt2_base_en\") output = generator.generate(\"The weather today\", max_length=50)","title":"KerasHub (NLP)"},{"location":"python/keras/#kerascv-computer-vision","text":"# Install: pip install keras-cv import keras_cv # Data augmentation augment = keras_cv.layers.RandAugment( value_range=(0, 255), magnitude=0.5, augmentations_per_image=3 ) # Object detection detector = keras_cv.models.RetinaNet.from_preset( \"retinanet_resnet50_pascalvoc\" )","title":"KerasCV (Computer Vision)"},{"location":"python/keras/#debugging-and-performance","text":"","title":"Debugging and Performance"},{"location":"python/keras/#debugging","text":"# Enable eager execution for debugging # tf.config.run_functions_eagerly(True) # For TensorFlow backend # Add debug prints in custom layers/models class DebugLayer(layers.Layer): def call(self, inputs): keras.utils.print_msg(f\"Input shape: {ops.shape(inputs)}\") return inputs # Check for NaN values def check_nan(tensor, name): if ops.any(ops.isnan(tensor)): print(f\"NaN detected in {name}\") return tensor","title":"Debugging"},{"location":"python/keras/#performance-optimization","text":"# Use mixed precision keras.mixed_precision.set_global_policy('mixed_float16') # Enable XLA compilation (TensorFlow backend) # model.compile(optimizer='adam', loss='mse', jit_compile=True) # Profile training # keras.utils.Progbar for custom progress bars # Use TensorBoard for performance profiling # Memory optimization keras.backend.clear_session() # Clear session to free memory","title":"Performance Optimization"},{"location":"python/keras/#best-practices","text":"Model Design : Start simple, add complexity gradually Data : Normalize inputs, use data augmentation for images Training : Use callbacks for early stopping and learning rate scheduling Validation : Always use validation data to monitor overfitting Reproducibility : Set random seeds and use keras.utils.set_random_seed() Save Models : Use .keras format for better compatibility Backend Choice : JAX for research, TensorFlow for production, PyTorch for flexibility Memory Management : Use keras.backend.clear_session() to free memory Debugging : Use model summaries and visualization tools Performance : Use mixed precision and appropriate batch sizes","title":"Best Practices"},{"location":"python/langchain/","text":"LangChain LangChain is a framework for developing applications powered by Large Language Models (LLMs). It simplifies the entire LLM application lifecycle with open-source components, third-party integrations, and tools for building complex AI workflows. Installation # Core LangChain library pip install langchain # Specific integrations pip install langchain-openai # OpenAI models pip install langchain-anthropic # Claude models pip install langchain-community # Community integrations pip install langchain-experimental # Experimental features # Vector stores pip install langchain-chroma # ChromaDB pip install langchain-pinecone # Pinecone pip install faiss-cpu # FAISS # All common packages pip install langchain[all] # Development installation git clone https://github.com/langchain-ai/langchain.git cd langchain pip install -e .[all] Quick Start from langchain_openai import ChatOpenAI from langchain_core.prompts import ChatPromptTemplate from langchain_core.output_parsers import StrOutputParser # Initialize LLM llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0) # Create prompt template prompt = ChatPromptTemplate.from_messages([ (\"system\", \"You are a helpful assistant.\"), (\"human\", \"{input}\") ]) # Create chain using LCEL (LangChain Expression Language) chain = prompt | llm | StrOutputParser() # Invoke the chain result = chain.invoke({\"input\": \"What is LangChain?\"}) print(result) Core Concepts 1. LangChain Expression Language (LCEL) from langchain_core.prompts import ChatPromptTemplate from langchain_openai import ChatOpenAI from langchain_core.output_parsers import StrOutputParser # Basic chain composition prompt = ChatPromptTemplate.from_template(\"Tell me a joke about {topic}\") model = ChatOpenAI() output_parser = StrOutputParser() # Chain components with | operator chain = prompt | model | output_parser # Invoke chain result = chain.invoke({\"topic\": \"programming\"}) # Batch processing results = chain.batch([ {\"topic\": \"cats\"}, {\"topic\": \"dogs\"} ]) # Streaming for chunk in chain.stream({\"topic\": \"AI\"}): print(chunk, end=\"\", flush=True) # Async support import asyncio async_result = await chain.ainvoke({\"topic\": \"python\"}) 2. Prompts and Templates from langchain_core.prompts import ChatPromptTemplate, PromptTemplate from langchain_core.prompts import FewShotPromptTemplate # Basic prompt template prompt = PromptTemplate( input_variables=[\"product\"], template=\"What is a good name for a company that makes {product}?\" ) # Chat prompt template chat_prompt = ChatPromptTemplate.from_messages([ (\"system\", \"You are a helpful assistant that translates {input_language} to {output_language}.\"), (\"human\", \"{text}\") ]) # Few-shot prompting examples = [ {\"input\": \"happy\", \"output\": \"sad\"}, {\"input\": \"tall\", \"output\": \"short\"}, ] example_prompt = PromptTemplate( input_variables=[\"input\", \"output\"], template=\"Input: {input}\\nOutput: {output}\" ) few_shot_prompt = FewShotPromptTemplate( examples=examples, example_prompt=example_prompt, prefix=\"Give the antonym of every input\", suffix=\"Input: {adjective}\\nOutput:\", input_variables=[\"adjective\"] ) # Partial prompts partial_prompt = prompt.partial(product=\"smartphones\") result = partial_prompt.format() # Prompt composition final_prompt = ChatPromptTemplate.from_messages([ (\"system\", \"You are a helpful assistant.\"), chat_prompt, (\"human\", \"Please also explain why this translation is correct.\") ]) 3. LLM Integration from langchain_openai import ChatOpenAI, OpenAI from langchain_anthropic import ChatAnthropic from langchain_community.llms import Ollama # OpenAI models openai_chat = ChatOpenAI( model=\"gpt-4o\", temperature=0.7, max_tokens=1000, api_key=\"your-api-key\" ) # Anthropic Claude anthropic = ChatAnthropic( model=\"claude-3-5-sonnet-20241022\", temperature=0, max_tokens=1000 ) # Local Ollama models ollama = Ollama( model=\"llama2\", base_url=\"http://localhost:11434\" ) # Model with callbacks for monitoring from langchain_core.callbacks import BaseCallbackHandler class TokenCountCallback(BaseCallbackHandler): def __init__(self): self.total_tokens = 0 def on_llm_end(self, response, **kwargs): if hasattr(response, 'llm_output') and 'token_usage' in response.llm_output: self.total_tokens += response.llm_output['token_usage']['total_tokens'] callback = TokenCountCallback() llm_with_callback = ChatOpenAI(callbacks=[callback]) Common Patterns 1. Sequential Chains from langchain.chains import LLMChain, SimpleSequentialChain from langchain_core.prompts import PromptTemplate # First chain: generate synopsis synopsis_template = \"\"\"You are a playwright. Given the title of play, it is your job to write a synopsis for that title. Title: {title} Playwright: This is a synopsis for the above play:\"\"\" synopsis_prompt = PromptTemplate( input_variables=[\"title\"], template=synopsis_template ) synopsis_chain = LLMChain(llm=llm, prompt=synopsis_prompt) # Second chain: write review review_template = \"\"\"You are a play critic from the New York Times. Given the synopsis of play, it is your job to write a review for that play. Synopsis: {synopsis} Review from a New York Times play critic of the above play:\"\"\" review_prompt = PromptTemplate( input_variables=[\"synopsis\"], template=review_template ) review_chain = LLMChain(llm=llm, prompt=review_prompt) # Combine chains overall_chain = SimpleSequentialChain( chains=[synopsis_chain, review_chain], verbose=True ) # Run the chain review = overall_chain.invoke({\"input\": \"Tragedy at sunset on the beach\"}) 2. Parallel Processing from langchain_core.runnables import RunnableParallel, RunnablePassthrough # Define parallel tasks joke_chain = ChatPromptTemplate.from_template(\"tell me a joke about {topic}\") | model | StrOutputParser() poem_chain = ChatPromptTemplate.from_template(\"write a short poem about {topic}\") | model | StrOutputParser() # Run in parallel parallel_chain = RunnableParallel({ \"joke\": joke_chain, \"poem\": poem_chain, \"original_topic\": RunnablePassthrough() }) result = parallel_chain.invoke({\"topic\": \"artificial intelligence\"}) print(result[\"joke\"]) print(result[\"poem\"]) print(result[\"original_topic\"]) 3. Conditional Logic and Routing from langchain_core.runnables import RunnableBranch def route_question(info): if \"math\" in info[\"question\"].lower(): return math_chain elif \"history\" in info[\"question\"].lower(): return history_chain else: return general_chain # Math chain math_chain = ChatPromptTemplate.from_template( \"You are a math expert. Answer this question: {question}\" ) | model | StrOutputParser() # History chain history_chain = ChatPromptTemplate.from_template( \"You are a history expert. Answer this question: {question}\" ) | model | StrOutputParser() # General chain general_chain = ChatPromptTemplate.from_template( \"Answer this question: {question}\" ) | model | StrOutputParser() # Route based on question content routing_chain = RunnableBranch( (lambda x: \"math\" in x[\"question\"].lower(), math_chain), (lambda x: \"history\" in x[\"question\"].lower(), history_chain), general_chain # default ) result = routing_chain.invoke({\"question\": \"What is 2+2?\"}) Memory Management 1. Conversation Buffer Memory from langchain.memory import ConversationBufferMemory from langchain.chains import ConversationChain # Basic conversation memory memory = ConversationBufferMemory() conversation = ConversationChain( llm=llm, memory=memory, verbose=True ) # Have a conversation response1 = conversation.invoke({\"input\": \"Hi, I'm John\"}) response2 = conversation.invoke({\"input\": \"What's my name?\"}) # Access memory print(memory.buffer) print(memory.chat_memory.messages) 2. Conversation Summary Memory from langchain.memory import ConversationSummaryMemory # Memory that summarizes conversation summary_memory = ConversationSummaryMemory( llm=llm, return_messages=True ) conversation_with_summary = ConversationChain( llm=llm, memory=summary_memory, verbose=True ) # Long conversation will be summarized for i in range(5): response = conversation_with_summary.invoke({ \"input\": f\"Tell me a fact about number {i}\" }) 3. Conversation Buffer Window Memory from langchain.memory import ConversationBufferWindowMemory # Keep only last k interactions window_memory = ConversationBufferWindowMemory( k=3, # Keep last 3 exchanges return_messages=True ) windowed_conversation = ConversationChain( llm=llm, memory=window_memory ) 4. Custom Memory with LCEL from langchain_core.runnables import RunnablePassthrough, RunnableLambda from langchain_core.messages import BaseMessage from typing import List # Custom memory implementation class CustomMemory: def __init__(self): self.messages: List[BaseMessage] = [] def add_message(self, message: BaseMessage): self.messages.append(message) def get_context(self) -> str: return \"\\n\".join([f\"{msg.type}: {msg.content}\" for msg in self.messages[-6:]]) memory = CustomMemory() # Chain with custom memory def add_memory(inputs): # Add user input to memory memory.add_message(HumanMessage(content=inputs[\"input\"])) inputs[\"chat_history\"] = memory.get_context() return inputs def save_response(response): # Save AI response to memory memory.add_message(AIMessage(content=response.content)) return response chat_with_memory = ( RunnableLambda(add_memory) | ChatPromptTemplate.from_messages([ (\"system\", \"You are a helpful assistant. Here's the chat history:\\n{chat_history}\"), (\"human\", \"{input}\") ]) | model | RunnableLambda(save_response) | StrOutputParser() ) Document Loading and Processing 1. Document Loaders from langchain_community.document_loaders import ( TextLoader, PDFLoader, WebBaseLoader, DirectoryLoader, CSVLoader, UnstructuredHTMLLoader ) # Text files text_loader = TextLoader(\"path/to/file.txt\") docs = text_loader.load() # PDF files pdf_loader = PDFLoader(\"path/to/document.pdf\") pdf_docs = pdf_loader.load() # Web pages web_loader = WebBaseLoader(\"https://example.com\") web_docs = web_loader.load() # Directory of files directory_loader = DirectoryLoader( \"path/to/directory\", glob=\"**/*.txt\", loader_cls=TextLoader ) all_docs = directory_loader.load() # CSV files csv_loader = CSVLoader(\"path/to/data.csv\") csv_docs = csv_loader.load() # Custom loader from langchain_core.documents import Document def custom_loader(file_path: str) -> List[Document]: # Custom loading logic with open(file_path, 'r') as f: content = f.read() return [Document( page_content=content, metadata={\"source\": file_path, \"custom_field\": \"value\"} )] 2. Text Splitting from langchain.text_splitter import ( CharacterTextSplitter, RecursiveCharacterTextSplitter, TokenTextSplitter, MarkdownHeaderTextSplitter ) # Character-based splitting char_splitter = CharacterTextSplitter( separator=\"\\n\\n\", chunk_size=1000, chunk_overlap=200 ) char_chunks = char_splitter.split_documents(docs) # Recursive character splitting (recommended) recursive_splitter = RecursiveCharacterTextSplitter( chunk_size=1000, chunk_overlap=200, separators=[\"\\n\\n\", \"\\n\", \" \", \"\"] ) recursive_chunks = recursive_splitter.split_documents(docs) # Token-based splitting token_splitter = TokenTextSplitter( chunk_size=512, chunk_overlap=50 ) token_chunks = token_splitter.split_documents(docs) # Markdown-aware splitting markdown_splitter = MarkdownHeaderTextSplitter( headers_to_split_on=[ (\"#\", \"Header 1\"), (\"##\", \"Header 2\"), (\"###\", \"Header 3\"), ] ) markdown_chunks = markdown_splitter.split_text(markdown_text) # Custom splitter from langchain.text_splitter import TextSplitter class CustomSplitter(TextSplitter): def split_text(self, text: str) -> List[str]: # Custom splitting logic return text.split(\"---\") # Split on custom separator custom_splitter = CustomSplitter() custom_chunks = custom_splitter.split_documents(docs) Vector Stores and Embeddings 1. Embeddings from langchain_openai import OpenAIEmbeddings from langchain_community.embeddings import HuggingFaceEmbeddings, OllamaEmbeddings # OpenAI embeddings openai_embeddings = OpenAIEmbeddings( model=\"text-embedding-3-small\" ) # Hugging Face embeddings hf_embeddings = HuggingFaceEmbeddings( model_name=\"sentence-transformers/all-MiniLM-L6-v2\" ) # Local Ollama embeddings ollama_embeddings = OllamaEmbeddings( model=\"llama2\", base_url=\"http://localhost:11434\" ) # Test embeddings text = \"This is a test document\" embedding_vector = openai_embeddings.embed_query(text) print(f\"Embedding dimension: {len(embedding_vector)}\") # Batch embeddings texts = [\"Document 1\", \"Document 2\", \"Document 3\"] batch_embeddings = openai_embeddings.embed_documents(texts) 2. Vector Store Operations from langchain_community.vectorstores import Chroma, FAISS, Pinecone from langchain_core.documents import Document # Create documents docs = [ Document(page_content=\"The sky is blue\", metadata={\"source\": \"fact1\"}), Document(page_content=\"Grass is green\", metadata={\"source\": \"fact2\"}), Document(page_content=\"Fire is hot\", metadata={\"source\": \"fact3\"}), ] # ChromaDB vector store chroma_db = Chroma.from_documents( documents=docs, embedding=openai_embeddings, persist_directory=\"./chroma_db\" ) # FAISS vector store (in-memory) faiss_db = FAISS.from_documents( documents=docs, embedding=openai_embeddings ) # Save/load FAISS faiss_db.save_local(\"./faiss_index\") loaded_faiss = FAISS.load_local(\"./faiss_index\", openai_embeddings) # Pinecone vector store import pinecone pinecone.init(api_key=\"your-api-key\", environment=\"your-env\") pinecone_db = Pinecone.from_documents( documents=docs, embedding=openai_embeddings, index_name=\"your-index\" ) # Search operations query = \"What color is the sky?\" similar_docs = chroma_db.similarity_search(query, k=2) # Search with scores docs_with_scores = chroma_db.similarity_search_with_score(query, k=2) for doc, score in docs_with_scores: print(f\"Score: {score}, Content: {doc.page_content}\") # Filtered search filtered_docs = chroma_db.similarity_search( query, k=2, filter={\"source\": \"fact1\"} ) # Add more documents new_docs = [Document(page_content=\"Water is wet\", metadata={\"source\": \"fact4\"})] chroma_db.add_documents(new_docs) # Delete documents chroma_db.delete(ids=[\"doc_id_to_delete\"]) Retrieval-Augmented Generation (RAG) 1. Basic RAG Chain from langchain.chains import RetrievalQA from langchain_core.runnables import RunnablePassthrough from langchain_core.prompts import ChatPromptTemplate # Set up vector store as retriever retriever = chroma_db.as_retriever( search_type=\"similarity\", search_kwargs={\"k\": 3} ) # Traditional approach with RetrievalQA qa_chain = RetrievalQA.from_chain_type( llm=llm, chain_type=\"stuff\", retriever=retriever, return_source_documents=True ) result = qa_chain.invoke({\"query\": \"What is the color of the sky?\"}) print(result[\"result\"]) print(result[\"source_documents\"]) # Modern approach with LCEL def format_docs(docs): return \"\\n\\n\".join(doc.page_content for doc in docs) rag_template = \"\"\"Answer the question based only on the following context: {context} Question: {question} Answer:\"\"\" rag_prompt = ChatPromptTemplate.from_template(rag_template) rag_chain = ( {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()} | rag_prompt | llm | StrOutputParser() ) answer = rag_chain.invoke(\"What is the color of the sky?\") 2. Advanced RAG with Multiple Retrievers from langchain.retrievers import EnsembleRetriever, MultiQueryRetriever from langchain_community.retrievers import BM25Retriever # BM25 retriever (keyword-based) texts = [doc.page_content for doc in docs] bm25_retriever = BM25Retriever.from_texts(texts) # Ensemble retriever (combines multiple retrievers) ensemble_retriever = EnsembleRetriever( retrievers=[chroma_db.as_retriever(), bm25_retriever], weights=[0.7, 0.3] # Weight vector search more than keyword search ) # Multi-query retriever (generates multiple queries) multi_query_retriever = MultiQueryRetriever.from_llm( retriever=chroma_db.as_retriever(), llm=llm ) # Use with RAG chain advanced_rag_chain = ( {\"context\": ensemble_retriever | format_docs, \"question\": RunnablePassthrough()} | rag_prompt | llm | StrOutputParser() ) 3. RAG with Chat History from langchain.chains import create_history_aware_retriever, create_retrieval_chain from langchain.chains.combine_documents import create_stuff_documents_chain # Contextualized retrieval contextualize_q_system_prompt = \"\"\"Given a chat history and the latest user question \\ which might reference context in the chat history, formulate a standalone question \\ which can be understood without the chat history. Do NOT answer the question, \\ just reformulate it if needed and otherwise return it as is.\"\"\" contextualize_q_prompt = ChatPromptTemplate.from_messages([ (\"system\", contextualize_q_system_prompt), MessagesPlaceholder(\"chat_history\"), (\"human\", \"{input}\"), ]) history_aware_retriever = create_history_aware_retriever( llm, retriever, contextualize_q_prompt ) # Answer generation qa_system_prompt = \"\"\"You are an assistant for question-answering tasks. \\ Use the following pieces of retrieved context to answer the question. \\ If you don't know the answer, just say that you don't know. {context}\"\"\" qa_prompt = ChatPromptTemplate.from_messages([ (\"system\", qa_system_prompt), MessagesPlaceholder(\"chat_history\"), (\"human\", \"{input}\"), ]) question_answer_chain = create_stuff_documents_chain(llm, qa_prompt) # Full RAG chain with history rag_chain_with_history = create_retrieval_chain( history_aware_retriever, question_answer_chain ) # Usage with session history from langchain_community.chat_message_histories import ChatMessageHistory from langchain_core.chat_history import BaseChatMessageHistory store = {} def get_session_history(session_id: str) -> BaseChatMessageHistory: if session_id not in store: store[session_id] = ChatMessageHistory() return store[session_id] conversational_rag_chain = RunnableWithMessageHistory( rag_chain_with_history, get_session_history, input_messages_key=\"input\", history_messages_key=\"chat_history\", output_messages_key=\"answer\", ) # Chat with history response = conversational_rag_chain.invoke( {\"input\": \"What is the sky color?\"}, config={\"configurable\": {\"session_id\": \"session_1\"}}, ) follow_up = conversational_rag_chain.invoke( {\"input\": \"Why is that?\"}, # References previous question config={\"configurable\": {\"session_id\": \"session_1\"}}, ) Agents and Tool Usage 1. Basic Agent Setup from langchain.agents import create_openai_tools_agent, AgentExecutor from langchain_community.tools import WikipediaQueryRun, DuckDuckGoSearchRun from langchain_community.utilities import WikipediaAPIWrapper from langchain.tools import BaseTool from typing import Type # Define tools wikipedia = WikipediaQueryRun(api_wrapper=WikipediaAPIWrapper()) search = DuckDuckGoSearchRun() # Custom tool class CalculatorTool(BaseTool): name = \"calculator\" description = \"Useful for mathematical calculations\" def _run(self, query: str) -> str: try: return str(eval(query)) # Be careful with eval in production except Exception as e: return f\"Error: {str(e)}\" calculator = CalculatorTool() # Available tools tools = [wikipedia, search, calculator] # Create agent agent_prompt = ChatPromptTemplate.from_messages([ (\"system\", \"You are a helpful assistant. Use tools when needed.\"), (\"human\", \"{input}\"), MessagesPlaceholder(variable_name=\"agent_scratchpad\"), ]) agent = create_openai_tools_agent(llm, tools, agent_prompt) agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True) # Use agent result = agent_executor.invoke({ \"input\": \"What is the population of Tokyo? Then calculate 10% of that number.\" }) 2. Custom Tools from langchain.tools import tool from langchain.pydantic_v1 import BaseModel, Field import requests # Decorator-based tool @tool def get_weather(city: str) -> str: \"\"\"Get current weather for a given city.\"\"\" # Mock weather API call return f\"The weather in {city} is sunny and 75\u00b0F\" # Class-based tool with input schema class WeatherInput(BaseModel): city: str = Field(description=\"The city to get weather for\") units: str = Field(default=\"fahrenheit\", description=\"Temperature units\") class WeatherTool(BaseTool): name = \"weather_tool\" description = \"Get current weather information\" args_schema: Type[BaseModel] = WeatherInput def _run(self, city: str, units: str = \"fahrenheit\") -> str: # Weather API integration return f\"Weather in {city}: 72\u00b0{units[0].upper()}, partly cloudy\" # API-based tool @tool def search_api(query: str) -> str: \"\"\"Search the web using a custom API.\"\"\" # Example API call response = requests.get( \"https://api.example.com/search\", params={\"q\": query}, headers={\"Authorization\": \"Bearer your-token\"} ) return response.json().get(\"results\", \"No results found\") # File system tool @tool def read_file(file_path: str) -> str: \"\"\"Read contents of a file.\"\"\" try: with open(file_path, 'r') as f: return f.read() except Exception as e: return f\"Error reading file: {str(e)}\" # Database tool @tool def query_database(sql_query: str) -> str: \"\"\"Execute SQL query on database.\"\"\" import sqlite3 conn = sqlite3.connect(\"example.db\") cursor = conn.cursor() try: cursor.execute(sql_query) results = cursor.fetchall() conn.close() return str(results) except Exception as e: conn.close() return f\"Database error: {str(e)}\" 3. Agent Types and Strategies from langchain.agents import create_react_agent, create_structured_chat_agent # ReAct agent (Reasoning and Acting) react_prompt = \"\"\"Answer the following questions as best you can. You have access to the following tools: {tools} Use the following format: Question: the input question you must answer Thought: you should always think about what to do Action: the action to take, should be one of [{tool_names}] Action Input: the input to the action Observation: the result of the action ... (this Thought/Action/Action Input/Observation can repeat N times) Thought: I now know the final answer Final Answer: the final answer to the original input question Begin! Question: {input} Thought:{agent_scratchpad}\"\"\" react_agent = create_react_agent(llm, tools, react_prompt) react_executor = AgentExecutor( agent=react_agent, tools=tools, verbose=True, max_iterations=5 ) # Structured chat agent structured_agent = create_structured_chat_agent( llm=llm, tools=tools, prompt=agent_prompt ) structured_executor = AgentExecutor( agent=structured_agent, tools=tools, verbose=True, handle_parsing_errors=True ) # Custom agent with error handling class CustomAgentExecutor(AgentExecutor): def _handle_error(self, error: Exception) -> str: return f\"I encountered an error: {str(error)}. Let me try a different approach.\" custom_executor = CustomAgentExecutor( agent=agent, tools=tools, verbose=True, max_iterations=3, early_stopping_method=\"generate\" ) Output Parsing 1. Built-in Parsers from langchain_core.output_parsers import ( StrOutputParser, JsonOutputParser, ListOutputParser, CommaSeparatedListOutputParser, DatetimeOutputParser ) from langchain_core.pydantic_v1 import BaseModel, Field # String parser (default) str_parser = StrOutputParser() # JSON parser json_parser = JsonOutputParser() # List parser list_parser = ListOutputParser() # Comma-separated list parser csv_parser = CommaSeparatedListOutputParser() # Datetime parser datetime_parser = DatetimeOutputParser() # Usage with chains json_chain = ( ChatPromptTemplate.from_template( \"Generate a JSON object with name and age for a person named {name}\" ) | llm | json_parser ) result = json_chain.invoke({\"name\": \"Alice\"}) 2. Pydantic Parser from langchain.output_parsers import PydanticOutputParser from pydantic import BaseModel, Field from typing import List # Define data model class Person(BaseModel): name: str = Field(description=\"person's name\") age: int = Field(description=\"person's age\") occupation: str = Field(description=\"person's job\") skills: List[str] = Field(description=\"list of skills\") # Create parser person_parser = PydanticOutputParser(pydantic_object=Person) # Create prompt with format instructions person_prompt = ChatPromptTemplate.from_messages([ (\"system\", \"Extract person information from the following text.\"), (\"human\", \"{text}\\n{format_instructions}\"), ]) # Chain with structured output person_chain = ( person_prompt.partial(format_instructions=person_parser.get_format_instructions()) | llm | person_parser ) # Usage text = \"John Doe is a 30-year-old software engineer who knows Python, JavaScript, and SQL.\" structured_data = person_chain.invoke({\"text\": text}) print(f\"Name: {structured_data.name}\") print(f\"Skills: {structured_data.skills}\") 3. Custom Output Parsers from langchain_core.output_parsers import BaseOutputParser from typing import Dict, Any import re class CustomEmailParser(BaseOutputParser[Dict[str, Any]]): \"\"\"Parse email components from LLM output.\"\"\" def parse(self, text: str) -> Dict[str, Any]: # Extract email components using regex subject_match = re.search(r'Subject:\\s*(.*)', text) body_match = re.search(r'Body:\\s*(.*?)(?=\\n\\n|\\Z)', text, re.DOTALL) recipient_match = re.search(r'To:\\s*(.*)', text) return { \"subject\": subject_match.group(1) if subject_match else \"\", \"body\": body_match.group(1).strip() if body_match else \"\", \"recipient\": recipient_match.group(1) if recipient_match else \"\" } @property def _type(self) -> str: return \"custom_email_parser\" # Usage email_parser = CustomEmailParser() email_prompt = ChatPromptTemplate.from_template( \"\"\"Write a professional email with the following format: Subject: [subject line] To: [recipient email] Body: [email content] Topic: {topic} Recipient: {recipient}\"\"\" ) email_chain = email_prompt | llm | email_parser parsed_email = email_chain.invoke({ \"topic\": \"Meeting followup\", \"recipient\": \"john@example.com\" }) print(parsed_email) Advanced Features 1. Callbacks and Monitoring from langchain_core.callbacks import BaseCallbackHandler from langchain_core.callbacks import CallbackManager import time class TimingCallback(BaseCallbackHandler): def __init__(self): self.start_time = None self.end_time = None def on_chain_start(self, serialized, inputs, **kwargs): self.start_time = time.time() print(f\"Chain started with inputs: {inputs}\") def on_chain_end(self, outputs, **kwargs): self.end_time = time.time() duration = self.end_time - self.start_time print(f\"Chain completed in {duration:.2f} seconds\") def on_llm_start(self, serialized, prompts, **kwargs): print(f\"LLM called with prompts: {prompts}\") def on_llm_end(self, response, **kwargs): if hasattr(response, 'llm_output') and response.llm_output: token_usage = response.llm_output.get('token_usage', {}) print(f\"Token usage: {token_usage}\") # Use callback timing_callback = TimingCallback() callback_manager = CallbackManager([timing_callback]) chain_with_callbacks = ( prompt | llm.with_config(callbacks=[timing_callback]) | StrOutputParser() ) result = chain_with_callbacks.invoke({\"input\": \"Hello, world!\"}) 2. Streaming and Async Operations import asyncio from langchain_core.callbacks import AsyncCallbackHandler # Streaming responses def stream_response(chain, input_data): for chunk in chain.stream(input_data): print(chunk, end=\"\", flush=True) # Async operations async def async_chain_example(): async_llm = ChatOpenAI(temperature=0) async_chain = prompt | async_llm | StrOutputParser() # Async invoke result = await async_chain.ainvoke({\"input\": \"Hello async world!\"}) print(result) # Async streaming async for chunk in async_chain.astream({\"input\": \"Stream this async\"}): print(chunk, end=\"\", flush=True) # Async batch processing batch_results = await async_chain.abatch([ {\"input\": \"First query\"}, {\"input\": \"Second query\"}, {\"input\": \"Third query\"} ]) return batch_results # Run async example # results = asyncio.run(async_chain_example()) # Async callback class AsyncTimingCallback(AsyncCallbackHandler): async def on_chain_start(self, serialized, inputs, **kwargs): print(f\"Async chain started: {inputs}\") async def on_chain_end(self, outputs, **kwargs): print(f\"Async chain completed: {outputs}\") 3. Configuration and Environment Management from langchain_core.runnables import RunnableConfig import os from dotenv import load_dotenv # Load environment variables load_dotenv() # Configuration management config = RunnableConfig( tags=[\"production\", \"chat\"], metadata={\"user_id\": \"123\", \"session_id\": \"abc\"}, recursion_limit=10 ) # Chain with config result = chain.invoke( {\"input\": \"Hello\"}, config=config ) # Environment-specific setup class EnvironmentConfig: def __init__(self, env: str = \"development\"): self.env = env if env == \"production\": self.llm_model = \"gpt-4\" self.temperature = 0.1 self.max_tokens = 1000 else: self.llm_model = \"gpt-3.5-turbo\" self.temperature = 0.7 self.max_tokens = 500 def get_llm(self): return ChatOpenAI( model=self.llm_model, temperature=self.temperature, max_tokens=self.max_tokens ) # Usage env_config = EnvironmentConfig(\"production\") production_llm = env_config.get_llm() 4. Custom Chain Classes from langchain_core.runnables import Runnable from typing import Dict, Any class CustomProcessingChain(Runnable): \"\"\"Custom chain with preprocessing and postprocessing.\"\"\" def __init__(self, llm, preprocessor=None, postprocessor=None): self.llm = llm self.preprocessor = preprocessor or self._default_preprocess self.postprocessor = postprocessor or self._default_postprocess def _default_preprocess(self, input_data: Dict[str, Any]) -> Dict[str, Any]: # Default preprocessing if \"text\" in input_data: input_data[\"text\"] = input_data[\"text\"].strip().lower() return input_data def _default_postprocess(self, output: str) -> str: # Default postprocessing return output.strip().capitalize() def invoke(self, input_data: Dict[str, Any], config=None) -> str: # Preprocess processed_input = self.preprocessor(input_data) # LLM call prompt = ChatPromptTemplate.from_template(\"Process this text: {text}\") chain = prompt | self.llm | StrOutputParser() result = chain.invoke(processed_input, config=config) # Postprocess final_result = self.postprocessor(result) return final_result # Custom preprocessing/postprocessing functions def custom_preprocessor(data): data[\"text\"] = f\"IMPORTANT: {data['text']}\" return data def custom_postprocessor(output): return f\"[PROCESSED] {output}\" # Usage custom_chain = CustomProcessingChain( llm=llm, preprocessor=custom_preprocessor, postprocessor=custom_postprocessor ) result = custom_chain.invoke({\"text\": \"hello world\"}) Integration Examples 1. FastAPI Web Service from fastapi import FastAPI, HTTPException from pydantic import BaseModel from typing import List, Optional app = FastAPI() class ChatRequest(BaseModel): message: str session_id: Optional[str] = None class ChatResponse(BaseModel): response: str session_id: str # Initialize chain chat_chain = prompt | llm | StrOutputParser() @app.post(\"/chat\", response_model=ChatResponse) async def chat_endpoint(request: ChatRequest): try: response = await chat_chain.ainvoke({\"input\": request.message}) return ChatResponse( response=response, session_id=request.session_id or \"default\" ) except Exception as e: raise HTTPException(status_code=500, detail=str(e)) @app.get(\"/health\") async def health_check(): return {\"status\": \"healthy\"} # Run with: uvicorn main:app --reload 2. Streamlit Chat Interface import streamlit as st from langchain_core.messages import HumanMessage, AIMessage # Initialize session state if \"messages\" not in st.session_state: st.session_state.messages = [] if \"chain\" not in st.session_state: st.session_state.chain = prompt | llm | StrOutputParser() st.title(\"LangChain Chatbot\") # Display chat history for message in st.session_state.messages: if isinstance(message, HumanMessage): with st.chat_message(\"user\"): st.write(message.content) else: with st.chat_message(\"assistant\"): st.write(message.content) # Chat input if user_input := st.chat_input(\"Type your message...\"): # Add user message st.session_state.messages.append(HumanMessage(content=user_input)) # Display user message with st.chat_message(\"user\"): st.write(user_input) # Get AI response with st.chat_message(\"assistant\"): with st.spinner(\"Thinking...\"): response = st.session_state.chain.invoke({\"input\": user_input}) st.write(response) st.session_state.messages.append(AIMessage(content=response)) 3. Gradio Interface import gradio as gr def chat_interface(message, history): # Convert history to proper format context = \"\\n\".join([f\"Human: {h[0]}\\nAssistant: {h[1]}\" for h in history]) # Add current message full_prompt = f\"{context}\\nHuman: {message}\\nAssistant:\" # Get response response = chain.invoke({\"input\": full_prompt}) return response # Create Gradio interface demo = gr.ChatInterface( fn=chat_interface, title=\"LangChain Chat\", description=\"Chat with LangChain-powered AI assistant\" ) # Launch interface if __name__ == \"__main__\": demo.launch(share=True) Performance Optimization 1. Caching from langchain.cache import InMemoryCache, SQLiteCache from langchain.globals import set_llm_cache # In-memory caching set_llm_cache(InMemoryCache()) # SQLite caching (persistent) set_llm_cache(SQLiteCache(database_path=\".langchain.db\")) # Redis caching from langchain.cache import RedisCache import redis redis_client = redis.Redis(host='localhost', port=6379, db=0) set_llm_cache(RedisCache(redis_client)) # Custom cache from langchain_core.caches import BaseCache class CustomCache(BaseCache): def __init__(self): self._cache = {} def lookup(self, prompt, llm_string): return self._cache.get((prompt, llm_string)) def update(self, prompt, llm_string, return_val): self._cache[(prompt, llm_string)] = return_val set_llm_cache(CustomCache()) 2. Batch Processing # Batch LLM calls batch_prompts = [ {\"input\": f\"Summarize topic {i}\"} for i in range(10) ] # Sequential processing results = [] for prompt in batch_prompts: result = chain.invoke(prompt) results.append(result) # Parallel batch processing batch_results = chain.batch(batch_prompts, config={\"max_concurrency\": 5}) # Async batch processing async def async_batch_processing(): return await chain.abatch(batch_prompts) # Streaming batch for result in chain.batch(batch_prompts): print(f\"Completed: {result}\") 3. Memory Management # Efficient memory usage from langchain.memory import ConversationSummaryBufferMemory # Summary + buffer memory (hybrid approach) memory = ConversationSummaryBufferMemory( llm=llm, max_token_limit=1000, return_messages=True ) # Custom memory with cleanup class EfficientMemory: def __init__(self, max_messages=10): self.messages = [] self.max_messages = max_messages def add_message(self, message): self.messages.append(message) if len(self.messages) > self.max_messages: # Keep only recent messages self.messages = self.messages[-self.max_messages:] def clear_old_messages(self): # Keep only last 5 messages self.messages = self.messages[-5:] # Periodic cleanup efficient_memory = EfficientMemory() # Use context managers for cleanup from contextlib import contextmanager @contextmanager def managed_chain(chain): try: yield chain finally: # Cleanup operations if hasattr(chain, 'memory') and chain.memory: chain.memory.clear() Best Practices 1. Error Handling from langchain_core.exceptions import LangChainException import logging # Configure logging logging.basicConfig(level=logging.INFO) logger = logging.getLogger(__name__) def robust_chain_invoke(chain, input_data, max_retries=3): \"\"\"Invoke chain with error handling and retries.\"\"\" for attempt in range(max_retries): try: result = chain.invoke(input_data) logger.info(f\"Chain invocation successful on attempt {attempt + 1}\") return result except LangChainException as e: logger.error(f\"LangChain error on attempt {attempt + 1}: {str(e)}\") if attempt == max_retries - 1: raise except Exception as e: logger.error(f\"Unexpected error on attempt {attempt + 1}: {str(e)}\") if attempt == max_retries - 1: raise # Exponential backoff time.sleep(2 ** attempt) # Usage try: result = robust_chain_invoke(chain, {\"input\": \"test\"}) except Exception as e: logger.error(f\"All retry attempts failed: {str(e)}\") # Fallback behavior result = \"I apologize, but I'm having trouble processing your request right now.\" 2. Testing import pytest from unittest.mock import Mock, patch class TestLangChainComponents: @pytest.fixture def mock_llm(self): \"\"\"Mock LLM for testing.\"\"\" mock = Mock() mock.invoke.return_value = \"Mocked response\" return mock @pytest.fixture def sample_chain(self, mock_llm): \"\"\"Sample chain for testing.\"\"\" prompt = ChatPromptTemplate.from_template(\"Test: {input}\") return prompt | mock_llm | StrOutputParser() def test_chain_invoke(self, sample_chain): \"\"\"Test basic chain invocation.\"\"\" result = sample_chain.invoke({\"input\": \"hello\"}) assert result == \"Mocked response\" def test_prompt_formatting(self): \"\"\"Test prompt template formatting.\"\"\" prompt = ChatPromptTemplate.from_template(\"Hello {name}\") formatted = prompt.format(name=\"Alice\") assert \"Alice\" in str(formatted) @patch('langchain_openai.ChatOpenAI') def test_with_real_llm_mock(self, mock_openai): \"\"\"Test with mocked OpenAI client.\"\"\" mock_openai.return_value.invoke.return_value = \"Test response\" llm = ChatOpenAI() result = llm.invoke(\"test prompt\") assert result == \"Test response\" mock_openai.assert_called_once() # Run tests with: pytest test_langchain.py 3. Production Deployment from langchain_core.runnables import RunnableConfig import os from typing import Dict, Any class ProductionChainWrapper: \"\"\"Production-ready chain wrapper with monitoring and error handling.\"\"\" def __init__(self, chain, environment=\"production\"): self.chain = chain self.environment = environment self.request_count = 0 self.error_count = 0 def invoke(self, input_data: Dict[str, Any]) -> str: \"\"\"Invoke chain with production safeguards.\"\"\" self.request_count += 1 try: # Input validation self._validate_input(input_data) # Rate limiting check if self.request_count > 1000: # Example limit raise Exception(\"Rate limit exceeded\") # Invoke chain with timeout config = RunnableConfig( tags=[self.environment], metadata={\"request_id\": self.request_count} ) result = self.chain.invoke(input_data, config=config) # Output validation self._validate_output(result) return result except Exception as e: self.error_count += 1 logger.error(f\"Chain error: {str(e)}\") # Fallback response return self._get_fallback_response(input_data) def _validate_input(self, input_data: Dict[str, Any]): \"\"\"Validate input data.\"\"\" if not isinstance(input_data, dict): raise ValueError(\"Input must be a dictionary\") if \"input\" not in input_data: raise ValueError(\"Input must contain 'input' key\") if len(input_data[\"input\"]) > 10000: # Character limit raise ValueError(\"Input too long\") def _validate_output(self, output: str): \"\"\"Validate output.\"\"\" if not isinstance(output, str): raise ValueError(\"Output must be a string\") if len(output) == 0: raise ValueError(\"Empty output\") def _get_fallback_response(self, input_data: Dict[str, Any]) -> str: \"\"\"Provide fallback response on error.\"\"\" return \"I apologize, but I'm unable to process your request at the moment.\" def get_metrics(self) -> Dict[str, Any]: \"\"\"Get performance metrics.\"\"\" return { \"request_count\": self.request_count, \"error_count\": self.error_count, \"error_rate\": self.error_count / max(self.request_count, 1), \"environment\": self.environment } # Usage production_chain = ProductionChainWrapper(chain, \"production\") result = production_chain.invoke({\"input\": \"Hello world\"}) metrics = production_chain.get_metrics() 4. Monitoring and Observability from langchain_community.callbacks import LangChainTracer from langchain.callbacks.manager import tracing_v2_enabled # LangSmith tracing (if available) os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\" os.environ[\"LANGCHAIN_API_KEY\"] = \"your-langsmith-api-key\" # Use tracing context with tracing_v2_enabled(): result = chain.invoke({\"input\": \"traced request\"}) # Custom monitoring class MonitoringCallback(BaseCallbackHandler): def __init__(self): self.metrics = { \"total_requests\": 0, \"total_tokens\": 0, \"average_response_time\": 0, \"error_count\": 0 } self.start_times = {} def on_chain_start(self, serialized, inputs, run_id, **kwargs): self.metrics[\"total_requests\"] += 1 self.start_times[run_id] = time.time() def on_chain_end(self, outputs, run_id, **kwargs): if run_id in self.start_times: duration = time.time() - self.start_times[run_id] # Update average response time current_avg = self.metrics[\"average_response_time\"] new_avg = ((current_avg * (self.metrics[\"total_requests\"] - 1)) + duration) / self.metrics[\"total_requests\"] self.metrics[\"average_response_time\"] = new_avg del self.start_times[run_id] def on_chain_error(self, error, run_id, **kwargs): self.metrics[\"error_count\"] += 1 if run_id in self.start_times: del self.start_times[run_id] # Use monitoring monitoring = MonitoringCallback() monitored_chain = chain.with_config(callbacks=[monitoring]) # Health check endpoint def health_check(): return { \"status\": \"healthy\", \"metrics\": monitoring.metrics, \"timestamp\": time.time() } Troubleshooting Common Issues and Solutions API Key Issues ```python # Check environment variables import os print(\"OpenAI API Key:\", \"SET\" if os.getenv(\"OPENAI_API_KEY\") else \"NOT SET\") # Set programmatically os.environ[\"OPENAI_API_KEY\"] = \"your-api-key\" ``` Memory Issues with Large Documents ```python # Use streaming for large documents def process_large_document(doc, chunk_size=1000): chunks = [doc[i:i+chunk_size] for i in range(0, len(doc), chunk_size)] results = [] for chunk in chunks: result = chain.invoke({\"input\": chunk}) results.append(result) return results ``` Rate Limiting ```python import time from tenacity import retry, wait_exponential, stop_after_attempt @retry( wait=wait_exponential(multiplier=1, min=4, max=10), stop=stop_after_attempt(3) ) def invoke_with_retry(chain, input_data): return chain.invoke(input_data) ``` Token Limits ```python import tiktoken def count_tokens(text, model=\"gpt-4\"): encoding = tiktoken.encoding_for_model(model) return len(encoding.encode(text)) def truncate_text(text, max_tokens=4000, model=\"gpt-4\"): encoding = tiktoken.encoding_for_model(model) tokens = encoding.encode(text) if len(tokens) > max_tokens: truncated_tokens = tokens[:max_tokens] return encoding.decode(truncated_tokens) return text ``` For the latest documentation and updates, visit the LangChain Documentation and GitHub Repository .","title":"LangChain"},{"location":"python/langchain/#langchain","text":"LangChain is a framework for developing applications powered by Large Language Models (LLMs). It simplifies the entire LLM application lifecycle with open-source components, third-party integrations, and tools for building complex AI workflows.","title":"LangChain"},{"location":"python/langchain/#installation","text":"# Core LangChain library pip install langchain # Specific integrations pip install langchain-openai # OpenAI models pip install langchain-anthropic # Claude models pip install langchain-community # Community integrations pip install langchain-experimental # Experimental features # Vector stores pip install langchain-chroma # ChromaDB pip install langchain-pinecone # Pinecone pip install faiss-cpu # FAISS # All common packages pip install langchain[all] # Development installation git clone https://github.com/langchain-ai/langchain.git cd langchain pip install -e .[all]","title":"Installation"},{"location":"python/langchain/#quick-start","text":"from langchain_openai import ChatOpenAI from langchain_core.prompts import ChatPromptTemplate from langchain_core.output_parsers import StrOutputParser # Initialize LLM llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0) # Create prompt template prompt = ChatPromptTemplate.from_messages([ (\"system\", \"You are a helpful assistant.\"), (\"human\", \"{input}\") ]) # Create chain using LCEL (LangChain Expression Language) chain = prompt | llm | StrOutputParser() # Invoke the chain result = chain.invoke({\"input\": \"What is LangChain?\"}) print(result)","title":"Quick Start"},{"location":"python/langchain/#core-concepts","text":"","title":"Core Concepts"},{"location":"python/langchain/#1-langchain-expression-language-lcel","text":"from langchain_core.prompts import ChatPromptTemplate from langchain_openai import ChatOpenAI from langchain_core.output_parsers import StrOutputParser # Basic chain composition prompt = ChatPromptTemplate.from_template(\"Tell me a joke about {topic}\") model = ChatOpenAI() output_parser = StrOutputParser() # Chain components with | operator chain = prompt | model | output_parser # Invoke chain result = chain.invoke({\"topic\": \"programming\"}) # Batch processing results = chain.batch([ {\"topic\": \"cats\"}, {\"topic\": \"dogs\"} ]) # Streaming for chunk in chain.stream({\"topic\": \"AI\"}): print(chunk, end=\"\", flush=True) # Async support import asyncio async_result = await chain.ainvoke({\"topic\": \"python\"})","title":"1. LangChain Expression Language (LCEL)"},{"location":"python/langchain/#2-prompts-and-templates","text":"from langchain_core.prompts import ChatPromptTemplate, PromptTemplate from langchain_core.prompts import FewShotPromptTemplate # Basic prompt template prompt = PromptTemplate( input_variables=[\"product\"], template=\"What is a good name for a company that makes {product}?\" ) # Chat prompt template chat_prompt = ChatPromptTemplate.from_messages([ (\"system\", \"You are a helpful assistant that translates {input_language} to {output_language}.\"), (\"human\", \"{text}\") ]) # Few-shot prompting examples = [ {\"input\": \"happy\", \"output\": \"sad\"}, {\"input\": \"tall\", \"output\": \"short\"}, ] example_prompt = PromptTemplate( input_variables=[\"input\", \"output\"], template=\"Input: {input}\\nOutput: {output}\" ) few_shot_prompt = FewShotPromptTemplate( examples=examples, example_prompt=example_prompt, prefix=\"Give the antonym of every input\", suffix=\"Input: {adjective}\\nOutput:\", input_variables=[\"adjective\"] ) # Partial prompts partial_prompt = prompt.partial(product=\"smartphones\") result = partial_prompt.format() # Prompt composition final_prompt = ChatPromptTemplate.from_messages([ (\"system\", \"You are a helpful assistant.\"), chat_prompt, (\"human\", \"Please also explain why this translation is correct.\") ])","title":"2. Prompts and Templates"},{"location":"python/langchain/#3-llm-integration","text":"from langchain_openai import ChatOpenAI, OpenAI from langchain_anthropic import ChatAnthropic from langchain_community.llms import Ollama # OpenAI models openai_chat = ChatOpenAI( model=\"gpt-4o\", temperature=0.7, max_tokens=1000, api_key=\"your-api-key\" ) # Anthropic Claude anthropic = ChatAnthropic( model=\"claude-3-5-sonnet-20241022\", temperature=0, max_tokens=1000 ) # Local Ollama models ollama = Ollama( model=\"llama2\", base_url=\"http://localhost:11434\" ) # Model with callbacks for monitoring from langchain_core.callbacks import BaseCallbackHandler class TokenCountCallback(BaseCallbackHandler): def __init__(self): self.total_tokens = 0 def on_llm_end(self, response, **kwargs): if hasattr(response, 'llm_output') and 'token_usage' in response.llm_output: self.total_tokens += response.llm_output['token_usage']['total_tokens'] callback = TokenCountCallback() llm_with_callback = ChatOpenAI(callbacks=[callback])","title":"3. LLM Integration"},{"location":"python/langchain/#common-patterns","text":"","title":"Common Patterns"},{"location":"python/langchain/#1-sequential-chains","text":"from langchain.chains import LLMChain, SimpleSequentialChain from langchain_core.prompts import PromptTemplate # First chain: generate synopsis synopsis_template = \"\"\"You are a playwright. Given the title of play, it is your job to write a synopsis for that title. Title: {title} Playwright: This is a synopsis for the above play:\"\"\" synopsis_prompt = PromptTemplate( input_variables=[\"title\"], template=synopsis_template ) synopsis_chain = LLMChain(llm=llm, prompt=synopsis_prompt) # Second chain: write review review_template = \"\"\"You are a play critic from the New York Times. Given the synopsis of play, it is your job to write a review for that play. Synopsis: {synopsis} Review from a New York Times play critic of the above play:\"\"\" review_prompt = PromptTemplate( input_variables=[\"synopsis\"], template=review_template ) review_chain = LLMChain(llm=llm, prompt=review_prompt) # Combine chains overall_chain = SimpleSequentialChain( chains=[synopsis_chain, review_chain], verbose=True ) # Run the chain review = overall_chain.invoke({\"input\": \"Tragedy at sunset on the beach\"})","title":"1. Sequential Chains"},{"location":"python/langchain/#2-parallel-processing","text":"from langchain_core.runnables import RunnableParallel, RunnablePassthrough # Define parallel tasks joke_chain = ChatPromptTemplate.from_template(\"tell me a joke about {topic}\") | model | StrOutputParser() poem_chain = ChatPromptTemplate.from_template(\"write a short poem about {topic}\") | model | StrOutputParser() # Run in parallel parallel_chain = RunnableParallel({ \"joke\": joke_chain, \"poem\": poem_chain, \"original_topic\": RunnablePassthrough() }) result = parallel_chain.invoke({\"topic\": \"artificial intelligence\"}) print(result[\"joke\"]) print(result[\"poem\"]) print(result[\"original_topic\"])","title":"2. Parallel Processing"},{"location":"python/langchain/#3-conditional-logic-and-routing","text":"from langchain_core.runnables import RunnableBranch def route_question(info): if \"math\" in info[\"question\"].lower(): return math_chain elif \"history\" in info[\"question\"].lower(): return history_chain else: return general_chain # Math chain math_chain = ChatPromptTemplate.from_template( \"You are a math expert. Answer this question: {question}\" ) | model | StrOutputParser() # History chain history_chain = ChatPromptTemplate.from_template( \"You are a history expert. Answer this question: {question}\" ) | model | StrOutputParser() # General chain general_chain = ChatPromptTemplate.from_template( \"Answer this question: {question}\" ) | model | StrOutputParser() # Route based on question content routing_chain = RunnableBranch( (lambda x: \"math\" in x[\"question\"].lower(), math_chain), (lambda x: \"history\" in x[\"question\"].lower(), history_chain), general_chain # default ) result = routing_chain.invoke({\"question\": \"What is 2+2?\"})","title":"3. Conditional Logic and Routing"},{"location":"python/langchain/#memory-management","text":"","title":"Memory Management"},{"location":"python/langchain/#1-conversation-buffer-memory","text":"from langchain.memory import ConversationBufferMemory from langchain.chains import ConversationChain # Basic conversation memory memory = ConversationBufferMemory() conversation = ConversationChain( llm=llm, memory=memory, verbose=True ) # Have a conversation response1 = conversation.invoke({\"input\": \"Hi, I'm John\"}) response2 = conversation.invoke({\"input\": \"What's my name?\"}) # Access memory print(memory.buffer) print(memory.chat_memory.messages)","title":"1. Conversation Buffer Memory"},{"location":"python/langchain/#2-conversation-summary-memory","text":"from langchain.memory import ConversationSummaryMemory # Memory that summarizes conversation summary_memory = ConversationSummaryMemory( llm=llm, return_messages=True ) conversation_with_summary = ConversationChain( llm=llm, memory=summary_memory, verbose=True ) # Long conversation will be summarized for i in range(5): response = conversation_with_summary.invoke({ \"input\": f\"Tell me a fact about number {i}\" })","title":"2. Conversation Summary Memory"},{"location":"python/langchain/#3-conversation-buffer-window-memory","text":"from langchain.memory import ConversationBufferWindowMemory # Keep only last k interactions window_memory = ConversationBufferWindowMemory( k=3, # Keep last 3 exchanges return_messages=True ) windowed_conversation = ConversationChain( llm=llm, memory=window_memory )","title":"3. Conversation Buffer Window Memory"},{"location":"python/langchain/#4-custom-memory-with-lcel","text":"from langchain_core.runnables import RunnablePassthrough, RunnableLambda from langchain_core.messages import BaseMessage from typing import List # Custom memory implementation class CustomMemory: def __init__(self): self.messages: List[BaseMessage] = [] def add_message(self, message: BaseMessage): self.messages.append(message) def get_context(self) -> str: return \"\\n\".join([f\"{msg.type}: {msg.content}\" for msg in self.messages[-6:]]) memory = CustomMemory() # Chain with custom memory def add_memory(inputs): # Add user input to memory memory.add_message(HumanMessage(content=inputs[\"input\"])) inputs[\"chat_history\"] = memory.get_context() return inputs def save_response(response): # Save AI response to memory memory.add_message(AIMessage(content=response.content)) return response chat_with_memory = ( RunnableLambda(add_memory) | ChatPromptTemplate.from_messages([ (\"system\", \"You are a helpful assistant. Here's the chat history:\\n{chat_history}\"), (\"human\", \"{input}\") ]) | model | RunnableLambda(save_response) | StrOutputParser() )","title":"4. Custom Memory with LCEL"},{"location":"python/langchain/#document-loading-and-processing","text":"","title":"Document Loading and Processing"},{"location":"python/langchain/#1-document-loaders","text":"from langchain_community.document_loaders import ( TextLoader, PDFLoader, WebBaseLoader, DirectoryLoader, CSVLoader, UnstructuredHTMLLoader ) # Text files text_loader = TextLoader(\"path/to/file.txt\") docs = text_loader.load() # PDF files pdf_loader = PDFLoader(\"path/to/document.pdf\") pdf_docs = pdf_loader.load() # Web pages web_loader = WebBaseLoader(\"https://example.com\") web_docs = web_loader.load() # Directory of files directory_loader = DirectoryLoader( \"path/to/directory\", glob=\"**/*.txt\", loader_cls=TextLoader ) all_docs = directory_loader.load() # CSV files csv_loader = CSVLoader(\"path/to/data.csv\") csv_docs = csv_loader.load() # Custom loader from langchain_core.documents import Document def custom_loader(file_path: str) -> List[Document]: # Custom loading logic with open(file_path, 'r') as f: content = f.read() return [Document( page_content=content, metadata={\"source\": file_path, \"custom_field\": \"value\"} )]","title":"1. Document Loaders"},{"location":"python/langchain/#2-text-splitting","text":"from langchain.text_splitter import ( CharacterTextSplitter, RecursiveCharacterTextSplitter, TokenTextSplitter, MarkdownHeaderTextSplitter ) # Character-based splitting char_splitter = CharacterTextSplitter( separator=\"\\n\\n\", chunk_size=1000, chunk_overlap=200 ) char_chunks = char_splitter.split_documents(docs) # Recursive character splitting (recommended) recursive_splitter = RecursiveCharacterTextSplitter( chunk_size=1000, chunk_overlap=200, separators=[\"\\n\\n\", \"\\n\", \" \", \"\"] ) recursive_chunks = recursive_splitter.split_documents(docs) # Token-based splitting token_splitter = TokenTextSplitter( chunk_size=512, chunk_overlap=50 ) token_chunks = token_splitter.split_documents(docs) # Markdown-aware splitting markdown_splitter = MarkdownHeaderTextSplitter( headers_to_split_on=[ (\"#\", \"Header 1\"), (\"##\", \"Header 2\"), (\"###\", \"Header 3\"), ] ) markdown_chunks = markdown_splitter.split_text(markdown_text) # Custom splitter from langchain.text_splitter import TextSplitter class CustomSplitter(TextSplitter): def split_text(self, text: str) -> List[str]: # Custom splitting logic return text.split(\"---\") # Split on custom separator custom_splitter = CustomSplitter() custom_chunks = custom_splitter.split_documents(docs)","title":"2. Text Splitting"},{"location":"python/langchain/#vector-stores-and-embeddings","text":"","title":"Vector Stores and Embeddings"},{"location":"python/langchain/#1-embeddings","text":"from langchain_openai import OpenAIEmbeddings from langchain_community.embeddings import HuggingFaceEmbeddings, OllamaEmbeddings # OpenAI embeddings openai_embeddings = OpenAIEmbeddings( model=\"text-embedding-3-small\" ) # Hugging Face embeddings hf_embeddings = HuggingFaceEmbeddings( model_name=\"sentence-transformers/all-MiniLM-L6-v2\" ) # Local Ollama embeddings ollama_embeddings = OllamaEmbeddings( model=\"llama2\", base_url=\"http://localhost:11434\" ) # Test embeddings text = \"This is a test document\" embedding_vector = openai_embeddings.embed_query(text) print(f\"Embedding dimension: {len(embedding_vector)}\") # Batch embeddings texts = [\"Document 1\", \"Document 2\", \"Document 3\"] batch_embeddings = openai_embeddings.embed_documents(texts)","title":"1. Embeddings"},{"location":"python/langchain/#2-vector-store-operations","text":"from langchain_community.vectorstores import Chroma, FAISS, Pinecone from langchain_core.documents import Document # Create documents docs = [ Document(page_content=\"The sky is blue\", metadata={\"source\": \"fact1\"}), Document(page_content=\"Grass is green\", metadata={\"source\": \"fact2\"}), Document(page_content=\"Fire is hot\", metadata={\"source\": \"fact3\"}), ] # ChromaDB vector store chroma_db = Chroma.from_documents( documents=docs, embedding=openai_embeddings, persist_directory=\"./chroma_db\" ) # FAISS vector store (in-memory) faiss_db = FAISS.from_documents( documents=docs, embedding=openai_embeddings ) # Save/load FAISS faiss_db.save_local(\"./faiss_index\") loaded_faiss = FAISS.load_local(\"./faiss_index\", openai_embeddings) # Pinecone vector store import pinecone pinecone.init(api_key=\"your-api-key\", environment=\"your-env\") pinecone_db = Pinecone.from_documents( documents=docs, embedding=openai_embeddings, index_name=\"your-index\" ) # Search operations query = \"What color is the sky?\" similar_docs = chroma_db.similarity_search(query, k=2) # Search with scores docs_with_scores = chroma_db.similarity_search_with_score(query, k=2) for doc, score in docs_with_scores: print(f\"Score: {score}, Content: {doc.page_content}\") # Filtered search filtered_docs = chroma_db.similarity_search( query, k=2, filter={\"source\": \"fact1\"} ) # Add more documents new_docs = [Document(page_content=\"Water is wet\", metadata={\"source\": \"fact4\"})] chroma_db.add_documents(new_docs) # Delete documents chroma_db.delete(ids=[\"doc_id_to_delete\"])","title":"2. Vector Store Operations"},{"location":"python/langchain/#retrieval-augmented-generation-rag","text":"","title":"Retrieval-Augmented Generation (RAG)"},{"location":"python/langchain/#1-basic-rag-chain","text":"from langchain.chains import RetrievalQA from langchain_core.runnables import RunnablePassthrough from langchain_core.prompts import ChatPromptTemplate # Set up vector store as retriever retriever = chroma_db.as_retriever( search_type=\"similarity\", search_kwargs={\"k\": 3} ) # Traditional approach with RetrievalQA qa_chain = RetrievalQA.from_chain_type( llm=llm, chain_type=\"stuff\", retriever=retriever, return_source_documents=True ) result = qa_chain.invoke({\"query\": \"What is the color of the sky?\"}) print(result[\"result\"]) print(result[\"source_documents\"]) # Modern approach with LCEL def format_docs(docs): return \"\\n\\n\".join(doc.page_content for doc in docs) rag_template = \"\"\"Answer the question based only on the following context: {context} Question: {question} Answer:\"\"\" rag_prompt = ChatPromptTemplate.from_template(rag_template) rag_chain = ( {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()} | rag_prompt | llm | StrOutputParser() ) answer = rag_chain.invoke(\"What is the color of the sky?\")","title":"1. Basic RAG Chain"},{"location":"python/langchain/#2-advanced-rag-with-multiple-retrievers","text":"from langchain.retrievers import EnsembleRetriever, MultiQueryRetriever from langchain_community.retrievers import BM25Retriever # BM25 retriever (keyword-based) texts = [doc.page_content for doc in docs] bm25_retriever = BM25Retriever.from_texts(texts) # Ensemble retriever (combines multiple retrievers) ensemble_retriever = EnsembleRetriever( retrievers=[chroma_db.as_retriever(), bm25_retriever], weights=[0.7, 0.3] # Weight vector search more than keyword search ) # Multi-query retriever (generates multiple queries) multi_query_retriever = MultiQueryRetriever.from_llm( retriever=chroma_db.as_retriever(), llm=llm ) # Use with RAG chain advanced_rag_chain = ( {\"context\": ensemble_retriever | format_docs, \"question\": RunnablePassthrough()} | rag_prompt | llm | StrOutputParser() )","title":"2. Advanced RAG with Multiple Retrievers"},{"location":"python/langchain/#3-rag-with-chat-history","text":"from langchain.chains import create_history_aware_retriever, create_retrieval_chain from langchain.chains.combine_documents import create_stuff_documents_chain # Contextualized retrieval contextualize_q_system_prompt = \"\"\"Given a chat history and the latest user question \\ which might reference context in the chat history, formulate a standalone question \\ which can be understood without the chat history. Do NOT answer the question, \\ just reformulate it if needed and otherwise return it as is.\"\"\" contextualize_q_prompt = ChatPromptTemplate.from_messages([ (\"system\", contextualize_q_system_prompt), MessagesPlaceholder(\"chat_history\"), (\"human\", \"{input}\"), ]) history_aware_retriever = create_history_aware_retriever( llm, retriever, contextualize_q_prompt ) # Answer generation qa_system_prompt = \"\"\"You are an assistant for question-answering tasks. \\ Use the following pieces of retrieved context to answer the question. \\ If you don't know the answer, just say that you don't know. {context}\"\"\" qa_prompt = ChatPromptTemplate.from_messages([ (\"system\", qa_system_prompt), MessagesPlaceholder(\"chat_history\"), (\"human\", \"{input}\"), ]) question_answer_chain = create_stuff_documents_chain(llm, qa_prompt) # Full RAG chain with history rag_chain_with_history = create_retrieval_chain( history_aware_retriever, question_answer_chain ) # Usage with session history from langchain_community.chat_message_histories import ChatMessageHistory from langchain_core.chat_history import BaseChatMessageHistory store = {} def get_session_history(session_id: str) -> BaseChatMessageHistory: if session_id not in store: store[session_id] = ChatMessageHistory() return store[session_id] conversational_rag_chain = RunnableWithMessageHistory( rag_chain_with_history, get_session_history, input_messages_key=\"input\", history_messages_key=\"chat_history\", output_messages_key=\"answer\", ) # Chat with history response = conversational_rag_chain.invoke( {\"input\": \"What is the sky color?\"}, config={\"configurable\": {\"session_id\": \"session_1\"}}, ) follow_up = conversational_rag_chain.invoke( {\"input\": \"Why is that?\"}, # References previous question config={\"configurable\": {\"session_id\": \"session_1\"}}, )","title":"3. RAG with Chat History"},{"location":"python/langchain/#agents-and-tool-usage","text":"","title":"Agents and Tool Usage"},{"location":"python/langchain/#1-basic-agent-setup","text":"from langchain.agents import create_openai_tools_agent, AgentExecutor from langchain_community.tools import WikipediaQueryRun, DuckDuckGoSearchRun from langchain_community.utilities import WikipediaAPIWrapper from langchain.tools import BaseTool from typing import Type # Define tools wikipedia = WikipediaQueryRun(api_wrapper=WikipediaAPIWrapper()) search = DuckDuckGoSearchRun() # Custom tool class CalculatorTool(BaseTool): name = \"calculator\" description = \"Useful for mathematical calculations\" def _run(self, query: str) -> str: try: return str(eval(query)) # Be careful with eval in production except Exception as e: return f\"Error: {str(e)}\" calculator = CalculatorTool() # Available tools tools = [wikipedia, search, calculator] # Create agent agent_prompt = ChatPromptTemplate.from_messages([ (\"system\", \"You are a helpful assistant. Use tools when needed.\"), (\"human\", \"{input}\"), MessagesPlaceholder(variable_name=\"agent_scratchpad\"), ]) agent = create_openai_tools_agent(llm, tools, agent_prompt) agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True) # Use agent result = agent_executor.invoke({ \"input\": \"What is the population of Tokyo? Then calculate 10% of that number.\" })","title":"1. Basic Agent Setup"},{"location":"python/langchain/#2-custom-tools","text":"from langchain.tools import tool from langchain.pydantic_v1 import BaseModel, Field import requests # Decorator-based tool @tool def get_weather(city: str) -> str: \"\"\"Get current weather for a given city.\"\"\" # Mock weather API call return f\"The weather in {city} is sunny and 75\u00b0F\" # Class-based tool with input schema class WeatherInput(BaseModel): city: str = Field(description=\"The city to get weather for\") units: str = Field(default=\"fahrenheit\", description=\"Temperature units\") class WeatherTool(BaseTool): name = \"weather_tool\" description = \"Get current weather information\" args_schema: Type[BaseModel] = WeatherInput def _run(self, city: str, units: str = \"fahrenheit\") -> str: # Weather API integration return f\"Weather in {city}: 72\u00b0{units[0].upper()}, partly cloudy\" # API-based tool @tool def search_api(query: str) -> str: \"\"\"Search the web using a custom API.\"\"\" # Example API call response = requests.get( \"https://api.example.com/search\", params={\"q\": query}, headers={\"Authorization\": \"Bearer your-token\"} ) return response.json().get(\"results\", \"No results found\") # File system tool @tool def read_file(file_path: str) -> str: \"\"\"Read contents of a file.\"\"\" try: with open(file_path, 'r') as f: return f.read() except Exception as e: return f\"Error reading file: {str(e)}\" # Database tool @tool def query_database(sql_query: str) -> str: \"\"\"Execute SQL query on database.\"\"\" import sqlite3 conn = sqlite3.connect(\"example.db\") cursor = conn.cursor() try: cursor.execute(sql_query) results = cursor.fetchall() conn.close() return str(results) except Exception as e: conn.close() return f\"Database error: {str(e)}\"","title":"2. Custom Tools"},{"location":"python/langchain/#3-agent-types-and-strategies","text":"from langchain.agents import create_react_agent, create_structured_chat_agent # ReAct agent (Reasoning and Acting) react_prompt = \"\"\"Answer the following questions as best you can. You have access to the following tools: {tools} Use the following format: Question: the input question you must answer Thought: you should always think about what to do Action: the action to take, should be one of [{tool_names}] Action Input: the input to the action Observation: the result of the action ... (this Thought/Action/Action Input/Observation can repeat N times) Thought: I now know the final answer Final Answer: the final answer to the original input question Begin! Question: {input} Thought:{agent_scratchpad}\"\"\" react_agent = create_react_agent(llm, tools, react_prompt) react_executor = AgentExecutor( agent=react_agent, tools=tools, verbose=True, max_iterations=5 ) # Structured chat agent structured_agent = create_structured_chat_agent( llm=llm, tools=tools, prompt=agent_prompt ) structured_executor = AgentExecutor( agent=structured_agent, tools=tools, verbose=True, handle_parsing_errors=True ) # Custom agent with error handling class CustomAgentExecutor(AgentExecutor): def _handle_error(self, error: Exception) -> str: return f\"I encountered an error: {str(error)}. Let me try a different approach.\" custom_executor = CustomAgentExecutor( agent=agent, tools=tools, verbose=True, max_iterations=3, early_stopping_method=\"generate\" )","title":"3. Agent Types and Strategies"},{"location":"python/langchain/#output-parsing","text":"","title":"Output Parsing"},{"location":"python/langchain/#1-built-in-parsers","text":"from langchain_core.output_parsers import ( StrOutputParser, JsonOutputParser, ListOutputParser, CommaSeparatedListOutputParser, DatetimeOutputParser ) from langchain_core.pydantic_v1 import BaseModel, Field # String parser (default) str_parser = StrOutputParser() # JSON parser json_parser = JsonOutputParser() # List parser list_parser = ListOutputParser() # Comma-separated list parser csv_parser = CommaSeparatedListOutputParser() # Datetime parser datetime_parser = DatetimeOutputParser() # Usage with chains json_chain = ( ChatPromptTemplate.from_template( \"Generate a JSON object with name and age for a person named {name}\" ) | llm | json_parser ) result = json_chain.invoke({\"name\": \"Alice\"})","title":"1. Built-in Parsers"},{"location":"python/langchain/#2-pydantic-parser","text":"from langchain.output_parsers import PydanticOutputParser from pydantic import BaseModel, Field from typing import List # Define data model class Person(BaseModel): name: str = Field(description=\"person's name\") age: int = Field(description=\"person's age\") occupation: str = Field(description=\"person's job\") skills: List[str] = Field(description=\"list of skills\") # Create parser person_parser = PydanticOutputParser(pydantic_object=Person) # Create prompt with format instructions person_prompt = ChatPromptTemplate.from_messages([ (\"system\", \"Extract person information from the following text.\"), (\"human\", \"{text}\\n{format_instructions}\"), ]) # Chain with structured output person_chain = ( person_prompt.partial(format_instructions=person_parser.get_format_instructions()) | llm | person_parser ) # Usage text = \"John Doe is a 30-year-old software engineer who knows Python, JavaScript, and SQL.\" structured_data = person_chain.invoke({\"text\": text}) print(f\"Name: {structured_data.name}\") print(f\"Skills: {structured_data.skills}\")","title":"2. Pydantic Parser"},{"location":"python/langchain/#3-custom-output-parsers","text":"from langchain_core.output_parsers import BaseOutputParser from typing import Dict, Any import re class CustomEmailParser(BaseOutputParser[Dict[str, Any]]): \"\"\"Parse email components from LLM output.\"\"\" def parse(self, text: str) -> Dict[str, Any]: # Extract email components using regex subject_match = re.search(r'Subject:\\s*(.*)', text) body_match = re.search(r'Body:\\s*(.*?)(?=\\n\\n|\\Z)', text, re.DOTALL) recipient_match = re.search(r'To:\\s*(.*)', text) return { \"subject\": subject_match.group(1) if subject_match else \"\", \"body\": body_match.group(1).strip() if body_match else \"\", \"recipient\": recipient_match.group(1) if recipient_match else \"\" } @property def _type(self) -> str: return \"custom_email_parser\" # Usage email_parser = CustomEmailParser() email_prompt = ChatPromptTemplate.from_template( \"\"\"Write a professional email with the following format: Subject: [subject line] To: [recipient email] Body: [email content] Topic: {topic} Recipient: {recipient}\"\"\" ) email_chain = email_prompt | llm | email_parser parsed_email = email_chain.invoke({ \"topic\": \"Meeting followup\", \"recipient\": \"john@example.com\" }) print(parsed_email)","title":"3. Custom Output Parsers"},{"location":"python/langchain/#advanced-features","text":"","title":"Advanced Features"},{"location":"python/langchain/#1-callbacks-and-monitoring","text":"from langchain_core.callbacks import BaseCallbackHandler from langchain_core.callbacks import CallbackManager import time class TimingCallback(BaseCallbackHandler): def __init__(self): self.start_time = None self.end_time = None def on_chain_start(self, serialized, inputs, **kwargs): self.start_time = time.time() print(f\"Chain started with inputs: {inputs}\") def on_chain_end(self, outputs, **kwargs): self.end_time = time.time() duration = self.end_time - self.start_time print(f\"Chain completed in {duration:.2f} seconds\") def on_llm_start(self, serialized, prompts, **kwargs): print(f\"LLM called with prompts: {prompts}\") def on_llm_end(self, response, **kwargs): if hasattr(response, 'llm_output') and response.llm_output: token_usage = response.llm_output.get('token_usage', {}) print(f\"Token usage: {token_usage}\") # Use callback timing_callback = TimingCallback() callback_manager = CallbackManager([timing_callback]) chain_with_callbacks = ( prompt | llm.with_config(callbacks=[timing_callback]) | StrOutputParser() ) result = chain_with_callbacks.invoke({\"input\": \"Hello, world!\"})","title":"1. Callbacks and Monitoring"},{"location":"python/langchain/#2-streaming-and-async-operations","text":"import asyncio from langchain_core.callbacks import AsyncCallbackHandler # Streaming responses def stream_response(chain, input_data): for chunk in chain.stream(input_data): print(chunk, end=\"\", flush=True) # Async operations async def async_chain_example(): async_llm = ChatOpenAI(temperature=0) async_chain = prompt | async_llm | StrOutputParser() # Async invoke result = await async_chain.ainvoke({\"input\": \"Hello async world!\"}) print(result) # Async streaming async for chunk in async_chain.astream({\"input\": \"Stream this async\"}): print(chunk, end=\"\", flush=True) # Async batch processing batch_results = await async_chain.abatch([ {\"input\": \"First query\"}, {\"input\": \"Second query\"}, {\"input\": \"Third query\"} ]) return batch_results # Run async example # results = asyncio.run(async_chain_example()) # Async callback class AsyncTimingCallback(AsyncCallbackHandler): async def on_chain_start(self, serialized, inputs, **kwargs): print(f\"Async chain started: {inputs}\") async def on_chain_end(self, outputs, **kwargs): print(f\"Async chain completed: {outputs}\")","title":"2. Streaming and Async Operations"},{"location":"python/langchain/#3-configuration-and-environment-management","text":"from langchain_core.runnables import RunnableConfig import os from dotenv import load_dotenv # Load environment variables load_dotenv() # Configuration management config = RunnableConfig( tags=[\"production\", \"chat\"], metadata={\"user_id\": \"123\", \"session_id\": \"abc\"}, recursion_limit=10 ) # Chain with config result = chain.invoke( {\"input\": \"Hello\"}, config=config ) # Environment-specific setup class EnvironmentConfig: def __init__(self, env: str = \"development\"): self.env = env if env == \"production\": self.llm_model = \"gpt-4\" self.temperature = 0.1 self.max_tokens = 1000 else: self.llm_model = \"gpt-3.5-turbo\" self.temperature = 0.7 self.max_tokens = 500 def get_llm(self): return ChatOpenAI( model=self.llm_model, temperature=self.temperature, max_tokens=self.max_tokens ) # Usage env_config = EnvironmentConfig(\"production\") production_llm = env_config.get_llm()","title":"3. Configuration and Environment Management"},{"location":"python/langchain/#4-custom-chain-classes","text":"from langchain_core.runnables import Runnable from typing import Dict, Any class CustomProcessingChain(Runnable): \"\"\"Custom chain with preprocessing and postprocessing.\"\"\" def __init__(self, llm, preprocessor=None, postprocessor=None): self.llm = llm self.preprocessor = preprocessor or self._default_preprocess self.postprocessor = postprocessor or self._default_postprocess def _default_preprocess(self, input_data: Dict[str, Any]) -> Dict[str, Any]: # Default preprocessing if \"text\" in input_data: input_data[\"text\"] = input_data[\"text\"].strip().lower() return input_data def _default_postprocess(self, output: str) -> str: # Default postprocessing return output.strip().capitalize() def invoke(self, input_data: Dict[str, Any], config=None) -> str: # Preprocess processed_input = self.preprocessor(input_data) # LLM call prompt = ChatPromptTemplate.from_template(\"Process this text: {text}\") chain = prompt | self.llm | StrOutputParser() result = chain.invoke(processed_input, config=config) # Postprocess final_result = self.postprocessor(result) return final_result # Custom preprocessing/postprocessing functions def custom_preprocessor(data): data[\"text\"] = f\"IMPORTANT: {data['text']}\" return data def custom_postprocessor(output): return f\"[PROCESSED] {output}\" # Usage custom_chain = CustomProcessingChain( llm=llm, preprocessor=custom_preprocessor, postprocessor=custom_postprocessor ) result = custom_chain.invoke({\"text\": \"hello world\"})","title":"4. Custom Chain Classes"},{"location":"python/langchain/#integration-examples","text":"","title":"Integration Examples"},{"location":"python/langchain/#1-fastapi-web-service","text":"from fastapi import FastAPI, HTTPException from pydantic import BaseModel from typing import List, Optional app = FastAPI() class ChatRequest(BaseModel): message: str session_id: Optional[str] = None class ChatResponse(BaseModel): response: str session_id: str # Initialize chain chat_chain = prompt | llm | StrOutputParser() @app.post(\"/chat\", response_model=ChatResponse) async def chat_endpoint(request: ChatRequest): try: response = await chat_chain.ainvoke({\"input\": request.message}) return ChatResponse( response=response, session_id=request.session_id or \"default\" ) except Exception as e: raise HTTPException(status_code=500, detail=str(e)) @app.get(\"/health\") async def health_check(): return {\"status\": \"healthy\"} # Run with: uvicorn main:app --reload","title":"1. FastAPI Web Service"},{"location":"python/langchain/#2-streamlit-chat-interface","text":"import streamlit as st from langchain_core.messages import HumanMessage, AIMessage # Initialize session state if \"messages\" not in st.session_state: st.session_state.messages = [] if \"chain\" not in st.session_state: st.session_state.chain = prompt | llm | StrOutputParser() st.title(\"LangChain Chatbot\") # Display chat history for message in st.session_state.messages: if isinstance(message, HumanMessage): with st.chat_message(\"user\"): st.write(message.content) else: with st.chat_message(\"assistant\"): st.write(message.content) # Chat input if user_input := st.chat_input(\"Type your message...\"): # Add user message st.session_state.messages.append(HumanMessage(content=user_input)) # Display user message with st.chat_message(\"user\"): st.write(user_input) # Get AI response with st.chat_message(\"assistant\"): with st.spinner(\"Thinking...\"): response = st.session_state.chain.invoke({\"input\": user_input}) st.write(response) st.session_state.messages.append(AIMessage(content=response))","title":"2. Streamlit Chat Interface"},{"location":"python/langchain/#3-gradio-interface","text":"import gradio as gr def chat_interface(message, history): # Convert history to proper format context = \"\\n\".join([f\"Human: {h[0]}\\nAssistant: {h[1]}\" for h in history]) # Add current message full_prompt = f\"{context}\\nHuman: {message}\\nAssistant:\" # Get response response = chain.invoke({\"input\": full_prompt}) return response # Create Gradio interface demo = gr.ChatInterface( fn=chat_interface, title=\"LangChain Chat\", description=\"Chat with LangChain-powered AI assistant\" ) # Launch interface if __name__ == \"__main__\": demo.launch(share=True)","title":"3. Gradio Interface"},{"location":"python/langchain/#performance-optimization","text":"","title":"Performance Optimization"},{"location":"python/langchain/#1-caching","text":"from langchain.cache import InMemoryCache, SQLiteCache from langchain.globals import set_llm_cache # In-memory caching set_llm_cache(InMemoryCache()) # SQLite caching (persistent) set_llm_cache(SQLiteCache(database_path=\".langchain.db\")) # Redis caching from langchain.cache import RedisCache import redis redis_client = redis.Redis(host='localhost', port=6379, db=0) set_llm_cache(RedisCache(redis_client)) # Custom cache from langchain_core.caches import BaseCache class CustomCache(BaseCache): def __init__(self): self._cache = {} def lookup(self, prompt, llm_string): return self._cache.get((prompt, llm_string)) def update(self, prompt, llm_string, return_val): self._cache[(prompt, llm_string)] = return_val set_llm_cache(CustomCache())","title":"1. Caching"},{"location":"python/langchain/#2-batch-processing","text":"# Batch LLM calls batch_prompts = [ {\"input\": f\"Summarize topic {i}\"} for i in range(10) ] # Sequential processing results = [] for prompt in batch_prompts: result = chain.invoke(prompt) results.append(result) # Parallel batch processing batch_results = chain.batch(batch_prompts, config={\"max_concurrency\": 5}) # Async batch processing async def async_batch_processing(): return await chain.abatch(batch_prompts) # Streaming batch for result in chain.batch(batch_prompts): print(f\"Completed: {result}\")","title":"2. Batch Processing"},{"location":"python/langchain/#3-memory-management","text":"# Efficient memory usage from langchain.memory import ConversationSummaryBufferMemory # Summary + buffer memory (hybrid approach) memory = ConversationSummaryBufferMemory( llm=llm, max_token_limit=1000, return_messages=True ) # Custom memory with cleanup class EfficientMemory: def __init__(self, max_messages=10): self.messages = [] self.max_messages = max_messages def add_message(self, message): self.messages.append(message) if len(self.messages) > self.max_messages: # Keep only recent messages self.messages = self.messages[-self.max_messages:] def clear_old_messages(self): # Keep only last 5 messages self.messages = self.messages[-5:] # Periodic cleanup efficient_memory = EfficientMemory() # Use context managers for cleanup from contextlib import contextmanager @contextmanager def managed_chain(chain): try: yield chain finally: # Cleanup operations if hasattr(chain, 'memory') and chain.memory: chain.memory.clear()","title":"3. Memory Management"},{"location":"python/langchain/#best-practices","text":"","title":"Best Practices"},{"location":"python/langchain/#1-error-handling","text":"from langchain_core.exceptions import LangChainException import logging # Configure logging logging.basicConfig(level=logging.INFO) logger = logging.getLogger(__name__) def robust_chain_invoke(chain, input_data, max_retries=3): \"\"\"Invoke chain with error handling and retries.\"\"\" for attempt in range(max_retries): try: result = chain.invoke(input_data) logger.info(f\"Chain invocation successful on attempt {attempt + 1}\") return result except LangChainException as e: logger.error(f\"LangChain error on attempt {attempt + 1}: {str(e)}\") if attempt == max_retries - 1: raise except Exception as e: logger.error(f\"Unexpected error on attempt {attempt + 1}: {str(e)}\") if attempt == max_retries - 1: raise # Exponential backoff time.sleep(2 ** attempt) # Usage try: result = robust_chain_invoke(chain, {\"input\": \"test\"}) except Exception as e: logger.error(f\"All retry attempts failed: {str(e)}\") # Fallback behavior result = \"I apologize, but I'm having trouble processing your request right now.\"","title":"1. Error Handling"},{"location":"python/langchain/#2-testing","text":"import pytest from unittest.mock import Mock, patch class TestLangChainComponents: @pytest.fixture def mock_llm(self): \"\"\"Mock LLM for testing.\"\"\" mock = Mock() mock.invoke.return_value = \"Mocked response\" return mock @pytest.fixture def sample_chain(self, mock_llm): \"\"\"Sample chain for testing.\"\"\" prompt = ChatPromptTemplate.from_template(\"Test: {input}\") return prompt | mock_llm | StrOutputParser() def test_chain_invoke(self, sample_chain): \"\"\"Test basic chain invocation.\"\"\" result = sample_chain.invoke({\"input\": \"hello\"}) assert result == \"Mocked response\" def test_prompt_formatting(self): \"\"\"Test prompt template formatting.\"\"\" prompt = ChatPromptTemplate.from_template(\"Hello {name}\") formatted = prompt.format(name=\"Alice\") assert \"Alice\" in str(formatted) @patch('langchain_openai.ChatOpenAI') def test_with_real_llm_mock(self, mock_openai): \"\"\"Test with mocked OpenAI client.\"\"\" mock_openai.return_value.invoke.return_value = \"Test response\" llm = ChatOpenAI() result = llm.invoke(\"test prompt\") assert result == \"Test response\" mock_openai.assert_called_once() # Run tests with: pytest test_langchain.py","title":"2. Testing"},{"location":"python/langchain/#3-production-deployment","text":"from langchain_core.runnables import RunnableConfig import os from typing import Dict, Any class ProductionChainWrapper: \"\"\"Production-ready chain wrapper with monitoring and error handling.\"\"\" def __init__(self, chain, environment=\"production\"): self.chain = chain self.environment = environment self.request_count = 0 self.error_count = 0 def invoke(self, input_data: Dict[str, Any]) -> str: \"\"\"Invoke chain with production safeguards.\"\"\" self.request_count += 1 try: # Input validation self._validate_input(input_data) # Rate limiting check if self.request_count > 1000: # Example limit raise Exception(\"Rate limit exceeded\") # Invoke chain with timeout config = RunnableConfig( tags=[self.environment], metadata={\"request_id\": self.request_count} ) result = self.chain.invoke(input_data, config=config) # Output validation self._validate_output(result) return result except Exception as e: self.error_count += 1 logger.error(f\"Chain error: {str(e)}\") # Fallback response return self._get_fallback_response(input_data) def _validate_input(self, input_data: Dict[str, Any]): \"\"\"Validate input data.\"\"\" if not isinstance(input_data, dict): raise ValueError(\"Input must be a dictionary\") if \"input\" not in input_data: raise ValueError(\"Input must contain 'input' key\") if len(input_data[\"input\"]) > 10000: # Character limit raise ValueError(\"Input too long\") def _validate_output(self, output: str): \"\"\"Validate output.\"\"\" if not isinstance(output, str): raise ValueError(\"Output must be a string\") if len(output) == 0: raise ValueError(\"Empty output\") def _get_fallback_response(self, input_data: Dict[str, Any]) -> str: \"\"\"Provide fallback response on error.\"\"\" return \"I apologize, but I'm unable to process your request at the moment.\" def get_metrics(self) -> Dict[str, Any]: \"\"\"Get performance metrics.\"\"\" return { \"request_count\": self.request_count, \"error_count\": self.error_count, \"error_rate\": self.error_count / max(self.request_count, 1), \"environment\": self.environment } # Usage production_chain = ProductionChainWrapper(chain, \"production\") result = production_chain.invoke({\"input\": \"Hello world\"}) metrics = production_chain.get_metrics()","title":"3. Production Deployment"},{"location":"python/langchain/#4-monitoring-and-observability","text":"from langchain_community.callbacks import LangChainTracer from langchain.callbacks.manager import tracing_v2_enabled # LangSmith tracing (if available) os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\" os.environ[\"LANGCHAIN_API_KEY\"] = \"your-langsmith-api-key\" # Use tracing context with tracing_v2_enabled(): result = chain.invoke({\"input\": \"traced request\"}) # Custom monitoring class MonitoringCallback(BaseCallbackHandler): def __init__(self): self.metrics = { \"total_requests\": 0, \"total_tokens\": 0, \"average_response_time\": 0, \"error_count\": 0 } self.start_times = {} def on_chain_start(self, serialized, inputs, run_id, **kwargs): self.metrics[\"total_requests\"] += 1 self.start_times[run_id] = time.time() def on_chain_end(self, outputs, run_id, **kwargs): if run_id in self.start_times: duration = time.time() - self.start_times[run_id] # Update average response time current_avg = self.metrics[\"average_response_time\"] new_avg = ((current_avg * (self.metrics[\"total_requests\"] - 1)) + duration) / self.metrics[\"total_requests\"] self.metrics[\"average_response_time\"] = new_avg del self.start_times[run_id] def on_chain_error(self, error, run_id, **kwargs): self.metrics[\"error_count\"] += 1 if run_id in self.start_times: del self.start_times[run_id] # Use monitoring monitoring = MonitoringCallback() monitored_chain = chain.with_config(callbacks=[monitoring]) # Health check endpoint def health_check(): return { \"status\": \"healthy\", \"metrics\": monitoring.metrics, \"timestamp\": time.time() }","title":"4. Monitoring and Observability"},{"location":"python/langchain/#troubleshooting","text":"","title":"Troubleshooting"},{"location":"python/langchain/#common-issues-and-solutions","text":"API Key Issues ```python # Check environment variables import os print(\"OpenAI API Key:\", \"SET\" if os.getenv(\"OPENAI_API_KEY\") else \"NOT SET\") # Set programmatically os.environ[\"OPENAI_API_KEY\"] = \"your-api-key\" ``` Memory Issues with Large Documents ```python # Use streaming for large documents def process_large_document(doc, chunk_size=1000): chunks = [doc[i:i+chunk_size] for i in range(0, len(doc), chunk_size)] results = [] for chunk in chunks: result = chain.invoke({\"input\": chunk}) results.append(result) return results ``` Rate Limiting ```python import time from tenacity import retry, wait_exponential, stop_after_attempt @retry( wait=wait_exponential(multiplier=1, min=4, max=10), stop=stop_after_attempt(3) ) def invoke_with_retry(chain, input_data): return chain.invoke(input_data) ``` Token Limits ```python import tiktoken def count_tokens(text, model=\"gpt-4\"): encoding = tiktoken.encoding_for_model(model) return len(encoding.encode(text)) def truncate_text(text, max_tokens=4000, model=\"gpt-4\"): encoding = tiktoken.encoding_for_model(model) tokens = encoding.encode(text) if len(tokens) > max_tokens: truncated_tokens = tokens[:max_tokens] return encoding.decode(truncated_tokens) return text ``` For the latest documentation and updates, visit the LangChain Documentation and GitHub Repository .","title":"Common Issues and Solutions"},{"location":"python/langextract/","text":"LangExtract LangExtract is Google's open-source Python library for extracting structured information from unstructured text using Large Language Models (LLMs). It provides precise source grounding, interactive visualizations, and supports multiple model providers. Installation # Basic installation pip install langextract # For development (from source) git clone https://github.com/google/langextract.git cd langextract pip install -e . Quick Start import langextract as lx # Basic extraction result = lx.extract( text_or_documents=\"Your unstructured text here...\", prompt_description=\"Extract names, dates, and locations\", examples=[ {\"input\": \"John visited Paris on May 15th\", \"output\": {\"names\": [\"John\"], \"places\": [\"Paris\"], \"dates\": [\"May 15th\"]}} ], model_id=\"gemini-2.0-flash-exp\" ) # Access results print(result.extractions) print(result.visualize()) # Interactive HTML visualization Core Components 1. Basic Extraction import langextract as lx # Simple extraction with few-shot examples result = lx.extract( text_or_documents=input_text, prompt_description=\"Extract character names and their emotions\", examples=[ { \"input\": \"Alice felt happy about the good news\", \"output\": { \"characters\": [{\"name\": \"Alice\", \"emotion\": \"happy\"}] } } ], model_id=\"gemini-2.0-flash-exp\" ) # Check extraction results for extraction in result.extractions: print(f\"Text: {extraction.text}\") print(f\"Data: {extraction.data}\") print(f\"Source spans: {extraction.source_spans}\") 2. Document Processing # Process multiple documents documents = [ {\"text\": \"Document 1 content...\", \"metadata\": {\"source\": \"doc1.txt\"}}, {\"text\": \"Document 2 content...\", \"metadata\": {\"source\": \"doc2.txt\"}}, ] result = lx.extract( text_or_documents=documents, prompt_description=\"Extract key findings and recommendations\", examples=[...], model_id=\"gemini-2.0-flash-exp\" ) 3. Model Configuration # Using different models result = lx.extract( text_or_documents=text, prompt_description=prompt, examples=examples, model_id=\"gemini-2.0-flash-exp\", # Recommended for speed # model_id=\"gemini-2.0-pro\", # For complex reasoning # model_id=\"gpt-4o-mini\", # OpenAI alternative ) # Configure model parameters result = lx.extract( text_or_documents=text, prompt_description=prompt, examples=examples, model_id=\"gemini-2.0-flash-exp\", generation_config={ \"temperature\": 0.1, \"max_output_tokens\": 8192, \"top_p\": 0.95 } ) Advanced Features 1. Source Grounding & Visualization # Extract with precise source tracking result = lx.extract( text_or_documents=long_text, prompt_description=\"Extract medical conditions and treatments\", examples=[...], model_id=\"gemini-2.0-flash-exp\" ) # Generate interactive visualization html_viz = result.visualize() # Save visualization to file with open(\"extraction_results.html\", \"w\") as f: f.write(html_viz) # Access source spans for each extraction for extraction in result.extractions: for entity in extraction.data.get(\"entities\", []): spans = extraction.source_spans.get(entity[\"id\"], []) print(f\"Entity: {entity['text']} found at positions: {spans}\") 2. Complex Schema Extraction # Define complex extraction schema medical_examples = [ { \"input\": \"Patient John Smith, 45, diagnosed with hypertension. Prescribed lisinopril 10mg daily.\", \"output\": { \"patient\": { \"name\": \"John Smith\", \"age\": 45, \"conditions\": [\"hypertension\"], \"medications\": [ { \"name\": \"lisinopril\", \"dosage\": \"10mg\", \"frequency\": \"daily\" } ] } } } ] result = lx.extract( text_or_documents=medical_report, prompt_description=\"Extract patient information, conditions, and medications\", examples=medical_examples, model_id=\"gemini-2.0-flash-exp\" ) 3. Batch Processing # Process multiple documents efficiently large_document_set = [ {\"text\": doc1_text, \"metadata\": {\"source\": \"report1.pdf\"}}, {\"text\": doc2_text, \"metadata\": {\"source\": \"report2.pdf\"}}, # ... more documents ] # Parallel processing for large datasets result = lx.extract( text_or_documents=large_document_set, prompt_description=\"Extract key metrics and insights\", examples=examples, model_id=\"gemini-2.0-flash-exp\", max_workers=4 # Control parallel processing ) # Process results per document for doc_result in result.extractions: source = doc_result.metadata.get(\"source\", \"unknown\") print(f\"Results from {source}: {doc_result.data}\") 4. Custom Output Parsers # Define custom parsing logic def parse_financial_data(extraction_result): \"\"\"Custom parser for financial documents\"\"\" parsed_data = {} for extraction in extraction_result.extractions: # Custom processing logic parsed_data[extraction.metadata.get(\"source\")] = { \"revenue\": extraction.data.get(\"revenue\"), \"expenses\": extraction.data.get(\"expenses\"), \"profit\": extraction.data.get(\"profit\") } return parsed_data # Use custom parser result = lx.extract( text_or_documents=financial_reports, prompt_description=\"Extract revenue, expenses, and profit figures\", examples=financial_examples, model_id=\"gemini-2.0-flash-exp\" ) parsed_results = parse_financial_data(result) Common Use Cases 1. Medical Report Processing medical_examples = [ { \"input\": \"Patient presents with chest pain. ECG shows normal sinus rhythm. Blood pressure 140/90.\", \"output\": { \"symptoms\": [\"chest pain\"], \"tests\": [ {\"name\": \"ECG\", \"result\": \"normal sinus rhythm\"}, {\"name\": \"blood pressure\", \"result\": \"140/90\"} ], \"assessment\": \"hypertensive\" } } ] result = lx.extract( text_or_documents=medical_notes, prompt_description=\"Extract symptoms, test results, and clinical assessments\", examples=medical_examples, model_id=\"gemini-2.0-flash-exp\" ) 2. Legal Document Analysis legal_examples = [ { \"input\": \"The agreement between ABC Corp and XYZ Inc, dated January 15, 2024, stipulates a payment of $50,000.\", \"output\": { \"parties\": [\"ABC Corp\", \"XYZ Inc\"], \"date\": \"January 15, 2024\", \"financial_terms\": [{\"amount\": \"$50,000\", \"type\": \"payment\"}], \"document_type\": \"agreement\" } } ] result = lx.extract( text_or_documents=legal_documents, prompt_description=\"Extract parties, dates, financial terms, and document types\", examples=legal_examples, model_id=\"gemini-2.0-pro\" # Use Pro for complex legal reasoning ) 3. Customer Feedback Analysis feedback_examples = [ { \"input\": \"The product quality is excellent but shipping was slow. Customer service was very helpful.\", \"output\": { \"sentiment\": \"mixed\", \"aspects\": [ {\"category\": \"product_quality\", \"sentiment\": \"positive\", \"text\": \"excellent\"}, {\"category\": \"shipping\", \"sentiment\": \"negative\", \"text\": \"slow\"}, {\"category\": \"customer_service\", \"sentiment\": \"positive\", \"text\": \"very helpful\"} ] } } ] result = lx.extract( text_or_documents=customer_reviews, prompt_description=\"Extract sentiment and specific aspects from customer feedback\", examples=feedback_examples, model_id=\"gemini-2.0-flash-exp\" ) 4. Research Paper Processing research_examples = [ { \"input\": \"We conducted a randomized controlled trial with 200 participants. Results showed 85% efficacy (p<0.05).\", \"output\": { \"study_design\": \"randomized controlled trial\", \"sample_size\": 200, \"key_findings\": [ {\"metric\": \"efficacy\", \"value\": \"85%\", \"significance\": \"p<0.05\"} ], \"study_type\": \"clinical trial\" } } ] result = lx.extract( text_or_documents=research_papers, prompt_description=\"Extract study methodology, sample sizes, and key findings\", examples=research_examples, model_id=\"gemini-2.0-flash-exp\" ) Integration Patterns 1. With Pandas for Data Analysis import pandas as pd import langextract as lx # Extract structured data result = lx.extract( text_or_documents=documents, prompt_description=\"Extract financial metrics\", examples=examples, model_id=\"gemini-2.0-flash-exp\" ) # Convert to DataFrame data_rows = [] for extraction in result.extractions: for metric in extraction.data.get(\"metrics\", []): data_rows.append({ \"source\": extraction.metadata.get(\"source\"), \"metric_name\": metric[\"name\"], \"value\": metric[\"value\"], \"period\": metric.get(\"period\") }) df = pd.DataFrame(data_rows) print(df.groupby(\"metric_name\")[\"value\"].mean()) 2. With LangChain for RAG Systems import langextract as lx from langchain.vectorstores import Chroma from langchain.embeddings import OpenAIEmbeddings # Extract structured data first extraction_result = lx.extract( text_or_documents=documents, prompt_description=\"Extract key concepts and definitions\", examples=examples, model_id=\"gemini-2.0-flash-exp\" ) # Create vector store from extracted data texts = [] metadatas = [] for extraction in extraction_result.extractions: for concept in extraction.data.get(\"concepts\", []): texts.append(f\"{concept['term']}: {concept['definition']}\") metadatas.append({ \"source\": extraction.metadata.get(\"source\"), \"term\": concept[\"term\"], \"source_spans\": extraction.source_spans.get(concept[\"id\"], []) }) vectorstore = Chroma.from_texts( texts=texts, metadatas=metadatas, embedding=OpenAIEmbeddings() ) 3. With FastAPI for API Services from fastapi import FastAPI, HTTPException from pydantic import BaseModel import langextract as lx app = FastAPI() class ExtractionRequest(BaseModel): text: str task_description: str examples: list class ExtractionResponse(BaseModel): extractions: list visualization_html: str @app.post(\"/extract\", response_model=ExtractionResponse) async def extract_information(request: ExtractionRequest): try: result = lx.extract( text_or_documents=request.text, prompt_description=request.task_description, examples=request.examples, model_id=\"gemini-2.0-flash-exp\" ) return ExtractionResponse( extractions=[ext.data for ext in result.extractions], visualization_html=result.visualize() ) except Exception as e: raise HTTPException(status_code=500, detail=str(e)) Performance Optimization 1. Efficient Example Selection # Use minimal but representative examples efficient_examples = [ { \"input\": \"Short representative text\", \"output\": {\"key_field\": \"value\"} }, # Limit to 3-5 high-quality examples ] # Avoid overly complex output schemas result = lx.extract( text_or_documents=text, prompt_description=\"Clear, specific task description\", examples=efficient_examples, model_id=\"gemini-2.0-flash-exp\" # Faster for most tasks ) 2. Chunking Strategy for Long Documents def chunk_document(text, max_chunk_size=8000): \"\"\"Split document into overlapping chunks\"\"\" chunks = [] words = text.split() for i in range(0, len(words), max_chunk_size - 200): # 200 word overlap chunk = \" \".join(words[i:i + max_chunk_size]) chunks.append(chunk) return chunks # Process long documents efficiently long_text = \"Very long document content...\" chunks = chunk_document(long_text) results = [] for chunk in chunks: result = lx.extract( text_or_documents=chunk, prompt_description=prompt, examples=examples, model_id=\"gemini-2.0-flash-exp\" ) results.append(result) 3. Caching and Rate Limiting import time from functools import lru_cache import hashlib @lru_cache(maxsize=100) def cached_extract(text_hash, prompt, examples_str, model_id): \"\"\"Cache extraction results for identical inputs\"\"\" return lx.extract( text_or_documents=text, prompt_description=prompt, examples=eval(examples_str), # Be careful with eval in production model_id=model_id ) def extract_with_rate_limit(text, prompt, examples, model_id, delay=1.0): \"\"\"Add rate limiting between API calls\"\"\" text_hash = hashlib.md5(text.encode()).hexdigest() examples_str = str(examples) result = cached_extract(text_hash, prompt, examples_str, model_id) time.sleep(delay) # Rate limiting return result Error Handling and Debugging 1. Robust Error Handling import langextract as lx from typing import Optional, List def safe_extract( text: str, prompt: str, examples: List[dict], model_id: str = \"gemini-2.0-flash-exp\", max_retries: int = 3 ) -> Optional[lx.ExtractionResult]: \"\"\"Extract with error handling and retries\"\"\" for attempt in range(max_retries): try: result = lx.extract( text_or_documents=text, prompt_description=prompt, examples=examples, model_id=model_id ) return result except Exception as e: print(f\"Attempt {attempt + 1} failed: {str(e)}\") if attempt == max_retries - 1: print(f\"All {max_retries} attempts failed\") return None time.sleep(2 ** attempt) # Exponential backoff return None # Usage result = safe_extract(text, prompt, examples) if result: print(\"Extraction successful\") print(result.extractions) else: print(\"Extraction failed after all retries\") 2. Validation and Quality Checks def validate_extraction_result(result: lx.ExtractionResult, expected_fields: List[str]) -> bool: \"\"\"Validate extraction results\"\"\" if not result or not result.extractions: return False for extraction in result.extractions: if not extraction.data: return False # Check for expected fields for field in expected_fields: if field not in extraction.data: print(f\"Missing field: {field}\") return False return True # Usage result = lx.extract(...) is_valid = validate_extraction_result(result, [\"entities\", \"relationships\"]) if not is_valid: print(\"Extraction result validation failed\") 3. Debugging and Inspection def debug_extraction(result: lx.ExtractionResult): \"\"\"Debug extraction results\"\"\" print(f\"Number of extractions: {len(result.extractions)}\") for i, extraction in enumerate(result.extractions): print(f\"\\nExtraction {i + 1}:\") print(f\" Text length: {len(extraction.text)}\") print(f\" Data keys: {list(extraction.data.keys())}\") print(f\" Source spans: {len(extraction.source_spans)}\") print(f\" Metadata: {extraction.metadata}\") # Usage result = lx.extract(...) debug_extraction(result) Best Practices 1. Example Design # \u2705 Good: Clear, specific examples good_examples = [ { \"input\": \"Dr. Smith prescribed aspirin 81mg daily for cardiovascular protection\", \"output\": { \"physician\": \"Dr. Smith\", \"medication\": { \"name\": \"aspirin\", \"dose\": \"81mg\", \"frequency\": \"daily\", \"indication\": \"cardiovascular protection\" } } } ] # \u274c Avoid: Vague or inconsistent examples bad_examples = [ { \"input\": \"Some text\", \"output\": {\"stuff\": \"things\"} } ] 2. Prompt Engineering # \u2705 Good: Specific, actionable prompts good_prompt = \"Extract medication names, dosages, frequencies, and indications from clinical notes. Include the prescribing physician if mentioned.\" # \u274c Avoid: Vague prompts bad_prompt = \"Extract medical information\" # Use the good prompt result = lx.extract( text_or_documents=clinical_notes, prompt_description=good_prompt, examples=good_examples, model_id=\"gemini-2.0-flash-exp\" ) 3. Model Selection Guidelines # Choose model based on task complexity def select_model(task_complexity: str) -> str: model_map = { \"simple\": \"gemini-2.0-flash-exp\", # Fast, cost-effective \"moderate\": \"gemini-2.0-flash-exp\", # Good balance \"complex\": \"gemini-2.0-pro\", # Deep reasoning \"specialized\": \"gemini-2.0-pro\" # Domain expertise } return model_map.get(task_complexity, \"gemini-2.0-flash-exp\") # Usage model_id = select_model(\"moderate\") result = lx.extract( text_or_documents=text, prompt_description=prompt, examples=examples, model_id=model_id ) 4. Output Quality Assurance def ensure_output_quality(result: lx.ExtractionResult) -> bool: \"\"\"Ensure extraction output meets quality standards\"\"\" quality_checks = { \"has_extractions\": len(result.extractions) > 0, \"has_source_spans\": all( len(ext.source_spans) > 0 for ext in result.extractions ), \"data_not_empty\": all( ext.data for ext in result.extractions ) } passed_checks = sum(quality_checks.values()) total_checks = len(quality_checks) print(f\"Quality score: {passed_checks}/{total_checks}\") return passed_checks == total_checks # Usage result = lx.extract(...) if ensure_output_quality(result): print(\"High quality extraction\") else: print(\"Consider refining examples or prompt\") Troubleshooting Common Issues Empty Extractions python # Check input text length and examples if not result.extractions: print(f\"Input length: {len(text)} characters\") print(f\"Number of examples: {len(examples)}\") # Try simpler examples or clearer prompt Inconsistent Output Format python # Ensure examples follow consistent schema # Use more specific prompt descriptions # Consider using fewer but higher-quality examples Missing Source Spans python # Verify text preprocessing doesn't remove character positions # Check if extraction entities exist in source text API Rate Limits python # Implement exponential backoff # Use caching for repeated requests # Consider batch processing Debugging Checklist [ ] Examples follow consistent format [ ] Prompt is specific and actionable [ ] Input text is well-formatted [ ] Model selection matches task complexity [ ] API credentials are properly configured [ ] Rate limiting is implemented for production use For the latest updates and detailed documentation, visit the LangExtract GitHub repository .","title":"LangExtract"},{"location":"python/langextract/#langextract","text":"LangExtract is Google's open-source Python library for extracting structured information from unstructured text using Large Language Models (LLMs). It provides precise source grounding, interactive visualizations, and supports multiple model providers.","title":"LangExtract"},{"location":"python/langextract/#installation","text":"# Basic installation pip install langextract # For development (from source) git clone https://github.com/google/langextract.git cd langextract pip install -e .","title":"Installation"},{"location":"python/langextract/#quick-start","text":"import langextract as lx # Basic extraction result = lx.extract( text_or_documents=\"Your unstructured text here...\", prompt_description=\"Extract names, dates, and locations\", examples=[ {\"input\": \"John visited Paris on May 15th\", \"output\": {\"names\": [\"John\"], \"places\": [\"Paris\"], \"dates\": [\"May 15th\"]}} ], model_id=\"gemini-2.0-flash-exp\" ) # Access results print(result.extractions) print(result.visualize()) # Interactive HTML visualization","title":"Quick Start"},{"location":"python/langextract/#core-components","text":"","title":"Core Components"},{"location":"python/langextract/#1-basic-extraction","text":"import langextract as lx # Simple extraction with few-shot examples result = lx.extract( text_or_documents=input_text, prompt_description=\"Extract character names and their emotions\", examples=[ { \"input\": \"Alice felt happy about the good news\", \"output\": { \"characters\": [{\"name\": \"Alice\", \"emotion\": \"happy\"}] } } ], model_id=\"gemini-2.0-flash-exp\" ) # Check extraction results for extraction in result.extractions: print(f\"Text: {extraction.text}\") print(f\"Data: {extraction.data}\") print(f\"Source spans: {extraction.source_spans}\")","title":"1. Basic Extraction"},{"location":"python/langextract/#2-document-processing","text":"# Process multiple documents documents = [ {\"text\": \"Document 1 content...\", \"metadata\": {\"source\": \"doc1.txt\"}}, {\"text\": \"Document 2 content...\", \"metadata\": {\"source\": \"doc2.txt\"}}, ] result = lx.extract( text_or_documents=documents, prompt_description=\"Extract key findings and recommendations\", examples=[...], model_id=\"gemini-2.0-flash-exp\" )","title":"2. Document Processing"},{"location":"python/langextract/#3-model-configuration","text":"# Using different models result = lx.extract( text_or_documents=text, prompt_description=prompt, examples=examples, model_id=\"gemini-2.0-flash-exp\", # Recommended for speed # model_id=\"gemini-2.0-pro\", # For complex reasoning # model_id=\"gpt-4o-mini\", # OpenAI alternative ) # Configure model parameters result = lx.extract( text_or_documents=text, prompt_description=prompt, examples=examples, model_id=\"gemini-2.0-flash-exp\", generation_config={ \"temperature\": 0.1, \"max_output_tokens\": 8192, \"top_p\": 0.95 } )","title":"3. Model Configuration"},{"location":"python/langextract/#advanced-features","text":"","title":"Advanced Features"},{"location":"python/langextract/#1-source-grounding-visualization","text":"# Extract with precise source tracking result = lx.extract( text_or_documents=long_text, prompt_description=\"Extract medical conditions and treatments\", examples=[...], model_id=\"gemini-2.0-flash-exp\" ) # Generate interactive visualization html_viz = result.visualize() # Save visualization to file with open(\"extraction_results.html\", \"w\") as f: f.write(html_viz) # Access source spans for each extraction for extraction in result.extractions: for entity in extraction.data.get(\"entities\", []): spans = extraction.source_spans.get(entity[\"id\"], []) print(f\"Entity: {entity['text']} found at positions: {spans}\")","title":"1. Source Grounding &amp; Visualization"},{"location":"python/langextract/#2-complex-schema-extraction","text":"# Define complex extraction schema medical_examples = [ { \"input\": \"Patient John Smith, 45, diagnosed with hypertension. Prescribed lisinopril 10mg daily.\", \"output\": { \"patient\": { \"name\": \"John Smith\", \"age\": 45, \"conditions\": [\"hypertension\"], \"medications\": [ { \"name\": \"lisinopril\", \"dosage\": \"10mg\", \"frequency\": \"daily\" } ] } } } ] result = lx.extract( text_or_documents=medical_report, prompt_description=\"Extract patient information, conditions, and medications\", examples=medical_examples, model_id=\"gemini-2.0-flash-exp\" )","title":"2. Complex Schema Extraction"},{"location":"python/langextract/#3-batch-processing","text":"# Process multiple documents efficiently large_document_set = [ {\"text\": doc1_text, \"metadata\": {\"source\": \"report1.pdf\"}}, {\"text\": doc2_text, \"metadata\": {\"source\": \"report2.pdf\"}}, # ... more documents ] # Parallel processing for large datasets result = lx.extract( text_or_documents=large_document_set, prompt_description=\"Extract key metrics and insights\", examples=examples, model_id=\"gemini-2.0-flash-exp\", max_workers=4 # Control parallel processing ) # Process results per document for doc_result in result.extractions: source = doc_result.metadata.get(\"source\", \"unknown\") print(f\"Results from {source}: {doc_result.data}\")","title":"3. Batch Processing"},{"location":"python/langextract/#4-custom-output-parsers","text":"# Define custom parsing logic def parse_financial_data(extraction_result): \"\"\"Custom parser for financial documents\"\"\" parsed_data = {} for extraction in extraction_result.extractions: # Custom processing logic parsed_data[extraction.metadata.get(\"source\")] = { \"revenue\": extraction.data.get(\"revenue\"), \"expenses\": extraction.data.get(\"expenses\"), \"profit\": extraction.data.get(\"profit\") } return parsed_data # Use custom parser result = lx.extract( text_or_documents=financial_reports, prompt_description=\"Extract revenue, expenses, and profit figures\", examples=financial_examples, model_id=\"gemini-2.0-flash-exp\" ) parsed_results = parse_financial_data(result)","title":"4. Custom Output Parsers"},{"location":"python/langextract/#common-use-cases","text":"","title":"Common Use Cases"},{"location":"python/langextract/#1-medical-report-processing","text":"medical_examples = [ { \"input\": \"Patient presents with chest pain. ECG shows normal sinus rhythm. Blood pressure 140/90.\", \"output\": { \"symptoms\": [\"chest pain\"], \"tests\": [ {\"name\": \"ECG\", \"result\": \"normal sinus rhythm\"}, {\"name\": \"blood pressure\", \"result\": \"140/90\"} ], \"assessment\": \"hypertensive\" } } ] result = lx.extract( text_or_documents=medical_notes, prompt_description=\"Extract symptoms, test results, and clinical assessments\", examples=medical_examples, model_id=\"gemini-2.0-flash-exp\" )","title":"1. Medical Report Processing"},{"location":"python/langextract/#2-legal-document-analysis","text":"legal_examples = [ { \"input\": \"The agreement between ABC Corp and XYZ Inc, dated January 15, 2024, stipulates a payment of $50,000.\", \"output\": { \"parties\": [\"ABC Corp\", \"XYZ Inc\"], \"date\": \"January 15, 2024\", \"financial_terms\": [{\"amount\": \"$50,000\", \"type\": \"payment\"}], \"document_type\": \"agreement\" } } ] result = lx.extract( text_or_documents=legal_documents, prompt_description=\"Extract parties, dates, financial terms, and document types\", examples=legal_examples, model_id=\"gemini-2.0-pro\" # Use Pro for complex legal reasoning )","title":"2. Legal Document Analysis"},{"location":"python/langextract/#3-customer-feedback-analysis","text":"feedback_examples = [ { \"input\": \"The product quality is excellent but shipping was slow. Customer service was very helpful.\", \"output\": { \"sentiment\": \"mixed\", \"aspects\": [ {\"category\": \"product_quality\", \"sentiment\": \"positive\", \"text\": \"excellent\"}, {\"category\": \"shipping\", \"sentiment\": \"negative\", \"text\": \"slow\"}, {\"category\": \"customer_service\", \"sentiment\": \"positive\", \"text\": \"very helpful\"} ] } } ] result = lx.extract( text_or_documents=customer_reviews, prompt_description=\"Extract sentiment and specific aspects from customer feedback\", examples=feedback_examples, model_id=\"gemini-2.0-flash-exp\" )","title":"3. Customer Feedback Analysis"},{"location":"python/langextract/#4-research-paper-processing","text":"research_examples = [ { \"input\": \"We conducted a randomized controlled trial with 200 participants. Results showed 85% efficacy (p<0.05).\", \"output\": { \"study_design\": \"randomized controlled trial\", \"sample_size\": 200, \"key_findings\": [ {\"metric\": \"efficacy\", \"value\": \"85%\", \"significance\": \"p<0.05\"} ], \"study_type\": \"clinical trial\" } } ] result = lx.extract( text_or_documents=research_papers, prompt_description=\"Extract study methodology, sample sizes, and key findings\", examples=research_examples, model_id=\"gemini-2.0-flash-exp\" )","title":"4. Research Paper Processing"},{"location":"python/langextract/#integration-patterns","text":"","title":"Integration Patterns"},{"location":"python/langextract/#1-with-pandas-for-data-analysis","text":"import pandas as pd import langextract as lx # Extract structured data result = lx.extract( text_or_documents=documents, prompt_description=\"Extract financial metrics\", examples=examples, model_id=\"gemini-2.0-flash-exp\" ) # Convert to DataFrame data_rows = [] for extraction in result.extractions: for metric in extraction.data.get(\"metrics\", []): data_rows.append({ \"source\": extraction.metadata.get(\"source\"), \"metric_name\": metric[\"name\"], \"value\": metric[\"value\"], \"period\": metric.get(\"period\") }) df = pd.DataFrame(data_rows) print(df.groupby(\"metric_name\")[\"value\"].mean())","title":"1. With Pandas for Data Analysis"},{"location":"python/langextract/#2-with-langchain-for-rag-systems","text":"import langextract as lx from langchain.vectorstores import Chroma from langchain.embeddings import OpenAIEmbeddings # Extract structured data first extraction_result = lx.extract( text_or_documents=documents, prompt_description=\"Extract key concepts and definitions\", examples=examples, model_id=\"gemini-2.0-flash-exp\" ) # Create vector store from extracted data texts = [] metadatas = [] for extraction in extraction_result.extractions: for concept in extraction.data.get(\"concepts\", []): texts.append(f\"{concept['term']}: {concept['definition']}\") metadatas.append({ \"source\": extraction.metadata.get(\"source\"), \"term\": concept[\"term\"], \"source_spans\": extraction.source_spans.get(concept[\"id\"], []) }) vectorstore = Chroma.from_texts( texts=texts, metadatas=metadatas, embedding=OpenAIEmbeddings() )","title":"2. With LangChain for RAG Systems"},{"location":"python/langextract/#3-with-fastapi-for-api-services","text":"from fastapi import FastAPI, HTTPException from pydantic import BaseModel import langextract as lx app = FastAPI() class ExtractionRequest(BaseModel): text: str task_description: str examples: list class ExtractionResponse(BaseModel): extractions: list visualization_html: str @app.post(\"/extract\", response_model=ExtractionResponse) async def extract_information(request: ExtractionRequest): try: result = lx.extract( text_or_documents=request.text, prompt_description=request.task_description, examples=request.examples, model_id=\"gemini-2.0-flash-exp\" ) return ExtractionResponse( extractions=[ext.data for ext in result.extractions], visualization_html=result.visualize() ) except Exception as e: raise HTTPException(status_code=500, detail=str(e))","title":"3. With FastAPI for API Services"},{"location":"python/langextract/#performance-optimization","text":"","title":"Performance Optimization"},{"location":"python/langextract/#1-efficient-example-selection","text":"# Use minimal but representative examples efficient_examples = [ { \"input\": \"Short representative text\", \"output\": {\"key_field\": \"value\"} }, # Limit to 3-5 high-quality examples ] # Avoid overly complex output schemas result = lx.extract( text_or_documents=text, prompt_description=\"Clear, specific task description\", examples=efficient_examples, model_id=\"gemini-2.0-flash-exp\" # Faster for most tasks )","title":"1. Efficient Example Selection"},{"location":"python/langextract/#2-chunking-strategy-for-long-documents","text":"def chunk_document(text, max_chunk_size=8000): \"\"\"Split document into overlapping chunks\"\"\" chunks = [] words = text.split() for i in range(0, len(words), max_chunk_size - 200): # 200 word overlap chunk = \" \".join(words[i:i + max_chunk_size]) chunks.append(chunk) return chunks # Process long documents efficiently long_text = \"Very long document content...\" chunks = chunk_document(long_text) results = [] for chunk in chunks: result = lx.extract( text_or_documents=chunk, prompt_description=prompt, examples=examples, model_id=\"gemini-2.0-flash-exp\" ) results.append(result)","title":"2. Chunking Strategy for Long Documents"},{"location":"python/langextract/#3-caching-and-rate-limiting","text":"import time from functools import lru_cache import hashlib @lru_cache(maxsize=100) def cached_extract(text_hash, prompt, examples_str, model_id): \"\"\"Cache extraction results for identical inputs\"\"\" return lx.extract( text_or_documents=text, prompt_description=prompt, examples=eval(examples_str), # Be careful with eval in production model_id=model_id ) def extract_with_rate_limit(text, prompt, examples, model_id, delay=1.0): \"\"\"Add rate limiting between API calls\"\"\" text_hash = hashlib.md5(text.encode()).hexdigest() examples_str = str(examples) result = cached_extract(text_hash, prompt, examples_str, model_id) time.sleep(delay) # Rate limiting return result","title":"3. Caching and Rate Limiting"},{"location":"python/langextract/#error-handling-and-debugging","text":"","title":"Error Handling and Debugging"},{"location":"python/langextract/#1-robust-error-handling","text":"import langextract as lx from typing import Optional, List def safe_extract( text: str, prompt: str, examples: List[dict], model_id: str = \"gemini-2.0-flash-exp\", max_retries: int = 3 ) -> Optional[lx.ExtractionResult]: \"\"\"Extract with error handling and retries\"\"\" for attempt in range(max_retries): try: result = lx.extract( text_or_documents=text, prompt_description=prompt, examples=examples, model_id=model_id ) return result except Exception as e: print(f\"Attempt {attempt + 1} failed: {str(e)}\") if attempt == max_retries - 1: print(f\"All {max_retries} attempts failed\") return None time.sleep(2 ** attempt) # Exponential backoff return None # Usage result = safe_extract(text, prompt, examples) if result: print(\"Extraction successful\") print(result.extractions) else: print(\"Extraction failed after all retries\")","title":"1. Robust Error Handling"},{"location":"python/langextract/#2-validation-and-quality-checks","text":"def validate_extraction_result(result: lx.ExtractionResult, expected_fields: List[str]) -> bool: \"\"\"Validate extraction results\"\"\" if not result or not result.extractions: return False for extraction in result.extractions: if not extraction.data: return False # Check for expected fields for field in expected_fields: if field not in extraction.data: print(f\"Missing field: {field}\") return False return True # Usage result = lx.extract(...) is_valid = validate_extraction_result(result, [\"entities\", \"relationships\"]) if not is_valid: print(\"Extraction result validation failed\")","title":"2. Validation and Quality Checks"},{"location":"python/langextract/#3-debugging-and-inspection","text":"def debug_extraction(result: lx.ExtractionResult): \"\"\"Debug extraction results\"\"\" print(f\"Number of extractions: {len(result.extractions)}\") for i, extraction in enumerate(result.extractions): print(f\"\\nExtraction {i + 1}:\") print(f\" Text length: {len(extraction.text)}\") print(f\" Data keys: {list(extraction.data.keys())}\") print(f\" Source spans: {len(extraction.source_spans)}\") print(f\" Metadata: {extraction.metadata}\") # Usage result = lx.extract(...) debug_extraction(result)","title":"3. Debugging and Inspection"},{"location":"python/langextract/#best-practices","text":"","title":"Best Practices"},{"location":"python/langextract/#1-example-design","text":"# \u2705 Good: Clear, specific examples good_examples = [ { \"input\": \"Dr. Smith prescribed aspirin 81mg daily for cardiovascular protection\", \"output\": { \"physician\": \"Dr. Smith\", \"medication\": { \"name\": \"aspirin\", \"dose\": \"81mg\", \"frequency\": \"daily\", \"indication\": \"cardiovascular protection\" } } } ] # \u274c Avoid: Vague or inconsistent examples bad_examples = [ { \"input\": \"Some text\", \"output\": {\"stuff\": \"things\"} } ]","title":"1. Example Design"},{"location":"python/langextract/#2-prompt-engineering","text":"# \u2705 Good: Specific, actionable prompts good_prompt = \"Extract medication names, dosages, frequencies, and indications from clinical notes. Include the prescribing physician if mentioned.\" # \u274c Avoid: Vague prompts bad_prompt = \"Extract medical information\" # Use the good prompt result = lx.extract( text_or_documents=clinical_notes, prompt_description=good_prompt, examples=good_examples, model_id=\"gemini-2.0-flash-exp\" )","title":"2. Prompt Engineering"},{"location":"python/langextract/#3-model-selection-guidelines","text":"# Choose model based on task complexity def select_model(task_complexity: str) -> str: model_map = { \"simple\": \"gemini-2.0-flash-exp\", # Fast, cost-effective \"moderate\": \"gemini-2.0-flash-exp\", # Good balance \"complex\": \"gemini-2.0-pro\", # Deep reasoning \"specialized\": \"gemini-2.0-pro\" # Domain expertise } return model_map.get(task_complexity, \"gemini-2.0-flash-exp\") # Usage model_id = select_model(\"moderate\") result = lx.extract( text_or_documents=text, prompt_description=prompt, examples=examples, model_id=model_id )","title":"3. Model Selection Guidelines"},{"location":"python/langextract/#4-output-quality-assurance","text":"def ensure_output_quality(result: lx.ExtractionResult) -> bool: \"\"\"Ensure extraction output meets quality standards\"\"\" quality_checks = { \"has_extractions\": len(result.extractions) > 0, \"has_source_spans\": all( len(ext.source_spans) > 0 for ext in result.extractions ), \"data_not_empty\": all( ext.data for ext in result.extractions ) } passed_checks = sum(quality_checks.values()) total_checks = len(quality_checks) print(f\"Quality score: {passed_checks}/{total_checks}\") return passed_checks == total_checks # Usage result = lx.extract(...) if ensure_output_quality(result): print(\"High quality extraction\") else: print(\"Consider refining examples or prompt\")","title":"4. Output Quality Assurance"},{"location":"python/langextract/#troubleshooting","text":"","title":"Troubleshooting"},{"location":"python/langextract/#common-issues","text":"Empty Extractions python # Check input text length and examples if not result.extractions: print(f\"Input length: {len(text)} characters\") print(f\"Number of examples: {len(examples)}\") # Try simpler examples or clearer prompt Inconsistent Output Format python # Ensure examples follow consistent schema # Use more specific prompt descriptions # Consider using fewer but higher-quality examples Missing Source Spans python # Verify text preprocessing doesn't remove character positions # Check if extraction entities exist in source text API Rate Limits python # Implement exponential backoff # Use caching for repeated requests # Consider batch processing","title":"Common Issues"},{"location":"python/langextract/#debugging-checklist","text":"[ ] Examples follow consistent format [ ] Prompt is specific and actionable [ ] Input text is well-formatted [ ] Model selection matches task complexity [ ] API credentials are properly configured [ ] Rate limiting is implemented for production use For the latest updates and detailed documentation, visit the LangExtract GitHub repository .","title":"Debugging Checklist"},{"location":"python/matplotlib/","text":"Matplotlib Installation # Basic installation pip install matplotlib # With optional dependencies pip install matplotlib[complete] # Check version python -c \"import matplotlib; print(matplotlib.__version__)\" # Check backend python -c \"import matplotlib; print(matplotlib.get_backend())\" Basic Setup # Essential imports import matplotlib.pyplot as plt import matplotlib as mpl import numpy as np # Set backend (optional) matplotlib.use('TkAgg') # or 'Qt5Agg', 'Agg', etc. # Enable inline plots in Jupyter %matplotlib inline # Basic figure creation fig, ax = plt.subplots() plt.show() Core Functionality Basic Plotting # Line plot x = np.linspace(0, 10, 100) y = np.sin(x) plt.figure(figsize=(8, 6)) plt.plot(x, y, label='sin(x)', linewidth=2, color='blue') plt.xlabel('X-axis') plt.ylabel('Y-axis') plt.title('Simple Sine Wave') plt.legend() plt.grid(True) plt.show() # Multiple lines plt.plot(x, np.sin(x), label='sin(x)') plt.plot(x, np.cos(x), label='cos(x)', linestyle='--') plt.legend() Scatter Plot # Basic scatter x = np.random.randn(100) y = np.random.randn(100) colors = np.random.rand(100) sizes = 1000 * np.random.rand(100) plt.scatter(x, y, c=colors, s=sizes, alpha=0.6, cmap='viridis') plt.colorbar() plt.title('Scatter Plot with Color and Size') Bar Charts # Vertical bar chart categories = ['A', 'B', 'C', 'D'] values = [23, 17, 35, 29] plt.bar(categories, values, color=['red', 'green', 'blue', 'orange']) plt.title('Bar Chart') plt.ylabel('Values') # Horizontal bar chart plt.barh(categories, values) # Grouped bar chart x = np.arange(len(categories)) width = 0.35 plt.bar(x - width/2, values, width, label='Series 1') plt.bar(x + width/2, [20, 25, 15, 30], width, label='Series 2') plt.xticks(x, categories) plt.legend() Histograms # Basic histogram data = np.random.normal(100, 15, 1000) plt.hist(data, bins=30, alpha=0.7, color='skyblue', edgecolor='black') plt.title('Histogram') plt.xlabel('Values') plt.ylabel('Frequency') # Multiple histograms data1 = np.random.normal(100, 15, 1000) data2 = np.random.normal(80, 20, 1000) plt.hist([data1, data2], bins=30, alpha=0.7, label=['Dataset 1', 'Dataset 2']) plt.legend() Subplots and Figure Management Creating Subplots # Basic subplots fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(10, 8)) ax1.plot([1, 2, 3], [1, 4, 2]) ax1.set_title('Plot 1') ax2.scatter([1, 2, 3], [1, 4, 2]) ax2.set_title('Plot 2') ax3.bar([1, 2, 3], [1, 4, 2]) ax3.set_title('Plot 3') ax4.hist(np.random.randn(100), bins=20) ax4.set_title('Plot 4') plt.tight_layout() # Adjust spacing plt.show() # Subplot with different sizes fig = plt.figure(figsize=(12, 8)) ax1 = plt.subplot(2, 2, 1) ax2 = plt.subplot(2, 2, 2) ax3 = plt.subplot(2, 1, 2) # Spans two columns GridSpec for Advanced Layouts import matplotlib.gridspec as gridspec fig = plt.figure(figsize=(10, 8)) gs = gridspec.GridSpec(3, 3) ax1 = fig.add_subplot(gs[0, :]) # Top row, all columns ax2 = fig.add_subplot(gs[1, :-1]) # Middle row, first two columns ax3 = fig.add_subplot(gs[1:, -1]) # Right column, bottom two rows ax4 = fig.add_subplot(gs[-1, 0]) # Bottom left ax5 = fig.add_subplot(gs[-1, -2]) # Bottom center Subplot with Shared Axes # Shared x-axis fig, (ax1, ax2) = plt.subplots(2, 1, sharex=True, figsize=(8, 6)) ax1.plot(x, np.sin(x)) ax2.plot(x, np.cos(x)) # Shared y-axis fig, (ax1, ax2) = plt.subplots(1, 2, sharey=True, figsize=(10, 4)) Customization Colors and Styles # Color specifications plt.plot(x, y, color='red') # Named color plt.plot(x, y, color='#FF5733') # Hex code plt.plot(x, y, color=(0.1, 0.2, 0.5)) # RGB tuple plt.plot(x, y, c='r') # Short form # Line styles plt.plot(x, y, linestyle='-') # Solid plt.plot(x, y, linestyle='--') # Dashed plt.plot(x, y, linestyle='-.') # Dash-dot plt.plot(x, y, linestyle=':') # Dotted plt.plot(x, y, ls=':') # Short form # Markers plt.plot(x, y, marker='o') # Circle plt.plot(x, y, marker='s') # Square plt.plot(x, y, marker='^') # Triangle up plt.plot(x, y, marker='D') # Diamond # Combined format string plt.plot(x, y, 'ro-') # Red circles with solid line plt.plot(x, y, 'g--^') # Green dashed line with triangle markers Fonts and Text # Font properties plt.rcParams['font.family'] = 'serif' plt.rcParams['font.size'] = 12 # Title and labels with custom fonts plt.title('Title', fontsize=16, fontweight='bold') plt.xlabel('X Label', fontsize=14, style='italic') plt.ylabel('Y Label', fontsize=14, color='red') # Text annotations plt.text(0.5, 0.5, 'Sample Text', fontsize=12, horizontalalignment='center', verticalalignment='center', transform=ax.transAxes) # Relative coordinates # Annotations with arrows plt.annotate('Important Point', xy=(2, 1), xytext=(3, 4), arrowprops=dict(arrowstyle='->', color='red', lw=2)) Axis Customization # Axis limits plt.xlim(0, 10) plt.ylim(-1, 1) # or ax.set_xlim(0, 10) ax.set_ylim(-1, 1) # Axis ticks plt.xticks([0, 2, 4, 6, 8, 10]) plt.yticks([-1, -0.5, 0, 0.5, 1]) # Custom tick labels plt.xticks([0, 1, 2, 3], ['A', 'B', 'C', 'D']) # Tick formatting from matplotlib.ticker import FuncFormatter def currency(x, pos): return f'${x:.0f}' ax.yaxis.set_major_formatter(FuncFormatter(currency)) # Logarithmic scale plt.yscale('log') plt.xscale('log') # Grid customization plt.grid(True, linestyle='--', alpha=0.7, color='gray') Legends # Basic legend plt.plot(x, np.sin(x), label='sin(x)') plt.plot(x, np.cos(x), label='cos(x)') plt.legend() # Legend positioning plt.legend(loc='upper right') # 'upper left', 'lower right', etc. plt.legend(loc='best') # Automatic best position plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left') # Outside plot # Legend customization plt.legend(frameon=True, fancybox=True, shadow=True, ncol=2, fontsize=10, title='Legend Title') Different Plot Types Statistical Plots # Box plot data = [np.random.normal(0, std, 100) for std in range(1, 4)] plt.boxplot(data, labels=['Group A', 'Group B', 'Group C']) # Violin plot (requires seaborn or custom implementation) # Error bars x = [1, 2, 3, 4] y = [1, 4, 2, 3] yerr = [0.1, 0.2, 0.1, 0.3] plt.errorbar(x, y, yerr=yerr, fmt='o-', capsize=5) # Fill between x = np.linspace(0, 10, 100) y1 = np.sin(x) y2 = np.cos(x) plt.fill_between(x, y1, y2, alpha=0.3, color='blue') 2D Plots # Heatmap/Image data = np.random.rand(10, 10) plt.imshow(data, cmap='hot', interpolation='nearest') plt.colorbar() # Contour plot x = np.linspace(-3, 3, 100) y = np.linspace(-3, 3, 100) X, Y = np.meshgrid(x, y) Z = np.sin(X) * np.cos(Y) plt.contour(X, Y, Z, levels=10) plt.contourf(X, Y, Z, levels=20, cmap='viridis') # Filled contours plt.colorbar() # 3D plotting from mpl_toolkits.mplot3d import Axes3D fig = plt.figure() ax = fig.add_subplot(111, projection='3d') ax.plot_surface(X, Y, Z, cmap='viridis') Pie Charts # Basic pie chart sizes = [25, 30, 15, 30] labels = ['A', 'B', 'C', 'D'] colors = ['gold', 'yellowgreen', 'lightcoral', 'lightskyblue'] explode = (0, 0.1, 0, 0) # Explode slice B plt.pie(sizes, explode=explode, labels=labels, colors=colors, autopct='%1.1f%%', shadow=True, startangle=90) plt.axis('equal') # Equal aspect ratio Saving Figures # Save in different formats plt.savefig('plot.png', dpi=300, bbox_inches='tight') plt.savefig('plot.pdf', format='pdf') plt.savefig('plot.svg', format='svg') plt.savefig('plot.eps', format='eps') # High-quality publication figure plt.savefig('publication.png', dpi=300, bbox_inches='tight', facecolor='white', edgecolor='none', transparent=False) # Save with specific size plt.figure(figsize=(10, 6)) # ... plotting code ... plt.savefig('sized_plot.png', dpi=150) Interactive Features Event Handling # Click event handling def onclick(event): if event.inaxes is not None: print(f'Clicked at: ({event.xdata:.2f}, {event.ydata:.2f})') fig, ax = plt.subplots() ax.plot([1, 2, 3], [1, 4, 2]) fig.canvas.mpl_connect('button_press_event', onclick) plt.show() # Key press events def onkey(event): print(f'Key pressed: {event.key}') fig.canvas.mpl_connect('key_press_event', onkey) Widgets (requires widget backend) from matplotlib.widgets import Button, Slider # Interactive slider fig, ax = plt.subplots() plt.subplots_adjust(bottom=0.25) # Initial plot t = np.linspace(0, 10, 1000) a0 = 1 f0 = 1 s = a0 * np.sin(2 * np.pi * f0 * t) l, = plt.plot(t, s) # Slider ax_freq = plt.axes([0.25, 0.1, 0.5, 0.03]) slider = Slider(ax_freq, 'Frequency', 0.1, 5.0, valinit=f0) def update(val): freq = slider.val l.set_ydata(a0 * np.sin(2 * np.pi * freq * t)) fig.canvas.draw_idle() slider.on_changed(update) plt.show() Advanced Features Animations from matplotlib.animation import FuncAnimation # Animated sine wave fig, ax = plt.subplots() x = np.linspace(0, 2*np.pi, 100) line, = ax.plot(x, np.sin(x)) def animate(frame): line.set_ydata(np.sin(x + frame/10)) return line, ani = FuncAnimation(fig, animate, frames=200, interval=50, blit=True) plt.show() # Save animation ani.save('animation.gif', writer='pillow', fps=20) ani.save('animation.mp4', writer='ffmpeg', fps=30) Custom Colormaps from matplotlib.colors import LinearSegmentedColormap # Create custom colormap colors = ['red', 'yellow', 'green', 'blue'] n_bins = 100 cmap = LinearSegmentedColormap.from_list('custom', colors, N=n_bins) # Use custom colormap data = np.random.rand(10, 10) plt.imshow(data, cmap=cmap) plt.colorbar() Dual Axes # Two different y-axes fig, ax1 = plt.subplots() x = np.linspace(0, 10, 100) y1 = np.sin(x) y2 = np.exp(x/5) # First y-axis ax1.plot(x, y1, 'g-') ax1.set_xlabel('X data') ax1.set_ylabel('sin(x)', color='g') ax1.tick_params(axis='y', labelcolor='g') # Second y-axis ax2 = ax1.twinx() ax2.plot(x, y2, 'b-') ax2.set_ylabel('exp(x/5)', color='b') ax2.tick_params(axis='y', labelcolor='b') plt.show() Customization & Best Practices Style Sheets # Available styles print(plt.style.available) # Use built-in styles plt.style.use('seaborn-v0_8') plt.style.use('ggplot') plt.style.use('dark_background') # Use multiple styles plt.style.use(['seaborn-v0_8', 'seaborn-v0_8-darkgrid']) # Context manager for temporary style with plt.style.context('bmh'): plt.plot([1, 2, 3], [1, 4, 2]) plt.show() RC Parameters # Global settings plt.rcParams['figure.figsize'] = [10, 6] plt.rcParams['font.size'] = 12 plt.rcParams['lines.linewidth'] = 2 plt.rcParams['grid.alpha'] = 0.3 # Context manager for temporary settings with plt.rc_context({'font.size': 14, 'lines.linewidth': 3}): plt.plot([1, 2, 3], [1, 4, 2]) # Reset to defaults plt.rcdefaults() Performance Tips # Use appropriate backends import matplotlib matplotlib.use('Agg') # For server/batch processing # Batch plotting plt.ioff() # Turn off interactive mode for i in range(100): plt.figure() plt.plot(data[i]) plt.savefig(f'plot_{i}.png') plt.close() # Important: close figures to free memory # Efficient line collection for many lines from matplotlib.collections import LineCollection lines = [np.column_stack([x, y + i]) for i in range(100)] lc = LineCollection(lines, linewidths=0.5) ax.add_collection(lc) Integration with Other Libraries NumPy Integration # Matplotlib works seamlessly with NumPy arrays x = np.linspace(0, 10, 100) y = np.sin(x) plt.plot(x, y) # Masked arrays y_masked = np.ma.masked_where(y < 0, y) plt.plot(x, y_masked) Pandas Integration import pandas as pd # DataFrame plotting df = pd.DataFrame({ 'x': range(10), 'y1': np.random.randn(10), 'y2': np.random.randn(10) }) # Direct pandas plotting df.plot(x='x', y=['y1', 'y2']) # Using matplotlib directly plt.plot(df['x'], df['y1'], label='y1') plt.plot(df['x'], df['y2'], label='y2') plt.legend() Common Gotchas & Best Practices Memory Management # Always close figures when done fig, ax = plt.subplots() # ... plotting code ... plt.close(fig) # or plt.close('all') # Clear current figure plt.clf() # Clear current axes plt.cla() Backend Issues # Check current backend print(plt.get_backend()) # Set backend before importing pyplot import matplotlib matplotlib.use('TkAgg') # Must be before importing pyplot import matplotlib.pyplot as plt Common Patterns # Professional plotting setup def setup_plot(figsize=(10, 6)): fig, ax = plt.subplots(figsize=figsize) ax.spines['top'].set_visible(False) ax.spines['right'].set_visible(False) ax.grid(True, alpha=0.3) return fig, ax # Context manager for consistent styling from contextlib import contextmanager @contextmanager def plot_style(style='seaborn-v0_8', figsize=(10, 6)): with plt.style.context(style): fig, ax = plt.subplots(figsize=figsize) yield fig, ax plt.tight_layout() # Usage with plot_style() as (fig, ax): ax.plot([1, 2, 3], [1, 4, 2]) ax.set_title('Styled Plot') plt.show() Quick Reference Essential Functions Function Purpose Example plt.figure() Create new figure plt.figure(figsize=(8,6)) plt.subplot() Add subplot plt.subplot(2,2,1) plt.plot() Line plot plt.plot(x, y, 'r-') plt.scatter() Scatter plot plt.scatter(x, y, c=colors) plt.bar() Bar chart plt.bar(x, height) plt.hist() Histogram plt.hist(data, bins=20) plt.imshow() Display image/2D data plt.imshow(array, cmap='hot') plt.savefig() Save figure plt.savefig('plot.png', dpi=300) Format Strings Code Meaning Code Meaning - Solid line o Circle marker -- Dashed line s Square marker -. Dash-dot line ^ Triangle up marker : Dotted line D Diamond marker r Red g Green b Blue k Black c Cyan m Magenta y Yellow w White Color Maps Common colormaps: viridis , plasma , inferno , magma , coolwarm , RdYlBu , seismic , hot , cool , spring , summer , autumn , winter , gray Use: plt.imshow(data, cmap='viridis')","title":"Matplotlib"},{"location":"python/matplotlib/#matplotlib","text":"","title":"Matplotlib"},{"location":"python/matplotlib/#installation","text":"# Basic installation pip install matplotlib # With optional dependencies pip install matplotlib[complete] # Check version python -c \"import matplotlib; print(matplotlib.__version__)\" # Check backend python -c \"import matplotlib; print(matplotlib.get_backend())\"","title":"Installation"},{"location":"python/matplotlib/#basic-setup","text":"# Essential imports import matplotlib.pyplot as plt import matplotlib as mpl import numpy as np # Set backend (optional) matplotlib.use('TkAgg') # or 'Qt5Agg', 'Agg', etc. # Enable inline plots in Jupyter %matplotlib inline # Basic figure creation fig, ax = plt.subplots() plt.show()","title":"Basic Setup"},{"location":"python/matplotlib/#core-functionality","text":"","title":"Core Functionality"},{"location":"python/matplotlib/#basic-plotting","text":"# Line plot x = np.linspace(0, 10, 100) y = np.sin(x) plt.figure(figsize=(8, 6)) plt.plot(x, y, label='sin(x)', linewidth=2, color='blue') plt.xlabel('X-axis') plt.ylabel('Y-axis') plt.title('Simple Sine Wave') plt.legend() plt.grid(True) plt.show() # Multiple lines plt.plot(x, np.sin(x), label='sin(x)') plt.plot(x, np.cos(x), label='cos(x)', linestyle='--') plt.legend()","title":"Basic Plotting"},{"location":"python/matplotlib/#scatter-plot","text":"# Basic scatter x = np.random.randn(100) y = np.random.randn(100) colors = np.random.rand(100) sizes = 1000 * np.random.rand(100) plt.scatter(x, y, c=colors, s=sizes, alpha=0.6, cmap='viridis') plt.colorbar() plt.title('Scatter Plot with Color and Size')","title":"Scatter Plot"},{"location":"python/matplotlib/#bar-charts","text":"# Vertical bar chart categories = ['A', 'B', 'C', 'D'] values = [23, 17, 35, 29] plt.bar(categories, values, color=['red', 'green', 'blue', 'orange']) plt.title('Bar Chart') plt.ylabel('Values') # Horizontal bar chart plt.barh(categories, values) # Grouped bar chart x = np.arange(len(categories)) width = 0.35 plt.bar(x - width/2, values, width, label='Series 1') plt.bar(x + width/2, [20, 25, 15, 30], width, label='Series 2') plt.xticks(x, categories) plt.legend()","title":"Bar Charts"},{"location":"python/matplotlib/#histograms","text":"# Basic histogram data = np.random.normal(100, 15, 1000) plt.hist(data, bins=30, alpha=0.7, color='skyblue', edgecolor='black') plt.title('Histogram') plt.xlabel('Values') plt.ylabel('Frequency') # Multiple histograms data1 = np.random.normal(100, 15, 1000) data2 = np.random.normal(80, 20, 1000) plt.hist([data1, data2], bins=30, alpha=0.7, label=['Dataset 1', 'Dataset 2']) plt.legend()","title":"Histograms"},{"location":"python/matplotlib/#subplots-and-figure-management","text":"","title":"Subplots and Figure Management"},{"location":"python/matplotlib/#creating-subplots","text":"# Basic subplots fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(10, 8)) ax1.plot([1, 2, 3], [1, 4, 2]) ax1.set_title('Plot 1') ax2.scatter([1, 2, 3], [1, 4, 2]) ax2.set_title('Plot 2') ax3.bar([1, 2, 3], [1, 4, 2]) ax3.set_title('Plot 3') ax4.hist(np.random.randn(100), bins=20) ax4.set_title('Plot 4') plt.tight_layout() # Adjust spacing plt.show() # Subplot with different sizes fig = plt.figure(figsize=(12, 8)) ax1 = plt.subplot(2, 2, 1) ax2 = plt.subplot(2, 2, 2) ax3 = plt.subplot(2, 1, 2) # Spans two columns","title":"Creating Subplots"},{"location":"python/matplotlib/#gridspec-for-advanced-layouts","text":"import matplotlib.gridspec as gridspec fig = plt.figure(figsize=(10, 8)) gs = gridspec.GridSpec(3, 3) ax1 = fig.add_subplot(gs[0, :]) # Top row, all columns ax2 = fig.add_subplot(gs[1, :-1]) # Middle row, first two columns ax3 = fig.add_subplot(gs[1:, -1]) # Right column, bottom two rows ax4 = fig.add_subplot(gs[-1, 0]) # Bottom left ax5 = fig.add_subplot(gs[-1, -2]) # Bottom center","title":"GridSpec for Advanced Layouts"},{"location":"python/matplotlib/#subplot-with-shared-axes","text":"# Shared x-axis fig, (ax1, ax2) = plt.subplots(2, 1, sharex=True, figsize=(8, 6)) ax1.plot(x, np.sin(x)) ax2.plot(x, np.cos(x)) # Shared y-axis fig, (ax1, ax2) = plt.subplots(1, 2, sharey=True, figsize=(10, 4))","title":"Subplot with Shared Axes"},{"location":"python/matplotlib/#customization","text":"","title":"Customization"},{"location":"python/matplotlib/#colors-and-styles","text":"# Color specifications plt.plot(x, y, color='red') # Named color plt.plot(x, y, color='#FF5733') # Hex code plt.plot(x, y, color=(0.1, 0.2, 0.5)) # RGB tuple plt.plot(x, y, c='r') # Short form # Line styles plt.plot(x, y, linestyle='-') # Solid plt.plot(x, y, linestyle='--') # Dashed plt.plot(x, y, linestyle='-.') # Dash-dot plt.plot(x, y, linestyle=':') # Dotted plt.plot(x, y, ls=':') # Short form # Markers plt.plot(x, y, marker='o') # Circle plt.plot(x, y, marker='s') # Square plt.plot(x, y, marker='^') # Triangle up plt.plot(x, y, marker='D') # Diamond # Combined format string plt.plot(x, y, 'ro-') # Red circles with solid line plt.plot(x, y, 'g--^') # Green dashed line with triangle markers","title":"Colors and Styles"},{"location":"python/matplotlib/#fonts-and-text","text":"# Font properties plt.rcParams['font.family'] = 'serif' plt.rcParams['font.size'] = 12 # Title and labels with custom fonts plt.title('Title', fontsize=16, fontweight='bold') plt.xlabel('X Label', fontsize=14, style='italic') plt.ylabel('Y Label', fontsize=14, color='red') # Text annotations plt.text(0.5, 0.5, 'Sample Text', fontsize=12, horizontalalignment='center', verticalalignment='center', transform=ax.transAxes) # Relative coordinates # Annotations with arrows plt.annotate('Important Point', xy=(2, 1), xytext=(3, 4), arrowprops=dict(arrowstyle='->', color='red', lw=2))","title":"Fonts and Text"},{"location":"python/matplotlib/#axis-customization","text":"# Axis limits plt.xlim(0, 10) plt.ylim(-1, 1) # or ax.set_xlim(0, 10) ax.set_ylim(-1, 1) # Axis ticks plt.xticks([0, 2, 4, 6, 8, 10]) plt.yticks([-1, -0.5, 0, 0.5, 1]) # Custom tick labels plt.xticks([0, 1, 2, 3], ['A', 'B', 'C', 'D']) # Tick formatting from matplotlib.ticker import FuncFormatter def currency(x, pos): return f'${x:.0f}' ax.yaxis.set_major_formatter(FuncFormatter(currency)) # Logarithmic scale plt.yscale('log') plt.xscale('log') # Grid customization plt.grid(True, linestyle='--', alpha=0.7, color='gray')","title":"Axis Customization"},{"location":"python/matplotlib/#legends","text":"# Basic legend plt.plot(x, np.sin(x), label='sin(x)') plt.plot(x, np.cos(x), label='cos(x)') plt.legend() # Legend positioning plt.legend(loc='upper right') # 'upper left', 'lower right', etc. plt.legend(loc='best') # Automatic best position plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left') # Outside plot # Legend customization plt.legend(frameon=True, fancybox=True, shadow=True, ncol=2, fontsize=10, title='Legend Title')","title":"Legends"},{"location":"python/matplotlib/#different-plot-types","text":"","title":"Different Plot Types"},{"location":"python/matplotlib/#statistical-plots","text":"# Box plot data = [np.random.normal(0, std, 100) for std in range(1, 4)] plt.boxplot(data, labels=['Group A', 'Group B', 'Group C']) # Violin plot (requires seaborn or custom implementation) # Error bars x = [1, 2, 3, 4] y = [1, 4, 2, 3] yerr = [0.1, 0.2, 0.1, 0.3] plt.errorbar(x, y, yerr=yerr, fmt='o-', capsize=5) # Fill between x = np.linspace(0, 10, 100) y1 = np.sin(x) y2 = np.cos(x) plt.fill_between(x, y1, y2, alpha=0.3, color='blue')","title":"Statistical Plots"},{"location":"python/matplotlib/#2d-plots","text":"# Heatmap/Image data = np.random.rand(10, 10) plt.imshow(data, cmap='hot', interpolation='nearest') plt.colorbar() # Contour plot x = np.linspace(-3, 3, 100) y = np.linspace(-3, 3, 100) X, Y = np.meshgrid(x, y) Z = np.sin(X) * np.cos(Y) plt.contour(X, Y, Z, levels=10) plt.contourf(X, Y, Z, levels=20, cmap='viridis') # Filled contours plt.colorbar() # 3D plotting from mpl_toolkits.mplot3d import Axes3D fig = plt.figure() ax = fig.add_subplot(111, projection='3d') ax.plot_surface(X, Y, Z, cmap='viridis')","title":"2D Plots"},{"location":"python/matplotlib/#pie-charts","text":"# Basic pie chart sizes = [25, 30, 15, 30] labels = ['A', 'B', 'C', 'D'] colors = ['gold', 'yellowgreen', 'lightcoral', 'lightskyblue'] explode = (0, 0.1, 0, 0) # Explode slice B plt.pie(sizes, explode=explode, labels=labels, colors=colors, autopct='%1.1f%%', shadow=True, startangle=90) plt.axis('equal') # Equal aspect ratio","title":"Pie Charts"},{"location":"python/matplotlib/#saving-figures","text":"# Save in different formats plt.savefig('plot.png', dpi=300, bbox_inches='tight') plt.savefig('plot.pdf', format='pdf') plt.savefig('plot.svg', format='svg') plt.savefig('plot.eps', format='eps') # High-quality publication figure plt.savefig('publication.png', dpi=300, bbox_inches='tight', facecolor='white', edgecolor='none', transparent=False) # Save with specific size plt.figure(figsize=(10, 6)) # ... plotting code ... plt.savefig('sized_plot.png', dpi=150)","title":"Saving Figures"},{"location":"python/matplotlib/#interactive-features","text":"","title":"Interactive Features"},{"location":"python/matplotlib/#event-handling","text":"# Click event handling def onclick(event): if event.inaxes is not None: print(f'Clicked at: ({event.xdata:.2f}, {event.ydata:.2f})') fig, ax = plt.subplots() ax.plot([1, 2, 3], [1, 4, 2]) fig.canvas.mpl_connect('button_press_event', onclick) plt.show() # Key press events def onkey(event): print(f'Key pressed: {event.key}') fig.canvas.mpl_connect('key_press_event', onkey)","title":"Event Handling"},{"location":"python/matplotlib/#widgets-requires-widget-backend","text":"from matplotlib.widgets import Button, Slider # Interactive slider fig, ax = plt.subplots() plt.subplots_adjust(bottom=0.25) # Initial plot t = np.linspace(0, 10, 1000) a0 = 1 f0 = 1 s = a0 * np.sin(2 * np.pi * f0 * t) l, = plt.plot(t, s) # Slider ax_freq = plt.axes([0.25, 0.1, 0.5, 0.03]) slider = Slider(ax_freq, 'Frequency', 0.1, 5.0, valinit=f0) def update(val): freq = slider.val l.set_ydata(a0 * np.sin(2 * np.pi * freq * t)) fig.canvas.draw_idle() slider.on_changed(update) plt.show()","title":"Widgets (requires widget backend)"},{"location":"python/matplotlib/#advanced-features","text":"","title":"Advanced Features"},{"location":"python/matplotlib/#animations","text":"from matplotlib.animation import FuncAnimation # Animated sine wave fig, ax = plt.subplots() x = np.linspace(0, 2*np.pi, 100) line, = ax.plot(x, np.sin(x)) def animate(frame): line.set_ydata(np.sin(x + frame/10)) return line, ani = FuncAnimation(fig, animate, frames=200, interval=50, blit=True) plt.show() # Save animation ani.save('animation.gif', writer='pillow', fps=20) ani.save('animation.mp4', writer='ffmpeg', fps=30)","title":"Animations"},{"location":"python/matplotlib/#custom-colormaps","text":"from matplotlib.colors import LinearSegmentedColormap # Create custom colormap colors = ['red', 'yellow', 'green', 'blue'] n_bins = 100 cmap = LinearSegmentedColormap.from_list('custom', colors, N=n_bins) # Use custom colormap data = np.random.rand(10, 10) plt.imshow(data, cmap=cmap) plt.colorbar()","title":"Custom Colormaps"},{"location":"python/matplotlib/#dual-axes","text":"# Two different y-axes fig, ax1 = plt.subplots() x = np.linspace(0, 10, 100) y1 = np.sin(x) y2 = np.exp(x/5) # First y-axis ax1.plot(x, y1, 'g-') ax1.set_xlabel('X data') ax1.set_ylabel('sin(x)', color='g') ax1.tick_params(axis='y', labelcolor='g') # Second y-axis ax2 = ax1.twinx() ax2.plot(x, y2, 'b-') ax2.set_ylabel('exp(x/5)', color='b') ax2.tick_params(axis='y', labelcolor='b') plt.show()","title":"Dual Axes"},{"location":"python/matplotlib/#customization-best-practices","text":"","title":"Customization &amp; Best Practices"},{"location":"python/matplotlib/#style-sheets","text":"# Available styles print(plt.style.available) # Use built-in styles plt.style.use('seaborn-v0_8') plt.style.use('ggplot') plt.style.use('dark_background') # Use multiple styles plt.style.use(['seaborn-v0_8', 'seaborn-v0_8-darkgrid']) # Context manager for temporary style with plt.style.context('bmh'): plt.plot([1, 2, 3], [1, 4, 2]) plt.show()","title":"Style Sheets"},{"location":"python/matplotlib/#rc-parameters","text":"# Global settings plt.rcParams['figure.figsize'] = [10, 6] plt.rcParams['font.size'] = 12 plt.rcParams['lines.linewidth'] = 2 plt.rcParams['grid.alpha'] = 0.3 # Context manager for temporary settings with plt.rc_context({'font.size': 14, 'lines.linewidth': 3}): plt.plot([1, 2, 3], [1, 4, 2]) # Reset to defaults plt.rcdefaults()","title":"RC Parameters"},{"location":"python/matplotlib/#performance-tips","text":"# Use appropriate backends import matplotlib matplotlib.use('Agg') # For server/batch processing # Batch plotting plt.ioff() # Turn off interactive mode for i in range(100): plt.figure() plt.plot(data[i]) plt.savefig(f'plot_{i}.png') plt.close() # Important: close figures to free memory # Efficient line collection for many lines from matplotlib.collections import LineCollection lines = [np.column_stack([x, y + i]) for i in range(100)] lc = LineCollection(lines, linewidths=0.5) ax.add_collection(lc)","title":"Performance Tips"},{"location":"python/matplotlib/#integration-with-other-libraries","text":"","title":"Integration with Other Libraries"},{"location":"python/matplotlib/#numpy-integration","text":"# Matplotlib works seamlessly with NumPy arrays x = np.linspace(0, 10, 100) y = np.sin(x) plt.plot(x, y) # Masked arrays y_masked = np.ma.masked_where(y < 0, y) plt.plot(x, y_masked)","title":"NumPy Integration"},{"location":"python/matplotlib/#pandas-integration","text":"import pandas as pd # DataFrame plotting df = pd.DataFrame({ 'x': range(10), 'y1': np.random.randn(10), 'y2': np.random.randn(10) }) # Direct pandas plotting df.plot(x='x', y=['y1', 'y2']) # Using matplotlib directly plt.plot(df['x'], df['y1'], label='y1') plt.plot(df['x'], df['y2'], label='y2') plt.legend()","title":"Pandas Integration"},{"location":"python/matplotlib/#common-gotchas-best-practices","text":"","title":"Common Gotchas &amp; Best Practices"},{"location":"python/matplotlib/#memory-management","text":"# Always close figures when done fig, ax = plt.subplots() # ... plotting code ... plt.close(fig) # or plt.close('all') # Clear current figure plt.clf() # Clear current axes plt.cla()","title":"Memory Management"},{"location":"python/matplotlib/#backend-issues","text":"# Check current backend print(plt.get_backend()) # Set backend before importing pyplot import matplotlib matplotlib.use('TkAgg') # Must be before importing pyplot import matplotlib.pyplot as plt","title":"Backend Issues"},{"location":"python/matplotlib/#common-patterns","text":"# Professional plotting setup def setup_plot(figsize=(10, 6)): fig, ax = plt.subplots(figsize=figsize) ax.spines['top'].set_visible(False) ax.spines['right'].set_visible(False) ax.grid(True, alpha=0.3) return fig, ax # Context manager for consistent styling from contextlib import contextmanager @contextmanager def plot_style(style='seaborn-v0_8', figsize=(10, 6)): with plt.style.context(style): fig, ax = plt.subplots(figsize=figsize) yield fig, ax plt.tight_layout() # Usage with plot_style() as (fig, ax): ax.plot([1, 2, 3], [1, 4, 2]) ax.set_title('Styled Plot') plt.show()","title":"Common Patterns"},{"location":"python/matplotlib/#quick-reference","text":"","title":"Quick Reference"},{"location":"python/matplotlib/#essential-functions","text":"Function Purpose Example plt.figure() Create new figure plt.figure(figsize=(8,6)) plt.subplot() Add subplot plt.subplot(2,2,1) plt.plot() Line plot plt.plot(x, y, 'r-') plt.scatter() Scatter plot plt.scatter(x, y, c=colors) plt.bar() Bar chart plt.bar(x, height) plt.hist() Histogram plt.hist(data, bins=20) plt.imshow() Display image/2D data plt.imshow(array, cmap='hot') plt.savefig() Save figure plt.savefig('plot.png', dpi=300)","title":"Essential Functions"},{"location":"python/matplotlib/#format-strings","text":"Code Meaning Code Meaning - Solid line o Circle marker -- Dashed line s Square marker -. Dash-dot line ^ Triangle up marker : Dotted line D Diamond marker r Red g Green b Blue k Black c Cyan m Magenta y Yellow w White","title":"Format Strings"},{"location":"python/matplotlib/#color-maps","text":"Common colormaps: viridis , plasma , inferno , magma , coolwarm , RdYlBu , seismic , hot , cool , spring , summer , autumn , winter , gray Use: plt.imshow(data, cmap='viridis')","title":"Color Maps"},{"location":"python/nltk/","text":"NLTK (Natural Language Toolkit) NLTK is a leading platform for building Python programs to work with human language data. It provides easy-to-use interfaces to over 50 corpora and lexical resources such as WordNet, along with a suite of text processing libraries for classification, tokenization, stemming, tagging, parsing, and semantic reasoning. Installation # Basic installation pip install nltk # Install with datasets pip install nltk[all] # Download specific data python -c \"import nltk; nltk.download('punkt')\" python -c \"import nltk; nltk.download('stopwords')\" python -c \"import nltk; nltk.download('vader_lexicon')\" python -c \"import nltk; nltk.download('wordnet')\" python -c \"import nltk; nltk.download('omw-1.4')\" # Download all datasets (large) python -c \"import nltk; nltk.download('all')\" Basic Setup import nltk from nltk.tokenize import word_tokenize, sent_tokenize from nltk.corpus import stopwords from nltk.stem import PorterStemmer, WordNetLemmatizer from nltk.tag import pos_tag from nltk.chunk import ne_chunk from nltk.sentiment import SentimentIntensityAnalyzer # Download required data (run once) nltk.download('punkt') nltk.download('stopwords') nltk.download('averaged_perceptron_tagger') nltk.download('maxent_ne_chunker') nltk.download('words') nltk.download('vader_lexicon') Core Functionality Text Tokenization # Sentence tokenization text = \"Hello world. This is NLTK. It's great for NLP!\" sentences = sent_tokenize(text) print(sentences) # ['Hello world.', 'This is NLTK.', \"It's great for NLP!\"] # Word tokenization words = word_tokenize(text) print(words) # ['Hello', 'world', '.', 'This', 'is', 'NLTK', '.', ...] # Custom tokenizers from nltk.tokenize import RegexpTokenizer, WhitespaceTokenizer, LineTokenizer # Only alphabetic tokens tokenizer = RegexpTokenizer(r'\\w+') tokens = tokenizer.tokenize(text) # Whitespace tokenization ws_tokenizer = WhitespaceTokenizer() tokens = ws_tokenizer.tokenize(text) Stop Words Removal from nltk.corpus import stopwords # Get English stopwords stop_words = set(stopwords.words('english')) # Filter stop words words = word_tokenize(\"This is a sample sentence with stop words.\") filtered_words = [w for w in words if w.lower() not in stop_words] print(filtered_words) # ['sample', 'sentence', 'stop', 'words', '.'] # Custom stop words custom_stops = stop_words.union({'sample', 'example'}) Stemming and Lemmatization # Porter Stemmer stemmer = PorterStemmer() words = [\"running\", \"runs\", \"ran\", \"runner\"] stems = [stemmer.stem(word) for word in words] print(stems) # ['run', 'run', 'ran', 'runner'] # WordNet Lemmatizer (more accurate) lemmatizer = WordNetLemmatizer() lemmas = [lemmatizer.lemmatize(word, pos='v') for word in words] print(lemmas) # ['run', 'run', 'run', 'runner'] # Lemmatize with different POS tags word = \"better\" print(lemmatizer.lemmatize(word, pos='a')) # good (adjective) print(lemmatizer.lemmatize(word, pos='r')) # well (adverb) Part-of-Speech Tagging # POS tagging text = \"The quick brown fox jumps over the lazy dog\" tokens = word_tokenize(text) pos_tags = pos_tag(tokens) print(pos_tags) # [('The', 'DT'), ('quick', 'JJ'), ('brown', 'JJ'), ('fox', 'NN'), ...] # Extract specific POS nouns = [word for word, pos in pos_tags if pos.startswith('N')] adjectives = [word for word, pos in pos_tags if pos.startswith('JJ')] # Universal POS tags from nltk.tag import pos_tag from nltk.corpus import brown universal_tags = pos_tag(tokens, tagset='universal') Named Entity Recognition # Named entity chunking tokens = word_tokenize(\"Barack Obama was the 44th President of the United States.\") pos_tags = pos_tag(tokens) entities = ne_chunk(pos_tags) # Extract named entities from nltk import Tree def extract_entities(tree): entities = [] if hasattr(tree, 'label'): entities.append((tree.label(), [token for token, pos in tree.leaves()])) else: for child in tree: entities.extend(extract_entities(child)) return entities named_entities = extract_entities(entities) print(named_entities) # [('PERSON', ['Barack', 'Obama']), ...] Common Use Cases Sentiment Analysis # VADER sentiment analyzer sia = SentimentIntensityAnalyzer() texts = [ \"I love this product! It's amazing!\", \"This is terrible. I hate it.\", \"It's okay, nothing special.\", \"Best purchase ever! Highly recommend!\" ] for text in texts: scores = sia.polarity_scores(text) print(f\"Text: {text}\") print(f\"Positive: {scores['pos']:.3f}\") print(f\"Negative: {scores['neg']:.3f}\") print(f\"Neutral: {scores['neu']:.3f}\") print(f\"Compound: {scores['compound']:.3f}\") print(\"-\" * 50) # Simple sentiment classification def classify_sentiment(text): score = sia.polarity_scores(text)['compound'] if score >= 0.05: return 'Positive' elif score <= -0.05: return 'Negative' else: return 'Neutral' Text Preprocessing Pipeline import re import string def preprocess_text(text, lowercase=True, remove_punctuation=True, remove_stopwords=True, lemmatize=True): \"\"\"Complete text preprocessing pipeline\"\"\" # Convert to lowercase if lowercase: text = text.lower() # Remove URLs, emails, mentions text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE) text = re.sub(r'\\@\\w+|\\#\\w+', '', text) # Remove punctuation if remove_punctuation: text = text.translate(str.maketrans('', '', string.punctuation)) # Tokenization tokens = word_tokenize(text) # Remove stopwords if remove_stopwords: stop_words = set(stopwords.words('english')) tokens = [token for token in tokens if token not in stop_words] # Lemmatization if lemmatize: lemmatizer = WordNetLemmatizer() tokens = [lemmatizer.lemmatize(token) for token in tokens] return tokens # Usage text = \"I'm loving this new product! Check out https://example.com #awesome @company\" processed = preprocess_text(text) print(processed) # ['loving', 'new', 'product', 'check'] Frequency Analysis from nltk import FreqDist from collections import Counter # Word frequency distribution text = \"the quick brown fox jumps over the lazy dog the fox is quick\" tokens = word_tokenize(text.lower()) fdist = FreqDist(tokens) # Most common words print(fdist.most_common(5)) # [('the', 3), ('quick', 2), ('fox', 2), ...] # Plot frequency distribution fdist.plot(30, cumulative=False) # Conditional frequency distribution from nltk import ConditionalFreqDist from nltk.corpus import brown # Frequency by genre cfdist = ConditionalFreqDist( (genre, word) for genre in brown.categories() for word in brown.words(categories=genre) ) # Words most common in news vs romance cfdist['news'].most_common(10) cfdist['romance'].most_common(10) N-grams and Collocations from nltk import ngrams, collocations from nltk.collocations import BigramCollocationFinder, TrigramCollocationFinder # Generate n-grams text = \"the quick brown fox jumps over the lazy dog\" tokens = word_tokenize(text) # Bigrams bigrams = list(ngrams(tokens, 2)) print(bigrams[:5]) # [('the', 'quick'), ('quick', 'brown'), ...] # Trigrams trigrams = list(ngrams(tokens, 3)) print(trigrams[:3]) # [('the', 'quick', 'brown'), ...] # Find collocations from nltk.corpus import text1 # Moby Dick # Bigram collocations bigram_measures = collocations.BigramAssocMeasures() finder = BigramCollocationFinder.from_words(text1.tokens) finder.apply_freq_filter(3) # Only bigrams that appear 3+ times # Best collocations by PMI collocations = finder.nbest(bigram_measures.pmi, 10) print(collocations) # [('Sperm', 'Whale'), ('Moby', 'Dick'), ...] Advanced Features Custom Text Classification import random from nltk.corpus import movie_reviews from nltk.tokenize import word_tokenize # Prepare movie review dataset documents = [(list(movie_reviews.words(fileid)), category) for category in movie_reviews.categories() for fileid in movie_reviews.fileids(category)] random.shuffle(documents) # Feature extraction def document_features(document): \"\"\"Extract features from document\"\"\" words = set(document) features = {} # Word presence features for word in word_features: features[f'contains({word})'] = (word in words) return features # Get most informative words all_words = nltk.FreqDist(w.lower() for w in movie_reviews.words()) word_features = list(all_words)[:2000] # Create feature sets featuresets = [(document_features(d), c) for (d, c) in documents] train_set, test_set = featuresets[100:], featuresets[:100] # Train classifier classifier = nltk.NaiveBayesClassifier.train(train_set) # Evaluate accuracy = nltk.classify.accuracy(classifier, test_set) print(f\"Accuracy: {accuracy:.3f}\") # Show most informative features classifier.show_most_informative_features(5) Working with Corpora from nltk.corpus import gutenberg, reuters, wordnet # Gutenberg corpus print(gutenberg.fileids()) # List of books emma = gutenberg.words('austen-emma.txt') print(f\"Emma has {len(emma)} words\") # Reuters corpus print(reuters.categories()) # News categories finance_docs = reuters.fileids('money-fx') print(f\"Finance articles: {len(finance_docs)}\") # WordNet (semantic dictionary) from nltk.corpus import wordnet as wn # Synsets (synonym sets) dog_synsets = wn.synsets('dog') print(dog_synsets[0].definition()) # 'a member of the genus Canis...' # Hypernyms and hyponyms dog = wn.synset('dog.n.01') print(dog.hypernyms()) # More general terms print(dog.hyponyms()) # More specific terms # Semantic similarity dog = wn.synset('dog.n.01') cat = wn.synset('cat.n.01') similarity = dog.path_similarity(cat) print(f\"Dog-cat similarity: {similarity:.3f}\") Text Parsing and Chunking # Grammar-based chunking grammar = r\"\"\" NP: {<DT|JJ|NN.*>+} # Chunk sequences of DT, JJ, NN PP: {<IN><NP>} # Chunk prepositions followed by NP VP: {<VB.*><NP|PP|CLAUSE>+$} # Chunk verbs followed by NP or PP \"\"\" chunk_parser = nltk.RegexpParser(grammar) sentence = \"The little yellow dog barked at the cat\" tokens = word_tokenize(sentence) pos_tags = pos_tag(tokens) parsed = chunk_parser.parse(pos_tags) # Draw parse tree parsed.draw() # Extract noun phrases def extract_noun_phrases(tree): noun_phrases = [] for subtree in tree: if hasattr(subtree, 'label') and subtree.label() == 'NP': np = ' '.join([token for token, pos in subtree.leaves()]) noun_phrases.append(np) return noun_phrases nps = extract_noun_phrases(parsed) print(nps) # ['The little yellow dog', 'the cat'] Integration with Other Libraries With Pandas for Data Analysis import pandas as pd import nltk from nltk.sentiment import SentimentIntensityAnalyzer # Create sample dataset data = { 'review': [ \"This product is amazing! Love it!\", \"Terrible quality. Very disappointed.\", \"It's okay, nothing special.\", \"Best purchase I've ever made!\" ], 'rating': [5, 1, 3, 5] } df = pd.DataFrame(data) # Add sentiment analysis sia = SentimentIntensityAnalyzer() df['sentiment_compound'] = df['review'].apply( lambda x: sia.polarity_scores(x)['compound'] ) # Add preprocessing def preprocess_for_analysis(text): tokens = word_tokenize(text.lower()) stop_words = set(stopwords.words('english')) tokens = [token for token in tokens if token.isalpha() and token not in stop_words] return ' '.join(tokens) df['processed_text'] = df['review'].apply(preprocess_for_analysis) df['word_count'] = df['processed_text'].apply(lambda x: len(x.split())) print(df[['review', 'sentiment_compound', 'word_count']]) With Scikit-learn for ML from sklearn.feature_extraction.text import TfidfVectorizer from sklearn.model_selection import train_test_split from sklearn.naive_bayes import MultinomialNB from sklearn.pipeline import Pipeline from sklearn.metrics import classification_report # Custom tokenizer using NLTK def nltk_tokenizer(text): tokens = word_tokenize(text.lower()) return [lemmatizer.lemmatize(token) for token in tokens if token.isalpha()] # Create pipeline pipeline = Pipeline([ ('tfidf', TfidfVectorizer(tokenizer=nltk_tokenizer, stop_words='english')), ('classifier', MultinomialNB()) ]) # Train model (using movie reviews data) X = [' '.join(d) for d, c in documents] y = [c for d, c in documents] X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42) pipeline.fit(X_train, y_train) predictions = pipeline.predict(X_test) print(classification_report(y_test, predictions)) Best Practices Performance Tips # 1. Cache expensive operations import functools @functools.lru_cache(maxsize=1000) def cached_lemmatize(word, pos='n'): return lemmatizer.lemmatize(word, pos=pos) # 2. Use generators for large datasets def process_large_corpus(file_path): with open(file_path, 'r') as f: for line in f: yield preprocess_text(line.strip()) # 3. Batch processing def batch_sentiment_analysis(texts, batch_size=100): sia = SentimentIntensityAnalyzer() results = [] for i in range(0, len(texts), batch_size): batch = texts[i:i + batch_size] batch_results = [sia.polarity_scores(text) for text in batch] results.extend(batch_results) return results # 4. Efficient stopword removal stop_words = set(stopwords.words('english')) # Create once, reuse many times def remove_stopwords_efficiently(tokens): return [token for token in tokens if token.lower() not in stop_words] Memory Management # For large text processing import gc from collections import deque def process_large_text_stream(text_stream, window_size=1000): \"\"\"Process large text streams efficiently\"\"\" buffer = deque(maxlen=window_size) for text in text_stream: # Process text processed = preprocess_text(text) buffer.append(processed) # Periodic cleanup if len(buffer) == window_size: # Do something with buffer yield list(buffer) gc.collect() # Force garbage collection Error Handling def robust_text_processing(text): \"\"\"Text processing with error handling\"\"\" try: # Validate input if not isinstance(text, str): text = str(text) if not text.strip(): return [] # Process with fallbacks try: tokens = word_tokenize(text) except: # Fallback to simple split tokens = text.split() # Safe POS tagging try: pos_tags = pos_tag(tokens) except: pos_tags = [(token, 'NN') for token in tokens] return pos_tags except Exception as e: print(f\"Error processing text: {e}\") return [] Real-world Examples Complete Sentiment Analysis Pipeline class SentimentAnalyzer: def __init__(self): self.sia = SentimentIntensityAnalyzer() self.lemmatizer = WordNetLemmatizer() self.stop_words = set(stopwords.words('english')) def preprocess(self, text): \"\"\"Clean and preprocess text\"\"\" # Basic cleaning text = re.sub(r'http\\S+|www\\S+', '', text) text = re.sub(r'[^a-zA-Z\\s]', '', text) # Tokenization and normalization tokens = word_tokenize(text.lower()) tokens = [self.lemmatizer.lemmatize(token) for token in tokens if token not in self.stop_words and len(token) > 2] return ' '.join(tokens) def analyze(self, text): \"\"\"Perform sentiment analysis\"\"\" # Preprocess clean_text = self.preprocess(text) # Get sentiment scores scores = self.sia.polarity_scores(text) # Use original text for better accuracy # Classify sentiment compound = scores['compound'] if compound >= 0.05: sentiment = 'positive' elif compound <= -0.05: sentiment = 'negative' else: sentiment = 'neutral' return { 'sentiment': sentiment, 'confidence': abs(compound), 'scores': scores, 'processed_text': clean_text } # Usage analyzer = SentimentAnalyzer() result = analyzer.analyze(\"I absolutely love this new product! It's fantastic!\") print(result) Text Summarization with NLTK from nltk.tokenize import sent_tokenize from collections import Counter import math def extractive_summarization(text, num_sentences=3): \"\"\"Simple extractive summarization using TF-IDF\"\"\" # Tokenize into sentences sentences = sent_tokenize(text) if len(sentences) <= num_sentences: return text # Tokenize and preprocess all_words = [] sentence_words = [] for sentence in sentences: words = word_tokenize(sentence.lower()) words = [word for word in words if word.isalpha() and word not in stop_words] sentence_words.append(words) all_words.extend(words) # Calculate word frequencies word_freq = Counter(all_words) # Calculate sentence scores sentence_scores = [] for words in sentence_words: score = sum(word_freq[word] for word in words) sentence_scores.append(score) # Get top sentences top_indices = sorted(range(len(sentence_scores)), key=lambda i: sentence_scores[i], reverse=True)[:num_sentences] # Return sentences in original order top_indices.sort() summary_sentences = [sentences[i] for i in top_indices] return ' '.join(summary_sentences) # Usage long_text = \"\"\" Natural language processing (NLP) is a subfield of linguistics, computer science, and artificial intelligence concerned with the interactions between computers and human language. In particular, it focuses on programming computers to process and analyze large amounts of natural language data. The result is a computer capable of \"understanding\" the contents of documents, including the contextual nuances of the language within them. The technology can then accurately extract information and insights contained in the documents as well as categorize and organize the documents themselves. Challenges in natural language processing frequently involve speech recognition, natural language understanding, and natural language generation. \"\"\" summary = extractive_summarization(long_text, num_sentences=2) print(summary) This cheat sheet covers the essential aspects of NLTK for natural language processing tasks. The library is particularly strong in academic and research contexts, providing comprehensive tools for text analysis, linguistic processing, and building NLP applications. Its extensive corpus collection and built-in algorithms make it an excellent choice for learning NLP concepts and rapid prototyping.","title":"NLTK (Natural Language Toolkit)"},{"location":"python/nltk/#nltk-natural-language-toolkit","text":"NLTK is a leading platform for building Python programs to work with human language data. It provides easy-to-use interfaces to over 50 corpora and lexical resources such as WordNet, along with a suite of text processing libraries for classification, tokenization, stemming, tagging, parsing, and semantic reasoning.","title":"NLTK (Natural Language Toolkit)"},{"location":"python/nltk/#installation","text":"# Basic installation pip install nltk # Install with datasets pip install nltk[all] # Download specific data python -c \"import nltk; nltk.download('punkt')\" python -c \"import nltk; nltk.download('stopwords')\" python -c \"import nltk; nltk.download('vader_lexicon')\" python -c \"import nltk; nltk.download('wordnet')\" python -c \"import nltk; nltk.download('omw-1.4')\" # Download all datasets (large) python -c \"import nltk; nltk.download('all')\"","title":"Installation"},{"location":"python/nltk/#basic-setup","text":"import nltk from nltk.tokenize import word_tokenize, sent_tokenize from nltk.corpus import stopwords from nltk.stem import PorterStemmer, WordNetLemmatizer from nltk.tag import pos_tag from nltk.chunk import ne_chunk from nltk.sentiment import SentimentIntensityAnalyzer # Download required data (run once) nltk.download('punkt') nltk.download('stopwords') nltk.download('averaged_perceptron_tagger') nltk.download('maxent_ne_chunker') nltk.download('words') nltk.download('vader_lexicon')","title":"Basic Setup"},{"location":"python/nltk/#core-functionality","text":"","title":"Core Functionality"},{"location":"python/nltk/#text-tokenization","text":"# Sentence tokenization text = \"Hello world. This is NLTK. It's great for NLP!\" sentences = sent_tokenize(text) print(sentences) # ['Hello world.', 'This is NLTK.', \"It's great for NLP!\"] # Word tokenization words = word_tokenize(text) print(words) # ['Hello', 'world', '.', 'This', 'is', 'NLTK', '.', ...] # Custom tokenizers from nltk.tokenize import RegexpTokenizer, WhitespaceTokenizer, LineTokenizer # Only alphabetic tokens tokenizer = RegexpTokenizer(r'\\w+') tokens = tokenizer.tokenize(text) # Whitespace tokenization ws_tokenizer = WhitespaceTokenizer() tokens = ws_tokenizer.tokenize(text)","title":"Text Tokenization"},{"location":"python/nltk/#stop-words-removal","text":"from nltk.corpus import stopwords # Get English stopwords stop_words = set(stopwords.words('english')) # Filter stop words words = word_tokenize(\"This is a sample sentence with stop words.\") filtered_words = [w for w in words if w.lower() not in stop_words] print(filtered_words) # ['sample', 'sentence', 'stop', 'words', '.'] # Custom stop words custom_stops = stop_words.union({'sample', 'example'})","title":"Stop Words Removal"},{"location":"python/nltk/#stemming-and-lemmatization","text":"# Porter Stemmer stemmer = PorterStemmer() words = [\"running\", \"runs\", \"ran\", \"runner\"] stems = [stemmer.stem(word) for word in words] print(stems) # ['run', 'run', 'ran', 'runner'] # WordNet Lemmatizer (more accurate) lemmatizer = WordNetLemmatizer() lemmas = [lemmatizer.lemmatize(word, pos='v') for word in words] print(lemmas) # ['run', 'run', 'run', 'runner'] # Lemmatize with different POS tags word = \"better\" print(lemmatizer.lemmatize(word, pos='a')) # good (adjective) print(lemmatizer.lemmatize(word, pos='r')) # well (adverb)","title":"Stemming and Lemmatization"},{"location":"python/nltk/#part-of-speech-tagging","text":"# POS tagging text = \"The quick brown fox jumps over the lazy dog\" tokens = word_tokenize(text) pos_tags = pos_tag(tokens) print(pos_tags) # [('The', 'DT'), ('quick', 'JJ'), ('brown', 'JJ'), ('fox', 'NN'), ...] # Extract specific POS nouns = [word for word, pos in pos_tags if pos.startswith('N')] adjectives = [word for word, pos in pos_tags if pos.startswith('JJ')] # Universal POS tags from nltk.tag import pos_tag from nltk.corpus import brown universal_tags = pos_tag(tokens, tagset='universal')","title":"Part-of-Speech Tagging"},{"location":"python/nltk/#named-entity-recognition","text":"# Named entity chunking tokens = word_tokenize(\"Barack Obama was the 44th President of the United States.\") pos_tags = pos_tag(tokens) entities = ne_chunk(pos_tags) # Extract named entities from nltk import Tree def extract_entities(tree): entities = [] if hasattr(tree, 'label'): entities.append((tree.label(), [token for token, pos in tree.leaves()])) else: for child in tree: entities.extend(extract_entities(child)) return entities named_entities = extract_entities(entities) print(named_entities) # [('PERSON', ['Barack', 'Obama']), ...]","title":"Named Entity Recognition"},{"location":"python/nltk/#common-use-cases","text":"","title":"Common Use Cases"},{"location":"python/nltk/#sentiment-analysis","text":"# VADER sentiment analyzer sia = SentimentIntensityAnalyzer() texts = [ \"I love this product! It's amazing!\", \"This is terrible. I hate it.\", \"It's okay, nothing special.\", \"Best purchase ever! Highly recommend!\" ] for text in texts: scores = sia.polarity_scores(text) print(f\"Text: {text}\") print(f\"Positive: {scores['pos']:.3f}\") print(f\"Negative: {scores['neg']:.3f}\") print(f\"Neutral: {scores['neu']:.3f}\") print(f\"Compound: {scores['compound']:.3f}\") print(\"-\" * 50) # Simple sentiment classification def classify_sentiment(text): score = sia.polarity_scores(text)['compound'] if score >= 0.05: return 'Positive' elif score <= -0.05: return 'Negative' else: return 'Neutral'","title":"Sentiment Analysis"},{"location":"python/nltk/#text-preprocessing-pipeline","text":"import re import string def preprocess_text(text, lowercase=True, remove_punctuation=True, remove_stopwords=True, lemmatize=True): \"\"\"Complete text preprocessing pipeline\"\"\" # Convert to lowercase if lowercase: text = text.lower() # Remove URLs, emails, mentions text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE) text = re.sub(r'\\@\\w+|\\#\\w+', '', text) # Remove punctuation if remove_punctuation: text = text.translate(str.maketrans('', '', string.punctuation)) # Tokenization tokens = word_tokenize(text) # Remove stopwords if remove_stopwords: stop_words = set(stopwords.words('english')) tokens = [token for token in tokens if token not in stop_words] # Lemmatization if lemmatize: lemmatizer = WordNetLemmatizer() tokens = [lemmatizer.lemmatize(token) for token in tokens] return tokens # Usage text = \"I'm loving this new product! Check out https://example.com #awesome @company\" processed = preprocess_text(text) print(processed) # ['loving', 'new', 'product', 'check']","title":"Text Preprocessing Pipeline"},{"location":"python/nltk/#frequency-analysis","text":"from nltk import FreqDist from collections import Counter # Word frequency distribution text = \"the quick brown fox jumps over the lazy dog the fox is quick\" tokens = word_tokenize(text.lower()) fdist = FreqDist(tokens) # Most common words print(fdist.most_common(5)) # [('the', 3), ('quick', 2), ('fox', 2), ...] # Plot frequency distribution fdist.plot(30, cumulative=False) # Conditional frequency distribution from nltk import ConditionalFreqDist from nltk.corpus import brown # Frequency by genre cfdist = ConditionalFreqDist( (genre, word) for genre in brown.categories() for word in brown.words(categories=genre) ) # Words most common in news vs romance cfdist['news'].most_common(10) cfdist['romance'].most_common(10)","title":"Frequency Analysis"},{"location":"python/nltk/#n-grams-and-collocations","text":"from nltk import ngrams, collocations from nltk.collocations import BigramCollocationFinder, TrigramCollocationFinder # Generate n-grams text = \"the quick brown fox jumps over the lazy dog\" tokens = word_tokenize(text) # Bigrams bigrams = list(ngrams(tokens, 2)) print(bigrams[:5]) # [('the', 'quick'), ('quick', 'brown'), ...] # Trigrams trigrams = list(ngrams(tokens, 3)) print(trigrams[:3]) # [('the', 'quick', 'brown'), ...] # Find collocations from nltk.corpus import text1 # Moby Dick # Bigram collocations bigram_measures = collocations.BigramAssocMeasures() finder = BigramCollocationFinder.from_words(text1.tokens) finder.apply_freq_filter(3) # Only bigrams that appear 3+ times # Best collocations by PMI collocations = finder.nbest(bigram_measures.pmi, 10) print(collocations) # [('Sperm', 'Whale'), ('Moby', 'Dick'), ...]","title":"N-grams and Collocations"},{"location":"python/nltk/#advanced-features","text":"","title":"Advanced Features"},{"location":"python/nltk/#custom-text-classification","text":"import random from nltk.corpus import movie_reviews from nltk.tokenize import word_tokenize # Prepare movie review dataset documents = [(list(movie_reviews.words(fileid)), category) for category in movie_reviews.categories() for fileid in movie_reviews.fileids(category)] random.shuffle(documents) # Feature extraction def document_features(document): \"\"\"Extract features from document\"\"\" words = set(document) features = {} # Word presence features for word in word_features: features[f'contains({word})'] = (word in words) return features # Get most informative words all_words = nltk.FreqDist(w.lower() for w in movie_reviews.words()) word_features = list(all_words)[:2000] # Create feature sets featuresets = [(document_features(d), c) for (d, c) in documents] train_set, test_set = featuresets[100:], featuresets[:100] # Train classifier classifier = nltk.NaiveBayesClassifier.train(train_set) # Evaluate accuracy = nltk.classify.accuracy(classifier, test_set) print(f\"Accuracy: {accuracy:.3f}\") # Show most informative features classifier.show_most_informative_features(5)","title":"Custom Text Classification"},{"location":"python/nltk/#working-with-corpora","text":"from nltk.corpus import gutenberg, reuters, wordnet # Gutenberg corpus print(gutenberg.fileids()) # List of books emma = gutenberg.words('austen-emma.txt') print(f\"Emma has {len(emma)} words\") # Reuters corpus print(reuters.categories()) # News categories finance_docs = reuters.fileids('money-fx') print(f\"Finance articles: {len(finance_docs)}\") # WordNet (semantic dictionary) from nltk.corpus import wordnet as wn # Synsets (synonym sets) dog_synsets = wn.synsets('dog') print(dog_synsets[0].definition()) # 'a member of the genus Canis...' # Hypernyms and hyponyms dog = wn.synset('dog.n.01') print(dog.hypernyms()) # More general terms print(dog.hyponyms()) # More specific terms # Semantic similarity dog = wn.synset('dog.n.01') cat = wn.synset('cat.n.01') similarity = dog.path_similarity(cat) print(f\"Dog-cat similarity: {similarity:.3f}\")","title":"Working with Corpora"},{"location":"python/nltk/#text-parsing-and-chunking","text":"# Grammar-based chunking grammar = r\"\"\" NP: {<DT|JJ|NN.*>+} # Chunk sequences of DT, JJ, NN PP: {<IN><NP>} # Chunk prepositions followed by NP VP: {<VB.*><NP|PP|CLAUSE>+$} # Chunk verbs followed by NP or PP \"\"\" chunk_parser = nltk.RegexpParser(grammar) sentence = \"The little yellow dog barked at the cat\" tokens = word_tokenize(sentence) pos_tags = pos_tag(tokens) parsed = chunk_parser.parse(pos_tags) # Draw parse tree parsed.draw() # Extract noun phrases def extract_noun_phrases(tree): noun_phrases = [] for subtree in tree: if hasattr(subtree, 'label') and subtree.label() == 'NP': np = ' '.join([token for token, pos in subtree.leaves()]) noun_phrases.append(np) return noun_phrases nps = extract_noun_phrases(parsed) print(nps) # ['The little yellow dog', 'the cat']","title":"Text Parsing and Chunking"},{"location":"python/nltk/#integration-with-other-libraries","text":"","title":"Integration with Other Libraries"},{"location":"python/nltk/#with-pandas-for-data-analysis","text":"import pandas as pd import nltk from nltk.sentiment import SentimentIntensityAnalyzer # Create sample dataset data = { 'review': [ \"This product is amazing! Love it!\", \"Terrible quality. Very disappointed.\", \"It's okay, nothing special.\", \"Best purchase I've ever made!\" ], 'rating': [5, 1, 3, 5] } df = pd.DataFrame(data) # Add sentiment analysis sia = SentimentIntensityAnalyzer() df['sentiment_compound'] = df['review'].apply( lambda x: sia.polarity_scores(x)['compound'] ) # Add preprocessing def preprocess_for_analysis(text): tokens = word_tokenize(text.lower()) stop_words = set(stopwords.words('english')) tokens = [token for token in tokens if token.isalpha() and token not in stop_words] return ' '.join(tokens) df['processed_text'] = df['review'].apply(preprocess_for_analysis) df['word_count'] = df['processed_text'].apply(lambda x: len(x.split())) print(df[['review', 'sentiment_compound', 'word_count']])","title":"With Pandas for Data Analysis"},{"location":"python/nltk/#with-scikit-learn-for-ml","text":"from sklearn.feature_extraction.text import TfidfVectorizer from sklearn.model_selection import train_test_split from sklearn.naive_bayes import MultinomialNB from sklearn.pipeline import Pipeline from sklearn.metrics import classification_report # Custom tokenizer using NLTK def nltk_tokenizer(text): tokens = word_tokenize(text.lower()) return [lemmatizer.lemmatize(token) for token in tokens if token.isalpha()] # Create pipeline pipeline = Pipeline([ ('tfidf', TfidfVectorizer(tokenizer=nltk_tokenizer, stop_words='english')), ('classifier', MultinomialNB()) ]) # Train model (using movie reviews data) X = [' '.join(d) for d, c in documents] y = [c for d, c in documents] X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42) pipeline.fit(X_train, y_train) predictions = pipeline.predict(X_test) print(classification_report(y_test, predictions))","title":"With Scikit-learn for ML"},{"location":"python/nltk/#best-practices","text":"","title":"Best Practices"},{"location":"python/nltk/#performance-tips","text":"# 1. Cache expensive operations import functools @functools.lru_cache(maxsize=1000) def cached_lemmatize(word, pos='n'): return lemmatizer.lemmatize(word, pos=pos) # 2. Use generators for large datasets def process_large_corpus(file_path): with open(file_path, 'r') as f: for line in f: yield preprocess_text(line.strip()) # 3. Batch processing def batch_sentiment_analysis(texts, batch_size=100): sia = SentimentIntensityAnalyzer() results = [] for i in range(0, len(texts), batch_size): batch = texts[i:i + batch_size] batch_results = [sia.polarity_scores(text) for text in batch] results.extend(batch_results) return results # 4. Efficient stopword removal stop_words = set(stopwords.words('english')) # Create once, reuse many times def remove_stopwords_efficiently(tokens): return [token for token in tokens if token.lower() not in stop_words]","title":"Performance Tips"},{"location":"python/nltk/#memory-management","text":"# For large text processing import gc from collections import deque def process_large_text_stream(text_stream, window_size=1000): \"\"\"Process large text streams efficiently\"\"\" buffer = deque(maxlen=window_size) for text in text_stream: # Process text processed = preprocess_text(text) buffer.append(processed) # Periodic cleanup if len(buffer) == window_size: # Do something with buffer yield list(buffer) gc.collect() # Force garbage collection","title":"Memory Management"},{"location":"python/nltk/#error-handling","text":"def robust_text_processing(text): \"\"\"Text processing with error handling\"\"\" try: # Validate input if not isinstance(text, str): text = str(text) if not text.strip(): return [] # Process with fallbacks try: tokens = word_tokenize(text) except: # Fallback to simple split tokens = text.split() # Safe POS tagging try: pos_tags = pos_tag(tokens) except: pos_tags = [(token, 'NN') for token in tokens] return pos_tags except Exception as e: print(f\"Error processing text: {e}\") return []","title":"Error Handling"},{"location":"python/nltk/#real-world-examples","text":"","title":"Real-world Examples"},{"location":"python/nltk/#complete-sentiment-analysis-pipeline","text":"class SentimentAnalyzer: def __init__(self): self.sia = SentimentIntensityAnalyzer() self.lemmatizer = WordNetLemmatizer() self.stop_words = set(stopwords.words('english')) def preprocess(self, text): \"\"\"Clean and preprocess text\"\"\" # Basic cleaning text = re.sub(r'http\\S+|www\\S+', '', text) text = re.sub(r'[^a-zA-Z\\s]', '', text) # Tokenization and normalization tokens = word_tokenize(text.lower()) tokens = [self.lemmatizer.lemmatize(token) for token in tokens if token not in self.stop_words and len(token) > 2] return ' '.join(tokens) def analyze(self, text): \"\"\"Perform sentiment analysis\"\"\" # Preprocess clean_text = self.preprocess(text) # Get sentiment scores scores = self.sia.polarity_scores(text) # Use original text for better accuracy # Classify sentiment compound = scores['compound'] if compound >= 0.05: sentiment = 'positive' elif compound <= -0.05: sentiment = 'negative' else: sentiment = 'neutral' return { 'sentiment': sentiment, 'confidence': abs(compound), 'scores': scores, 'processed_text': clean_text } # Usage analyzer = SentimentAnalyzer() result = analyzer.analyze(\"I absolutely love this new product! It's fantastic!\") print(result)","title":"Complete Sentiment Analysis Pipeline"},{"location":"python/nltk/#text-summarization-with-nltk","text":"from nltk.tokenize import sent_tokenize from collections import Counter import math def extractive_summarization(text, num_sentences=3): \"\"\"Simple extractive summarization using TF-IDF\"\"\" # Tokenize into sentences sentences = sent_tokenize(text) if len(sentences) <= num_sentences: return text # Tokenize and preprocess all_words = [] sentence_words = [] for sentence in sentences: words = word_tokenize(sentence.lower()) words = [word for word in words if word.isalpha() and word not in stop_words] sentence_words.append(words) all_words.extend(words) # Calculate word frequencies word_freq = Counter(all_words) # Calculate sentence scores sentence_scores = [] for words in sentence_words: score = sum(word_freq[word] for word in words) sentence_scores.append(score) # Get top sentences top_indices = sorted(range(len(sentence_scores)), key=lambda i: sentence_scores[i], reverse=True)[:num_sentences] # Return sentences in original order top_indices.sort() summary_sentences = [sentences[i] for i in top_indices] return ' '.join(summary_sentences) # Usage long_text = \"\"\" Natural language processing (NLP) is a subfield of linguistics, computer science, and artificial intelligence concerned with the interactions between computers and human language. In particular, it focuses on programming computers to process and analyze large amounts of natural language data. The result is a computer capable of \"understanding\" the contents of documents, including the contextual nuances of the language within them. The technology can then accurately extract information and insights contained in the documents as well as categorize and organize the documents themselves. Challenges in natural language processing frequently involve speech recognition, natural language understanding, and natural language generation. \"\"\" summary = extractive_summarization(long_text, num_sentences=2) print(summary) This cheat sheet covers the essential aspects of NLTK for natural language processing tasks. The library is particularly strong in academic and research contexts, providing comprehensive tools for text analysis, linguistic processing, and building NLP applications. Its extensive corpus collection and built-in algorithms make it an excellent choice for learning NLP concepts and rapid prototyping.","title":"Text Summarization with NLTK"},{"location":"python/numpy/","text":"NumPy Installation pip install numpy Import import numpy as np Array Creation Basic Creation # From lists arr = np.array([1, 2, 3, 4]) arr_2d = np.array([[1, 2], [3, 4]]) # Zeros, ones, empty np.zeros((3, 4)) # 3x4 array of zeros np.ones((2, 3)) # 2x3 array of ones np.empty((2, 2)) # uninitialized 2x2 array # Identity matrix np.eye(3) # 3x3 identity matrix np.identity(4) # 4x4 identity matrix Range Arrays np.arange(10) # [0, 1, 2, ..., 9] np.arange(2, 10, 2) # [2, 4, 6, 8] np.linspace(0, 1, 5) # 5 evenly spaced values from 0 to 1 Random Arrays np.random.random((3, 3)) # 3x3 random floats [0, 1) np.random.randint(0, 10, 5) # 5 random ints [0, 10) np.random.normal(0, 1, 100) # 100 samples from normal distribution np.random.seed(42) # set random seed Array Properties arr.shape # dimensions arr.size # total number of elements arr.ndim # number of dimensions arr.dtype # data type arr.itemsize # size of each element in bytes Array Operations Basic Math arr + 5 # add scalar arr * 2 # multiply by scalar arr1 + arr2 # element-wise addition arr1 * arr2 # element-wise multiplication arr1 @ arr2 # matrix multiplication np.dot(arr1, arr2) # matrix multiplication (alternative) Mathematical Functions np.sqrt(arr) # square root np.exp(arr) # exponential np.log(arr) # natural log np.sin(arr), np.cos(arr), np.tan(arr) # trig functions np.abs(arr) # absolute value Aggregation Functions np.sum(arr) # sum all elements np.mean(arr) # mean np.median(arr) # median np.std(arr) # standard deviation np.min(arr), np.max(arr) # min/max np.argmin(arr), np.argmax(arr) # indices of min/max Axis Operations arr_2d.sum(axis=0) # sum along rows (column-wise) arr_2d.sum(axis=1) # sum along columns (row-wise) arr_2d.mean(axis=0) # mean along axis 0 Array Indexing and Slicing Basic Indexing arr[0] # first element arr[-1] # last element arr[1:4] # elements 1, 2, 3 arr[::2] # every second element 2D Indexing arr_2d[0, 1] # element at row 0, column 1 arr_2d[0, :] # entire first row arr_2d[:, 1] # entire second column arr_2d[1:3, 0:2] # subarray Boolean Indexing mask = arr > 5 arr[mask] # elements greater than 5 arr[arr > 5] # same as above arr[(arr > 5) & (arr < 10)] # multiple conditions Fancy Indexing indices = [0, 2, 4] arr[indices] # elements at specified indices arr_2d[[0, 2], [1, 3]] # elements at (0,1) and (2,3) Array Manipulation Reshaping arr.reshape(3, 4) # reshape to 3x4 arr.flatten() # flatten to 1D arr.ravel() # flatten to 1D (view if possible) arr.T # transpose np.transpose(arr) # transpose (alternative) Joining Arrays np.concatenate([arr1, arr2]) # concatenate along existing axis np.vstack([arr1, arr2]) # stack vertically np.hstack([arr1, arr2]) # stack horizontally np.column_stack([arr1, arr2]) # stack as columns Splitting Arrays np.split(arr, 3) # split into 3 equal parts np.hsplit(arr_2d, 2) # split horizontally np.vsplit(arr_2d, 2) # split vertically Advanced Operations Broadcasting # Arrays of different shapes can be operated on arr_2d = np.array([[1, 2, 3], [4, 5, 6]]) arr_1d = np.array([10, 20, 30]) result = arr_2d + arr_1d # broadcasts arr_1d across rows Conditional Operations np.where(arr > 5, arr, 0) # replace values <= 5 with 0 np.select([arr < 5, arr > 10], [0, 100], arr) # multiple conditions Unique and Set Operations np.unique(arr) # unique elements np.in1d(arr1, arr2) # test membership np.intersect1d(arr1, arr2) # intersection np.union1d(arr1, arr2) # union Sorting np.sort(arr) # sort array np.argsort(arr) # indices that would sort array np.partition(arr, 3) # partition around 3rd element Linear Algebra # Dot product np.dot(a, b) # Matrix multiplication a @ b # Eigenvalues and eigenvectors np.linalg.eig(matrix) # Singular value decomposition np.linalg.svd(matrix) # Matrix inverse np.linalg.inv(matrix) # Determinant np.linalg.det(matrix) # Solve linear system Ax = b np.linalg.solve(A, b) Performance Tips Use vectorized operations instead of loops Avoid unnecessary array copies Use views when possible ( arr.view() ) Pre-allocate arrays when size is known Use appropriate data types ( dtype ) to save memory","title":"NumPy"},{"location":"python/numpy/#numpy","text":"","title":"NumPy"},{"location":"python/numpy/#installation","text":"pip install numpy","title":"Installation"},{"location":"python/numpy/#import","text":"import numpy as np","title":"Import"},{"location":"python/numpy/#array-creation","text":"","title":"Array Creation"},{"location":"python/numpy/#basic-creation","text":"# From lists arr = np.array([1, 2, 3, 4]) arr_2d = np.array([[1, 2], [3, 4]]) # Zeros, ones, empty np.zeros((3, 4)) # 3x4 array of zeros np.ones((2, 3)) # 2x3 array of ones np.empty((2, 2)) # uninitialized 2x2 array # Identity matrix np.eye(3) # 3x3 identity matrix np.identity(4) # 4x4 identity matrix","title":"Basic Creation"},{"location":"python/numpy/#range-arrays","text":"np.arange(10) # [0, 1, 2, ..., 9] np.arange(2, 10, 2) # [2, 4, 6, 8] np.linspace(0, 1, 5) # 5 evenly spaced values from 0 to 1","title":"Range Arrays"},{"location":"python/numpy/#random-arrays","text":"np.random.random((3, 3)) # 3x3 random floats [0, 1) np.random.randint(0, 10, 5) # 5 random ints [0, 10) np.random.normal(0, 1, 100) # 100 samples from normal distribution np.random.seed(42) # set random seed","title":"Random Arrays"},{"location":"python/numpy/#array-properties","text":"arr.shape # dimensions arr.size # total number of elements arr.ndim # number of dimensions arr.dtype # data type arr.itemsize # size of each element in bytes","title":"Array Properties"},{"location":"python/numpy/#array-operations","text":"","title":"Array Operations"},{"location":"python/numpy/#basic-math","text":"arr + 5 # add scalar arr * 2 # multiply by scalar arr1 + arr2 # element-wise addition arr1 * arr2 # element-wise multiplication arr1 @ arr2 # matrix multiplication np.dot(arr1, arr2) # matrix multiplication (alternative)","title":"Basic Math"},{"location":"python/numpy/#mathematical-functions","text":"np.sqrt(arr) # square root np.exp(arr) # exponential np.log(arr) # natural log np.sin(arr), np.cos(arr), np.tan(arr) # trig functions np.abs(arr) # absolute value","title":"Mathematical Functions"},{"location":"python/numpy/#aggregation-functions","text":"np.sum(arr) # sum all elements np.mean(arr) # mean np.median(arr) # median np.std(arr) # standard deviation np.min(arr), np.max(arr) # min/max np.argmin(arr), np.argmax(arr) # indices of min/max","title":"Aggregation Functions"},{"location":"python/numpy/#axis-operations","text":"arr_2d.sum(axis=0) # sum along rows (column-wise) arr_2d.sum(axis=1) # sum along columns (row-wise) arr_2d.mean(axis=0) # mean along axis 0","title":"Axis Operations"},{"location":"python/numpy/#array-indexing-and-slicing","text":"","title":"Array Indexing and Slicing"},{"location":"python/numpy/#basic-indexing","text":"arr[0] # first element arr[-1] # last element arr[1:4] # elements 1, 2, 3 arr[::2] # every second element","title":"Basic Indexing"},{"location":"python/numpy/#2d-indexing","text":"arr_2d[0, 1] # element at row 0, column 1 arr_2d[0, :] # entire first row arr_2d[:, 1] # entire second column arr_2d[1:3, 0:2] # subarray","title":"2D Indexing"},{"location":"python/numpy/#boolean-indexing","text":"mask = arr > 5 arr[mask] # elements greater than 5 arr[arr > 5] # same as above arr[(arr > 5) & (arr < 10)] # multiple conditions","title":"Boolean Indexing"},{"location":"python/numpy/#fancy-indexing","text":"indices = [0, 2, 4] arr[indices] # elements at specified indices arr_2d[[0, 2], [1, 3]] # elements at (0,1) and (2,3)","title":"Fancy Indexing"},{"location":"python/numpy/#array-manipulation","text":"","title":"Array Manipulation"},{"location":"python/numpy/#reshaping","text":"arr.reshape(3, 4) # reshape to 3x4 arr.flatten() # flatten to 1D arr.ravel() # flatten to 1D (view if possible) arr.T # transpose np.transpose(arr) # transpose (alternative)","title":"Reshaping"},{"location":"python/numpy/#joining-arrays","text":"np.concatenate([arr1, arr2]) # concatenate along existing axis np.vstack([arr1, arr2]) # stack vertically np.hstack([arr1, arr2]) # stack horizontally np.column_stack([arr1, arr2]) # stack as columns","title":"Joining Arrays"},{"location":"python/numpy/#splitting-arrays","text":"np.split(arr, 3) # split into 3 equal parts np.hsplit(arr_2d, 2) # split horizontally np.vsplit(arr_2d, 2) # split vertically","title":"Splitting Arrays"},{"location":"python/numpy/#advanced-operations","text":"","title":"Advanced Operations"},{"location":"python/numpy/#broadcasting","text":"# Arrays of different shapes can be operated on arr_2d = np.array([[1, 2, 3], [4, 5, 6]]) arr_1d = np.array([10, 20, 30]) result = arr_2d + arr_1d # broadcasts arr_1d across rows","title":"Broadcasting"},{"location":"python/numpy/#conditional-operations","text":"np.where(arr > 5, arr, 0) # replace values <= 5 with 0 np.select([arr < 5, arr > 10], [0, 100], arr) # multiple conditions","title":"Conditional Operations"},{"location":"python/numpy/#unique-and-set-operations","text":"np.unique(arr) # unique elements np.in1d(arr1, arr2) # test membership np.intersect1d(arr1, arr2) # intersection np.union1d(arr1, arr2) # union","title":"Unique and Set Operations"},{"location":"python/numpy/#sorting","text":"np.sort(arr) # sort array np.argsort(arr) # indices that would sort array np.partition(arr, 3) # partition around 3rd element","title":"Sorting"},{"location":"python/numpy/#linear-algebra","text":"# Dot product np.dot(a, b) # Matrix multiplication a @ b # Eigenvalues and eigenvectors np.linalg.eig(matrix) # Singular value decomposition np.linalg.svd(matrix) # Matrix inverse np.linalg.inv(matrix) # Determinant np.linalg.det(matrix) # Solve linear system Ax = b np.linalg.solve(A, b)","title":"Linear Algebra"},{"location":"python/numpy/#performance-tips","text":"Use vectorized operations instead of loops Avoid unnecessary array copies Use views when possible ( arr.view() ) Pre-allocate arrays when size is known Use appropriate data types ( dtype ) to save memory","title":"Performance Tips"},{"location":"python/pandas/","text":"Pandas Installation pip install pandas Import import pandas as pd import numpy as np Data Structures Series (1D) # From list s = pd.Series([1, 2, 3, 4]) # With custom index s = pd.Series([1, 2, 3], index=['a', 'b', 'c']) # From dictionary s = pd.Series({'a': 1, 'b': 2, 'c': 3}) DataFrame (2D) # From dictionary df = pd.DataFrame({ 'name': ['Alice', 'Bob', 'Charlie'], 'age': [25, 30, 35], 'city': ['NYC', 'LA', 'Chicago'] }) # From list of dictionaries df = pd.DataFrame([ {'name': 'Alice', 'age': 25}, {'name': 'Bob', 'age': 30} ]) # From NumPy array df = pd.DataFrame(np.random.randn(4, 3), columns=['A', 'B', 'C']) Data Input/Output Reading Data # CSV files df = pd.read_csv('file.csv') df = pd.read_csv('file.csv', index_col=0) # use first column as index df = pd.read_csv('file.csv', sep=';') # custom separator # Excel files df = pd.read_excel('file.xlsx') df = pd.read_excel('file.xlsx', sheet_name='Sheet1') # JSON df = pd.read_json('file.json') # SQL df = pd.read_sql('SELECT * FROM table', connection) # Parquet df = pd.read_parquet('file.parquet') Writing Data df.to_csv('output.csv', index=False) df.to_excel('output.xlsx', index=False) df.to_json('output.json') df.to_parquet('output.parquet') DataFrame Inspection Basic Info df.head() # first 5 rows df.tail(3) # last 3 rows df.info() # data types and memory usage df.describe() # summary statistics df.shape # (rows, columns) df.columns # column names df.index # row indices df.dtypes # data types Quick Stats df.nunique() # unique values per column df.isnull().sum() # count of missing values df.value_counts() # frequency counts (Series) df['col'].value_counts() # frequency counts for column Data Selection Column Selection df['name'] # single column (Series) df[['name', 'age']] # multiple columns (DataFrame) df.name # single column (attribute access) Row Selection df.iloc[0] # first row by position df.iloc[0:3] # first 3 rows df.loc['row_name'] # row by label df.loc[0:2, 'name':'age'] # rows and columns by label Boolean Indexing df[df['age'] > 30] # rows where age > 30 df[df['name'].isin(['Alice', 'Bob'])] # rows where name in list df[(df['age'] > 25) & (df['age'] < 35)] # multiple conditions df.query('age > 30 and city == \"NYC\"') # query string Data Manipulation Adding/Modifying Columns df['new_col'] = 0 # add column with constant df['age_squared'] = df['age'] ** 2 # derived column df['full_name'] = df['first'] + ' ' + df['last'] # string concatenation df.assign(new_col=df['age'] * 2) # add column (returns new DataFrame) Dropping Data df.drop('column_name', axis=1) # drop column df.drop(['col1', 'col2'], axis=1) # drop multiple columns df.drop(0, axis=0) # drop row by index df.dropna() # drop rows with NaN df.dropna(axis=1) # drop columns with NaN df.drop_duplicates() # remove duplicate rows Handling Missing Data df.isnull() # boolean mask of NaN values df.notnull() # boolean mask of non-NaN values df.fillna(0) # fill NaN with 0 df.fillna(method='ffill') # forward fill df.fillna(method='bfill') # backward fill df.fillna(df.mean()) # fill with column means df.interpolate() # interpolate missing values Data Aggregation and Grouping Basic Aggregation df.sum() # sum of each column df.mean() # mean of each column df.median() # median df.std() # standard deviation df.min(), df.max() # min/max df.count() # non-null count GroupBy Operations # Group by single column df.groupby('category').mean() df.groupby('category')['value'].sum() # Group by multiple columns df.groupby(['cat1', 'cat2']).agg({ 'value1': 'sum', 'value2': 'mean' }) # Apply custom functions df.groupby('category').apply(lambda x: x.max() - x.min()) # Multiple aggregations df.groupby('category').agg(['sum', 'mean', 'count']) Data Transformation Apply Functions df['col'].apply(lambda x: x * 2) # apply to Series df.apply(lambda x: x.max() - x.min(), axis=1) # apply to rows df.apply(np.sum, axis=0) # apply to columns String Operations df['name'].str.upper() # uppercase df['name'].str.lower() # lowercase df['name'].str.len() # length df['name'].str.contains('pattern') # contains pattern df['name'].str.replace('old', 'new') # replace df['name'].str.split(',') # split string df['name'].str.extract('(\\d+)') # extract with regex Datetime Operations df['date'] = pd.to_datetime(df['date']) # convert to datetime df['date'].dt.year # extract year df['date'].dt.month # extract month df['date'].dt.dayofweek # day of week (0=Monday) df['date'].dt.strftime('%Y-%m') # format as string Merging and Joining Concatenation pd.concat([df1, df2]) # vertical concatenation pd.concat([df1, df2], axis=1) # horizontal concatenation pd.concat([df1, df2], ignore_index=True) # reset index Merging # Inner join (default) pd.merge(df1, df2, on='key') # Left join pd.merge(df1, df2, on='key', how='left') # Outer join pd.merge(df1, df2, on='key', how='outer') # Multiple keys pd.merge(df1, df2, on=['key1', 'key2']) # Different column names pd.merge(df1, df2, left_on='key1', right_on='key2') Reshaping Data Pivot Tables # Basic pivot df.pivot(index='date', columns='category', values='value') # Pivot table with aggregation df.pivot_table( values='value', index='date', columns='category', aggfunc='sum' ) Melt (Wide to Long) df.melt( id_vars=['id', 'name'], # columns to keep value_vars=['col1', 'col2'], # columns to melt var_name='variable', # name for variable column value_name='value' # name for value column ) Stack/Unstack df.stack() # pivot columns to rows df.unstack() # pivot rows to columns df.unstack(level=0) # unstack specific level Sorting df.sort_values('column') # sort by single column df.sort_values(['col1', 'col2']) # sort by multiple columns df.sort_values('col', ascending=False) # descending order df.sort_index() # sort by index df.nlargest(5, 'column') # top 5 values df.nsmallest(5, 'column') # bottom 5 values Advanced Operations Rolling Windows df['value'].rolling(window=3).mean() # 3-period moving average df['value'].rolling(window=7).sum() # 7-period rolling sum df['value'].expanding().mean() # expanding window mean Resampling (Time Series) # Resample daily to monthly df.resample('M').mean() df.resample('Q').sum() # quarterly df.resample('W').last() # weekly, last value MultiIndex # Create MultiIndex df.set_index(['col1', 'col2']) # Access MultiIndex data df.loc[('level1', 'level2')] df.xs('level1', level=0) # Reset MultiIndex df.reset_index() Performance Optimization # Use categorical data for repeated strings df['category'] = df['category'].astype('category') # Use appropriate data types df['int_col'] = df['int_col'].astype('int32') # smaller int type df['float_col'] = df['float_col'].astype('float32') # Use chaining for multiple operations (df .dropna() .groupby('category') .sum() .sort_values('value', ascending=False) ) Common Patterns Conditional Logic # np.where for simple conditions df['new_col'] = np.where(df['age'] > 30, 'Senior', 'Junior') # np.select for multiple conditions conditions = [df['age'] < 25, df['age'] < 40, df['age'] >= 40] choices = ['Young', 'Middle', 'Senior'] df['age_group'] = np.select(conditions, choices) Window Functions df['rank'] = df['value'].rank() df['pct_rank'] = df['value'].rank(pct=True) df['cumsum'] = df['value'].cumsum() df['lag'] = df['value'].shift(1) # previous value df['lead'] = df['value'].shift(-1) # next value Memory Usage df.memory_usage(deep=True) # memory usage by column df.info(memory_usage='deep') # detailed memory info","title":"Pandas"},{"location":"python/pandas/#pandas","text":"","title":"Pandas"},{"location":"python/pandas/#installation","text":"pip install pandas","title":"Installation"},{"location":"python/pandas/#import","text":"import pandas as pd import numpy as np","title":"Import"},{"location":"python/pandas/#data-structures","text":"","title":"Data Structures"},{"location":"python/pandas/#series-1d","text":"# From list s = pd.Series([1, 2, 3, 4]) # With custom index s = pd.Series([1, 2, 3], index=['a', 'b', 'c']) # From dictionary s = pd.Series({'a': 1, 'b': 2, 'c': 3})","title":"Series (1D)"},{"location":"python/pandas/#dataframe-2d","text":"# From dictionary df = pd.DataFrame({ 'name': ['Alice', 'Bob', 'Charlie'], 'age': [25, 30, 35], 'city': ['NYC', 'LA', 'Chicago'] }) # From list of dictionaries df = pd.DataFrame([ {'name': 'Alice', 'age': 25}, {'name': 'Bob', 'age': 30} ]) # From NumPy array df = pd.DataFrame(np.random.randn(4, 3), columns=['A', 'B', 'C'])","title":"DataFrame (2D)"},{"location":"python/pandas/#data-inputoutput","text":"","title":"Data Input/Output"},{"location":"python/pandas/#reading-data","text":"# CSV files df = pd.read_csv('file.csv') df = pd.read_csv('file.csv', index_col=0) # use first column as index df = pd.read_csv('file.csv', sep=';') # custom separator # Excel files df = pd.read_excel('file.xlsx') df = pd.read_excel('file.xlsx', sheet_name='Sheet1') # JSON df = pd.read_json('file.json') # SQL df = pd.read_sql('SELECT * FROM table', connection) # Parquet df = pd.read_parquet('file.parquet')","title":"Reading Data"},{"location":"python/pandas/#writing-data","text":"df.to_csv('output.csv', index=False) df.to_excel('output.xlsx', index=False) df.to_json('output.json') df.to_parquet('output.parquet')","title":"Writing Data"},{"location":"python/pandas/#dataframe-inspection","text":"","title":"DataFrame Inspection"},{"location":"python/pandas/#basic-info","text":"df.head() # first 5 rows df.tail(3) # last 3 rows df.info() # data types and memory usage df.describe() # summary statistics df.shape # (rows, columns) df.columns # column names df.index # row indices df.dtypes # data types","title":"Basic Info"},{"location":"python/pandas/#quick-stats","text":"df.nunique() # unique values per column df.isnull().sum() # count of missing values df.value_counts() # frequency counts (Series) df['col'].value_counts() # frequency counts for column","title":"Quick Stats"},{"location":"python/pandas/#data-selection","text":"","title":"Data Selection"},{"location":"python/pandas/#column-selection","text":"df['name'] # single column (Series) df[['name', 'age']] # multiple columns (DataFrame) df.name # single column (attribute access)","title":"Column Selection"},{"location":"python/pandas/#row-selection","text":"df.iloc[0] # first row by position df.iloc[0:3] # first 3 rows df.loc['row_name'] # row by label df.loc[0:2, 'name':'age'] # rows and columns by label","title":"Row Selection"},{"location":"python/pandas/#boolean-indexing","text":"df[df['age'] > 30] # rows where age > 30 df[df['name'].isin(['Alice', 'Bob'])] # rows where name in list df[(df['age'] > 25) & (df['age'] < 35)] # multiple conditions df.query('age > 30 and city == \"NYC\"') # query string","title":"Boolean Indexing"},{"location":"python/pandas/#data-manipulation","text":"","title":"Data Manipulation"},{"location":"python/pandas/#addingmodifying-columns","text":"df['new_col'] = 0 # add column with constant df['age_squared'] = df['age'] ** 2 # derived column df['full_name'] = df['first'] + ' ' + df['last'] # string concatenation df.assign(new_col=df['age'] * 2) # add column (returns new DataFrame)","title":"Adding/Modifying Columns"},{"location":"python/pandas/#dropping-data","text":"df.drop('column_name', axis=1) # drop column df.drop(['col1', 'col2'], axis=1) # drop multiple columns df.drop(0, axis=0) # drop row by index df.dropna() # drop rows with NaN df.dropna(axis=1) # drop columns with NaN df.drop_duplicates() # remove duplicate rows","title":"Dropping Data"},{"location":"python/pandas/#handling-missing-data","text":"df.isnull() # boolean mask of NaN values df.notnull() # boolean mask of non-NaN values df.fillna(0) # fill NaN with 0 df.fillna(method='ffill') # forward fill df.fillna(method='bfill') # backward fill df.fillna(df.mean()) # fill with column means df.interpolate() # interpolate missing values","title":"Handling Missing Data"},{"location":"python/pandas/#data-aggregation-and-grouping","text":"","title":"Data Aggregation and Grouping"},{"location":"python/pandas/#basic-aggregation","text":"df.sum() # sum of each column df.mean() # mean of each column df.median() # median df.std() # standard deviation df.min(), df.max() # min/max df.count() # non-null count","title":"Basic Aggregation"},{"location":"python/pandas/#groupby-operations","text":"# Group by single column df.groupby('category').mean() df.groupby('category')['value'].sum() # Group by multiple columns df.groupby(['cat1', 'cat2']).agg({ 'value1': 'sum', 'value2': 'mean' }) # Apply custom functions df.groupby('category').apply(lambda x: x.max() - x.min()) # Multiple aggregations df.groupby('category').agg(['sum', 'mean', 'count'])","title":"GroupBy Operations"},{"location":"python/pandas/#data-transformation","text":"","title":"Data Transformation"},{"location":"python/pandas/#apply-functions","text":"df['col'].apply(lambda x: x * 2) # apply to Series df.apply(lambda x: x.max() - x.min(), axis=1) # apply to rows df.apply(np.sum, axis=0) # apply to columns","title":"Apply Functions"},{"location":"python/pandas/#string-operations","text":"df['name'].str.upper() # uppercase df['name'].str.lower() # lowercase df['name'].str.len() # length df['name'].str.contains('pattern') # contains pattern df['name'].str.replace('old', 'new') # replace df['name'].str.split(',') # split string df['name'].str.extract('(\\d+)') # extract with regex","title":"String Operations"},{"location":"python/pandas/#datetime-operations","text":"df['date'] = pd.to_datetime(df['date']) # convert to datetime df['date'].dt.year # extract year df['date'].dt.month # extract month df['date'].dt.dayofweek # day of week (0=Monday) df['date'].dt.strftime('%Y-%m') # format as string","title":"Datetime Operations"},{"location":"python/pandas/#merging-and-joining","text":"","title":"Merging and Joining"},{"location":"python/pandas/#concatenation","text":"pd.concat([df1, df2]) # vertical concatenation pd.concat([df1, df2], axis=1) # horizontal concatenation pd.concat([df1, df2], ignore_index=True) # reset index","title":"Concatenation"},{"location":"python/pandas/#merging","text":"# Inner join (default) pd.merge(df1, df2, on='key') # Left join pd.merge(df1, df2, on='key', how='left') # Outer join pd.merge(df1, df2, on='key', how='outer') # Multiple keys pd.merge(df1, df2, on=['key1', 'key2']) # Different column names pd.merge(df1, df2, left_on='key1', right_on='key2')","title":"Merging"},{"location":"python/pandas/#reshaping-data","text":"","title":"Reshaping Data"},{"location":"python/pandas/#pivot-tables","text":"# Basic pivot df.pivot(index='date', columns='category', values='value') # Pivot table with aggregation df.pivot_table( values='value', index='date', columns='category', aggfunc='sum' )","title":"Pivot Tables"},{"location":"python/pandas/#melt-wide-to-long","text":"df.melt( id_vars=['id', 'name'], # columns to keep value_vars=['col1', 'col2'], # columns to melt var_name='variable', # name for variable column value_name='value' # name for value column )","title":"Melt (Wide to Long)"},{"location":"python/pandas/#stackunstack","text":"df.stack() # pivot columns to rows df.unstack() # pivot rows to columns df.unstack(level=0) # unstack specific level","title":"Stack/Unstack"},{"location":"python/pandas/#sorting","text":"df.sort_values('column') # sort by single column df.sort_values(['col1', 'col2']) # sort by multiple columns df.sort_values('col', ascending=False) # descending order df.sort_index() # sort by index df.nlargest(5, 'column') # top 5 values df.nsmallest(5, 'column') # bottom 5 values","title":"Sorting"},{"location":"python/pandas/#advanced-operations","text":"","title":"Advanced Operations"},{"location":"python/pandas/#rolling-windows","text":"df['value'].rolling(window=3).mean() # 3-period moving average df['value'].rolling(window=7).sum() # 7-period rolling sum df['value'].expanding().mean() # expanding window mean","title":"Rolling Windows"},{"location":"python/pandas/#resampling-time-series","text":"# Resample daily to monthly df.resample('M').mean() df.resample('Q').sum() # quarterly df.resample('W').last() # weekly, last value","title":"Resampling (Time Series)"},{"location":"python/pandas/#multiindex","text":"# Create MultiIndex df.set_index(['col1', 'col2']) # Access MultiIndex data df.loc[('level1', 'level2')] df.xs('level1', level=0) # Reset MultiIndex df.reset_index()","title":"MultiIndex"},{"location":"python/pandas/#performance-optimization","text":"# Use categorical data for repeated strings df['category'] = df['category'].astype('category') # Use appropriate data types df['int_col'] = df['int_col'].astype('int32') # smaller int type df['float_col'] = df['float_col'].astype('float32') # Use chaining for multiple operations (df .dropna() .groupby('category') .sum() .sort_values('value', ascending=False) )","title":"Performance Optimization"},{"location":"python/pandas/#common-patterns","text":"","title":"Common Patterns"},{"location":"python/pandas/#conditional-logic","text":"# np.where for simple conditions df['new_col'] = np.where(df['age'] > 30, 'Senior', 'Junior') # np.select for multiple conditions conditions = [df['age'] < 25, df['age'] < 40, df['age'] >= 40] choices = ['Young', 'Middle', 'Senior'] df['age_group'] = np.select(conditions, choices)","title":"Conditional Logic"},{"location":"python/pandas/#window-functions","text":"df['rank'] = df['value'].rank() df['pct_rank'] = df['value'].rank(pct=True) df['cumsum'] = df['value'].cumsum() df['lag'] = df['value'].shift(1) # previous value df['lead'] = df['value'].shift(-1) # next value","title":"Window Functions"},{"location":"python/pandas/#memory-usage","text":"df.memory_usage(deep=True) # memory usage by column df.info(memory_usage='deep') # detailed memory info","title":"Memory Usage"},{"location":"python/pillow/","text":"Pillow (PIL) Pillow is the modern, friendly fork of the Python Imaging Library (PIL). It provides extensive file format support, efficient internal representation, and powerful image processing capabilities. Pillow is the de facto standard for image manipulation in Python. Installation # Basic installation pip install Pillow # With optional dependencies pip install Pillow[complete] # Includes all optional dependencies # With specific extras pip install \"Pillow[extra]\" # WebP, PDF, and other format support # Development version pip install git+https://github.com/python-pillow/Pillow.git # System dependencies (Ubuntu/Debian) sudo apt-get install libjpeg-dev zlib1g-dev libtiff-dev libfreetype6-dev Basic Setup from PIL import Image, ImageDraw, ImageFont, ImageFilter, ImageEnhance from PIL import ImageOps, ImageChops, ImageStat, ImageColor import os import io import numpy as np # Check Pillow version and features print(f\"Pillow version: {Image.__version__}\") # Check supported formats print(\"Supported formats:\") print(\"Read:\", \", \".join(sorted(Image.registered_extensions()))) print(\"Write:\", \", \".join(sorted(Image.SAVE.keys()))) Core Functionality Loading and Saving Images # Load images img = Image.open(\"path/to/image.jpg\") img = Image.open(\"path/to/image.png\") # Load from URL import requests from io import BytesIO response = requests.get(\"https://example.com/image.jpg\") img = Image.open(BytesIO(response.content)) # Load from bytes with open(\"image.jpg\", \"rb\") as f: img = Image.open(BytesIO(f.read())) # Basic image information print(f\"Format: {img.format}\") # JPEG, PNG, etc. print(f\"Mode: {img.mode}\") # RGB, RGBA, L, etc. print(f\"Size: {img.size}\") # (width, height) print(f\"Info: {img.info}\") # Metadata dictionary # Save images img.save(\"output.jpg\") # Auto-detect format from extension img.save(\"output.png\", \"PNG\") # Explicit format img.save(\"output.jpg\", quality=95) # JPEG with quality setting # Save with optimization img.save(\"optimized.jpg\", optimize=True, quality=85) img.save(\"progressive.jpg\", progressive=True, quality=90) # Save to bytes buffer = io.BytesIO() img.save(buffer, format='JPEG') image_bytes = buffer.getvalue() Image Modes and Conversions # Common image modes # L: Grayscale (8-bit) # RGB: Color (3x8-bit) # RGBA: Color with transparency (4x8-bit) # CMYK: Color for printing (4x8-bit) # P: Palette mode (8-bit mapped) # Mode conversions rgb_img = img.convert('RGB') # Convert to RGB gray_img = img.convert('L') # Convert to grayscale rgba_img = img.convert('RGBA') # Add alpha channel # Grayscale with custom weights def rgb_to_gray_custom(img, weights=(0.299, 0.587, 0.114)): \"\"\"Convert RGB to grayscale with custom weights\"\"\" r, g, b = img.split() gray = Image.eval(r, lambda x: int(x * weights[0])) gray.paste(Image.eval(g, lambda x: int(x * weights[1])), mask=None) gray.paste(Image.eval(b, lambda x: int(x * weights[2])), mask=None) return gray # Color quantization (reduce colors) quantized = img.quantize(colors=256) # Reduce to 256 colors quantized = img.quantize(colors=8) # Reduce to 8 colors Basic Image Operations # Resize images resized = img.resize((800, 600)) # Resize to specific size resized = img.resize((400, 300), Image.LANCZOS) # High-quality resampling # Maintain aspect ratio def resize_with_aspect(img, max_size=(800, 600)): img.thumbnail(max_size, Image.LANCZOS) # In-place resize maintaining aspect return img # Crop images cropped = img.crop((100, 100, 400, 400)) # (left, top, right, bottom) # Rotate images rotated = img.rotate(45) # Rotate 45 degrees rotated = img.rotate(30, expand=True) # Expand canvas to fit rotated = img.rotate(-90, fillcolor='white') # Fill empty areas with white # Flip and transpose flipped_h = img.transpose(Image.FLIP_LEFT_RIGHT) # Horizontal flip flipped_v = img.transpose(Image.FLIP_TOP_BOTTOM) # Vertical flip rotated_90 = img.transpose(Image.ROTATE_90) # 90-degree rotation rotated_180 = img.transpose(Image.ROTATE_180) # 180-degree rotation rotated_270 = img.transpose(Image.ROTATE_270) # 270-degree rotation # Paste one image onto another background = Image.new('RGB', (800, 600), 'white') background.paste(img, (100, 100)) # Paste at position background.paste(img, (200, 200), img) # Use img as mask (if RGBA) Common Use Cases Image Resizing and Thumbnails def create_thumbnail(input_path, output_path, size=(150, 150)): \"\"\"Create a thumbnail maintaining aspect ratio\"\"\" with Image.open(input_path) as img: # Convert to RGB if necessary (for JPEG output) if img.mode in ('RGBA', 'LA', 'P'): img = img.convert('RGB') img.thumbnail(size, Image.LANCZOS) img.save(output_path, 'JPEG', quality=85, optimize=True) def resize_to_fit(img, target_size, background_color='white'): \"\"\"Resize image to fit within target size, adding padding if needed\"\"\" img.thumbnail(target_size, Image.LANCZOS) # Create new image with target size new_img = Image.new('RGB', target_size, background_color) # Calculate position to center the image x = (target_size[0] - img.width) // 2 y = (target_size[1] - img.height) // 2 new_img.paste(img, (x, y)) return new_img def resize_to_cover(img, target_size): \"\"\"Resize and crop image to cover target size\"\"\" img_ratio = img.width / img.height target_ratio = target_size[0] / target_size[1] if img_ratio > target_ratio: # Image is wider, resize by height new_height = target_size[1] new_width = int(new_height * img_ratio) img = img.resize((new_width, new_height), Image.LANCZOS) # Crop horizontally left = (new_width - target_size[0]) // 2 img = img.crop((left, 0, left + target_size[0], target_size[1])) else: # Image is taller, resize by width new_width = target_size[0] new_height = int(new_width / img_ratio) img = img.resize((new_width, new_height), Image.LANCZOS) # Crop vertically top = (new_height - target_size[1]) // 2 img = img.crop((0, top, target_size[0], top + target_size[1])) return img # Usage examples create_thumbnail('large_image.jpg', 'thumbnail.jpg', (200, 200)) img = Image.open('original.jpg') fitted = resize_to_fit(img, (800, 600), 'black') covered = resize_to_cover(img, (800, 600)) Image Filters and Enhancement # Built-in filters blurred = img.filter(ImageFilter.BLUR) sharp = img.filter(ImageFilter.SHARPEN) smooth = img.filter(ImageFilter.SMOOTH) detail = img.filter(ImageFilter.DETAIL) edge_enhance = img.filter(ImageFilter.EDGE_ENHANCE) emboss = img.filter(ImageFilter.EMBOSS) contour = img.filter(ImageFilter.CONTOUR) # Gaussian blur with radius gaussian = img.filter(ImageFilter.GaussianBlur(radius=2)) # Box blur box_blur = img.filter(ImageFilter.BoxBlur(radius=1)) # Unsharp mask for sharpening unsharp = img.filter(ImageFilter.UnsharpMask(radius=2, percent=150, threshold=3)) # Kernel-based filters kernel_sharpen = ImageFilter.Kernel( size=(3, 3), kernel=[-1, -1, -1, -1, 9, -1, -1, -1, -1], scale=1 ) sharpened = img.filter(kernel_sharpen) # Edge detection kernel kernel_edge = ImageFilter.Kernel( size=(3, 3), kernel=[-1, -1, -1, -1, 8, -1, -1, -1, -1], scale=1 ) edges = img.filter(kernel_edge) # Image enhancement enhancer = ImageEnhance.Brightness(img) brighter = enhancer.enhance(1.3) # 30% brighter darker = enhancer.enhance(0.7) # 30% darker enhancer = ImageEnhance.Contrast(img) high_contrast = enhancer.enhance(1.5) # Increase contrast enhancer = ImageEnhance.Color(img) saturated = enhancer.enhance(1.4) # More saturated desaturated = enhancer.enhance(0.6) # Less saturated enhancer = ImageEnhance.Sharpness(img) sharp = enhancer.enhance(2.0) # Sharper soft = enhancer.enhance(0.5) # Softer Drawing on Images def add_watermark(img, text, position='bottom-right', font_size=36, opacity=128): \"\"\"Add text watermark to image\"\"\" # Create a transparent overlay overlay = Image.new('RGBA', img.size, (255, 255, 255, 0)) draw = ImageDraw.Draw(overlay) # Try to load a font try: font = ImageFont.truetype(\"arial.ttf\", font_size) except: font = ImageFont.load_default() # Get text dimensions bbox = draw.textbbox((0, 0), text, font=font) text_width = bbox[2] - bbox[0] text_height = bbox[3] - bbox[1] # Calculate position margin = 20 if position == 'bottom-right': x = img.width - text_width - margin y = img.height - text_height - margin elif position == 'bottom-left': x = margin y = img.height - text_height - margin elif position == 'top-right': x = img.width - text_width - margin y = margin else: # top-left x = margin y = margin # Draw text draw.text((x, y), text, font=font, fill=(255, 255, 255, opacity)) # Composite with original image if img.mode != 'RGBA': img = img.convert('RGBA') watermarked = Image.alpha_composite(img, overlay) return watermarked.convert('RGB') def draw_shapes_and_text(img): \"\"\"Draw various shapes and text on image\"\"\" draw = ImageDraw.Draw(img) # Rectangle draw.rectangle([50, 50, 150, 100], fill='red', outline='black', width=2) # Circle (ellipse with equal width and height) draw.ellipse([200, 50, 300, 150], fill='blue', outline='white', width=3) # Line draw.line([50, 150, 300, 200], fill='green', width=5) # Polygon draw.polygon([(400, 50), (450, 100), (400, 150), (350, 100)], fill='yellow', outline='purple') # Text try: font = ImageFont.truetype(\"arial.ttf\", 24) except: font = ImageFont.load_default() draw.text((50, 220), \"Hello, Pillow!\", font=font, fill='black') return img def add_border(img, border_size=10, color='black'): \"\"\"Add border around image\"\"\" return ImageOps.expand(img, border=border_size, fill=color) def create_rounded_corners(img, radius=20): \"\"\"Create image with rounded corners\"\"\" # Create mask mask = Image.new('L', img.size, 0) draw = ImageDraw.Draw(mask) draw.rounded_rectangle([0, 0, img.width, img.height], radius, fill=255) # Apply mask img = img.convert('RGBA') img.putalpha(mask) return img # Usage examples img = Image.open('photo.jpg') watermarked = add_watermark(img, \"\u00a9 2025 My Company\", opacity=100) bordered = add_border(img, 15, 'white') rounded = create_rounded_corners(img, 30) Batch Processing import os from pathlib import Path from concurrent.futures import ThreadPoolExecutor import multiprocessing def process_image(input_path, output_path, operations): \"\"\"Process a single image with specified operations\"\"\" try: with Image.open(input_path) as img: # Convert to RGB if needed if img.mode in ('RGBA', 'LA', 'P'): img = img.convert('RGB') # Apply operations for operation, params in operations.items(): if operation == 'resize': img = img.resize(params['size'], Image.LANCZOS) elif operation == 'thumbnail': img.thumbnail(params['size'], Image.LANCZOS) elif operation == 'rotate': img = img.rotate(params['angle']) elif operation == 'enhance_brightness': enhancer = ImageEnhance.Brightness(img) img = enhancer.enhance(params['factor']) elif operation == 'enhance_contrast': enhancer = ImageEnhance.Contrast(img) img = enhancer.enhance(params['factor']) elif operation == 'filter': img = img.filter(params['filter']) elif operation == 'grayscale': img = img.convert('L') # Save processed image os.makedirs(os.path.dirname(output_path), exist_ok=True) img.save(output_path, quality=params.get('quality', 90), optimize=True) return f\"Processed: {input_path} -> {output_path}\" except Exception as e: return f\"Error processing {input_path}: {str(e)}\" def batch_process_images(input_dir, output_dir, operations, file_extensions=None): \"\"\"Batch process images in a directory\"\"\" if file_extensions is None: file_extensions = {'.jpg', '.jpeg', '.png', '.bmp', '.tiff', '.webp'} input_path = Path(input_dir) output_path = Path(output_dir) # Find all image files image_files = [] for ext in file_extensions: image_files.extend(input_path.glob(f\"**/*{ext}\")) image_files.extend(input_path.glob(f\"**/*{ext.upper()}\")) # Prepare tasks tasks = [] for img_file in image_files: relative_path = img_file.relative_to(input_path) output_file = output_path / relative_path tasks.append((str(img_file), str(output_file), operations)) # Process with multiple threads max_workers = min(32, multiprocessing.cpu_count() * 2) with ThreadPoolExecutor(max_workers=max_workers) as executor: results = executor.map(lambda args: process_image(*args), tasks) # Print results for result in results: print(result) # Usage example operations = { 'thumbnail': {'size': (800, 600)}, 'enhance_contrast': {'factor': 1.1}, 'filter': {'filter': ImageFilter.SHARPEN}, 'quality': 85 } batch_process_images('./input_photos', './output_photos', operations) # Specific batch operations def create_thumbnails_batch(input_dir, output_dir, size=(200, 200)): \"\"\"Create thumbnails for all images in directory\"\"\" operations = { 'thumbnail': {'size': size}, 'quality': 85 } batch_process_images(input_dir, output_dir, operations) def optimize_images_batch(input_dir, output_dir, quality=85): \"\"\"Optimize images for web (reduce file size)\"\"\" operations = { 'resize': {'size': (1920, 1080)}, # Max size for web 'quality': quality } batch_process_images(input_dir, output_dir, operations) # Usage create_thumbnails_batch('./photos', './thumbnails', (150, 150)) optimize_images_batch('./large_photos', './optimized', quality=75) Advanced Features Working with Image Metadata from PIL.ExifTags import TAGS, GPSTAGS import json def extract_exif_data(img_path): \"\"\"Extract EXIF data from image\"\"\" with Image.open(img_path) as img: exif_data = {} # Get raw EXIF data exif = img._getexif() if exif: for tag_id, value in exif.items(): tag = TAGS.get(tag_id, tag_id) # Handle GPS data specially if tag == \"GPSInfo\": gps_data = {} for gps_tag_id, gps_value in value.items(): gps_tag = GPSTAGS.get(gps_tag_id, gps_tag_id) gps_data[gps_tag] = gps_value exif_data[tag] = gps_data else: exif_data[tag] = value return exif_data def get_image_info(img_path): \"\"\"Get comprehensive image information\"\"\" with Image.open(img_path) as img: info = { 'filename': os.path.basename(img_path), 'format': img.format, 'mode': img.mode, 'size': img.size, 'width': img.width, 'height': img.height, 'aspect_ratio': round(img.width / img.height, 2), 'file_size': os.path.getsize(img_path), 'has_transparency': img.mode in ('RGBA', 'LA') or 'transparency' in img.info } # Add EXIF data if available exif = extract_exif_data(img_path) if exif: info['exif'] = { 'make': exif.get('Make', 'Unknown'), 'model': exif.get('Model', 'Unknown'), 'datetime': exif.get('DateTime', 'Unknown'), 'orientation': exif.get('Orientation', 1), 'iso': exif.get('ISOSpeedRatings', 'Unknown'), 'focal_length': exif.get('FocalLength', 'Unknown') } return info def auto_rotate_image(img_path, output_path=None): \"\"\"Auto-rotate image based on EXIF orientation\"\"\" with Image.open(img_path) as img: # Get orientation from EXIF exif = img._getexif() orientation = 1 if exif and 'Orientation' in [TAGS.get(k) for k in exif.keys()]: for tag_id, value in exif.items(): if TAGS.get(tag_id) == 'Orientation': orientation = value break # Apply rotation based on orientation if orientation == 3: img = img.rotate(180, expand=True) elif orientation == 6: img = img.rotate(270, expand=True) elif orientation == 8: img = img.rotate(90, expand=True) # Save rotated image if output_path: img.save(output_path) else: img.save(img_path) return img # Usage info = get_image_info('photo.jpg') print(json.dumps(info, indent=2, default=str)) auto_rotate_image('rotated_photo.jpg', 'corrected_photo.jpg') Color Operations def adjust_color_balance(img, cyan_red=0, magenta_green=0, yellow_blue=0): \"\"\"Adjust color balance similar to Photoshop\"\"\" # Split into RGB channels r, g, b = img.split() # Apply adjustments r = r.point(lambda x: max(0, min(255, x + cyan_red))) g = g.point(lambda x: max(0, min(255, x + magenta_green))) b = b.point(lambda x: max(0, min(255, x + yellow_blue))) return Image.merge('RGB', (r, g, b)) def apply_color_curves(img, curve_points): \"\"\"Apply color curves adjustment\"\"\" # Create lookup table curve = list(range(256)) # Interpolate curve points for i in range(len(curve_points) - 1): x1, y1 = curve_points[i] x2, y2 = curve_points[i + 1] for x in range(x1, x2 + 1): if x2 > x1: ratio = (x - x1) / (x2 - x1) curve[x] = int(y1 + ratio * (y2 - y1)) return img.point(curve) def create_sepia_effect(img): \"\"\"Create sepia tone effect\"\"\" # Convert to RGB if necessary if img.mode != 'RGB': img = img.convert('RGB') # Apply sepia transformation matrix pixels = img.load() width, height = img.size for y in range(height): for x in range(width): r, g, b = pixels[x, y] # Sepia transformation tr = int(0.393 * r + 0.769 * g + 0.189 * b) tg = int(0.349 * r + 0.686 * g + 0.168 * b) tb = int(0.272 * r + 0.534 * g + 0.131 * b) # Ensure values are within range pixels[x, y] = (min(255, tr), min(255, tg), min(255, tb)) return img def create_vintage_effect(img): \"\"\"Create vintage photo effect\"\"\" # Apply sepia img = create_sepia_effect(img) # Reduce contrast slightly enhancer = ImageEnhance.Contrast(img) img = enhancer.enhance(0.9) # Add slight blur img = img.filter(ImageFilter.GaussianBlur(0.5)) # Add vignette effect width, height = img.size vignette = Image.new('L', (width, height), 255) draw = ImageDraw.Draw(vignette) # Create radial gradient for vignette center_x, center_y = width // 2, height // 2 max_distance = min(width, height) // 2 for y in range(height): for x in range(width): distance = ((x - center_x) ** 2 + (y - center_y) ** 2) ** 0.5 if distance < max_distance: alpha = int(255 * (1 - (distance / max_distance) ** 2)) vignette.putpixel((x, y), alpha) else: vignette.putpixel((x, y), 0) # Apply vignette img = img.convert('RGBA') img.putalpha(vignette) return img def extract_dominant_colors(img, num_colors=5): \"\"\"Extract dominant colors from image\"\"\" # Convert to RGB and resize for performance img = img.convert('RGB') img = img.resize((150, 150)) # Smaller size for faster processing # Quantize to reduce colors quantized = img.quantize(colors=num_colors) # Get palette colors palette = quantized.getpalette() colors = [] for i in range(num_colors): r = palette[i * 3] g = palette[i * 3 + 1] b = palette[i * 3 + 2] colors.append((r, g, b)) # Count occurrences of each color quantized = quantized.convert('RGB') pixels = list(quantized.getdata()) color_counts = {} for pixel in pixels: color_counts[pixel] = color_counts.get(pixel, 0) + 1 # Sort by frequency sorted_colors = sorted(color_counts.items(), key=lambda x: x[1], reverse=True) return [color for color, count in sorted_colors[:num_colors]] # Usage examples img = Image.open('photo.jpg') # Color adjustments balanced = adjust_color_balance(img, cyan_red=10, yellow_blue=-5) # Curves adjustment (darken shadows, brighten highlights) curves = apply_color_curves(img, [(0, 0), (64, 50), (128, 128), (192, 200), (255, 255)]) # Effects sepia = create_sepia_effect(img) vintage = create_vintage_effect(img) # Extract colors dominant_colors = extract_dominant_colors(img) print(\"Dominant colors:\", dominant_colors) Advanced Compositing def blend_images(img1, img2, mode='normal', opacity=0.5): \"\"\"Blend two images with different blend modes\"\"\" # Ensure images are same size if img1.size != img2.size: img2 = img2.resize(img1.size, Image.LANCZOS) # Convert to same mode if img1.mode != img2.mode: img2 = img2.convert(img1.mode) if mode == 'normal': return Image.blend(img1, img2, opacity) elif mode == 'multiply': return ImageChops.multiply(img1, img2) elif mode == 'screen': return ImageChops.screen(img1, img2) elif mode == 'overlay': return ImageChops.overlay(img1, img2) elif mode == 'difference': return ImageChops.difference(img1, img2) elif mode == 'add': return ImageChops.add(img1, img2) elif mode == 'subtract': return ImageChops.subtract(img1, img2) elif mode == 'darker': return ImageChops.darker(img1, img2) elif mode == 'lighter': return ImageChops.lighter(img1, img2) else: return Image.blend(img1, img2, opacity) def create_photo_collage(images, layout=(2, 2), spacing=10, background_color='white'): \"\"\"Create a photo collage from multiple images\"\"\" rows, cols = layout # Calculate dimensions for each cell total_images = len(images) images = images[:rows * cols] # Limit to layout size # Find maximum dimensions max_width = max(img.width for img in images) max_height = max(img.height for img in images) # Calculate canvas size canvas_width = cols * max_width + (cols + 1) * spacing canvas_height = rows * max_height + (rows + 1) * spacing # Create canvas canvas = Image.new('RGB', (canvas_width, canvas_height), background_color) # Place images for i, img in enumerate(images): row = i // cols col = i % cols # Resize image to fit cell img_resized = img.copy() img_resized.thumbnail((max_width, max_height), Image.LANCZOS) # Calculate position x = spacing + col * (max_width + spacing) + (max_width - img_resized.width) // 2 y = spacing + row * (max_height + spacing) + (max_height - img_resized.height) // 2 canvas.paste(img_resized, (x, y)) return canvas def apply_gradient_mask(img, direction='horizontal', start_alpha=255, end_alpha=0): \"\"\"Apply gradient mask to image\"\"\" # Create gradient mask width, height = img.size mask = Image.new('L', (width, height)) for y in range(height): for x in range(width): if direction == 'horizontal': alpha = int(start_alpha + (end_alpha - start_alpha) * x / width) elif direction == 'vertical': alpha = int(start_alpha + (end_alpha - start_alpha) * y / height) elif direction == 'radial': center_x, center_y = width // 2, height // 2 distance = ((x - center_x) ** 2 + (y - center_y) ** 2) ** 0.5 max_distance = min(width, height) // 2 alpha = int(start_alpha + (end_alpha - start_alpha) * min(distance / max_distance, 1)) mask.putpixel((x, y), max(0, min(255, alpha))) # Apply mask if img.mode != 'RGBA': img = img.convert('RGBA') img.putalpha(mask) return img def create_panorama(images): \"\"\"Simple panorama creation (basic horizontal stitching)\"\"\" if not images: return None # Resize all images to same height min_height = min(img.height for img in images) resized_images = [] for img in images: aspect_ratio = img.width / img.height new_width = int(min_height * aspect_ratio) resized_img = img.resize((new_width, min_height), Image.LANCZOS) resized_images.append(resized_img) # Calculate total width total_width = sum(img.width for img in resized_images) # Create panorama canvas panorama = Image.new('RGB', (total_width, min_height)) # Paste images horizontally x_offset = 0 for img in resized_images: panorama.paste(img, (x_offset, 0)) x_offset += img.width return panorama # Usage examples img1 = Image.open('photo1.jpg') img2 = Image.open('photo2.jpg') # Blend images blended = blend_images(img1, img2, 'overlay', 0.7) # Create collage images = [Image.open(f'photo{i}.jpg') for i in range(1, 5)] collage = create_photo_collage(images, (2, 2), spacing=15) # Apply gradient gradient_img = apply_gradient_mask(img1, 'radial') # Create panorama pano_images = [Image.open(f'pano{i}.jpg') for i in range(1, 4)] panorama = create_panorama(pano_images) Integration with Other Libraries With NumPy import numpy as np # Convert PIL Image to NumPy array img_array = np.array(img) print(f\"Array shape: {img_array.shape}\") # (height, width, channels) print(f\"Array dtype: {img_array.dtype}\") # uint8 # Convert NumPy array to PIL Image img_from_array = Image.fromarray(img_array) # Advanced NumPy operations def adjust_gamma(img, gamma=1.0): \"\"\"Apply gamma correction\"\"\" img_array = np.array(img, dtype=np.float64) img_array = img_array / 255.0 # Normalize to [0, 1] img_array = np.power(img_array, gamma) img_array = (img_array * 255).astype(np.uint8) return Image.fromarray(img_array) def apply_histogram_equalization(img): \"\"\"Apply histogram equalization using NumPy\"\"\" if img.mode != 'L': img = img.convert('L') img_array = np.array(img) # Calculate histogram hist, bins = np.histogram(img_array.flatten(), 256, [0, 256]) # Calculate cumulative distribution cdf = hist.cumsum() cdf_normalized = cdf * 255 / cdf[-1] # Apply equalization img_equalized = np.interp(img_array.flatten(), bins[:-1], cdf_normalized) img_equalized = img_equalized.reshape(img_array.shape).astype(np.uint8) return Image.fromarray(img_equalized) def create_noise(size, noise_type='gaussian'): \"\"\"Create noise using NumPy\"\"\" if noise_type == 'gaussian': noise = np.random.normal(128, 30, size).astype(np.uint8) elif noise_type == 'uniform': noise = np.random.uniform(0, 255, size).astype(np.uint8) elif noise_type == 'salt_pepper': noise = np.random.choice([0, 255], size=size, p=[0.5, 0.5]).astype(np.uint8) return Image.fromarray(noise) # Usage gamma_corrected = adjust_gamma(img, gamma=1.5) equalized = apply_histogram_equalization(img) noise_img = create_noise((200, 200, 3), 'gaussian') With Matplotlib import matplotlib.pyplot as plt import matplotlib.patches as patches def plot_image_analysis(img): \"\"\"Create comprehensive image analysis plot\"\"\" fig, axes = plt.subplots(2, 3, figsize=(15, 10)) # Original image axes[0, 0].imshow(img) axes[0, 0].set_title('Original Image') axes[0, 0].axis('off') # Grayscale gray_img = img.convert('L') axes[0, 1].imshow(gray_img, cmap='gray') axes[0, 1].set_title('Grayscale') axes[0, 1].axis('off') # Edge detection edges = gray_img.filter(ImageFilter.FIND_EDGES) axes[0, 2].imshow(edges, cmap='gray') axes[0, 2].set_title('Edge Detection') axes[0, 2].axis('off') # RGB Histogram if img.mode == 'RGB': r_hist = np.array(img.split()[0]).flatten() g_hist = np.array(img.split()[1]).flatten() b_hist = np.array(img.split()[2]).flatten() axes[1, 0].hist(r_hist, bins=256, color='red', alpha=0.7, density=True) axes[1, 0].hist(g_hist, bins=256, color='green', alpha=0.7, density=True) axes[1, 0].hist(b_hist, bins=256, color='blue', alpha=0.7, density=True) axes[1, 0].set_title('RGB Histogram') axes[1, 0].set_xlabel('Pixel Value') axes[1, 0].set_ylabel('Density') # Grayscale histogram gray_hist = np.array(gray_img).flatten() axes[1, 1].hist(gray_hist, bins=256, color='gray', alpha=0.7) axes[1, 1].set_title('Grayscale Histogram') axes[1, 1].set_xlabel('Pixel Value') axes[1, 1].set_ylabel('Frequency') # Image statistics stats = ImageStat.Stat(img) axes[1, 2].axis('off') stats_text = f\"\"\" Size: {img.size} Mode: {img.mode} Mean: {[round(m, 1) for m in stats.mean]} Median: {[round(m, 1) for m in stats.median]} StdDev: {[round(s, 1) for s in stats.stddev]} \"\"\" axes[1, 2].text(0.1, 0.5, stats_text, fontsize=12, verticalalignment='center') axes[1, 2].set_title('Image Statistics') plt.tight_layout() plt.show() def create_before_after_plot(original, processed, title=\"Before / After\"): \"\"\"Create side-by-side comparison\"\"\" fig, axes = plt.subplots(1, 2, figsize=(12, 6)) axes[0].imshow(original) axes[0].set_title('Before') axes[0].axis('off') axes[1].imshow(processed) axes[1].set_title('After') axes[1].axis('off') fig.suptitle(title, fontsize=16) plt.tight_layout() plt.show() # Usage plot_image_analysis(img) processed_img = img.filter(ImageFilter.SHARPEN) create_before_after_plot(img, processed_img, \"Sharpening Effect\") With OpenCV Integration import cv2 def pil_to_opencv(pil_img): \"\"\"Convert PIL Image to OpenCV format\"\"\" return cv2.cvtColor(np.array(pil_img), cv2.COLOR_RGB2BGR) def opencv_to_pil(cv_img): \"\"\"Convert OpenCV image to PIL format\"\"\" return Image.fromarray(cv2.cvtColor(cv_img, cv2.COLOR_BGR2RGB)) def advanced_edge_detection(img): \"\"\"Advanced edge detection using OpenCV\"\"\" # Convert to OpenCV format cv_img = pil_to_opencv(img) gray = cv2.cvtColor(cv_img, cv2.COLOR_BGR2GRAY) # Apply Canny edge detection edges = cv2.Canny(gray, 50, 150) # Convert back to PIL return Image.fromarray(edges, mode='L') def detect_contours(img, min_area=1000): \"\"\"Detect and draw contours\"\"\" cv_img = pil_to_opencv(img) gray = cv2.cvtColor(cv_img, cv2.COLOR_BGR2GRAY) # Find contours contours, _ = cv2.findContours(gray, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE) # Filter by area and draw for contour in contours: area = cv2.contourArea(contour) if area > min_area: cv2.drawContours(cv_img, [contour], -1, (0, 255, 0), 2) return opencv_to_pil(cv_img) # Usage edges = advanced_edge_detection(img) contours = detect_contours(img) Best Practices Performance Optimization # 1. Use appropriate resampling filters resizing_filters = { 'fastest': Image.NEAREST, # Fastest, lowest quality 'balanced': Image.BILINEAR, # Good balance 'quality': Image.LANCZOS # Best quality, slower } # 2. Work with smaller images when possible def optimize_for_processing(img, max_size=1024): \"\"\"Resize large images for faster processing\"\"\" if max(img.size) > max_size: img.thumbnail((max_size, max_size), Image.LANCZOS) return img # 3. Use context managers for file handling def process_multiple_images(file_paths, operations): \"\"\"Efficiently process multiple images\"\"\" results = [] for path in file_paths: with Image.open(path) as img: # Process without loading full image into memory for op in operations: img = op(img) results.append(img.copy()) # Make a copy before context ends return results # 4. Batch operations when possible def batch_resize(image_paths, size, output_dir): \"\"\"Batch resize operation\"\"\" os.makedirs(output_dir, exist_ok=True) for path in image_paths: with Image.open(path) as img: img.thumbnail(size, Image.LANCZOS) filename = os.path.basename(path) img.save(os.path.join(output_dir, filename), optimize=True) # 5. Use appropriate image formats format_recommendations = { 'photos': 'JPEG', # Best for photos 'graphics': 'PNG', # Best for graphics with transparency 'web_photos': 'WebP', # Modern web format 'icons': 'PNG', # Best for icons 'print': 'TIFF' # Best for print } Memory Management import psutil import gc def monitor_memory_usage(): \"\"\"Monitor memory usage\"\"\" process = psutil.Process() return process.memory_info().rss / 1024 / 1024 # MB def process_large_image_safely(img_path, operations, chunk_size=None): \"\"\"Process large images without loading everything into memory\"\"\" with Image.open(img_path) as img: print(f\"Processing {img.size} image\") print(f\"Memory before: {monitor_memory_usage():.1f} MB\") # Work with image for operation in operations: img = operation(img) gc.collect() # Force garbage collection print(f\"Memory after: {monitor_memory_usage():.1f} MB\") return img def create_image_pyramid(img, levels=3): \"\"\"Create image pyramid to save memory\"\"\" pyramid = [img] current = img for level in range(1, levels): size = (current.width // 2, current.height // 2) current = current.resize(size, Image.LANCZOS) pyramid.append(current) return pyramid Error Handling and Validation def safe_image_operation(operation): \"\"\"Decorator for safe image operations\"\"\" def wrapper(img_path, *args, **kwargs): try: with Image.open(img_path) as img: return operation(img, *args, **kwargs) except IOError: print(f\"Cannot open image: {img_path}\") return None except Exception as e: print(f\"Error processing {img_path}: {str(e)}\") return None return wrapper @safe_image_operation def safe_resize(img, size): \"\"\"Safely resize image with error handling\"\"\" return img.resize(size, Image.LANCZOS) def validate_image_format(img_path, allowed_formats=None): \"\"\"Validate image format\"\"\" if allowed_formats is None: allowed_formats = {'JPEG', 'PNG', 'BMP', 'TIFF', 'WebP'} try: with Image.open(img_path) as img: if img.format in allowed_formats: return True, img.format else: return False, f\"Format {img.format} not allowed\" except: return False, \"Cannot open file\" def robust_image_save(img, output_path, fallback_format='JPEG', **kwargs): \"\"\"Save image with fallback options\"\"\" try: img.save(output_path, **kwargs) return True, \"Saved successfully\" except: try: # Try with fallback format base_name = os.path.splitext(output_path)[0] fallback_path = f\"{base_name}.{fallback_format.lower()}\" if img.mode in ('RGBA', 'LA'): img = img.convert('RGB') img.save(fallback_path, fallback_format, quality=90) return True, f\"Saved as {fallback_format}\" except Exception as e: return False, str(e) # Usage result = safe_resize('photo.jpg', (800, 600)) valid, msg = validate_image_format('image.xyz') success, msg = robust_image_save(img, 'output.webp') This comprehensive cheat sheet covers the essential aspects of Pillow for image processing in Python. The library's strength lies in its broad format support, ease of use, and extensive functionality for both simple and complex image operations. It's the go-to library for Python developers working with images in web development, data science, and desktop applications.","title":"Pillow (PIL)"},{"location":"python/pillow/#pillow-pil","text":"Pillow is the modern, friendly fork of the Python Imaging Library (PIL). It provides extensive file format support, efficient internal representation, and powerful image processing capabilities. Pillow is the de facto standard for image manipulation in Python.","title":"Pillow (PIL)"},{"location":"python/pillow/#installation","text":"# Basic installation pip install Pillow # With optional dependencies pip install Pillow[complete] # Includes all optional dependencies # With specific extras pip install \"Pillow[extra]\" # WebP, PDF, and other format support # Development version pip install git+https://github.com/python-pillow/Pillow.git # System dependencies (Ubuntu/Debian) sudo apt-get install libjpeg-dev zlib1g-dev libtiff-dev libfreetype6-dev","title":"Installation"},{"location":"python/pillow/#basic-setup","text":"from PIL import Image, ImageDraw, ImageFont, ImageFilter, ImageEnhance from PIL import ImageOps, ImageChops, ImageStat, ImageColor import os import io import numpy as np # Check Pillow version and features print(f\"Pillow version: {Image.__version__}\") # Check supported formats print(\"Supported formats:\") print(\"Read:\", \", \".join(sorted(Image.registered_extensions()))) print(\"Write:\", \", \".join(sorted(Image.SAVE.keys())))","title":"Basic Setup"},{"location":"python/pillow/#core-functionality","text":"","title":"Core Functionality"},{"location":"python/pillow/#loading-and-saving-images","text":"# Load images img = Image.open(\"path/to/image.jpg\") img = Image.open(\"path/to/image.png\") # Load from URL import requests from io import BytesIO response = requests.get(\"https://example.com/image.jpg\") img = Image.open(BytesIO(response.content)) # Load from bytes with open(\"image.jpg\", \"rb\") as f: img = Image.open(BytesIO(f.read())) # Basic image information print(f\"Format: {img.format}\") # JPEG, PNG, etc. print(f\"Mode: {img.mode}\") # RGB, RGBA, L, etc. print(f\"Size: {img.size}\") # (width, height) print(f\"Info: {img.info}\") # Metadata dictionary # Save images img.save(\"output.jpg\") # Auto-detect format from extension img.save(\"output.png\", \"PNG\") # Explicit format img.save(\"output.jpg\", quality=95) # JPEG with quality setting # Save with optimization img.save(\"optimized.jpg\", optimize=True, quality=85) img.save(\"progressive.jpg\", progressive=True, quality=90) # Save to bytes buffer = io.BytesIO() img.save(buffer, format='JPEG') image_bytes = buffer.getvalue()","title":"Loading and Saving Images"},{"location":"python/pillow/#image-modes-and-conversions","text":"# Common image modes # L: Grayscale (8-bit) # RGB: Color (3x8-bit) # RGBA: Color with transparency (4x8-bit) # CMYK: Color for printing (4x8-bit) # P: Palette mode (8-bit mapped) # Mode conversions rgb_img = img.convert('RGB') # Convert to RGB gray_img = img.convert('L') # Convert to grayscale rgba_img = img.convert('RGBA') # Add alpha channel # Grayscale with custom weights def rgb_to_gray_custom(img, weights=(0.299, 0.587, 0.114)): \"\"\"Convert RGB to grayscale with custom weights\"\"\" r, g, b = img.split() gray = Image.eval(r, lambda x: int(x * weights[0])) gray.paste(Image.eval(g, lambda x: int(x * weights[1])), mask=None) gray.paste(Image.eval(b, lambda x: int(x * weights[2])), mask=None) return gray # Color quantization (reduce colors) quantized = img.quantize(colors=256) # Reduce to 256 colors quantized = img.quantize(colors=8) # Reduce to 8 colors","title":"Image Modes and Conversions"},{"location":"python/pillow/#basic-image-operations","text":"# Resize images resized = img.resize((800, 600)) # Resize to specific size resized = img.resize((400, 300), Image.LANCZOS) # High-quality resampling # Maintain aspect ratio def resize_with_aspect(img, max_size=(800, 600)): img.thumbnail(max_size, Image.LANCZOS) # In-place resize maintaining aspect return img # Crop images cropped = img.crop((100, 100, 400, 400)) # (left, top, right, bottom) # Rotate images rotated = img.rotate(45) # Rotate 45 degrees rotated = img.rotate(30, expand=True) # Expand canvas to fit rotated = img.rotate(-90, fillcolor='white') # Fill empty areas with white # Flip and transpose flipped_h = img.transpose(Image.FLIP_LEFT_RIGHT) # Horizontal flip flipped_v = img.transpose(Image.FLIP_TOP_BOTTOM) # Vertical flip rotated_90 = img.transpose(Image.ROTATE_90) # 90-degree rotation rotated_180 = img.transpose(Image.ROTATE_180) # 180-degree rotation rotated_270 = img.transpose(Image.ROTATE_270) # 270-degree rotation # Paste one image onto another background = Image.new('RGB', (800, 600), 'white') background.paste(img, (100, 100)) # Paste at position background.paste(img, (200, 200), img) # Use img as mask (if RGBA)","title":"Basic Image Operations"},{"location":"python/pillow/#common-use-cases","text":"","title":"Common Use Cases"},{"location":"python/pillow/#image-resizing-and-thumbnails","text":"def create_thumbnail(input_path, output_path, size=(150, 150)): \"\"\"Create a thumbnail maintaining aspect ratio\"\"\" with Image.open(input_path) as img: # Convert to RGB if necessary (for JPEG output) if img.mode in ('RGBA', 'LA', 'P'): img = img.convert('RGB') img.thumbnail(size, Image.LANCZOS) img.save(output_path, 'JPEG', quality=85, optimize=True) def resize_to_fit(img, target_size, background_color='white'): \"\"\"Resize image to fit within target size, adding padding if needed\"\"\" img.thumbnail(target_size, Image.LANCZOS) # Create new image with target size new_img = Image.new('RGB', target_size, background_color) # Calculate position to center the image x = (target_size[0] - img.width) // 2 y = (target_size[1] - img.height) // 2 new_img.paste(img, (x, y)) return new_img def resize_to_cover(img, target_size): \"\"\"Resize and crop image to cover target size\"\"\" img_ratio = img.width / img.height target_ratio = target_size[0] / target_size[1] if img_ratio > target_ratio: # Image is wider, resize by height new_height = target_size[1] new_width = int(new_height * img_ratio) img = img.resize((new_width, new_height), Image.LANCZOS) # Crop horizontally left = (new_width - target_size[0]) // 2 img = img.crop((left, 0, left + target_size[0], target_size[1])) else: # Image is taller, resize by width new_width = target_size[0] new_height = int(new_width / img_ratio) img = img.resize((new_width, new_height), Image.LANCZOS) # Crop vertically top = (new_height - target_size[1]) // 2 img = img.crop((0, top, target_size[0], top + target_size[1])) return img # Usage examples create_thumbnail('large_image.jpg', 'thumbnail.jpg', (200, 200)) img = Image.open('original.jpg') fitted = resize_to_fit(img, (800, 600), 'black') covered = resize_to_cover(img, (800, 600))","title":"Image Resizing and Thumbnails"},{"location":"python/pillow/#image-filters-and-enhancement","text":"# Built-in filters blurred = img.filter(ImageFilter.BLUR) sharp = img.filter(ImageFilter.SHARPEN) smooth = img.filter(ImageFilter.SMOOTH) detail = img.filter(ImageFilter.DETAIL) edge_enhance = img.filter(ImageFilter.EDGE_ENHANCE) emboss = img.filter(ImageFilter.EMBOSS) contour = img.filter(ImageFilter.CONTOUR) # Gaussian blur with radius gaussian = img.filter(ImageFilter.GaussianBlur(radius=2)) # Box blur box_blur = img.filter(ImageFilter.BoxBlur(radius=1)) # Unsharp mask for sharpening unsharp = img.filter(ImageFilter.UnsharpMask(radius=2, percent=150, threshold=3)) # Kernel-based filters kernel_sharpen = ImageFilter.Kernel( size=(3, 3), kernel=[-1, -1, -1, -1, 9, -1, -1, -1, -1], scale=1 ) sharpened = img.filter(kernel_sharpen) # Edge detection kernel kernel_edge = ImageFilter.Kernel( size=(3, 3), kernel=[-1, -1, -1, -1, 8, -1, -1, -1, -1], scale=1 ) edges = img.filter(kernel_edge) # Image enhancement enhancer = ImageEnhance.Brightness(img) brighter = enhancer.enhance(1.3) # 30% brighter darker = enhancer.enhance(0.7) # 30% darker enhancer = ImageEnhance.Contrast(img) high_contrast = enhancer.enhance(1.5) # Increase contrast enhancer = ImageEnhance.Color(img) saturated = enhancer.enhance(1.4) # More saturated desaturated = enhancer.enhance(0.6) # Less saturated enhancer = ImageEnhance.Sharpness(img) sharp = enhancer.enhance(2.0) # Sharper soft = enhancer.enhance(0.5) # Softer","title":"Image Filters and Enhancement"},{"location":"python/pillow/#drawing-on-images","text":"def add_watermark(img, text, position='bottom-right', font_size=36, opacity=128): \"\"\"Add text watermark to image\"\"\" # Create a transparent overlay overlay = Image.new('RGBA', img.size, (255, 255, 255, 0)) draw = ImageDraw.Draw(overlay) # Try to load a font try: font = ImageFont.truetype(\"arial.ttf\", font_size) except: font = ImageFont.load_default() # Get text dimensions bbox = draw.textbbox((0, 0), text, font=font) text_width = bbox[2] - bbox[0] text_height = bbox[3] - bbox[1] # Calculate position margin = 20 if position == 'bottom-right': x = img.width - text_width - margin y = img.height - text_height - margin elif position == 'bottom-left': x = margin y = img.height - text_height - margin elif position == 'top-right': x = img.width - text_width - margin y = margin else: # top-left x = margin y = margin # Draw text draw.text((x, y), text, font=font, fill=(255, 255, 255, opacity)) # Composite with original image if img.mode != 'RGBA': img = img.convert('RGBA') watermarked = Image.alpha_composite(img, overlay) return watermarked.convert('RGB') def draw_shapes_and_text(img): \"\"\"Draw various shapes and text on image\"\"\" draw = ImageDraw.Draw(img) # Rectangle draw.rectangle([50, 50, 150, 100], fill='red', outline='black', width=2) # Circle (ellipse with equal width and height) draw.ellipse([200, 50, 300, 150], fill='blue', outline='white', width=3) # Line draw.line([50, 150, 300, 200], fill='green', width=5) # Polygon draw.polygon([(400, 50), (450, 100), (400, 150), (350, 100)], fill='yellow', outline='purple') # Text try: font = ImageFont.truetype(\"arial.ttf\", 24) except: font = ImageFont.load_default() draw.text((50, 220), \"Hello, Pillow!\", font=font, fill='black') return img def add_border(img, border_size=10, color='black'): \"\"\"Add border around image\"\"\" return ImageOps.expand(img, border=border_size, fill=color) def create_rounded_corners(img, radius=20): \"\"\"Create image with rounded corners\"\"\" # Create mask mask = Image.new('L', img.size, 0) draw = ImageDraw.Draw(mask) draw.rounded_rectangle([0, 0, img.width, img.height], radius, fill=255) # Apply mask img = img.convert('RGBA') img.putalpha(mask) return img # Usage examples img = Image.open('photo.jpg') watermarked = add_watermark(img, \"\u00a9 2025 My Company\", opacity=100) bordered = add_border(img, 15, 'white') rounded = create_rounded_corners(img, 30)","title":"Drawing on Images"},{"location":"python/pillow/#batch-processing","text":"import os from pathlib import Path from concurrent.futures import ThreadPoolExecutor import multiprocessing def process_image(input_path, output_path, operations): \"\"\"Process a single image with specified operations\"\"\" try: with Image.open(input_path) as img: # Convert to RGB if needed if img.mode in ('RGBA', 'LA', 'P'): img = img.convert('RGB') # Apply operations for operation, params in operations.items(): if operation == 'resize': img = img.resize(params['size'], Image.LANCZOS) elif operation == 'thumbnail': img.thumbnail(params['size'], Image.LANCZOS) elif operation == 'rotate': img = img.rotate(params['angle']) elif operation == 'enhance_brightness': enhancer = ImageEnhance.Brightness(img) img = enhancer.enhance(params['factor']) elif operation == 'enhance_contrast': enhancer = ImageEnhance.Contrast(img) img = enhancer.enhance(params['factor']) elif operation == 'filter': img = img.filter(params['filter']) elif operation == 'grayscale': img = img.convert('L') # Save processed image os.makedirs(os.path.dirname(output_path), exist_ok=True) img.save(output_path, quality=params.get('quality', 90), optimize=True) return f\"Processed: {input_path} -> {output_path}\" except Exception as e: return f\"Error processing {input_path}: {str(e)}\" def batch_process_images(input_dir, output_dir, operations, file_extensions=None): \"\"\"Batch process images in a directory\"\"\" if file_extensions is None: file_extensions = {'.jpg', '.jpeg', '.png', '.bmp', '.tiff', '.webp'} input_path = Path(input_dir) output_path = Path(output_dir) # Find all image files image_files = [] for ext in file_extensions: image_files.extend(input_path.glob(f\"**/*{ext}\")) image_files.extend(input_path.glob(f\"**/*{ext.upper()}\")) # Prepare tasks tasks = [] for img_file in image_files: relative_path = img_file.relative_to(input_path) output_file = output_path / relative_path tasks.append((str(img_file), str(output_file), operations)) # Process with multiple threads max_workers = min(32, multiprocessing.cpu_count() * 2) with ThreadPoolExecutor(max_workers=max_workers) as executor: results = executor.map(lambda args: process_image(*args), tasks) # Print results for result in results: print(result) # Usage example operations = { 'thumbnail': {'size': (800, 600)}, 'enhance_contrast': {'factor': 1.1}, 'filter': {'filter': ImageFilter.SHARPEN}, 'quality': 85 } batch_process_images('./input_photos', './output_photos', operations) # Specific batch operations def create_thumbnails_batch(input_dir, output_dir, size=(200, 200)): \"\"\"Create thumbnails for all images in directory\"\"\" operations = { 'thumbnail': {'size': size}, 'quality': 85 } batch_process_images(input_dir, output_dir, operations) def optimize_images_batch(input_dir, output_dir, quality=85): \"\"\"Optimize images for web (reduce file size)\"\"\" operations = { 'resize': {'size': (1920, 1080)}, # Max size for web 'quality': quality } batch_process_images(input_dir, output_dir, operations) # Usage create_thumbnails_batch('./photos', './thumbnails', (150, 150)) optimize_images_batch('./large_photos', './optimized', quality=75)","title":"Batch Processing"},{"location":"python/pillow/#advanced-features","text":"","title":"Advanced Features"},{"location":"python/pillow/#working-with-image-metadata","text":"from PIL.ExifTags import TAGS, GPSTAGS import json def extract_exif_data(img_path): \"\"\"Extract EXIF data from image\"\"\" with Image.open(img_path) as img: exif_data = {} # Get raw EXIF data exif = img._getexif() if exif: for tag_id, value in exif.items(): tag = TAGS.get(tag_id, tag_id) # Handle GPS data specially if tag == \"GPSInfo\": gps_data = {} for gps_tag_id, gps_value in value.items(): gps_tag = GPSTAGS.get(gps_tag_id, gps_tag_id) gps_data[gps_tag] = gps_value exif_data[tag] = gps_data else: exif_data[tag] = value return exif_data def get_image_info(img_path): \"\"\"Get comprehensive image information\"\"\" with Image.open(img_path) as img: info = { 'filename': os.path.basename(img_path), 'format': img.format, 'mode': img.mode, 'size': img.size, 'width': img.width, 'height': img.height, 'aspect_ratio': round(img.width / img.height, 2), 'file_size': os.path.getsize(img_path), 'has_transparency': img.mode in ('RGBA', 'LA') or 'transparency' in img.info } # Add EXIF data if available exif = extract_exif_data(img_path) if exif: info['exif'] = { 'make': exif.get('Make', 'Unknown'), 'model': exif.get('Model', 'Unknown'), 'datetime': exif.get('DateTime', 'Unknown'), 'orientation': exif.get('Orientation', 1), 'iso': exif.get('ISOSpeedRatings', 'Unknown'), 'focal_length': exif.get('FocalLength', 'Unknown') } return info def auto_rotate_image(img_path, output_path=None): \"\"\"Auto-rotate image based on EXIF orientation\"\"\" with Image.open(img_path) as img: # Get orientation from EXIF exif = img._getexif() orientation = 1 if exif and 'Orientation' in [TAGS.get(k) for k in exif.keys()]: for tag_id, value in exif.items(): if TAGS.get(tag_id) == 'Orientation': orientation = value break # Apply rotation based on orientation if orientation == 3: img = img.rotate(180, expand=True) elif orientation == 6: img = img.rotate(270, expand=True) elif orientation == 8: img = img.rotate(90, expand=True) # Save rotated image if output_path: img.save(output_path) else: img.save(img_path) return img # Usage info = get_image_info('photo.jpg') print(json.dumps(info, indent=2, default=str)) auto_rotate_image('rotated_photo.jpg', 'corrected_photo.jpg')","title":"Working with Image Metadata"},{"location":"python/pillow/#color-operations","text":"def adjust_color_balance(img, cyan_red=0, magenta_green=0, yellow_blue=0): \"\"\"Adjust color balance similar to Photoshop\"\"\" # Split into RGB channels r, g, b = img.split() # Apply adjustments r = r.point(lambda x: max(0, min(255, x + cyan_red))) g = g.point(lambda x: max(0, min(255, x + magenta_green))) b = b.point(lambda x: max(0, min(255, x + yellow_blue))) return Image.merge('RGB', (r, g, b)) def apply_color_curves(img, curve_points): \"\"\"Apply color curves adjustment\"\"\" # Create lookup table curve = list(range(256)) # Interpolate curve points for i in range(len(curve_points) - 1): x1, y1 = curve_points[i] x2, y2 = curve_points[i + 1] for x in range(x1, x2 + 1): if x2 > x1: ratio = (x - x1) / (x2 - x1) curve[x] = int(y1 + ratio * (y2 - y1)) return img.point(curve) def create_sepia_effect(img): \"\"\"Create sepia tone effect\"\"\" # Convert to RGB if necessary if img.mode != 'RGB': img = img.convert('RGB') # Apply sepia transformation matrix pixels = img.load() width, height = img.size for y in range(height): for x in range(width): r, g, b = pixels[x, y] # Sepia transformation tr = int(0.393 * r + 0.769 * g + 0.189 * b) tg = int(0.349 * r + 0.686 * g + 0.168 * b) tb = int(0.272 * r + 0.534 * g + 0.131 * b) # Ensure values are within range pixels[x, y] = (min(255, tr), min(255, tg), min(255, tb)) return img def create_vintage_effect(img): \"\"\"Create vintage photo effect\"\"\" # Apply sepia img = create_sepia_effect(img) # Reduce contrast slightly enhancer = ImageEnhance.Contrast(img) img = enhancer.enhance(0.9) # Add slight blur img = img.filter(ImageFilter.GaussianBlur(0.5)) # Add vignette effect width, height = img.size vignette = Image.new('L', (width, height), 255) draw = ImageDraw.Draw(vignette) # Create radial gradient for vignette center_x, center_y = width // 2, height // 2 max_distance = min(width, height) // 2 for y in range(height): for x in range(width): distance = ((x - center_x) ** 2 + (y - center_y) ** 2) ** 0.5 if distance < max_distance: alpha = int(255 * (1 - (distance / max_distance) ** 2)) vignette.putpixel((x, y), alpha) else: vignette.putpixel((x, y), 0) # Apply vignette img = img.convert('RGBA') img.putalpha(vignette) return img def extract_dominant_colors(img, num_colors=5): \"\"\"Extract dominant colors from image\"\"\" # Convert to RGB and resize for performance img = img.convert('RGB') img = img.resize((150, 150)) # Smaller size for faster processing # Quantize to reduce colors quantized = img.quantize(colors=num_colors) # Get palette colors palette = quantized.getpalette() colors = [] for i in range(num_colors): r = palette[i * 3] g = palette[i * 3 + 1] b = palette[i * 3 + 2] colors.append((r, g, b)) # Count occurrences of each color quantized = quantized.convert('RGB') pixels = list(quantized.getdata()) color_counts = {} for pixel in pixels: color_counts[pixel] = color_counts.get(pixel, 0) + 1 # Sort by frequency sorted_colors = sorted(color_counts.items(), key=lambda x: x[1], reverse=True) return [color for color, count in sorted_colors[:num_colors]] # Usage examples img = Image.open('photo.jpg') # Color adjustments balanced = adjust_color_balance(img, cyan_red=10, yellow_blue=-5) # Curves adjustment (darken shadows, brighten highlights) curves = apply_color_curves(img, [(0, 0), (64, 50), (128, 128), (192, 200), (255, 255)]) # Effects sepia = create_sepia_effect(img) vintage = create_vintage_effect(img) # Extract colors dominant_colors = extract_dominant_colors(img) print(\"Dominant colors:\", dominant_colors)","title":"Color Operations"},{"location":"python/pillow/#advanced-compositing","text":"def blend_images(img1, img2, mode='normal', opacity=0.5): \"\"\"Blend two images with different blend modes\"\"\" # Ensure images are same size if img1.size != img2.size: img2 = img2.resize(img1.size, Image.LANCZOS) # Convert to same mode if img1.mode != img2.mode: img2 = img2.convert(img1.mode) if mode == 'normal': return Image.blend(img1, img2, opacity) elif mode == 'multiply': return ImageChops.multiply(img1, img2) elif mode == 'screen': return ImageChops.screen(img1, img2) elif mode == 'overlay': return ImageChops.overlay(img1, img2) elif mode == 'difference': return ImageChops.difference(img1, img2) elif mode == 'add': return ImageChops.add(img1, img2) elif mode == 'subtract': return ImageChops.subtract(img1, img2) elif mode == 'darker': return ImageChops.darker(img1, img2) elif mode == 'lighter': return ImageChops.lighter(img1, img2) else: return Image.blend(img1, img2, opacity) def create_photo_collage(images, layout=(2, 2), spacing=10, background_color='white'): \"\"\"Create a photo collage from multiple images\"\"\" rows, cols = layout # Calculate dimensions for each cell total_images = len(images) images = images[:rows * cols] # Limit to layout size # Find maximum dimensions max_width = max(img.width for img in images) max_height = max(img.height for img in images) # Calculate canvas size canvas_width = cols * max_width + (cols + 1) * spacing canvas_height = rows * max_height + (rows + 1) * spacing # Create canvas canvas = Image.new('RGB', (canvas_width, canvas_height), background_color) # Place images for i, img in enumerate(images): row = i // cols col = i % cols # Resize image to fit cell img_resized = img.copy() img_resized.thumbnail((max_width, max_height), Image.LANCZOS) # Calculate position x = spacing + col * (max_width + spacing) + (max_width - img_resized.width) // 2 y = spacing + row * (max_height + spacing) + (max_height - img_resized.height) // 2 canvas.paste(img_resized, (x, y)) return canvas def apply_gradient_mask(img, direction='horizontal', start_alpha=255, end_alpha=0): \"\"\"Apply gradient mask to image\"\"\" # Create gradient mask width, height = img.size mask = Image.new('L', (width, height)) for y in range(height): for x in range(width): if direction == 'horizontal': alpha = int(start_alpha + (end_alpha - start_alpha) * x / width) elif direction == 'vertical': alpha = int(start_alpha + (end_alpha - start_alpha) * y / height) elif direction == 'radial': center_x, center_y = width // 2, height // 2 distance = ((x - center_x) ** 2 + (y - center_y) ** 2) ** 0.5 max_distance = min(width, height) // 2 alpha = int(start_alpha + (end_alpha - start_alpha) * min(distance / max_distance, 1)) mask.putpixel((x, y), max(0, min(255, alpha))) # Apply mask if img.mode != 'RGBA': img = img.convert('RGBA') img.putalpha(mask) return img def create_panorama(images): \"\"\"Simple panorama creation (basic horizontal stitching)\"\"\" if not images: return None # Resize all images to same height min_height = min(img.height for img in images) resized_images = [] for img in images: aspect_ratio = img.width / img.height new_width = int(min_height * aspect_ratio) resized_img = img.resize((new_width, min_height), Image.LANCZOS) resized_images.append(resized_img) # Calculate total width total_width = sum(img.width for img in resized_images) # Create panorama canvas panorama = Image.new('RGB', (total_width, min_height)) # Paste images horizontally x_offset = 0 for img in resized_images: panorama.paste(img, (x_offset, 0)) x_offset += img.width return panorama # Usage examples img1 = Image.open('photo1.jpg') img2 = Image.open('photo2.jpg') # Blend images blended = blend_images(img1, img2, 'overlay', 0.7) # Create collage images = [Image.open(f'photo{i}.jpg') for i in range(1, 5)] collage = create_photo_collage(images, (2, 2), spacing=15) # Apply gradient gradient_img = apply_gradient_mask(img1, 'radial') # Create panorama pano_images = [Image.open(f'pano{i}.jpg') for i in range(1, 4)] panorama = create_panorama(pano_images)","title":"Advanced Compositing"},{"location":"python/pillow/#integration-with-other-libraries","text":"","title":"Integration with Other Libraries"},{"location":"python/pillow/#with-numpy","text":"import numpy as np # Convert PIL Image to NumPy array img_array = np.array(img) print(f\"Array shape: {img_array.shape}\") # (height, width, channels) print(f\"Array dtype: {img_array.dtype}\") # uint8 # Convert NumPy array to PIL Image img_from_array = Image.fromarray(img_array) # Advanced NumPy operations def adjust_gamma(img, gamma=1.0): \"\"\"Apply gamma correction\"\"\" img_array = np.array(img, dtype=np.float64) img_array = img_array / 255.0 # Normalize to [0, 1] img_array = np.power(img_array, gamma) img_array = (img_array * 255).astype(np.uint8) return Image.fromarray(img_array) def apply_histogram_equalization(img): \"\"\"Apply histogram equalization using NumPy\"\"\" if img.mode != 'L': img = img.convert('L') img_array = np.array(img) # Calculate histogram hist, bins = np.histogram(img_array.flatten(), 256, [0, 256]) # Calculate cumulative distribution cdf = hist.cumsum() cdf_normalized = cdf * 255 / cdf[-1] # Apply equalization img_equalized = np.interp(img_array.flatten(), bins[:-1], cdf_normalized) img_equalized = img_equalized.reshape(img_array.shape).astype(np.uint8) return Image.fromarray(img_equalized) def create_noise(size, noise_type='gaussian'): \"\"\"Create noise using NumPy\"\"\" if noise_type == 'gaussian': noise = np.random.normal(128, 30, size).astype(np.uint8) elif noise_type == 'uniform': noise = np.random.uniform(0, 255, size).astype(np.uint8) elif noise_type == 'salt_pepper': noise = np.random.choice([0, 255], size=size, p=[0.5, 0.5]).astype(np.uint8) return Image.fromarray(noise) # Usage gamma_corrected = adjust_gamma(img, gamma=1.5) equalized = apply_histogram_equalization(img) noise_img = create_noise((200, 200, 3), 'gaussian')","title":"With NumPy"},{"location":"python/pillow/#with-matplotlib","text":"import matplotlib.pyplot as plt import matplotlib.patches as patches def plot_image_analysis(img): \"\"\"Create comprehensive image analysis plot\"\"\" fig, axes = plt.subplots(2, 3, figsize=(15, 10)) # Original image axes[0, 0].imshow(img) axes[0, 0].set_title('Original Image') axes[0, 0].axis('off') # Grayscale gray_img = img.convert('L') axes[0, 1].imshow(gray_img, cmap='gray') axes[0, 1].set_title('Grayscale') axes[0, 1].axis('off') # Edge detection edges = gray_img.filter(ImageFilter.FIND_EDGES) axes[0, 2].imshow(edges, cmap='gray') axes[0, 2].set_title('Edge Detection') axes[0, 2].axis('off') # RGB Histogram if img.mode == 'RGB': r_hist = np.array(img.split()[0]).flatten() g_hist = np.array(img.split()[1]).flatten() b_hist = np.array(img.split()[2]).flatten() axes[1, 0].hist(r_hist, bins=256, color='red', alpha=0.7, density=True) axes[1, 0].hist(g_hist, bins=256, color='green', alpha=0.7, density=True) axes[1, 0].hist(b_hist, bins=256, color='blue', alpha=0.7, density=True) axes[1, 0].set_title('RGB Histogram') axes[1, 0].set_xlabel('Pixel Value') axes[1, 0].set_ylabel('Density') # Grayscale histogram gray_hist = np.array(gray_img).flatten() axes[1, 1].hist(gray_hist, bins=256, color='gray', alpha=0.7) axes[1, 1].set_title('Grayscale Histogram') axes[1, 1].set_xlabel('Pixel Value') axes[1, 1].set_ylabel('Frequency') # Image statistics stats = ImageStat.Stat(img) axes[1, 2].axis('off') stats_text = f\"\"\" Size: {img.size} Mode: {img.mode} Mean: {[round(m, 1) for m in stats.mean]} Median: {[round(m, 1) for m in stats.median]} StdDev: {[round(s, 1) for s in stats.stddev]} \"\"\" axes[1, 2].text(0.1, 0.5, stats_text, fontsize=12, verticalalignment='center') axes[1, 2].set_title('Image Statistics') plt.tight_layout() plt.show() def create_before_after_plot(original, processed, title=\"Before / After\"): \"\"\"Create side-by-side comparison\"\"\" fig, axes = plt.subplots(1, 2, figsize=(12, 6)) axes[0].imshow(original) axes[0].set_title('Before') axes[0].axis('off') axes[1].imshow(processed) axes[1].set_title('After') axes[1].axis('off') fig.suptitle(title, fontsize=16) plt.tight_layout() plt.show() # Usage plot_image_analysis(img) processed_img = img.filter(ImageFilter.SHARPEN) create_before_after_plot(img, processed_img, \"Sharpening Effect\")","title":"With Matplotlib"},{"location":"python/pillow/#with-opencv-integration","text":"import cv2 def pil_to_opencv(pil_img): \"\"\"Convert PIL Image to OpenCV format\"\"\" return cv2.cvtColor(np.array(pil_img), cv2.COLOR_RGB2BGR) def opencv_to_pil(cv_img): \"\"\"Convert OpenCV image to PIL format\"\"\" return Image.fromarray(cv2.cvtColor(cv_img, cv2.COLOR_BGR2RGB)) def advanced_edge_detection(img): \"\"\"Advanced edge detection using OpenCV\"\"\" # Convert to OpenCV format cv_img = pil_to_opencv(img) gray = cv2.cvtColor(cv_img, cv2.COLOR_BGR2GRAY) # Apply Canny edge detection edges = cv2.Canny(gray, 50, 150) # Convert back to PIL return Image.fromarray(edges, mode='L') def detect_contours(img, min_area=1000): \"\"\"Detect and draw contours\"\"\" cv_img = pil_to_opencv(img) gray = cv2.cvtColor(cv_img, cv2.COLOR_BGR2GRAY) # Find contours contours, _ = cv2.findContours(gray, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE) # Filter by area and draw for contour in contours: area = cv2.contourArea(contour) if area > min_area: cv2.drawContours(cv_img, [contour], -1, (0, 255, 0), 2) return opencv_to_pil(cv_img) # Usage edges = advanced_edge_detection(img) contours = detect_contours(img)","title":"With OpenCV Integration"},{"location":"python/pillow/#best-practices","text":"","title":"Best Practices"},{"location":"python/pillow/#performance-optimization","text":"# 1. Use appropriate resampling filters resizing_filters = { 'fastest': Image.NEAREST, # Fastest, lowest quality 'balanced': Image.BILINEAR, # Good balance 'quality': Image.LANCZOS # Best quality, slower } # 2. Work with smaller images when possible def optimize_for_processing(img, max_size=1024): \"\"\"Resize large images for faster processing\"\"\" if max(img.size) > max_size: img.thumbnail((max_size, max_size), Image.LANCZOS) return img # 3. Use context managers for file handling def process_multiple_images(file_paths, operations): \"\"\"Efficiently process multiple images\"\"\" results = [] for path in file_paths: with Image.open(path) as img: # Process without loading full image into memory for op in operations: img = op(img) results.append(img.copy()) # Make a copy before context ends return results # 4. Batch operations when possible def batch_resize(image_paths, size, output_dir): \"\"\"Batch resize operation\"\"\" os.makedirs(output_dir, exist_ok=True) for path in image_paths: with Image.open(path) as img: img.thumbnail(size, Image.LANCZOS) filename = os.path.basename(path) img.save(os.path.join(output_dir, filename), optimize=True) # 5. Use appropriate image formats format_recommendations = { 'photos': 'JPEG', # Best for photos 'graphics': 'PNG', # Best for graphics with transparency 'web_photos': 'WebP', # Modern web format 'icons': 'PNG', # Best for icons 'print': 'TIFF' # Best for print }","title":"Performance Optimization"},{"location":"python/pillow/#memory-management","text":"import psutil import gc def monitor_memory_usage(): \"\"\"Monitor memory usage\"\"\" process = psutil.Process() return process.memory_info().rss / 1024 / 1024 # MB def process_large_image_safely(img_path, operations, chunk_size=None): \"\"\"Process large images without loading everything into memory\"\"\" with Image.open(img_path) as img: print(f\"Processing {img.size} image\") print(f\"Memory before: {monitor_memory_usage():.1f} MB\") # Work with image for operation in operations: img = operation(img) gc.collect() # Force garbage collection print(f\"Memory after: {monitor_memory_usage():.1f} MB\") return img def create_image_pyramid(img, levels=3): \"\"\"Create image pyramid to save memory\"\"\" pyramid = [img] current = img for level in range(1, levels): size = (current.width // 2, current.height // 2) current = current.resize(size, Image.LANCZOS) pyramid.append(current) return pyramid","title":"Memory Management"},{"location":"python/pillow/#error-handling-and-validation","text":"def safe_image_operation(operation): \"\"\"Decorator for safe image operations\"\"\" def wrapper(img_path, *args, **kwargs): try: with Image.open(img_path) as img: return operation(img, *args, **kwargs) except IOError: print(f\"Cannot open image: {img_path}\") return None except Exception as e: print(f\"Error processing {img_path}: {str(e)}\") return None return wrapper @safe_image_operation def safe_resize(img, size): \"\"\"Safely resize image with error handling\"\"\" return img.resize(size, Image.LANCZOS) def validate_image_format(img_path, allowed_formats=None): \"\"\"Validate image format\"\"\" if allowed_formats is None: allowed_formats = {'JPEG', 'PNG', 'BMP', 'TIFF', 'WebP'} try: with Image.open(img_path) as img: if img.format in allowed_formats: return True, img.format else: return False, f\"Format {img.format} not allowed\" except: return False, \"Cannot open file\" def robust_image_save(img, output_path, fallback_format='JPEG', **kwargs): \"\"\"Save image with fallback options\"\"\" try: img.save(output_path, **kwargs) return True, \"Saved successfully\" except: try: # Try with fallback format base_name = os.path.splitext(output_path)[0] fallback_path = f\"{base_name}.{fallback_format.lower()}\" if img.mode in ('RGBA', 'LA'): img = img.convert('RGB') img.save(fallback_path, fallback_format, quality=90) return True, f\"Saved as {fallback_format}\" except Exception as e: return False, str(e) # Usage result = safe_resize('photo.jpg', (800, 600)) valid, msg = validate_image_format('image.xyz') success, msg = robust_image_save(img, 'output.webp') This comprehensive cheat sheet covers the essential aspects of Pillow for image processing in Python. The library's strength lies in its broad format support, ease of use, and extensive functionality for both simple and complex image operations. It's the go-to library for Python developers working with images in web development, data science, and desktop applications.","title":"Error Handling and Validation"},{"location":"python/polars/","text":"Polars Polars is a blazingly fast DataFrame library implemented in Rust, offering lazy and eager execution, multi-threading, and a powerful expression API for Python. Quick Start Installation pip install polars # With optional dependencies pip install polars[all] # For cloud storage support pip install polars[aws,azure,gcp] Basic Import import polars as pl DataFrame Creation From Dictionary df = pl.DataFrame({ \"name\": [\"Alice\", \"Bob\", \"Charlie\"], \"age\": [25, 30, 35], \"city\": [\"NY\", \"LA\", \"Chicago\"] }) From Lists df = pl.DataFrame([ [\"Alice\", 25, \"NY\"], [\"Bob\", 30, \"LA\"], [\"Charlie\", 35, \"Chicago\"] ], schema=[\"name\", \"age\", \"city\"]) From NumPy/Pandas import numpy as np import pandas as pd # From NumPy df = pl.from_numpy(np_array, schema=[\"col1\", \"col2\"]) # From Pandas df = pl.from_pandas(pd_df) Data Loading & Saving CSV Operations # Read CSV df = pl.read_csv(\"data.csv\") # Scan CSV (lazy loading) lazy_df = pl.scan_csv(\"data.csv\") # Write CSV df.write_csv(\"output.csv\") # Advanced reading with options df = pl.read_csv( \"data.csv\", separator=\",\", has_header=True, dtypes={\"age\": pl.Int64, \"salary\": pl.Float64}, null_values=[\"NULL\", \"NA\", \"\"], try_parse_dates=True ) Parquet Operations # Read Parquet df = pl.read_parquet(\"data.parquet\") # Scan Parquet (lazy loading) lazy_df = pl.scan_parquet(\"data.parquet\") # Write Parquet df.write_parquet(\"output.parquet\") # Read with filters (predicate pushdown) df = pl.scan_parquet(\"data.parquet\").filter( pl.col(\"age\") > 25 ).collect() JSON Operations # Read JSON df = pl.read_json(\"data.json\") # Read NDJSON (newline-delimited JSON) df = pl.read_ndjson(\"data.ndjson\") # Write JSON df.write_json(\"output.json\") df.write_ndjson(\"output.ndjson\") Cloud Storage # Read from S3 df = pl.read_parquet(\"s3://bucket/file.parquet\") # Read from Azure df = pl.read_csv(\"azure://container/file.csv\") # Read from Google Cloud df = pl.read_parquet(\"gs://bucket/file.parquet\") Data Selection & Filtering Column Selection # Select columns df.select([\"name\", \"age\"]) df.select(pl.col(\"name\", \"age\")) # Select with expressions df.select([ pl.col(\"name\"), pl.col(\"age\").alias(\"years\"), pl.col(\"salary\") * 1.1 # 10% increase ]) # Select by data type df.select(pl.col(pl.Utf8)) # String columns df.select(pl.col(pl.Int64)) # Integer columns Row Filtering # Basic filtering df.filter(pl.col(\"age\") > 25) # Multiple conditions df.filter( (pl.col(\"age\") > 25) & (pl.col(\"city\") == \"NY\") ) # String operations df.filter(pl.col(\"name\").str.contains(\"A\")) df.filter(pl.col(\"name\").str.starts_with(\"A\")) df.filter(pl.col(\"name\").str.ends_with(\"e\")) # Null filtering df.filter(pl.col(\"age\").is_not_null()) df.filter(pl.col(\"name\").is_null()) First/Last Rows df.head(5) # First 5 rows df.tail(5) # Last 5 rows df.limit(10) # First 10 rows df.slice(5, 10) # Rows 5-14 Data Transformation Adding/Modifying Columns # Add new columns df = df.with_columns([ pl.col(\"age\").alias(\"years\"), (pl.col(\"salary\") * 1.1).alias(\"new_salary\"), pl.lit(\"employee\").alias(\"type\") ]) # Conditional column creation df = df.with_columns( pl.when(pl.col(\"age\") > 30) .then(pl.lit(\"Senior\")) .otherwise(pl.lit(\"Junior\")) .alias(\"level\") ) String Operations df = df.with_columns([ pl.col(\"name\").str.to_uppercase().alias(\"name_upper\"), pl.col(\"name\").str.to_lowercase().alias(\"name_lower\"), pl.col(\"name\").str.len().alias(\"name_length\"), pl.col(\"text\").str.replace(\"old\", \"new\"), pl.col(\"text\").str.split(\" \").alias(\"words\") ]) Mathematical Operations df = df.with_columns([ pl.col(\"value\") + 10, pl.col(\"value\") * 2, pl.col(\"value\").sqrt(), pl.col(\"value\").log(), pl.col(\"value\").abs(), pl.col(\"value\").round(2) ]) Date/Time Operations df = df.with_columns([ pl.col(\"date\").dt.year().alias(\"year\"), pl.col(\"date\").dt.month().alias(\"month\"), pl.col(\"date\").dt.day().alias(\"day\"), pl.col(\"date\").dt.weekday().alias(\"weekday\"), pl.col(\"timestamp\").dt.hour().alias(\"hour\") ]) Aggregation & Grouping Basic Aggregations # Single column aggregations df.select([ pl.col(\"age\").sum(), pl.col(\"age\").mean(), pl.col(\"age\").median(), pl.col(\"age\").min(), pl.col(\"age\").max(), pl.col(\"age\").std(), pl.col(\"age\").var() ]) Group By Operations # Basic groupby result = df.group_by(\"city\").agg([ pl.col(\"age\").mean().alias(\"avg_age\"), pl.col(\"salary\").sum().alias(\"total_salary\"), pl.col(\"name\").count().alias(\"count\") ]) # Multiple groupby columns result = df.group_by([\"city\", \"department\"]).agg([ pl.col(\"salary\").mean(), pl.col(\"age\").max() ]) # Complex aggregations result = df.group_by(\"city\").agg([ pl.col(\"age\").filter(pl.col(\"age\") > 25).mean(), pl.col(\"salary\").quantile(0.95), pl.col(\"name\").n_unique() ]) Window Functions df = df.with_columns([ pl.col(\"salary\").sum().over(\"department\").alias(\"dept_total\"), pl.col(\"salary\").rank().over(\"department\").alias(\"salary_rank\"), pl.col(\"age\").mean().over(\"city\").alias(\"city_avg_age\"), pl.col(\"sales\").rolling_mean(window_size=3).alias(\"rolling_avg\") ]) Joining Operations Basic Joins # Inner join result = df1.join(df2, on=\"id\", how=\"inner\") # Left join result = df1.join(df2, on=\"id\", how=\"left\") # Outer join result = df1.join(df2, on=\"id\", how=\"outer\") # Different column names result = df1.join(df2, left_on=\"user_id\", right_on=\"id\") Advanced Joins # Multiple columns result = df1.join(df2, on=[\"id\", \"date\"]) # As-of join (temporal join) result = df1.join_asof( df2, on=\"timestamp\", strategy=\"backward\" # or \"forward\", \"nearest\" ) # Cross join result = df1.join(df2, how=\"cross\") # Semi and anti joins result = df1.join(df2, on=\"id\", how=\"semi\") # Keep matching rows result = df1.join(df2, on=\"id\", how=\"anti\") # Keep non-matching rows Data Manipulation Sorting # Single column df.sort(\"age\") df.sort(\"age\", descending=True) # Multiple columns df.sort([\"city\", \"age\"], descending=[False, True]) # By expression df.sort(pl.col(\"salary\") * pl.col(\"bonus\")) Unique Values # Get unique rows df.unique() # Unique based on subset df.unique(subset=[\"city\"]) # Drop duplicates df = df.unique(maintain_order=True) Reshaping # Pivot pivot_df = df.pivot( values=\"salary\", index=\"name\", columns=\"year\", aggregate=\"sum\" ) # Melt (unpivot) melted = df.melt( id_vars=[\"name\", \"city\"], value_vars=[\"salary_2022\", \"salary_2023\"], variable_name=\"year\", value_name=\"salary\" ) Handling Missing Data # Fill null values df = df.fill_null(0) # Fill with constant df = df.fill_null(pl.col(\"age\").median()) # Fill with median # Drop null values df = df.drop_nulls() # Drop rows with any nulls df = df.drop_nulls(subset=[\"age\", \"salary\"]) # Drop if specific columns null # Forward/backward fill df = df.fill_null(strategy=\"forward\") df = df.fill_null(strategy=\"backward\") Lazy Evaluation Creating Lazy Frames # From scan operations lazy_df = pl.scan_csv(\"large_file.csv\") # Convert DataFrame to LazyFrame lazy_df = df.lazy() Lazy Operations # Chain operations without execution query = ( pl.scan_csv(\"data.csv\") .filter(pl.col(\"age\") > 25) .group_by(\"city\") .agg(pl.col(\"salary\").mean()) .sort(\"salary\", descending=True) ) # Execute the query result = query.collect() # Show query plan print(query.explain()) Streaming # For very large datasets result = ( pl.scan_csv(\"huge_file.csv\") .filter(pl.col(\"value\") > 100) .group_by(\"category\") .agg(pl.col(\"amount\").sum()) .collect(streaming=True) ) Column Operations List Operations df = df.with_columns([ pl.col(\"list_col\").list.len().alias(\"list_length\"), pl.col(\"list_col\").list.get(0).alias(\"first_item\"), pl.col(\"list_col\").list.sum().alias(\"list_sum\"), pl.col(\"list_col\").list.unique().alias(\"unique_items\") ]) # Explode lists to rows df = df.explode(\"list_col\") Struct Operations # Create struct df = df.with_columns( pl.struct([\"name\", \"age\"]).alias(\"person\") ) # Extract struct fields df = df.with_columns([ pl.col(\"person\").struct.field(\"name\"), pl.col(\"person\").struct.field(\"age\") ]) Categorical Operations # Convert to categorical df = df.with_columns( pl.col(\"category\").cast(pl.Categorical) ) # Get categories df.select(pl.col(\"category\").cat.get_categories()) Performance Optimization Data Types # Optimize data types for memory df = df.with_columns([ pl.col(\"small_int\").cast(pl.Int8), # vs Int64 pl.col(\"category\").cast(pl.Categorical), # vs String pl.col(\"flag\").cast(pl.Boolean) # vs String ]) Query Optimization # Use lazy evaluation for large datasets lazy_result = ( pl.scan_parquet(\"large_data.parquet\") .select([\"needed_col1\", \"needed_col2\"]) # Project early .filter(pl.col(\"date\") > \"2023-01-01\") # Filter early .collect() ) # Use predicate pushdown with file formats df = pl.scan_parquet(\"data.parquet\").filter( pl.col(\"partition_col\") == \"value\" ).collect() Memory Management # For memory-constrained environments df = df.rechunk() # Optimize memory layout # Process in chunks for batch in pl.read_csv_batched(\"large_file.csv\", batch_size=10000): result = process_batch(batch) Integration with Other Libraries Pandas Integration # Convert to pandas pandas_df = df.to_pandas() # From pandas with zero-copy (when possible) polars_df = pl.from_pandas(pandas_df, rechunk=False) NumPy Integration # To NumPy numpy_array = df.to_numpy() # From NumPy df = pl.from_numpy(numpy_array, schema=[\"col1\", \"col2\"]) Arrow Integration # To Arrow arrow_table = df.to_arrow() # From Arrow df = pl.from_arrow(arrow_table) SQL Interface Basic SQL # Execute SQL on DataFrame result = df.sql(\"\"\" SELECT name, age, salary * 1.1 as new_salary FROM self WHERE age > 25 ORDER BY salary DESC \"\"\") # Global SQL context result = pl.sql(\"\"\" SELECT df1.name, df2.department FROM df1 JOIN df2 ON df1.id = df2.user_id \"\"\", eager=True) Table Functions in SQL # Read files directly in SQL result = pl.sql(\"\"\" SELECT * FROM read_csv('data.csv') WHERE age > 25 \"\"\") Common Patterns Data Cleaning Pipeline cleaned_df = ( pl.scan_csv(\"raw_data.csv\") .filter(pl.col(\"id\").is_not_null()) .with_columns([ pl.col(\"name\").str.strip_chars().str.to_title(), pl.col(\"age\").cast(pl.Int32), pl.col(\"email\").str.to_lowercase() ]) .filter(pl.col(\"age\").is_between(18, 100)) .unique(subset=[\"id\"]) .collect() ) Time Series Analysis time_series_df = ( df.sort(\"timestamp\") .with_columns([ pl.col(\"value\").rolling_mean(window_size=7).alias(\"7day_avg\"), pl.col(\"value\").rolling_std(window_size=7).alias(\"7day_std\"), pl.col(\"value\").pct_change().alias(\"pct_change\") ]) .filter(pl.col(\"timestamp\") > pl.date(2023, 1, 1)) ) Business Metrics metrics = ( sales_df .group_by([\"region\", \"product\"]) .agg([ pl.col(\"revenue\").sum().alias(\"total_revenue\"), pl.col(\"quantity\").sum().alias(\"total_quantity\"), pl.col(\"customer_id\").n_unique().alias(\"unique_customers\"), (pl.col(\"revenue\") / pl.col(\"quantity\")).mean().alias(\"avg_price\") ]) .with_columns( (pl.col(\"total_revenue\") / pl.col(\"total_revenue\").sum()).alias(\"revenue_share\") ) .sort(\"total_revenue\", descending=True) ) Error Handling & Debugging Common Errors # Schema mismatch in joins try: result = df1.join(df2, on=\"id\") except pl.SchemaError as e: print(f\"Schema error: {e}\") # Type casting errors df = df.with_columns( pl.col(\"maybe_numeric\").cast(pl.Float64, strict=False) ) Debugging # Inspect intermediate results df.glimpse() # Overview of DataFrame df.describe() # Statistical summary # Check lazy query plan lazy_df.explain() lazy_df.show_graph() # Visual representation Best Practices Use lazy evaluation for large datasets and complex queries Project and filter early to reduce memory usage Specify data types explicitly when reading data Use categorical types for string columns with limited unique values Leverage predicate pushdown with file formats like Parquet Chain operations in a single expression when possible Use window functions instead of self-joins for analytical queries Prefer scan_* functions over read_* for large files Use streaming for datasets larger than memory Consider partitioning for very large datasets Common Gotchas Column selection : pl.col(\"name\") vs \"name\" - use expressions for consistency Lazy evaluation : Remember to .collect() lazy frames Boolean operators : Use & and | instead of and and or String operations : Chain .str methods properly Join suffixes : Specify suffixes to avoid column name conflicts Memory usage : Large eager DataFrames can consume significant memory Type inference : Be explicit with data types for predictable behavior This cheat sheet covers the most commonly used Polars operations. For advanced features and detailed documentation, visit the official Polars documentation.","title":"Polars"},{"location":"python/polars/#polars","text":"Polars is a blazingly fast DataFrame library implemented in Rust, offering lazy and eager execution, multi-threading, and a powerful expression API for Python.","title":"Polars"},{"location":"python/polars/#quick-start","text":"","title":"Quick Start"},{"location":"python/polars/#installation","text":"pip install polars # With optional dependencies pip install polars[all] # For cloud storage support pip install polars[aws,azure,gcp]","title":"Installation"},{"location":"python/polars/#basic-import","text":"import polars as pl","title":"Basic Import"},{"location":"python/polars/#dataframe-creation","text":"","title":"DataFrame Creation"},{"location":"python/polars/#from-dictionary","text":"df = pl.DataFrame({ \"name\": [\"Alice\", \"Bob\", \"Charlie\"], \"age\": [25, 30, 35], \"city\": [\"NY\", \"LA\", \"Chicago\"] })","title":"From Dictionary"},{"location":"python/polars/#from-lists","text":"df = pl.DataFrame([ [\"Alice\", 25, \"NY\"], [\"Bob\", 30, \"LA\"], [\"Charlie\", 35, \"Chicago\"] ], schema=[\"name\", \"age\", \"city\"])","title":"From Lists"},{"location":"python/polars/#from-numpypandas","text":"import numpy as np import pandas as pd # From NumPy df = pl.from_numpy(np_array, schema=[\"col1\", \"col2\"]) # From Pandas df = pl.from_pandas(pd_df)","title":"From NumPy/Pandas"},{"location":"python/polars/#data-loading-saving","text":"","title":"Data Loading &amp; Saving"},{"location":"python/polars/#csv-operations","text":"# Read CSV df = pl.read_csv(\"data.csv\") # Scan CSV (lazy loading) lazy_df = pl.scan_csv(\"data.csv\") # Write CSV df.write_csv(\"output.csv\") # Advanced reading with options df = pl.read_csv( \"data.csv\", separator=\",\", has_header=True, dtypes={\"age\": pl.Int64, \"salary\": pl.Float64}, null_values=[\"NULL\", \"NA\", \"\"], try_parse_dates=True )","title":"CSV Operations"},{"location":"python/polars/#parquet-operations","text":"# Read Parquet df = pl.read_parquet(\"data.parquet\") # Scan Parquet (lazy loading) lazy_df = pl.scan_parquet(\"data.parquet\") # Write Parquet df.write_parquet(\"output.parquet\") # Read with filters (predicate pushdown) df = pl.scan_parquet(\"data.parquet\").filter( pl.col(\"age\") > 25 ).collect()","title":"Parquet Operations"},{"location":"python/polars/#json-operations","text":"# Read JSON df = pl.read_json(\"data.json\") # Read NDJSON (newline-delimited JSON) df = pl.read_ndjson(\"data.ndjson\") # Write JSON df.write_json(\"output.json\") df.write_ndjson(\"output.ndjson\")","title":"JSON Operations"},{"location":"python/polars/#cloud-storage","text":"# Read from S3 df = pl.read_parquet(\"s3://bucket/file.parquet\") # Read from Azure df = pl.read_csv(\"azure://container/file.csv\") # Read from Google Cloud df = pl.read_parquet(\"gs://bucket/file.parquet\")","title":"Cloud Storage"},{"location":"python/polars/#data-selection-filtering","text":"","title":"Data Selection &amp; Filtering"},{"location":"python/polars/#column-selection","text":"# Select columns df.select([\"name\", \"age\"]) df.select(pl.col(\"name\", \"age\")) # Select with expressions df.select([ pl.col(\"name\"), pl.col(\"age\").alias(\"years\"), pl.col(\"salary\") * 1.1 # 10% increase ]) # Select by data type df.select(pl.col(pl.Utf8)) # String columns df.select(pl.col(pl.Int64)) # Integer columns","title":"Column Selection"},{"location":"python/polars/#row-filtering","text":"# Basic filtering df.filter(pl.col(\"age\") > 25) # Multiple conditions df.filter( (pl.col(\"age\") > 25) & (pl.col(\"city\") == \"NY\") ) # String operations df.filter(pl.col(\"name\").str.contains(\"A\")) df.filter(pl.col(\"name\").str.starts_with(\"A\")) df.filter(pl.col(\"name\").str.ends_with(\"e\")) # Null filtering df.filter(pl.col(\"age\").is_not_null()) df.filter(pl.col(\"name\").is_null())","title":"Row Filtering"},{"location":"python/polars/#firstlast-rows","text":"df.head(5) # First 5 rows df.tail(5) # Last 5 rows df.limit(10) # First 10 rows df.slice(5, 10) # Rows 5-14","title":"First/Last Rows"},{"location":"python/polars/#data-transformation","text":"","title":"Data Transformation"},{"location":"python/polars/#addingmodifying-columns","text":"# Add new columns df = df.with_columns([ pl.col(\"age\").alias(\"years\"), (pl.col(\"salary\") * 1.1).alias(\"new_salary\"), pl.lit(\"employee\").alias(\"type\") ]) # Conditional column creation df = df.with_columns( pl.when(pl.col(\"age\") > 30) .then(pl.lit(\"Senior\")) .otherwise(pl.lit(\"Junior\")) .alias(\"level\") )","title":"Adding/Modifying Columns"},{"location":"python/polars/#string-operations","text":"df = df.with_columns([ pl.col(\"name\").str.to_uppercase().alias(\"name_upper\"), pl.col(\"name\").str.to_lowercase().alias(\"name_lower\"), pl.col(\"name\").str.len().alias(\"name_length\"), pl.col(\"text\").str.replace(\"old\", \"new\"), pl.col(\"text\").str.split(\" \").alias(\"words\") ])","title":"String Operations"},{"location":"python/polars/#mathematical-operations","text":"df = df.with_columns([ pl.col(\"value\") + 10, pl.col(\"value\") * 2, pl.col(\"value\").sqrt(), pl.col(\"value\").log(), pl.col(\"value\").abs(), pl.col(\"value\").round(2) ])","title":"Mathematical Operations"},{"location":"python/polars/#datetime-operations","text":"df = df.with_columns([ pl.col(\"date\").dt.year().alias(\"year\"), pl.col(\"date\").dt.month().alias(\"month\"), pl.col(\"date\").dt.day().alias(\"day\"), pl.col(\"date\").dt.weekday().alias(\"weekday\"), pl.col(\"timestamp\").dt.hour().alias(\"hour\") ])","title":"Date/Time Operations"},{"location":"python/polars/#aggregation-grouping","text":"","title":"Aggregation &amp; Grouping"},{"location":"python/polars/#basic-aggregations","text":"# Single column aggregations df.select([ pl.col(\"age\").sum(), pl.col(\"age\").mean(), pl.col(\"age\").median(), pl.col(\"age\").min(), pl.col(\"age\").max(), pl.col(\"age\").std(), pl.col(\"age\").var() ])","title":"Basic Aggregations"},{"location":"python/polars/#group-by-operations","text":"# Basic groupby result = df.group_by(\"city\").agg([ pl.col(\"age\").mean().alias(\"avg_age\"), pl.col(\"salary\").sum().alias(\"total_salary\"), pl.col(\"name\").count().alias(\"count\") ]) # Multiple groupby columns result = df.group_by([\"city\", \"department\"]).agg([ pl.col(\"salary\").mean(), pl.col(\"age\").max() ]) # Complex aggregations result = df.group_by(\"city\").agg([ pl.col(\"age\").filter(pl.col(\"age\") > 25).mean(), pl.col(\"salary\").quantile(0.95), pl.col(\"name\").n_unique() ])","title":"Group By Operations"},{"location":"python/polars/#window-functions","text":"df = df.with_columns([ pl.col(\"salary\").sum().over(\"department\").alias(\"dept_total\"), pl.col(\"salary\").rank().over(\"department\").alias(\"salary_rank\"), pl.col(\"age\").mean().over(\"city\").alias(\"city_avg_age\"), pl.col(\"sales\").rolling_mean(window_size=3).alias(\"rolling_avg\") ])","title":"Window Functions"},{"location":"python/polars/#joining-operations","text":"","title":"Joining Operations"},{"location":"python/polars/#basic-joins","text":"# Inner join result = df1.join(df2, on=\"id\", how=\"inner\") # Left join result = df1.join(df2, on=\"id\", how=\"left\") # Outer join result = df1.join(df2, on=\"id\", how=\"outer\") # Different column names result = df1.join(df2, left_on=\"user_id\", right_on=\"id\")","title":"Basic Joins"},{"location":"python/polars/#advanced-joins","text":"# Multiple columns result = df1.join(df2, on=[\"id\", \"date\"]) # As-of join (temporal join) result = df1.join_asof( df2, on=\"timestamp\", strategy=\"backward\" # or \"forward\", \"nearest\" ) # Cross join result = df1.join(df2, how=\"cross\") # Semi and anti joins result = df1.join(df2, on=\"id\", how=\"semi\") # Keep matching rows result = df1.join(df2, on=\"id\", how=\"anti\") # Keep non-matching rows","title":"Advanced Joins"},{"location":"python/polars/#data-manipulation","text":"","title":"Data Manipulation"},{"location":"python/polars/#sorting","text":"# Single column df.sort(\"age\") df.sort(\"age\", descending=True) # Multiple columns df.sort([\"city\", \"age\"], descending=[False, True]) # By expression df.sort(pl.col(\"salary\") * pl.col(\"bonus\"))","title":"Sorting"},{"location":"python/polars/#unique-values","text":"# Get unique rows df.unique() # Unique based on subset df.unique(subset=[\"city\"]) # Drop duplicates df = df.unique(maintain_order=True)","title":"Unique Values"},{"location":"python/polars/#reshaping","text":"# Pivot pivot_df = df.pivot( values=\"salary\", index=\"name\", columns=\"year\", aggregate=\"sum\" ) # Melt (unpivot) melted = df.melt( id_vars=[\"name\", \"city\"], value_vars=[\"salary_2022\", \"salary_2023\"], variable_name=\"year\", value_name=\"salary\" )","title":"Reshaping"},{"location":"python/polars/#handling-missing-data","text":"# Fill null values df = df.fill_null(0) # Fill with constant df = df.fill_null(pl.col(\"age\").median()) # Fill with median # Drop null values df = df.drop_nulls() # Drop rows with any nulls df = df.drop_nulls(subset=[\"age\", \"salary\"]) # Drop if specific columns null # Forward/backward fill df = df.fill_null(strategy=\"forward\") df = df.fill_null(strategy=\"backward\")","title":"Handling Missing Data"},{"location":"python/polars/#lazy-evaluation","text":"","title":"Lazy Evaluation"},{"location":"python/polars/#creating-lazy-frames","text":"# From scan operations lazy_df = pl.scan_csv(\"large_file.csv\") # Convert DataFrame to LazyFrame lazy_df = df.lazy()","title":"Creating Lazy Frames"},{"location":"python/polars/#lazy-operations","text":"# Chain operations without execution query = ( pl.scan_csv(\"data.csv\") .filter(pl.col(\"age\") > 25) .group_by(\"city\") .agg(pl.col(\"salary\").mean()) .sort(\"salary\", descending=True) ) # Execute the query result = query.collect() # Show query plan print(query.explain())","title":"Lazy Operations"},{"location":"python/polars/#streaming","text":"# For very large datasets result = ( pl.scan_csv(\"huge_file.csv\") .filter(pl.col(\"value\") > 100) .group_by(\"category\") .agg(pl.col(\"amount\").sum()) .collect(streaming=True) )","title":"Streaming"},{"location":"python/polars/#column-operations","text":"","title":"Column Operations"},{"location":"python/polars/#list-operations","text":"df = df.with_columns([ pl.col(\"list_col\").list.len().alias(\"list_length\"), pl.col(\"list_col\").list.get(0).alias(\"first_item\"), pl.col(\"list_col\").list.sum().alias(\"list_sum\"), pl.col(\"list_col\").list.unique().alias(\"unique_items\") ]) # Explode lists to rows df = df.explode(\"list_col\")","title":"List Operations"},{"location":"python/polars/#struct-operations","text":"# Create struct df = df.with_columns( pl.struct([\"name\", \"age\"]).alias(\"person\") ) # Extract struct fields df = df.with_columns([ pl.col(\"person\").struct.field(\"name\"), pl.col(\"person\").struct.field(\"age\") ])","title":"Struct Operations"},{"location":"python/polars/#categorical-operations","text":"# Convert to categorical df = df.with_columns( pl.col(\"category\").cast(pl.Categorical) ) # Get categories df.select(pl.col(\"category\").cat.get_categories())","title":"Categorical Operations"},{"location":"python/polars/#performance-optimization","text":"","title":"Performance Optimization"},{"location":"python/polars/#data-types","text":"# Optimize data types for memory df = df.with_columns([ pl.col(\"small_int\").cast(pl.Int8), # vs Int64 pl.col(\"category\").cast(pl.Categorical), # vs String pl.col(\"flag\").cast(pl.Boolean) # vs String ])","title":"Data Types"},{"location":"python/polars/#query-optimization","text":"# Use lazy evaluation for large datasets lazy_result = ( pl.scan_parquet(\"large_data.parquet\") .select([\"needed_col1\", \"needed_col2\"]) # Project early .filter(pl.col(\"date\") > \"2023-01-01\") # Filter early .collect() ) # Use predicate pushdown with file formats df = pl.scan_parquet(\"data.parquet\").filter( pl.col(\"partition_col\") == \"value\" ).collect()","title":"Query Optimization"},{"location":"python/polars/#memory-management","text":"# For memory-constrained environments df = df.rechunk() # Optimize memory layout # Process in chunks for batch in pl.read_csv_batched(\"large_file.csv\", batch_size=10000): result = process_batch(batch)","title":"Memory Management"},{"location":"python/polars/#integration-with-other-libraries","text":"","title":"Integration with Other Libraries"},{"location":"python/polars/#pandas-integration","text":"# Convert to pandas pandas_df = df.to_pandas() # From pandas with zero-copy (when possible) polars_df = pl.from_pandas(pandas_df, rechunk=False)","title":"Pandas Integration"},{"location":"python/polars/#numpy-integration","text":"# To NumPy numpy_array = df.to_numpy() # From NumPy df = pl.from_numpy(numpy_array, schema=[\"col1\", \"col2\"])","title":"NumPy Integration"},{"location":"python/polars/#arrow-integration","text":"# To Arrow arrow_table = df.to_arrow() # From Arrow df = pl.from_arrow(arrow_table)","title":"Arrow Integration"},{"location":"python/polars/#sql-interface","text":"","title":"SQL Interface"},{"location":"python/polars/#basic-sql","text":"# Execute SQL on DataFrame result = df.sql(\"\"\" SELECT name, age, salary * 1.1 as new_salary FROM self WHERE age > 25 ORDER BY salary DESC \"\"\") # Global SQL context result = pl.sql(\"\"\" SELECT df1.name, df2.department FROM df1 JOIN df2 ON df1.id = df2.user_id \"\"\", eager=True)","title":"Basic SQL"},{"location":"python/polars/#table-functions-in-sql","text":"# Read files directly in SQL result = pl.sql(\"\"\" SELECT * FROM read_csv('data.csv') WHERE age > 25 \"\"\")","title":"Table Functions in SQL"},{"location":"python/polars/#common-patterns","text":"","title":"Common Patterns"},{"location":"python/polars/#data-cleaning-pipeline","text":"cleaned_df = ( pl.scan_csv(\"raw_data.csv\") .filter(pl.col(\"id\").is_not_null()) .with_columns([ pl.col(\"name\").str.strip_chars().str.to_title(), pl.col(\"age\").cast(pl.Int32), pl.col(\"email\").str.to_lowercase() ]) .filter(pl.col(\"age\").is_between(18, 100)) .unique(subset=[\"id\"]) .collect() )","title":"Data Cleaning Pipeline"},{"location":"python/polars/#time-series-analysis","text":"time_series_df = ( df.sort(\"timestamp\") .with_columns([ pl.col(\"value\").rolling_mean(window_size=7).alias(\"7day_avg\"), pl.col(\"value\").rolling_std(window_size=7).alias(\"7day_std\"), pl.col(\"value\").pct_change().alias(\"pct_change\") ]) .filter(pl.col(\"timestamp\") > pl.date(2023, 1, 1)) )","title":"Time Series Analysis"},{"location":"python/polars/#business-metrics","text":"metrics = ( sales_df .group_by([\"region\", \"product\"]) .agg([ pl.col(\"revenue\").sum().alias(\"total_revenue\"), pl.col(\"quantity\").sum().alias(\"total_quantity\"), pl.col(\"customer_id\").n_unique().alias(\"unique_customers\"), (pl.col(\"revenue\") / pl.col(\"quantity\")).mean().alias(\"avg_price\") ]) .with_columns( (pl.col(\"total_revenue\") / pl.col(\"total_revenue\").sum()).alias(\"revenue_share\") ) .sort(\"total_revenue\", descending=True) )","title":"Business Metrics"},{"location":"python/polars/#error-handling-debugging","text":"","title":"Error Handling &amp; Debugging"},{"location":"python/polars/#common-errors","text":"# Schema mismatch in joins try: result = df1.join(df2, on=\"id\") except pl.SchemaError as e: print(f\"Schema error: {e}\") # Type casting errors df = df.with_columns( pl.col(\"maybe_numeric\").cast(pl.Float64, strict=False) )","title":"Common Errors"},{"location":"python/polars/#debugging","text":"# Inspect intermediate results df.glimpse() # Overview of DataFrame df.describe() # Statistical summary # Check lazy query plan lazy_df.explain() lazy_df.show_graph() # Visual representation","title":"Debugging"},{"location":"python/polars/#best-practices","text":"Use lazy evaluation for large datasets and complex queries Project and filter early to reduce memory usage Specify data types explicitly when reading data Use categorical types for string columns with limited unique values Leverage predicate pushdown with file formats like Parquet Chain operations in a single expression when possible Use window functions instead of self-joins for analytical queries Prefer scan_* functions over read_* for large files Use streaming for datasets larger than memory Consider partitioning for very large datasets","title":"Best Practices"},{"location":"python/polars/#common-gotchas","text":"Column selection : pl.col(\"name\") vs \"name\" - use expressions for consistency Lazy evaluation : Remember to .collect() lazy frames Boolean operators : Use & and | instead of and and or String operations : Chain .str methods properly Join suffixes : Specify suffixes to avoid column name conflicts Memory usage : Large eager DataFrames can consume significant memory Type inference : Be explicit with data types for predictable behavior This cheat sheet covers the most commonly used Polars operations. For advanced features and detailed documentation, visit the official Polars documentation.","title":"Common Gotchas"},{"location":"python/python/","text":"Python Installation # Download from python.org or use package manager # macOS with Homebrew brew install python # Ubuntu/Debian sudo apt update && sudo apt install python3 python3-pip # Windows # Download from python.org or use Microsoft Store # Check version python --version python3 --version Basic Syntax Variables and Assignment # Variable assignment x = 5 name = \"Alice\" is_active = True # Multiple assignment a, b, c = 1, 2, 3 x = y = z = 0 # Swapping variables a, b = b, a Data Types # Numeric types integer = 42 float_num = 3.14 complex_num = 2 + 3j # Strings single_quote = 'Hello' double_quote = \"World\" multiline = \"\"\"This is a multiline string\"\"\" # Boolean is_true = True is_false = False # None type empty_value = None # Type checking type(42) # <class 'int'> isinstance(42, int) # True Operators Arithmetic Operators # Basic arithmetic a + b # Addition a - b # Subtraction a * b # Multiplication a / b # Division (float) a // b # Floor division a % b # Modulus a ** b # Exponentiation # Augmented assignment x += 5 # x = x + 5 x -= 3 # x = x - 3 x *= 2 # x = x * 2 x /= 4 # x = x / 4 Comparison Operators a == b # Equal a != b # Not equal a < b # Less than a <= b # Less than or equal a > b # Greater than a >= b # Greater than or equal # Chaining comparisons 1 < x < 10 # True if x is between 1 and 10 Logical Operators # Boolean logic a and b # Logical AND a or b # Logical OR not a # Logical NOT # Short-circuit evaluation result = condition1 and condition2 # condition2 only evaluated if condition1 is True result = condition1 or condition2 # condition2 only evaluated if condition1 is False Identity and Membership # Identity operators a is b # Same object a is not b # Different objects # Membership operators item in container # True if item is in container item not in container # True if item is not in container # Examples x = [1, 2, 3] 2 in x # True 4 not in x # True Control Flow Conditional Statements # if-elif-else if condition1: # code block elif condition2: # code block else: # code block # Ternary operator result = value_if_true if condition else value_if_false # Examples age = 18 status = \"adult\" if age >= 18 else \"minor\" # Multiple conditions if 18 <= age < 65: print(\"Working age\") Loops For Loops # Iterating over sequences for item in [1, 2, 3]: print(item) # Range function for i in range(5): # 0 to 4 print(i) for i in range(2, 8): # 2 to 7 print(i) for i in range(0, 10, 2): # 0, 2, 4, 6, 8 print(i) # Enumerate for index and value for index, value in enumerate(['a', 'b', 'c']): print(f\"{index}: {value}\") # Zip for parallel iteration for x, y in zip([1, 2, 3], ['a', 'b', 'c']): print(x, y) While Loops # While loop count = 0 while count < 5: print(count) count += 1 # Infinite loop with break while True: user_input = input(\"Enter 'quit' to exit: \") if user_input == 'quit': break print(f\"You entered: {user_input}\") Loop Control # break - exit loop for i in range(10): if i == 5: break print(i) # prints 0, 1, 2, 3, 4 # continue - skip iteration for i in range(5): if i == 2: continue print(i) # prints 0, 1, 3, 4 # else clause (executes if loop completes normally) for i in range(3): print(i) else: print(\"Loop completed\") Data Structures Lists # Creating lists empty_list = [] numbers = [1, 2, 3, 4, 5] mixed = [1, \"hello\", 3.14, True] # List methods numbers.append(6) # Add to end numbers.insert(0, 0) # Insert at index numbers.extend([7, 8]) # Add multiple items numbers.remove(3) # Remove first occurrence item = numbers.pop() # Remove and return last item item = numbers.pop(0) # Remove and return item at index # List operations len(numbers) # Length numbers[0] # Access by index numbers[-1] # Last item numbers[1:4] # Slicing numbers[:3] # First 3 items numbers[2:] # From index 2 to end numbers[::2] # Every 2nd item # List comprehension squares = [x**2 for x in range(10)] evens = [x for x in range(20) if x % 2 == 0] Tuples # Creating tuples empty_tuple = () single_item = (42,) # Note the comma coordinates = (10, 20) rgb = (255, 128, 0) # Tuple unpacking x, y = coordinates r, g, b = rgb # Named tuples from collections import namedtuple Point = namedtuple('Point', ['x', 'y']) p = Point(10, 20) print(p.x, p.y) Dictionaries # Creating dictionaries empty_dict = {} person = {'name': 'Alice', 'age': 30, 'city': 'New York'} person = dict(name='Alice', age=30, city='New York') # Dictionary operations person['name'] # Access value person['email'] = 'alice@example.com' # Add/update del person['age'] # Delete key person.get('phone', 'N/A') # Get with default # Dictionary methods person.keys() # All keys person.values() # All values person.items() # Key-value pairs person.update({'age': 31}) # Update multiple # Dictionary comprehension squares = {x: x**2 for x in range(5)} Sets # Creating sets empty_set = set() numbers = {1, 2, 3, 4, 5} from_list = set([1, 2, 2, 3]) # Duplicates removed # Set operations numbers.add(6) # Add element numbers.remove(3) # Remove element (raises error if not found) numbers.discard(10) # Remove element (no error if not found) # Set mathematics set1 = {1, 2, 3} set2 = {3, 4, 5} set1 | set2 # Union {1, 2, 3, 4, 5} set1 & set2 # Intersection {3} set1 - set2 # Difference {1, 2} set1 ^ set2 # Symmetric difference {1, 2, 4, 5} Functions Basic Functions # Function definition def greet(name): return f\"Hello, {name}!\" # Function with default parameters def greet(name, greeting=\"Hello\"): return f\"{greeting}, {name}!\" # Multiple return values def divide_and_remainder(a, b): return a // b, a % b quotient, remainder = divide_and_remainder(17, 5) # Variable arguments def sum_all(*args): return sum(args) def print_info(**kwargs): for key, value in kwargs.items(): print(f\"{key}: {value}\") # Mixed arguments def complex_func(required, default=\"default\", *args, **kwargs): print(f\"Required: {required}\") print(f\"Default: {default}\") print(f\"Args: {args}\") print(f\"Kwargs: {kwargs}\") Lambda Functions # Lambda (anonymous) functions square = lambda x: x**2 add = lambda x, y: x + y # Common use with higher-order functions numbers = [1, 2, 3, 4, 5] squares = list(map(lambda x: x**2, numbers)) evens = list(filter(lambda x: x % 2 == 0, numbers)) # Sorting with lambda students = [('Alice', 85), ('Bob', 92), ('Charlie', 78)] students.sort(key=lambda student: student[1]) # Sort by grade Decorators # Simple decorator def my_decorator(func): def wrapper(): print(\"Before function call\") func() print(\"After function call\") return wrapper @my_decorator def say_hello(): print(\"Hello!\") # Decorator with arguments def repeat(times): def decorator(func): def wrapper(*args, **kwargs): for _ in range(times): result = func(*args, **kwargs) return result return wrapper return decorator @repeat(3) def greet(name): print(f\"Hello, {name}!\") # Built-in decorators @staticmethod def utility_function(): pass @classmethod def from_string(cls, string): pass @property def full_name(self): return f\"{self.first} {self.last}\" Classes and Objects Basic Classes # Class definition class Person: # Class variable species = \"Homo sapiens\" # Constructor def __init__(self, name, age): self.name = name # Instance variable self.age = age # Instance method def greet(self): return f\"Hello, I'm {self.name}\" # Human-readable string representation def __str__(self): return f\"Person named {self.name}, age {self.age}\" # Developer-friendly string representation def __repr__(self): return f\"Person('{self.name}', {self.age})\" # Creating objects person1 = Person(\"Alice\", 30) print(person1.greet()) Inheritance # Base class class Animal: def __init__(self, name): self.name = name def speak(self): pass def __str__(self): return f\"{self.__class__.__name__}('{self.name}')\" # Derived classes class Dog(Animal): def speak(self): return f\"{self.name} says Woof!\" class Cat(Animal): def speak(self): return f\"{self.name} says Meow!\" # Multiple inheritance class FlyingMixin: def fly(self): return f\"{self.name} is flying!\" class Bird(Animal, FlyingMixin): def speak(self): return f\"{self.name} says Tweet!\" # Using super() class Employee(Person): def __init__(self, name, age, employee_id): super().__init__(name, age) self.employee_id = employee_id Dunder Methods (Magic Methods) Dunder methods (double underscore methods) are special methods that allow Python objects to implement or modify built-in behaviors. They define how objects interact with operators, built-in functions, and language constructs. Object Representation class Person: def __init__(self, name, age): self.name = name self.age = age def __str__(self): # Human-readable string representation # Called by str() and print() return f\"Person named {self.name}, age {self.age}\" def __repr__(self): # Unambiguous string representation for developers # Called by repr() and in interactive shell # Should ideally be valid Python code to recreate the object return f\"Person('{self.name}', {self.age})\" # Usage person = Person(\"Alice\", 30) print(person) # Uses __str__: Person named Alice, age 30 repr(person) # Uses __repr__: Person('Alice', 30) str(person) # Uses __str__: Person named Alice, age 30 # In interactive shell or debugger, __repr__ is used by default Object Initialization and Creation class DatabaseConnection: def __new__(cls, host, port): # Controls object creation (rarely overridden) # Called before __init__ print(f\"Creating connection to {host}:{port}\") instance = super().__new__(cls) return instance def __init__(self, host, port): # Object initialization after creation # Most commonly used constructor method self.host = host self.port = port print(f\"Initialized connection to {host}:{port}\") # Example of when __new__ is useful (Singleton pattern) class Singleton: _instance = None def __new__(cls): if cls._instance is None: cls._instance = super().__new__(cls) return cls._instance Container-like Behavior class CustomList: def __init__(self, items=None): self.items = items or [] def __len__(self): # Called by len() return len(self.items) def __bool__(self): # Called by bool() and in boolean contexts # If not defined, __len__ is used (0 is False) return len(self.items) > 0 def __getitem__(self, key): # Called for indexing: obj[key] return self.items[key] def __setitem__(self, key, value): # Called for item assignment: obj[key] = value self.items[key] = value def __delitem__(self, key): # Called for item deletion: del obj[key] del self.items[key] def __contains__(self, item): # Called by 'in' operator return item in self.items # Usage custom_list = CustomList([1, 2, 3, 4]) print(len(custom_list)) # 4 print(bool(custom_list)) # True print(custom_list[0]) # 1 custom_list[0] = 10 # Sets first item to 10 del custom_list[1] # Removes second item print(2 in custom_list) # False (was deleted) Iterator Protocol class NumberSequence: def __init__(self, start, end): self.start = start self.end = end def __iter__(self): # Returns iterator object (often self) # Called by iter() and in for loops self.current = self.start return self def __next__(self): # Returns next item in iteration # Called by next() and automatically in for loops if self.current < self.end: num = self.current self.current += 1 return num else: raise StopIteration # Usage sequence = NumberSequence(1, 5) for num in sequence: # Uses __iter__ and __next__ print(num) # Prints 1, 2, 3, 4 # Manual iteration iterator = iter(sequence) # Calls __iter__ print(next(iterator)) # Calls __next__ Context Manager Protocol class FileManager: def __init__(self, filename, mode): self.filename = filename self.mode = mode self.file = None def __enter__(self): # Called when entering 'with' block # Return value is assigned to 'as' variable print(f\"Opening {self.filename}\") self.file = open(self.filename, self.mode) return self.file def __exit__(self, exc_type, exc_val, exc_tb): # Called when exiting 'with' block # Parameters contain exception info if one occurred print(f\"Closing {self.filename}\") if self.file: self.file.close() # Return False to propagate exceptions # Return True to suppress exceptions return False # Usage with FileManager(\"data.txt\", \"w\") as f: f.write(\"Hello, World!\") # File is automatically closed # Another example: Timer context manager import time class Timer: def __enter__(self): self.start_time = time.time() return self def __exit__(self, exc_type, exc_val, exc_tb): elapsed = time.time() - self.start_time print(f\"Elapsed time: {elapsed:.2f} seconds\") return False with Timer(): # Some time-consuming operation time.sleep(1) Callable Objects class Multiplier: def __init__(self, factor): self.factor = factor def __call__(self, value): # Makes the object callable like a function return value * self.factor # Usage double = Multiplier(2) triple = Multiplier(3) print(double(5)) # 10 (calls __call__) print(triple(4)) # 12 # Check if object is callable print(callable(double)) # True # Useful for creating function-like objects with state class Counter: def __init__(self): self.count = 0 def __call__(self): self.count += 1 return self.count counter = Counter() print(counter()) # 1 print(counter()) # 2 Hashing and Equality class Point: def __init__(self, x, y): self.x = x self.y = y def __eq__(self, other): # Defines equality (==) # Also affects !=, which returns the opposite if not isinstance(other, Point): return False return self.x == other.x and self.y == other.y def __hash__(self): # Makes object hashable (can be used as dict key or in set) # Objects that compare equal must have same hash value # Immutable objects should implement this return hash((self.x, self.y)) def __repr__(self): return f\"Point({self.x}, {self.y})\" # Usage p1 = Point(1, 2) p2 = Point(1, 2) p3 = Point(2, 3) print(p1 == p2) # True print(p1 == p3) # False # Can be used as dictionary keys points_dict = {p1: \"origin area\", p3: \"far point\"} print(points_dict[p2]) # \"origin area\" (p1 == p2) # Can be added to sets point_set = {p1, p2, p3} # Only p1 and p3 (p1 == p2) print(len(point_set)) # 2 Arithmetic Operators class Vector: def __init__(self, x, y): self.x = x self.y = y def __add__(self, other): # Addition: self + other return Vector(self.x + other.x, self.y + other.y) def __sub__(self, other): # Subtraction: self - other return Vector(self.x - other.x, self.y - other.y) def __mul__(self, other): # Multiplication: self * other if isinstance(other, (int, float)): # Scalar multiplication return Vector(self.x * other, self.y * other) else: # Dot product with another vector return self.x * other.x + self.y * other.y def __rmul__(self, other): # Right multiplication: other * self # Called when left operand doesn't support operation return self.__mul__(other) def __truediv__(self, scalar): # Division: self / other return Vector(self.x / scalar, self.y / scalar) def __floordiv__(self, scalar): # Floor division: self // other return Vector(self.x // scalar, self.y // scalar) def __mod__(self, scalar): # Modulus: self % other return Vector(self.x % scalar, self.y % scalar) def __pow__(self, power): # Exponentiation: self ** other return Vector(self.x ** power, self.y ** power) def __abs__(self): # Absolute value: abs(self) return (self.x**2 + self.y**2)**0.5 def __neg__(self): # Unary minus: -self return Vector(-self.x, -self.y) def __str__(self): return f\"Vector({self.x}, {self.y})\" # Usage v1 = Vector(3, 4) v2 = Vector(1, 2) print(v1 + v2) # Vector(4, 6) print(v1 - v2) # Vector(2, 2) print(v1 * 2) # Vector(6, 8) - scalar multiplication print(3 * v1) # Vector(9, 12) - uses __rmul__ print(v1 * v2) # 11 - dot product print(v1 / 2) # Vector(1.5, 2.0) print(abs(v1)) # 5.0 - magnitude print(-v1) # Vector(-3, -4) Comparison Operators class Student: def __init__(self, name, grade): self.name = name self.grade = grade def __eq__(self, other): return self.grade == other.grade def __lt__(self, other): # Less than: self < other return self.grade < other.grade def __le__(self, other): # Less than or equal: self <= other return self.grade <= other.grade def __gt__(self, other): # Greater than: self > other return self.grade > other.grade def __ge__(self, other): # Greater than or equal: self >= other return self.grade >= other.grade def __ne__(self, other): # Not equal: self != other (usually auto-generated from __eq__) return not self.__eq__(other) def __repr__(self): return f\"Student('{self.name}', {self.grade})\" # Usage alice = Student(\"Alice\", 85) bob = Student(\"Bob\", 92) charlie = Student(\"Charlie\", 85) print(alice < bob) # True print(alice == charlie) # True print(bob >= alice) # True # Can be sorted students = [bob, alice, charlie] sorted_students = sorted(students) # Sorts by grade using __lt__ Python Slang and Terminology Understanding Python's unique terminology and idioms is essential for reading code, documentation, and communicating with other Python developers. Core Python Terminology Dunder (Double Underscore) # \"Dunder\" refers to methods with double underscores before and after class MyClass: def __init__(self): # \"dunder init\" pass def __str__(self): # \"dunder str\" return \"MyClass\" def __len__(self): # \"dunder len\" return 0 # Also applies to built-in variables print(__name__) # \"dunder name\" print(__file__) # \"dunder file\" Pythonic Writing code that follows Python idioms and conventions. Emphasizes readability, simplicity, and following \"The Zen of Python.\" # Non-Pythonic numbers = [1, 2, 3, 4, 5] squares = [] for num in numbers: squares.append(num ** 2) # Pythonic squares = [num ** 2 for num in numbers] # Non-Pythonic if len(my_list) == 0: print(\"List is empty\") # Pythonic if not my_list: print(\"List is empty\") # Non-Pythonic for i in range(len(items)): print(f\"{i}: {items[i]}\") # Pythonic for i, item in enumerate(items): print(f\"{i}: {item}\") Programming Philosophies EAFP (Easier to Ask for Forgiveness than Permission) Python's preferred approach: try the operation and handle exceptions rather than checking conditions first. # EAFP - Pythonic approach def get_value(dictionary, key): try: return dictionary[key] except KeyError: return None def process_file(filename): try: with open(filename, 'r') as file: return file.read() except FileNotFoundError: return \"File not found\" # Example with attribute access try: result = obj.some_method() except AttributeError: result = \"Method not available\" LBYL (Look Before You Leap) The alternative approach: check conditions before performing operations. # LBYL - Less Pythonic in most cases def get_value(dictionary, key): if key in dictionary: return dictionary[key] else: return None def process_file(filename): path = Path(filename) if path.exists(): with path.open('r') as file: return file.read() else: return \"File not found\" # Example with attribute access if hasattr(obj, 'some_method'): result = obj.some_method() else: result = \"Method not available\" # When LBYL is appropriate: # - Performance critical code where exceptions are expensive # - When checking is much faster than trying and failing Type System Concepts Duck Typing \"If it walks like a duck and quacks like a duck, then it's a duck.\" Objects are judged by their behavior, not their type. # Duck typing example def make_sound(animal): # We don't care what type animal is # We just call its sound() method print(animal.sound()) class Dog: def sound(self): return \"Woof!\" class Cat: def sound(self): return \"Meow!\" class Robot: def sound(self): return \"Beep!\" # All work with make_sound function make_sound(Dog()) # Works because Dog has sound() make_sound(Cat()) # Works because Cat has sound() make_sound(Robot()) # Works because Robot has sound() # Another example: file-like objects def process_data(file_obj): # Works with any object that has read() method return file_obj.read() # Works with files, StringIO, BytesIO, etc. with open('data.txt') as f: process_data(f) from io import StringIO string_file = StringIO(\"Hello, World!\") process_data(string_file) Monkey Patching Dynamically modifying classes or modules at runtime. # Monkey patching example class Calculator: def add(self, a, b): return a + b # Add a new method to the class def subtract(self, a, b): return a - b Calculator.subtract = subtract # Now all Calculator instances have subtract method calc = Calculator() print(calc.add(5, 3)) # 8 print(calc.subtract(5, 3)) # 2 # Monkey patching built-in modules import datetime # Add a custom method to datetime def is_weekend(self): return self.weekday() >= 5 datetime.date.is_weekend = is_weekend # Now all dates have is_weekend method today = datetime.date.today() print(today.is_weekend()) # Be cautious with monkey patching: # - Can make code harder to understand # - Can break if the original implementation changes # - Use sparingly and document well Data Structure Terminology List Comprehension vs Generator Expression # List comprehension - creates a list immediately squares_list = [x**2 for x in range(10)] print(type(squares_list)) # <class 'list'> print(squares_list) # [0, 1, 4, 9, 16, 25, 36, 49, 64, 81] # Generator expression - creates a generator (lazy evaluation) squares_gen = (x**2 for x in range(10)) print(type(squares_gen)) # <class 'generator'> print(squares_gen) # <generator object at 0x...> # Generator values are produced on-demand for square in squares_gen: print(square) # Prints one at a time # Memory comparison import sys large_list = [x for x in range(1000000)] large_gen = (x for x in range(1000000)) print(f\"List size: {sys.getsizeof(large_list)} bytes\") print(f\"Generator size: {sys.getsizeof(large_gen)} bytes\") Language Features GIL (Global Interpreter Lock) Python's mechanism that allows only one thread to execute Python code at a time. import threading import time # The GIL affects CPU-bound tasks def cpu_bound_task(): # This won't run in parallel due to GIL total = 0 for i in range(10000000): total += i return total # Multiple threads won't speed up CPU-bound work start_time = time.time() threads = [] for _ in range(4): thread = threading.Thread(target=cpu_bound_task) threads.append(thread) thread.start() for thread in threads: thread.join() print(f\"Multi-threaded time: {time.time() - start_time}\") # For CPU-bound work, use multiprocessing instead from multiprocessing import Pool def parallel_cpu_work(): with Pool() as pool: results = pool.map(lambda x: sum(range(x)), [1000000] * 4) return results # GIL doesn't affect I/O-bound tasks import asyncio import aiohttp async def io_bound_task(url): async with aiohttp.ClientSession() as session: async with session.get(url) as response: return await response.text() # This can run concurrently despite the GIL Advanced Concepts Descriptor Protocol Objects that define how attribute access is handled. class Descriptor: def __get__(self, obj, objtype=None): return \"Getting attribute\" def __set__(self, obj, value): print(f\"Setting attribute to {value}\") def __delete__(self, obj): print(\"Deleting attribute\") class MyClass: attr = Descriptor() obj = MyClass() print(obj.attr) # \"Getting attribute\" obj.attr = \"new value\" # \"Setting attribute to new value\" del obj.attr # \"Deleting attribute\" Context Manager Objects that define runtime context for executing code blocks (used with with statements). # Built-in context managers with open('file.txt', 'r') as f: # File is a context manager content = f.read() # File is automatically closed # Custom context manager using contextlib from contextlib import contextmanager @contextmanager def temporary_change(obj, attr, new_value): old_value = getattr(obj, attr) setattr(obj, attr, new_value) try: yield obj finally: setattr(obj, attr, old_value) # Usage class Config: debug = False config = Config() with temporary_change(config, 'debug', True): print(config.debug) # True print(config.debug) # False (restored) Metaclass Classes whose instances are classes themselves. \"Classes that create classes.\" # Simple metaclass example class SingletonMeta(type): _instances = {} def __call__(cls, *args, **kwargs): if cls not in cls._instances: cls._instances[cls] = super().__call__(*args, **kwargs) return cls._instances[cls] class Singleton(metaclass=SingletonMeta): def __init__(self, value): self.value = value # Both variables refer to the same instance s1 = Singleton(\"first\") s2 = Singleton(\"second\") print(s1 is s2) # True print(s1.value) # \"first\" (unchanged) Common Patterns and Idioms Unpacking and Packing # Tuple unpacking point = (3, 4) x, y = point # Extended unpacking (Python 3+) first, *middle, last = [1, 2, 3, 4, 5] print(first) # 1 print(middle) # [2, 3, 4] print(last) # 5 # Function argument unpacking def greet(name, age, city): print(f\"{name} is {age} years old and lives in {city}\") person_info = (\"Alice\", 30, \"New York\") greet(*person_info) # Unpacks tuple as arguments person_dict = {\"name\": \"Bob\", \"age\": 25, \"city\": \"Boston\"} greet(**person_dict) # Unpacks dictionary as keyword arguments Walrus Operator (Assignment Expression) # Walrus operator := (Python 3.8+) # Assigns and returns a value in one expression # Traditional approach numbers = [1, 2, 3, 4, 5] squared = [] for num in numbers: square = num ** 2 if square > 10: squared.append(square) # With walrus operator squared = [square for num in numbers if (square := num ** 2) > 10] # Useful in while loops import random while (dice := random.randint(1, 6)) != 6: print(f\"Rolled {dice}, try again\") print(\"Finally rolled a 6!\") # In conditional statements if (match := some_pattern.search(text)): print(f\"Found match: {match.group()}\") Understanding Python Culture The Zen of Python import this # Prints \"The Zen of Python\" # Key principles: # - Beautiful is better than ugly # - Explicit is better than implicit # - Simple is better than complex # - Readability counts # - There should be one obvious way to do it Exception Handling Basic Exception Handling # try-except try: result = 10 / 0 except ZeroDivisionError: print(\"Cannot divide by zero\") # Multiple exceptions try: value = int(input(\"Enter a number: \")) result = 10 / value except ValueError: print(\"Invalid input\") except ZeroDivisionError: print(\"Cannot divide by zero\") # Catch multiple exception types try: # risky code pass except (ValueError, TypeError) as e: print(f\"Error: {e}\") # Catch all exceptions try: # risky code pass except Exception as e: print(f\"Unexpected error: {e}\") # finally block (always executes) try: file = open(\"data.txt\") # process file except FileNotFoundError: print(\"File not found\") finally: try: file.close() except NameError: pass # file was never opened Custom Exceptions class CustomError(Exception): pass class ValidationError(Exception): def __init__(self, message, code=None): super().__init__(message) self.code = code def validate_age(age): if age < 0: raise ValidationError(\"Age cannot be negative\", code=\"NEGATIVE_AGE\") if age > 150: raise ValidationError(\"Age seems unrealistic\", code=\"HIGH_AGE\") try: validate_age(-5) except ValidationError as e: print(f\"Validation failed: {e} (Code: {e.code})\") File Handling Reading and Writing Files # Reading files with open(\"file.txt\", \"r\") as file: content = file.read() # Read entire file with open(\"file.txt\", \"r\") as file: lines = file.readlines() # Read all lines as list with open(\"file.txt\", \"r\") as file: for line in file: # Iterate line by line print(line.strip()) # Writing files with open(\"output.txt\", \"w\") as file: file.write(\"Hello, World!\\n\") file.writelines([\"Line 1\\n\", \"Line 2\\n\"]) # Appending to files with open(\"log.txt\", \"a\") as file: file.write(\"New log entry\\n\") # File modes # \"r\" - read (default) # \"w\" - write (overwrites) # \"a\" - append # \"x\" - exclusive creation # \"b\" - binary mode # \"t\" - text mode (default) # \"+\" - read and write Working with JSON import json # Writing JSON data = {\"name\": \"Alice\", \"age\": 30, \"city\": \"New York\"} with open(\"data.json\", \"w\") as file: json.dump(data, file, indent=2) # Reading JSON with open(\"data.json\", \"r\") as file: data = json.load(file) # JSON strings json_string = json.dumps(data, indent=2) parsed_data = json.loads(json_string) Working with CSV import csv # Writing CSV data = [ [\"Name\", \"Age\", \"City\"], [\"Alice\", 30, \"New York\"], [\"Bob\", 25, \"Boston\"] ] with open(\"people.csv\", \"w\", newline=\"\") as file: writer = csv.writer(file) writer.writerows(data) # Reading CSV with open(\"people.csv\", \"r\") as file: reader = csv.reader(file) for row in reader: print(row) # CSV with dictionaries with open(\"people.csv\", \"w\", newline=\"\") as file: fieldnames = [\"name\", \"age\", \"city\"] writer = csv.DictWriter(file, fieldnames=fieldnames) writer.writeheader() writer.writerow({\"name\": \"Alice\", \"age\": 30, \"city\": \"New York\"}) Modules and Packages Importing Modules # Different import styles import math from math import pi, sqrt from math import * # Not recommended import math as m # Using imported functions result = math.sqrt(16) result = sqrt(16) result = m.sqrt(16) # Importing from packages from os.path import join, exists from urllib.parse import urlparse Creating Modules # mymodule.py \"\"\"A simple module example.\"\"\" PI = 3.14159 def circle_area(radius): \"\"\"Calculate the area of a circle.\"\"\" return PI * radius ** 2 def circle_circumference(radius): \"\"\"Calculate the circumference of a circle.\"\"\" return 2 * PI * radius if __name__ == \"__main__\": # This code runs only when the module is executed directly print(\"Testing the module\") print(f\"Area of circle with radius 5: {circle_area(5)}\") Package Structure mypackage/ __init__.py module1.py module2.py subpackage/ __init__.py submodule.py # __init__.py \"\"\"MyPackage - A sample package.\"\"\" from .module1 import function1 from .module2 import Class2 __version__ = \"1.0.0\" __all__ = [\"function1\", \"Class2\"] Built-in Functions Common Built-ins # Type conversion int(\"42\") # String to integer float(\"3.14\") # String to float str(42) # Number to string bool(1) # To boolean list(\"hello\") # String to list of characters # Math functions abs(-5) # Absolute value round(3.7) # Round to nearest integer round(3.14159, 2) # Round to 2 decimal places min(1, 2, 3) # Minimum value max([1, 2, 3]) # Maximum value sum([1, 2, 3]) # Sum of iterable # Sequence functions len([1, 2, 3]) # Length sorted([3, 1, 2]) # Return sorted list reversed([1, 2, 3]) # Return reversed iterator enumerate(['a', 'b']) # Return index-value pairs zip([1, 2], ['a', 'b']) # Combine iterables # Higher-order functions map(str, [1, 2, 3]) # Apply function to each item filter(lambda x: x > 0, [-1, 0, 1, 2]) # Filter items all([True, True, False]) # True if all elements are true any([False, True, False]) # True if any element is true Input/Output # User input name = input(\"Enter your name: \") age = int(input(\"Enter your age: \")) # Printing print(\"Hello, World!\") print(\"Name:\", name, \"Age:\", age) print(f\"Hello, {name}! You are {age} years old.\") print(\"Value:\", 42, sep=\" = \", end=\"\\n\\n\") # String formatting name = \"Alice\" age = 30 print(\"Name: {}, Age: {}\".format(name, age)) print(\"Name: {name}, Age: {age}\".format(name=name, age=age)) print(f\"Name: {name}, Age: {age}\") # f-strings (Python 3.6+) String Operations String Methods text = \" Hello, World! \" # Case conversion text.upper() # \" HELLO, WORLD! \" text.lower() # \" hello, world! \" text.title() # \" Hello, World! \" text.capitalize() # \" hello, world! \" text.swapcase() # \" hELLO, wORLD! \" # Whitespace handling text.strip() # \"Hello, World!\" text.lstrip() # \"Hello, World! \" text.rstrip() # \" Hello, World!\" # Searching and checking text.find(\"World\") # Index of substring (or -1) text.index(\"World\") # Index of substring (raises ValueError) text.count(\"l\") # Count occurrences text.startswith(\" H\") # True text.endswith(\"! \") # True \"123\".isdigit() # True \"abc\".isalpha() # True \"abc123\".isalnum() # True # Splitting and joining \"a,b,c\".split(\",\") # [\"a\", \"b\", \"c\"] \"hello world\".split() # [\"hello\", \"world\"] \"-\".join([\"a\", \"b\", \"c\"]) # \"a-b-c\" # Replacement text.replace(\"World\", \"Python\") # \" Hello, Python! \" # Formatting \"The value is {:.2f}\".format(3.14159) # \"The value is 3.14\" f\"The value is {3.14159:.2f}\" # \"The value is 3.14\" String Slicing and Indexing text = \"Hello, World!\" # Indexing text[0] # \"H\" text[-1] # \"!\" text[7] # \"W\" # Slicing text[0:5] # \"Hello\" text[7:] # \"World!\" text[:5] # \"Hello\" text[::2] # \"Hlo ol!\" text[::-1] # \"!dlroW ,olleH\" (reversed) List Comprehensions and Generators List Comprehensions # Basic list comprehension squares = [x**2 for x in range(10)] # With condition evens = [x for x in range(20) if x % 2 == 0] # Nested loops pairs = [(x, y) for x in range(3) for y in range(3) if x != y] # Processing strings words = [\"hello\", \"world\", \"python\"] lengths = [len(word) for word in words] upper_words = [word.upper() for word in words if len(word) > 4] Dictionary and Set Comprehensions # Dictionary comprehension squares = {x: x**2 for x in range(5)} word_lengths = {word: len(word) for word in [\"hello\", \"world\"]} # Set comprehension unique_lengths = {len(word) for word in [\"hello\", \"world\", \"hi\"]} Generator Expressions # Generator expression (lazy evaluation) squares_gen = (x**2 for x in range(10)) # Generator function def fibonacci(n): a, b = 0, 1 for _ in range(n): yield a a, b = b, a + b # Using generators for num in fibonacci(10): print(num) # Generator with yield from def flatten(nested_list): for sublist in nested_list: if isinstance(sublist, list): yield from flatten(sublist) else: yield sublist nested = [[1, 2], [3, [4, 5]], 6] flat = list(flatten(nested)) # [1, 2, 3, 4, 5, 6] Context Managers Using Context Managers # File handling with context manager with open(\"file.txt\", \"r\") as file: content = file.read() # File is automatically closed # Multiple context managers with open(\"input.txt\", \"r\") as infile, open(\"output.txt\", \"w\") as outfile: outfile.write(infile.read()) Creating Context Managers # Using contextlib from contextlib import contextmanager @contextmanager def timer(): import time start = time.time() try: yield finally: end = time.time() print(f\"Elapsed time: {end - start:.2f} seconds\") # Usage with timer(): # Some time-consuming operation sum(range(1000000)) # Class-based context manager class DatabaseConnection: def __enter__(self): print(\"Connecting to database\") return self def __exit__(self, exc_type, exc_val, exc_tb): print(\"Closing database connection\") return False # Don't suppress exceptions with DatabaseConnection() as db: print(\"Using database connection\") Regular Expressions Basic Regex Operations import re # Pattern matching pattern = r\"\\d+\" # One or more digits text = \"I have 5 apples and 10 oranges\" # Search for first match match = re.search(pattern, text) if match: print(match.group()) # \"5\" # Find all matches matches = re.findall(pattern, text) # [\"5\", \"10\"] # Match at beginning of string match = re.match(r\"\\w+\", \"Hello World\") # \"Hello\" # Split by pattern parts = re.split(r\"\\s+\", \"Hello World Python\") # [\"Hello\", \"World\", \"Python\"] # Replace patterns result = re.sub(r\"\\d+\", \"X\", text) # \"I have X apples and X oranges\" Common Regex Patterns # Email validation (simplified) email_pattern = r\"[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}\" # Phone number (US format) phone_pattern = r\"\\(\\d{3}\\)\\s\\d{3}-\\d{4}\" # URL pattern url_pattern = r\"https?://[^\\s]+\" # Date pattern (YYYY-MM-DD) date_pattern = r\"\\d{4}-\\d{2}-\\d{2}\" # Compiled patterns for efficiency compiled_email = re.compile(email_pattern) result = compiled_email.search(\"Contact us at info@example.com\") Working with Dates and Times datetime Module from datetime import datetime, date, time, timedelta # Current date and time now = datetime.now() today = date.today() current_time = datetime.now().time() # Creating specific dates birthday = date(1990, 5, 15) meeting_time = datetime(2023, 12, 25, 14, 30) # Formatting dates formatted = now.strftime(\"%Y-%m-%d %H:%M:%S\") formatted_date = today.strftime(\"%B %d, %Y\") # Parsing strings to dates parsed = datetime.strptime(\"2023-12-25 14:30\", \"%Y-%m-%d %H:%M\") # Date arithmetic tomorrow = today + timedelta(days=1) week_ago = now - timedelta(weeks=1) in_2_hours = now + timedelta(hours=2) # Date comparisons if birthday < today: print(\"Birthday has passed this year\") time Module import time # Current timestamp timestamp = time.time() # Sleep/pause execution time.sleep(2) # Pause for 2 seconds # Measure execution time start_time = time.time() # ... some operation ... end_time = time.time() elapsed = end_time - start_time Error Handling Best Practices Specific Exception Handling def safe_divide(a, b): try: return a / b except TypeError: print(\"Both arguments must be numbers\") return None except ZeroDivisionError: print(\"Cannot divide by zero\") return None except Exception as e: print(f\"Unexpected error: {e}\") return None def read_config_file(filename): try: with open(filename, 'r') as file: return json.load(file) except FileNotFoundError: print(f\"Config file {filename} not found\") return {} except json.JSONDecodeError as e: print(f\"Invalid JSON in config file: {e}\") return {} except PermissionError: print(f\"Permission denied reading {filename}\") return {} Common Patterns Singleton Pattern class Singleton: _instance = None def __new__(cls): if cls._instance is None: cls._instance = super().__new__(cls) return cls._instance Factory Pattern class Animal: def speak(self): pass class Dog(Animal): def speak(self): return \"Woof!\" class Cat(Animal): def speak(self): return \"Meow!\" def create_animal(animal_type): animals = { 'dog': Dog, 'cat': Cat } return animals.get(animal_type.lower(), Animal)() Performance Tips Use built-in functions : sum() , max() , min() are optimized List comprehensions : Generally faster than equivalent loops Use join() for string concatenation : Instead of += in loops Use set for membership testing : O(1) vs O(n) for lists Use collections.defaultdict : Avoid checking if keys exist Use generators : For memory-efficient iteration over large datasets Profile your code : Use cProfile and timeit Type Hints and Annotations Basic Type Hints from typing import List, Dict, Optional, Union, Callable, Tuple # Function with type hints def greet(name: str, age: int) -> str: return f\"Hello {name}, you are {age} years old\" # Variable annotations count: int = 0 names: List[str] = [\"Alice\", \"Bob\"] scores: Dict[str, float] = {\"Alice\": 95.5, \"Bob\": 87.2} # Optional and Union types def find_user(user_id: int) -> Optional[str]: # Returns string or None return users.get(user_id) def process_data(data: Union[str, int]) -> str: # Accepts string or int return str(data).upper() # Function type hints def apply_operation(func: Callable[[int, int], int], x: int, y: int) -> int: return func(x, y) # Generic types from typing import TypeVar T = TypeVar('T') def first_item(items: List[T]) -> Optional[T]: return items[0] if items else None Advanced Type Hints from typing import Protocol, Literal, Final # Protocol for structural typing class Drawable(Protocol): def draw(self) -> None: ... # Literal types def set_mode(mode: Literal['read', 'write', 'append']) -> None: pass # Final variables (constants) API_KEY: Final[str] = \"secret-key\" # Class with type hints class User: def __init__(self, name: str, email: str) -> None: self.name = name self.email = email def get_info(self) -> Dict[str, str]: return {\"name\": self.name, \"email\": self.email} Dataclasses Basic Dataclasses from dataclasses import dataclass, field from typing import List @dataclass class Person: name: str age: int email: str = \"\" # Default value def greet(self) -> str: return f\"Hello, I'm {self.name}\" # Usage person = Person(\"Alice\", 30, \"alice@example.com\") print(person.name) # Alice # With post-init processing @dataclass class Rectangle: width: float height: float area: float = field(init=False) # Computed field def __post_init__(self): self.area = self.width * self.height # Frozen dataclass (immutable) @dataclass(frozen=True) class Point: x: float y: float # With default factory @dataclass class Team: name: str members: List[str] = field(default_factory=list) Async Programming Basic Async/Await import asyncio import aiohttp from typing import List # Async function async def fetch_data(url: str) -> str: async with aiohttp.ClientSession() as session: async with session.get(url) as response: return await response.text() # Running async code async def main(): data = await fetch_data(\"https://api.example.com\") print(data) # Run the main function asyncio.run(main()) # Concurrent execution async def fetch_multiple(urls: List[str]) -> List[str]: tasks = [fetch_data(url) for url in urls] results = await asyncio.gather(*tasks) return results # Async generator async def async_counter(max_count: int): for i in range(max_count): yield i await asyncio.sleep(0.1) # Simulate async work # Using async generator async def use_async_generator(): async for number in async_counter(5): print(number) Collections Module Specialized Data Structures from collections import defaultdict, Counter, deque, namedtuple, OrderedDict # defaultdict - provides default values for missing keys dd = defaultdict(list) dd['fruits'].append('apple') # No KeyError dd['fruits'].append('banana') dd_int = defaultdict(int) dd_int['count'] += 1 # Starts at 0 # Counter - count occurrences text = \"hello world\" counter = Counter(text) print(counter['l']) # 3 print(counter.most_common(3)) # [('l', 3), ('o', 2), ...] # Count items in list items = ['apple', 'banana', 'apple', 'orange', 'banana', 'apple'] item_counts = Counter(items) # deque - double-ended queue (efficient append/pop from both ends) dq = deque([1, 2, 3]) dq.appendleft(0) # [0, 1, 2, 3] dq.append(4) # [0, 1, 2, 3, 4] dq.popleft() # [1, 2, 3, 4] dq.pop() # [1, 2, 3] # Rotating dq.rotate(1) # [3, 1, 2] dq.rotate(-1) # [1, 2, 3] # OrderedDict - dict that remembers insertion order # Note: Since Python 3.7, standard dicts also remember insertion order. # OrderedDict is still useful for its move_to_end() method and equality behavior. od = OrderedDict() od['a'] = 1 od['b'] = 2 od['c'] = 3 # namedtuple - immutable classes Point = namedtuple('Point', ['x', 'y']) p = Point(10, 20) print(p.x, p.y) # 10 20 Itertools Advanced Iteration Patterns import itertools # Infinite iterators counter = itertools.count(10, 2) # 10, 12, 14, 16, ... cycle_data = itertools.cycle(['A', 'B', 'C']) # A, B, C, A, B, C, ... repeated = itertools.repeat('hello', 3) # 'hello', 'hello', 'hello' # Finite iterators data = [1, 2, 3, 4, 5] # Chain multiple iterables chained = itertools.chain([1, 2], [3, 4], [5, 6]) # 1, 2, 3, 4, 5, 6 # Combinations and permutations combos = list(itertools.combinations([1, 2, 3], 2)) # [(1, 2), (1, 3), (2, 3)] perms = list(itertools.permutations([1, 2, 3], 2)) # [(1, 2), (1, 3), (2, 1), ...] # Groupby data = [('a', 1), ('a', 2), ('b', 3), ('b', 4), ('c', 5)] for key, group in itertools.groupby(data, key=lambda x: x[0]): print(f\"{key}: {list(group)}\") # Take while condition is true numbers = [1, 3, 5, 8, 9, 11, 13] odds = list(itertools.takewhile(lambda x: x % 2 == 1, numbers)) # [1, 3, 5] # Drop while condition is true rest = list(itertools.dropwhile(lambda x: x % 2 == 1, numbers)) # [8, 9, 11, 13] # Product (cartesian product) colors = ['red', 'blue'] sizes = ['S', 'M', 'L'] variants = list(itertools.product(colors, sizes)) # [('red', 'S'), ('red', 'M'), ('red', 'L'), ('blue', 'S'), ...] Pathlib (Modern File Handling) Path Operations from pathlib import Path import os # Creating paths current_dir = Path.cwd() home_dir = Path.home() file_path = Path(\"data/file.txt\") absolute_path = Path(\"/usr/local/bin/python\") # Path manipulation file_path = Path(\"documents/projects/my_project/data.txt\") print(file_path.parent) # documents/projects/my_project print(file_path.name) # data.txt print(file_path.stem) # data print(file_path.suffix) # .txt print(file_path.parts) # ('documents', 'projects', 'my_project', 'data.txt') # Joining paths project_dir = Path(\"projects\") config_file = project_dir / \"config\" / \"settings.json\" # File operations if file_path.exists(): content = file_path.read_text() lines = file_path.read_text().splitlines() # Write to file output_path = Path(\"output.txt\") output_path.write_text(\"Hello, World!\") # Directory operations data_dir = Path(\"data\") data_dir.mkdir(parents=True, exist_ok=True) # Create directory # List directory contents for item in data_dir.iterdir(): if item.is_file(): print(f\"File: {item.name}\") elif item.is_dir(): print(f\"Directory: {item.name}\") # Glob patterns python_files = list(Path(\".\").glob(\"*.py\")) all_python_files = list(Path(\".\").rglob(\"*.py\")) # Recursive Logging Basic Logging import logging # Basic configuration logging.basicConfig( level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s', handlers=[ logging.FileHandler('app.log'), logging.StreamHandler() ] ) # Create logger logger = logging.getLogger(__name__) # Log levels logger.debug(\"Debug message\") # Not shown with INFO level logger.info(\"Info message\") logger.warning(\"Warning message\") logger.error(\"Error message\") logger.critical(\"Critical message\") # Logging with variables name = \"Alice\" age = 30 logger.info(f\"User {name} is {age} years old\") # Exception logging try: result = 10 / 0 except ZeroDivisionError: logger.exception(\"Division by zero occurred\") # Includes traceback Advanced Logging import logging.config # Dictionary configuration LOGGING_CONFIG = { 'version': 1, 'disable_existing_loggers': False, 'formatters': { 'standard': { 'format': '%(asctime)s [%(levelname)s] %(name)s: %(message)s' }, }, 'handlers': { 'file': { 'level': 'INFO', 'class': 'logging.handlers.RotatingFileHandler', 'filename': 'app.log', 'maxBytes': 1024*1024*5, # 5MB 'backupCount': 3, 'formatter': 'standard', }, 'console': { 'level': 'DEBUG', 'class': 'logging.StreamHandler', 'formatter': 'standard', }, }, 'root': { 'handlers': ['file', 'console'], 'level': 'INFO', } } logging.config.dictConfig(LOGGING_CONFIG) logger = logging.getLogger(__name__) Command Line Arguments Using argparse import argparse def main(): parser = argparse.ArgumentParser(description='Process some files.') # Positional arguments parser.add_argument('filename', help='Input filename') # Optional arguments parser.add_argument('-o', '--output', help='Output filename') parser.add_argument('-v', '--verbose', action='store_true', help='Verbose output') parser.add_argument('--count', type=int, default=1, help='Number of times to process') parser.add_argument('--format', choices=['json', 'csv', 'xml'], default='json') # Parse arguments args = parser.parse_args() print(f\"Input file: {args.filename}\") if args.output: print(f\"Output file: {args.output}\") if args.verbose: print(\"Verbose mode enabled\") print(f\"Processing {args.count} times in {args.format} format\") if __name__ == \"__main__\": main() # Usage examples: # python script.py input.txt # python script.py input.txt -o output.txt --verbose --count 3 --format csv Testing Using unittest import unittest from mymodule import Calculator class TestCalculator(unittest.TestCase): def setUp(self): \"\"\"Set up test fixtures before each test method.\"\"\" self.calc = Calculator() def test_add(self): \"\"\"Test addition method.\"\"\" result = self.calc.add(2, 3) self.assertEqual(result, 5) def test_divide_by_zero(self): \"\"\"Test division by zero raises exception.\"\"\" with self.assertRaises(ValueError): self.calc.divide(10, 0) def test_multiple_operations(self): \"\"\"Test multiple operations.\"\"\" self.assertEqual(self.calc.add(2, 3), 5) self.assertEqual(self.calc.subtract(10, 4), 6) self.assertEqual(self.calc.multiply(3, 7), 21) def tearDown(self): \"\"\"Clean up after each test method.\"\"\" pass # Run tests if __name__ == '__main__': unittest.main() # Or run from the command line: # python -m unittest discover # Common assertions # self.assertEqual(a, b) # a == b # self.assertNotEqual(a, b) # a != b # self.assertTrue(x) # bool(x) is True # self.assertFalse(x) # bool(x) is False # self.assertIs(a, b) # a is b # self.assertIsNot(a, b) # a is not b # self.assertIsNone(x) # x is None # self.assertIn(a, b) # a in b # self.assertGreater(a, b) # a > b # self.assertRaises(exc, fun, *args) Using pytest (Alternative) import pytest from mymodule import Calculator # Fixture for test setup @pytest.fixture def calculator(): return Calculator() def test_add(calculator): assert calculator.add(2, 3) == 5 def test_divide_by_zero(calculator): with pytest.raises(ValueError): calculator.divide(10, 0) # Parametrized tests @pytest.mark.parametrize(\"a,b,expected\", [ (2, 3, 5), (1, 1, 2), (-1, 1, 0), (0, 0, 0), ]) def test_add_parametrized(calculator, a, b, expected): assert calculator.add(a, b) == expected # Run with: pytest test_file.py Virtual Environments and Package Management Creating Virtual Environments # Using venv (built-in) python -m venv myenv source myenv/bin/activate # Linux/Mac myenv\\Scripts\\activate # Windows deactivate # Exit virtual environment # Using virtualenv pip install virtualenv virtualenv myenv source myenv/bin/activate # Using conda conda create --name myenv python=3.9 conda activate myenv conda deactivate Package Management # Install packages pip install requests pip install requests==2.28.0 # Specific version pip install requests>=2.25.0 # Minimum version # Install from requirements file pip install -r requirements.txt # Create requirements file pip freeze > requirements.txt # Install in development mode pip install -e . # Upgrade packages pip install --upgrade requests pip list --outdated requirements.txt example requests==2.28.0 pandas>=1.4.0 numpy>=1.21.0,<2.0.0 pytest>=7.0.0 black==22.6.0 Common Third-Party Libraries Requests (HTTP Client) import requests import json # GET request response = requests.get('https://api.github.com/users/octocat') if response.status_code == 200: data = response.json() print(data['name']) # POST request payload = {'key1': 'value1', 'key2': 'value2'} response = requests.post('https://httpbin.org/post', json=payload) # With headers and authentication headers = {'Authorization': 'Bearer token123'} response = requests.get('https://api.example.com/data', headers=headers) # Session for multiple requests session = requests.Session() session.headers.update({'User-Agent': 'MyApp/1.0'}) response = session.get('https://api.example.com') Basic Data Analysis (Pandas) import pandas as pd import numpy as np # Create DataFrame data = { 'name': ['Alice', 'Bob', 'Charlie'], 'age': [25, 30, 35], 'city': ['NYC', 'LA', 'Chicago'] } df = pd.DataFrame(data) # Read from files df = pd.read_csv('data.csv') df = pd.read_json('data.json') df = pd.read_excel('data.xlsx') # Basic operations print(df.head()) # First 5 rows print(df.info()) # Data info print(df.describe()) # Statistics # Selecting data ages = df['age'] # Single column subset = df[['name', 'age']] # Multiple columns filtered = df[df['age'] > 25] # Filter rows # Save data df.to_csv('output.csv', index=False) df.to_json('output.json') Best Practices Follow PEP 8 : Python style guide Use meaningful variable names : user_count not uc Write docstrings : Document functions and classes Use type hints : Help with code clarity and tools Handle exceptions gracefully : Don't use bare except: Use context managers : For resource management Keep functions small : Single responsibility principle Use virtual environments : Isolate project dependencies Test your code : Write unit tests Use version control : Git for tracking changes Use pathlib : Instead of os.path for file operations Prefer f-strings : For string formatting in Python 3.6+ Use dataclasses : For simple data containers Use async/await : For I/O-bound operations Profile before optimizing : Use cProfile, timeit, or py-spy","title":"Python"},{"location":"python/python/#python","text":"","title":"Python"},{"location":"python/python/#installation","text":"# Download from python.org or use package manager # macOS with Homebrew brew install python # Ubuntu/Debian sudo apt update && sudo apt install python3 python3-pip # Windows # Download from python.org or use Microsoft Store # Check version python --version python3 --version","title":"Installation"},{"location":"python/python/#basic-syntax","text":"","title":"Basic Syntax"},{"location":"python/python/#variables-and-assignment","text":"# Variable assignment x = 5 name = \"Alice\" is_active = True # Multiple assignment a, b, c = 1, 2, 3 x = y = z = 0 # Swapping variables a, b = b, a","title":"Variables and Assignment"},{"location":"python/python/#data-types","text":"# Numeric types integer = 42 float_num = 3.14 complex_num = 2 + 3j # Strings single_quote = 'Hello' double_quote = \"World\" multiline = \"\"\"This is a multiline string\"\"\" # Boolean is_true = True is_false = False # None type empty_value = None # Type checking type(42) # <class 'int'> isinstance(42, int) # True","title":"Data Types"},{"location":"python/python/#operators","text":"","title":"Operators"},{"location":"python/python/#arithmetic-operators","text":"# Basic arithmetic a + b # Addition a - b # Subtraction a * b # Multiplication a / b # Division (float) a // b # Floor division a % b # Modulus a ** b # Exponentiation # Augmented assignment x += 5 # x = x + 5 x -= 3 # x = x - 3 x *= 2 # x = x * 2 x /= 4 # x = x / 4","title":"Arithmetic Operators"},{"location":"python/python/#comparison-operators","text":"a == b # Equal a != b # Not equal a < b # Less than a <= b # Less than or equal a > b # Greater than a >= b # Greater than or equal # Chaining comparisons 1 < x < 10 # True if x is between 1 and 10","title":"Comparison Operators"},{"location":"python/python/#logical-operators","text":"# Boolean logic a and b # Logical AND a or b # Logical OR not a # Logical NOT # Short-circuit evaluation result = condition1 and condition2 # condition2 only evaluated if condition1 is True result = condition1 or condition2 # condition2 only evaluated if condition1 is False","title":"Logical Operators"},{"location":"python/python/#identity-and-membership","text":"# Identity operators a is b # Same object a is not b # Different objects # Membership operators item in container # True if item is in container item not in container # True if item is not in container # Examples x = [1, 2, 3] 2 in x # True 4 not in x # True","title":"Identity and Membership"},{"location":"python/python/#control-flow","text":"","title":"Control Flow"},{"location":"python/python/#conditional-statements","text":"# if-elif-else if condition1: # code block elif condition2: # code block else: # code block # Ternary operator result = value_if_true if condition else value_if_false # Examples age = 18 status = \"adult\" if age >= 18 else \"minor\" # Multiple conditions if 18 <= age < 65: print(\"Working age\")","title":"Conditional Statements"},{"location":"python/python/#loops","text":"","title":"Loops"},{"location":"python/python/#for-loops","text":"# Iterating over sequences for item in [1, 2, 3]: print(item) # Range function for i in range(5): # 0 to 4 print(i) for i in range(2, 8): # 2 to 7 print(i) for i in range(0, 10, 2): # 0, 2, 4, 6, 8 print(i) # Enumerate for index and value for index, value in enumerate(['a', 'b', 'c']): print(f\"{index}: {value}\") # Zip for parallel iteration for x, y in zip([1, 2, 3], ['a', 'b', 'c']): print(x, y)","title":"For Loops"},{"location":"python/python/#while-loops","text":"# While loop count = 0 while count < 5: print(count) count += 1 # Infinite loop with break while True: user_input = input(\"Enter 'quit' to exit: \") if user_input == 'quit': break print(f\"You entered: {user_input}\")","title":"While Loops"},{"location":"python/python/#loop-control","text":"# break - exit loop for i in range(10): if i == 5: break print(i) # prints 0, 1, 2, 3, 4 # continue - skip iteration for i in range(5): if i == 2: continue print(i) # prints 0, 1, 3, 4 # else clause (executes if loop completes normally) for i in range(3): print(i) else: print(\"Loop completed\")","title":"Loop Control"},{"location":"python/python/#data-structures","text":"","title":"Data Structures"},{"location":"python/python/#lists","text":"# Creating lists empty_list = [] numbers = [1, 2, 3, 4, 5] mixed = [1, \"hello\", 3.14, True] # List methods numbers.append(6) # Add to end numbers.insert(0, 0) # Insert at index numbers.extend([7, 8]) # Add multiple items numbers.remove(3) # Remove first occurrence item = numbers.pop() # Remove and return last item item = numbers.pop(0) # Remove and return item at index # List operations len(numbers) # Length numbers[0] # Access by index numbers[-1] # Last item numbers[1:4] # Slicing numbers[:3] # First 3 items numbers[2:] # From index 2 to end numbers[::2] # Every 2nd item # List comprehension squares = [x**2 for x in range(10)] evens = [x for x in range(20) if x % 2 == 0]","title":"Lists"},{"location":"python/python/#tuples","text":"# Creating tuples empty_tuple = () single_item = (42,) # Note the comma coordinates = (10, 20) rgb = (255, 128, 0) # Tuple unpacking x, y = coordinates r, g, b = rgb # Named tuples from collections import namedtuple Point = namedtuple('Point', ['x', 'y']) p = Point(10, 20) print(p.x, p.y)","title":"Tuples"},{"location":"python/python/#dictionaries","text":"# Creating dictionaries empty_dict = {} person = {'name': 'Alice', 'age': 30, 'city': 'New York'} person = dict(name='Alice', age=30, city='New York') # Dictionary operations person['name'] # Access value person['email'] = 'alice@example.com' # Add/update del person['age'] # Delete key person.get('phone', 'N/A') # Get with default # Dictionary methods person.keys() # All keys person.values() # All values person.items() # Key-value pairs person.update({'age': 31}) # Update multiple # Dictionary comprehension squares = {x: x**2 for x in range(5)}","title":"Dictionaries"},{"location":"python/python/#sets","text":"# Creating sets empty_set = set() numbers = {1, 2, 3, 4, 5} from_list = set([1, 2, 2, 3]) # Duplicates removed # Set operations numbers.add(6) # Add element numbers.remove(3) # Remove element (raises error if not found) numbers.discard(10) # Remove element (no error if not found) # Set mathematics set1 = {1, 2, 3} set2 = {3, 4, 5} set1 | set2 # Union {1, 2, 3, 4, 5} set1 & set2 # Intersection {3} set1 - set2 # Difference {1, 2} set1 ^ set2 # Symmetric difference {1, 2, 4, 5}","title":"Sets"},{"location":"python/python/#functions","text":"","title":"Functions"},{"location":"python/python/#basic-functions","text":"# Function definition def greet(name): return f\"Hello, {name}!\" # Function with default parameters def greet(name, greeting=\"Hello\"): return f\"{greeting}, {name}!\" # Multiple return values def divide_and_remainder(a, b): return a // b, a % b quotient, remainder = divide_and_remainder(17, 5) # Variable arguments def sum_all(*args): return sum(args) def print_info(**kwargs): for key, value in kwargs.items(): print(f\"{key}: {value}\") # Mixed arguments def complex_func(required, default=\"default\", *args, **kwargs): print(f\"Required: {required}\") print(f\"Default: {default}\") print(f\"Args: {args}\") print(f\"Kwargs: {kwargs}\")","title":"Basic Functions"},{"location":"python/python/#lambda-functions","text":"# Lambda (anonymous) functions square = lambda x: x**2 add = lambda x, y: x + y # Common use with higher-order functions numbers = [1, 2, 3, 4, 5] squares = list(map(lambda x: x**2, numbers)) evens = list(filter(lambda x: x % 2 == 0, numbers)) # Sorting with lambda students = [('Alice', 85), ('Bob', 92), ('Charlie', 78)] students.sort(key=lambda student: student[1]) # Sort by grade","title":"Lambda Functions"},{"location":"python/python/#decorators","text":"# Simple decorator def my_decorator(func): def wrapper(): print(\"Before function call\") func() print(\"After function call\") return wrapper @my_decorator def say_hello(): print(\"Hello!\") # Decorator with arguments def repeat(times): def decorator(func): def wrapper(*args, **kwargs): for _ in range(times): result = func(*args, **kwargs) return result return wrapper return decorator @repeat(3) def greet(name): print(f\"Hello, {name}!\") # Built-in decorators @staticmethod def utility_function(): pass @classmethod def from_string(cls, string): pass @property def full_name(self): return f\"{self.first} {self.last}\"","title":"Decorators"},{"location":"python/python/#classes-and-objects","text":"","title":"Classes and Objects"},{"location":"python/python/#basic-classes","text":"# Class definition class Person: # Class variable species = \"Homo sapiens\" # Constructor def __init__(self, name, age): self.name = name # Instance variable self.age = age # Instance method def greet(self): return f\"Hello, I'm {self.name}\" # Human-readable string representation def __str__(self): return f\"Person named {self.name}, age {self.age}\" # Developer-friendly string representation def __repr__(self): return f\"Person('{self.name}', {self.age})\" # Creating objects person1 = Person(\"Alice\", 30) print(person1.greet())","title":"Basic Classes"},{"location":"python/python/#inheritance","text":"# Base class class Animal: def __init__(self, name): self.name = name def speak(self): pass def __str__(self): return f\"{self.__class__.__name__}('{self.name}')\" # Derived classes class Dog(Animal): def speak(self): return f\"{self.name} says Woof!\" class Cat(Animal): def speak(self): return f\"{self.name} says Meow!\" # Multiple inheritance class FlyingMixin: def fly(self): return f\"{self.name} is flying!\" class Bird(Animal, FlyingMixin): def speak(self): return f\"{self.name} says Tweet!\" # Using super() class Employee(Person): def __init__(self, name, age, employee_id): super().__init__(name, age) self.employee_id = employee_id","title":"Inheritance"},{"location":"python/python/#dunder-methods-magic-methods","text":"Dunder methods (double underscore methods) are special methods that allow Python objects to implement or modify built-in behaviors. They define how objects interact with operators, built-in functions, and language constructs.","title":"Dunder Methods (Magic Methods)"},{"location":"python/python/#object-representation","text":"class Person: def __init__(self, name, age): self.name = name self.age = age def __str__(self): # Human-readable string representation # Called by str() and print() return f\"Person named {self.name}, age {self.age}\" def __repr__(self): # Unambiguous string representation for developers # Called by repr() and in interactive shell # Should ideally be valid Python code to recreate the object return f\"Person('{self.name}', {self.age})\" # Usage person = Person(\"Alice\", 30) print(person) # Uses __str__: Person named Alice, age 30 repr(person) # Uses __repr__: Person('Alice', 30) str(person) # Uses __str__: Person named Alice, age 30 # In interactive shell or debugger, __repr__ is used by default","title":"Object Representation"},{"location":"python/python/#object-initialization-and-creation","text":"class DatabaseConnection: def __new__(cls, host, port): # Controls object creation (rarely overridden) # Called before __init__ print(f\"Creating connection to {host}:{port}\") instance = super().__new__(cls) return instance def __init__(self, host, port): # Object initialization after creation # Most commonly used constructor method self.host = host self.port = port print(f\"Initialized connection to {host}:{port}\") # Example of when __new__ is useful (Singleton pattern) class Singleton: _instance = None def __new__(cls): if cls._instance is None: cls._instance = super().__new__(cls) return cls._instance","title":"Object Initialization and Creation"},{"location":"python/python/#container-like-behavior","text":"class CustomList: def __init__(self, items=None): self.items = items or [] def __len__(self): # Called by len() return len(self.items) def __bool__(self): # Called by bool() and in boolean contexts # If not defined, __len__ is used (0 is False) return len(self.items) > 0 def __getitem__(self, key): # Called for indexing: obj[key] return self.items[key] def __setitem__(self, key, value): # Called for item assignment: obj[key] = value self.items[key] = value def __delitem__(self, key): # Called for item deletion: del obj[key] del self.items[key] def __contains__(self, item): # Called by 'in' operator return item in self.items # Usage custom_list = CustomList([1, 2, 3, 4]) print(len(custom_list)) # 4 print(bool(custom_list)) # True print(custom_list[0]) # 1 custom_list[0] = 10 # Sets first item to 10 del custom_list[1] # Removes second item print(2 in custom_list) # False (was deleted)","title":"Container-like Behavior"},{"location":"python/python/#iterator-protocol","text":"class NumberSequence: def __init__(self, start, end): self.start = start self.end = end def __iter__(self): # Returns iterator object (often self) # Called by iter() and in for loops self.current = self.start return self def __next__(self): # Returns next item in iteration # Called by next() and automatically in for loops if self.current < self.end: num = self.current self.current += 1 return num else: raise StopIteration # Usage sequence = NumberSequence(1, 5) for num in sequence: # Uses __iter__ and __next__ print(num) # Prints 1, 2, 3, 4 # Manual iteration iterator = iter(sequence) # Calls __iter__ print(next(iterator)) # Calls __next__","title":"Iterator Protocol"},{"location":"python/python/#context-manager-protocol","text":"class FileManager: def __init__(self, filename, mode): self.filename = filename self.mode = mode self.file = None def __enter__(self): # Called when entering 'with' block # Return value is assigned to 'as' variable print(f\"Opening {self.filename}\") self.file = open(self.filename, self.mode) return self.file def __exit__(self, exc_type, exc_val, exc_tb): # Called when exiting 'with' block # Parameters contain exception info if one occurred print(f\"Closing {self.filename}\") if self.file: self.file.close() # Return False to propagate exceptions # Return True to suppress exceptions return False # Usage with FileManager(\"data.txt\", \"w\") as f: f.write(\"Hello, World!\") # File is automatically closed # Another example: Timer context manager import time class Timer: def __enter__(self): self.start_time = time.time() return self def __exit__(self, exc_type, exc_val, exc_tb): elapsed = time.time() - self.start_time print(f\"Elapsed time: {elapsed:.2f} seconds\") return False with Timer(): # Some time-consuming operation time.sleep(1)","title":"Context Manager Protocol"},{"location":"python/python/#callable-objects","text":"class Multiplier: def __init__(self, factor): self.factor = factor def __call__(self, value): # Makes the object callable like a function return value * self.factor # Usage double = Multiplier(2) triple = Multiplier(3) print(double(5)) # 10 (calls __call__) print(triple(4)) # 12 # Check if object is callable print(callable(double)) # True # Useful for creating function-like objects with state class Counter: def __init__(self): self.count = 0 def __call__(self): self.count += 1 return self.count counter = Counter() print(counter()) # 1 print(counter()) # 2","title":"Callable Objects"},{"location":"python/python/#hashing-and-equality","text":"class Point: def __init__(self, x, y): self.x = x self.y = y def __eq__(self, other): # Defines equality (==) # Also affects !=, which returns the opposite if not isinstance(other, Point): return False return self.x == other.x and self.y == other.y def __hash__(self): # Makes object hashable (can be used as dict key or in set) # Objects that compare equal must have same hash value # Immutable objects should implement this return hash((self.x, self.y)) def __repr__(self): return f\"Point({self.x}, {self.y})\" # Usage p1 = Point(1, 2) p2 = Point(1, 2) p3 = Point(2, 3) print(p1 == p2) # True print(p1 == p3) # False # Can be used as dictionary keys points_dict = {p1: \"origin area\", p3: \"far point\"} print(points_dict[p2]) # \"origin area\" (p1 == p2) # Can be added to sets point_set = {p1, p2, p3} # Only p1 and p3 (p1 == p2) print(len(point_set)) # 2","title":"Hashing and Equality"},{"location":"python/python/#arithmetic-operators_1","text":"class Vector: def __init__(self, x, y): self.x = x self.y = y def __add__(self, other): # Addition: self + other return Vector(self.x + other.x, self.y + other.y) def __sub__(self, other): # Subtraction: self - other return Vector(self.x - other.x, self.y - other.y) def __mul__(self, other): # Multiplication: self * other if isinstance(other, (int, float)): # Scalar multiplication return Vector(self.x * other, self.y * other) else: # Dot product with another vector return self.x * other.x + self.y * other.y def __rmul__(self, other): # Right multiplication: other * self # Called when left operand doesn't support operation return self.__mul__(other) def __truediv__(self, scalar): # Division: self / other return Vector(self.x / scalar, self.y / scalar) def __floordiv__(self, scalar): # Floor division: self // other return Vector(self.x // scalar, self.y // scalar) def __mod__(self, scalar): # Modulus: self % other return Vector(self.x % scalar, self.y % scalar) def __pow__(self, power): # Exponentiation: self ** other return Vector(self.x ** power, self.y ** power) def __abs__(self): # Absolute value: abs(self) return (self.x**2 + self.y**2)**0.5 def __neg__(self): # Unary minus: -self return Vector(-self.x, -self.y) def __str__(self): return f\"Vector({self.x}, {self.y})\" # Usage v1 = Vector(3, 4) v2 = Vector(1, 2) print(v1 + v2) # Vector(4, 6) print(v1 - v2) # Vector(2, 2) print(v1 * 2) # Vector(6, 8) - scalar multiplication print(3 * v1) # Vector(9, 12) - uses __rmul__ print(v1 * v2) # 11 - dot product print(v1 / 2) # Vector(1.5, 2.0) print(abs(v1)) # 5.0 - magnitude print(-v1) # Vector(-3, -4)","title":"Arithmetic Operators"},{"location":"python/python/#comparison-operators_1","text":"class Student: def __init__(self, name, grade): self.name = name self.grade = grade def __eq__(self, other): return self.grade == other.grade def __lt__(self, other): # Less than: self < other return self.grade < other.grade def __le__(self, other): # Less than or equal: self <= other return self.grade <= other.grade def __gt__(self, other): # Greater than: self > other return self.grade > other.grade def __ge__(self, other): # Greater than or equal: self >= other return self.grade >= other.grade def __ne__(self, other): # Not equal: self != other (usually auto-generated from __eq__) return not self.__eq__(other) def __repr__(self): return f\"Student('{self.name}', {self.grade})\" # Usage alice = Student(\"Alice\", 85) bob = Student(\"Bob\", 92) charlie = Student(\"Charlie\", 85) print(alice < bob) # True print(alice == charlie) # True print(bob >= alice) # True # Can be sorted students = [bob, alice, charlie] sorted_students = sorted(students) # Sorts by grade using __lt__","title":"Comparison Operators"},{"location":"python/python/#python-slang-and-terminology","text":"Understanding Python's unique terminology and idioms is essential for reading code, documentation, and communicating with other Python developers.","title":"Python Slang and Terminology"},{"location":"python/python/#core-python-terminology","text":"","title":"Core Python Terminology"},{"location":"python/python/#dunder-double-underscore","text":"# \"Dunder\" refers to methods with double underscores before and after class MyClass: def __init__(self): # \"dunder init\" pass def __str__(self): # \"dunder str\" return \"MyClass\" def __len__(self): # \"dunder len\" return 0 # Also applies to built-in variables print(__name__) # \"dunder name\" print(__file__) # \"dunder file\"","title":"Dunder (Double Underscore)"},{"location":"python/python/#pythonic","text":"Writing code that follows Python idioms and conventions. Emphasizes readability, simplicity, and following \"The Zen of Python.\" # Non-Pythonic numbers = [1, 2, 3, 4, 5] squares = [] for num in numbers: squares.append(num ** 2) # Pythonic squares = [num ** 2 for num in numbers] # Non-Pythonic if len(my_list) == 0: print(\"List is empty\") # Pythonic if not my_list: print(\"List is empty\") # Non-Pythonic for i in range(len(items)): print(f\"{i}: {items[i]}\") # Pythonic for i, item in enumerate(items): print(f\"{i}: {item}\")","title":"Pythonic"},{"location":"python/python/#programming-philosophies","text":"","title":"Programming Philosophies"},{"location":"python/python/#eafp-easier-to-ask-for-forgiveness-than-permission","text":"Python's preferred approach: try the operation and handle exceptions rather than checking conditions first. # EAFP - Pythonic approach def get_value(dictionary, key): try: return dictionary[key] except KeyError: return None def process_file(filename): try: with open(filename, 'r') as file: return file.read() except FileNotFoundError: return \"File not found\" # Example with attribute access try: result = obj.some_method() except AttributeError: result = \"Method not available\"","title":"EAFP (Easier to Ask for Forgiveness than Permission)"},{"location":"python/python/#lbyl-look-before-you-leap","text":"The alternative approach: check conditions before performing operations. # LBYL - Less Pythonic in most cases def get_value(dictionary, key): if key in dictionary: return dictionary[key] else: return None def process_file(filename): path = Path(filename) if path.exists(): with path.open('r') as file: return file.read() else: return \"File not found\" # Example with attribute access if hasattr(obj, 'some_method'): result = obj.some_method() else: result = \"Method not available\" # When LBYL is appropriate: # - Performance critical code where exceptions are expensive # - When checking is much faster than trying and failing","title":"LBYL (Look Before You Leap)"},{"location":"python/python/#type-system-concepts","text":"","title":"Type System Concepts"},{"location":"python/python/#duck-typing","text":"\"If it walks like a duck and quacks like a duck, then it's a duck.\" Objects are judged by their behavior, not their type. # Duck typing example def make_sound(animal): # We don't care what type animal is # We just call its sound() method print(animal.sound()) class Dog: def sound(self): return \"Woof!\" class Cat: def sound(self): return \"Meow!\" class Robot: def sound(self): return \"Beep!\" # All work with make_sound function make_sound(Dog()) # Works because Dog has sound() make_sound(Cat()) # Works because Cat has sound() make_sound(Robot()) # Works because Robot has sound() # Another example: file-like objects def process_data(file_obj): # Works with any object that has read() method return file_obj.read() # Works with files, StringIO, BytesIO, etc. with open('data.txt') as f: process_data(f) from io import StringIO string_file = StringIO(\"Hello, World!\") process_data(string_file)","title":"Duck Typing"},{"location":"python/python/#monkey-patching","text":"Dynamically modifying classes or modules at runtime. # Monkey patching example class Calculator: def add(self, a, b): return a + b # Add a new method to the class def subtract(self, a, b): return a - b Calculator.subtract = subtract # Now all Calculator instances have subtract method calc = Calculator() print(calc.add(5, 3)) # 8 print(calc.subtract(5, 3)) # 2 # Monkey patching built-in modules import datetime # Add a custom method to datetime def is_weekend(self): return self.weekday() >= 5 datetime.date.is_weekend = is_weekend # Now all dates have is_weekend method today = datetime.date.today() print(today.is_weekend()) # Be cautious with monkey patching: # - Can make code harder to understand # - Can break if the original implementation changes # - Use sparingly and document well","title":"Monkey Patching"},{"location":"python/python/#data-structure-terminology","text":"","title":"Data Structure Terminology"},{"location":"python/python/#list-comprehension-vs-generator-expression","text":"# List comprehension - creates a list immediately squares_list = [x**2 for x in range(10)] print(type(squares_list)) # <class 'list'> print(squares_list) # [0, 1, 4, 9, 16, 25, 36, 49, 64, 81] # Generator expression - creates a generator (lazy evaluation) squares_gen = (x**2 for x in range(10)) print(type(squares_gen)) # <class 'generator'> print(squares_gen) # <generator object at 0x...> # Generator values are produced on-demand for square in squares_gen: print(square) # Prints one at a time # Memory comparison import sys large_list = [x for x in range(1000000)] large_gen = (x for x in range(1000000)) print(f\"List size: {sys.getsizeof(large_list)} bytes\") print(f\"Generator size: {sys.getsizeof(large_gen)} bytes\")","title":"List Comprehension vs Generator Expression"},{"location":"python/python/#language-features","text":"","title":"Language Features"},{"location":"python/python/#gil-global-interpreter-lock","text":"Python's mechanism that allows only one thread to execute Python code at a time. import threading import time # The GIL affects CPU-bound tasks def cpu_bound_task(): # This won't run in parallel due to GIL total = 0 for i in range(10000000): total += i return total # Multiple threads won't speed up CPU-bound work start_time = time.time() threads = [] for _ in range(4): thread = threading.Thread(target=cpu_bound_task) threads.append(thread) thread.start() for thread in threads: thread.join() print(f\"Multi-threaded time: {time.time() - start_time}\") # For CPU-bound work, use multiprocessing instead from multiprocessing import Pool def parallel_cpu_work(): with Pool() as pool: results = pool.map(lambda x: sum(range(x)), [1000000] * 4) return results # GIL doesn't affect I/O-bound tasks import asyncio import aiohttp async def io_bound_task(url): async with aiohttp.ClientSession() as session: async with session.get(url) as response: return await response.text() # This can run concurrently despite the GIL","title":"GIL (Global Interpreter Lock)"},{"location":"python/python/#advanced-concepts","text":"","title":"Advanced Concepts"},{"location":"python/python/#descriptor-protocol","text":"Objects that define how attribute access is handled. class Descriptor: def __get__(self, obj, objtype=None): return \"Getting attribute\" def __set__(self, obj, value): print(f\"Setting attribute to {value}\") def __delete__(self, obj): print(\"Deleting attribute\") class MyClass: attr = Descriptor() obj = MyClass() print(obj.attr) # \"Getting attribute\" obj.attr = \"new value\" # \"Setting attribute to new value\" del obj.attr # \"Deleting attribute\"","title":"Descriptor Protocol"},{"location":"python/python/#context-manager","text":"Objects that define runtime context for executing code blocks (used with with statements). # Built-in context managers with open('file.txt', 'r') as f: # File is a context manager content = f.read() # File is automatically closed # Custom context manager using contextlib from contextlib import contextmanager @contextmanager def temporary_change(obj, attr, new_value): old_value = getattr(obj, attr) setattr(obj, attr, new_value) try: yield obj finally: setattr(obj, attr, old_value) # Usage class Config: debug = False config = Config() with temporary_change(config, 'debug', True): print(config.debug) # True print(config.debug) # False (restored)","title":"Context Manager"},{"location":"python/python/#metaclass","text":"Classes whose instances are classes themselves. \"Classes that create classes.\" # Simple metaclass example class SingletonMeta(type): _instances = {} def __call__(cls, *args, **kwargs): if cls not in cls._instances: cls._instances[cls] = super().__call__(*args, **kwargs) return cls._instances[cls] class Singleton(metaclass=SingletonMeta): def __init__(self, value): self.value = value # Both variables refer to the same instance s1 = Singleton(\"first\") s2 = Singleton(\"second\") print(s1 is s2) # True print(s1.value) # \"first\" (unchanged)","title":"Metaclass"},{"location":"python/python/#common-patterns-and-idioms","text":"","title":"Common Patterns and Idioms"},{"location":"python/python/#unpacking-and-packing","text":"# Tuple unpacking point = (3, 4) x, y = point # Extended unpacking (Python 3+) first, *middle, last = [1, 2, 3, 4, 5] print(first) # 1 print(middle) # [2, 3, 4] print(last) # 5 # Function argument unpacking def greet(name, age, city): print(f\"{name} is {age} years old and lives in {city}\") person_info = (\"Alice\", 30, \"New York\") greet(*person_info) # Unpacks tuple as arguments person_dict = {\"name\": \"Bob\", \"age\": 25, \"city\": \"Boston\"} greet(**person_dict) # Unpacks dictionary as keyword arguments","title":"Unpacking and Packing"},{"location":"python/python/#walrus-operator-assignment-expression","text":"# Walrus operator := (Python 3.8+) # Assigns and returns a value in one expression # Traditional approach numbers = [1, 2, 3, 4, 5] squared = [] for num in numbers: square = num ** 2 if square > 10: squared.append(square) # With walrus operator squared = [square for num in numbers if (square := num ** 2) > 10] # Useful in while loops import random while (dice := random.randint(1, 6)) != 6: print(f\"Rolled {dice}, try again\") print(\"Finally rolled a 6!\") # In conditional statements if (match := some_pattern.search(text)): print(f\"Found match: {match.group()}\")","title":"Walrus Operator (Assignment Expression)"},{"location":"python/python/#understanding-python-culture","text":"","title":"Understanding Python Culture"},{"location":"python/python/#the-zen-of-python","text":"import this # Prints \"The Zen of Python\" # Key principles: # - Beautiful is better than ugly # - Explicit is better than implicit # - Simple is better than complex # - Readability counts # - There should be one obvious way to do it","title":"The Zen of Python"},{"location":"python/python/#exception-handling","text":"","title":"Exception Handling"},{"location":"python/python/#basic-exception-handling","text":"# try-except try: result = 10 / 0 except ZeroDivisionError: print(\"Cannot divide by zero\") # Multiple exceptions try: value = int(input(\"Enter a number: \")) result = 10 / value except ValueError: print(\"Invalid input\") except ZeroDivisionError: print(\"Cannot divide by zero\") # Catch multiple exception types try: # risky code pass except (ValueError, TypeError) as e: print(f\"Error: {e}\") # Catch all exceptions try: # risky code pass except Exception as e: print(f\"Unexpected error: {e}\") # finally block (always executes) try: file = open(\"data.txt\") # process file except FileNotFoundError: print(\"File not found\") finally: try: file.close() except NameError: pass # file was never opened","title":"Basic Exception Handling"},{"location":"python/python/#custom-exceptions","text":"class CustomError(Exception): pass class ValidationError(Exception): def __init__(self, message, code=None): super().__init__(message) self.code = code def validate_age(age): if age < 0: raise ValidationError(\"Age cannot be negative\", code=\"NEGATIVE_AGE\") if age > 150: raise ValidationError(\"Age seems unrealistic\", code=\"HIGH_AGE\") try: validate_age(-5) except ValidationError as e: print(f\"Validation failed: {e} (Code: {e.code})\")","title":"Custom Exceptions"},{"location":"python/python/#file-handling","text":"","title":"File Handling"},{"location":"python/python/#reading-and-writing-files","text":"# Reading files with open(\"file.txt\", \"r\") as file: content = file.read() # Read entire file with open(\"file.txt\", \"r\") as file: lines = file.readlines() # Read all lines as list with open(\"file.txt\", \"r\") as file: for line in file: # Iterate line by line print(line.strip()) # Writing files with open(\"output.txt\", \"w\") as file: file.write(\"Hello, World!\\n\") file.writelines([\"Line 1\\n\", \"Line 2\\n\"]) # Appending to files with open(\"log.txt\", \"a\") as file: file.write(\"New log entry\\n\") # File modes # \"r\" - read (default) # \"w\" - write (overwrites) # \"a\" - append # \"x\" - exclusive creation # \"b\" - binary mode # \"t\" - text mode (default) # \"+\" - read and write","title":"Reading and Writing Files"},{"location":"python/python/#working-with-json","text":"import json # Writing JSON data = {\"name\": \"Alice\", \"age\": 30, \"city\": \"New York\"} with open(\"data.json\", \"w\") as file: json.dump(data, file, indent=2) # Reading JSON with open(\"data.json\", \"r\") as file: data = json.load(file) # JSON strings json_string = json.dumps(data, indent=2) parsed_data = json.loads(json_string)","title":"Working with JSON"},{"location":"python/python/#working-with-csv","text":"import csv # Writing CSV data = [ [\"Name\", \"Age\", \"City\"], [\"Alice\", 30, \"New York\"], [\"Bob\", 25, \"Boston\"] ] with open(\"people.csv\", \"w\", newline=\"\") as file: writer = csv.writer(file) writer.writerows(data) # Reading CSV with open(\"people.csv\", \"r\") as file: reader = csv.reader(file) for row in reader: print(row) # CSV with dictionaries with open(\"people.csv\", \"w\", newline=\"\") as file: fieldnames = [\"name\", \"age\", \"city\"] writer = csv.DictWriter(file, fieldnames=fieldnames) writer.writeheader() writer.writerow({\"name\": \"Alice\", \"age\": 30, \"city\": \"New York\"})","title":"Working with CSV"},{"location":"python/python/#modules-and-packages","text":"","title":"Modules and Packages"},{"location":"python/python/#importing-modules","text":"# Different import styles import math from math import pi, sqrt from math import * # Not recommended import math as m # Using imported functions result = math.sqrt(16) result = sqrt(16) result = m.sqrt(16) # Importing from packages from os.path import join, exists from urllib.parse import urlparse","title":"Importing Modules"},{"location":"python/python/#creating-modules","text":"# mymodule.py \"\"\"A simple module example.\"\"\" PI = 3.14159 def circle_area(radius): \"\"\"Calculate the area of a circle.\"\"\" return PI * radius ** 2 def circle_circumference(radius): \"\"\"Calculate the circumference of a circle.\"\"\" return 2 * PI * radius if __name__ == \"__main__\": # This code runs only when the module is executed directly print(\"Testing the module\") print(f\"Area of circle with radius 5: {circle_area(5)}\")","title":"Creating Modules"},{"location":"python/python/#package-structure","text":"mypackage/ __init__.py module1.py module2.py subpackage/ __init__.py submodule.py # __init__.py \"\"\"MyPackage - A sample package.\"\"\" from .module1 import function1 from .module2 import Class2 __version__ = \"1.0.0\" __all__ = [\"function1\", \"Class2\"]","title":"Package Structure"},{"location":"python/python/#built-in-functions","text":"","title":"Built-in Functions"},{"location":"python/python/#common-built-ins","text":"# Type conversion int(\"42\") # String to integer float(\"3.14\") # String to float str(42) # Number to string bool(1) # To boolean list(\"hello\") # String to list of characters # Math functions abs(-5) # Absolute value round(3.7) # Round to nearest integer round(3.14159, 2) # Round to 2 decimal places min(1, 2, 3) # Minimum value max([1, 2, 3]) # Maximum value sum([1, 2, 3]) # Sum of iterable # Sequence functions len([1, 2, 3]) # Length sorted([3, 1, 2]) # Return sorted list reversed([1, 2, 3]) # Return reversed iterator enumerate(['a', 'b']) # Return index-value pairs zip([1, 2], ['a', 'b']) # Combine iterables # Higher-order functions map(str, [1, 2, 3]) # Apply function to each item filter(lambda x: x > 0, [-1, 0, 1, 2]) # Filter items all([True, True, False]) # True if all elements are true any([False, True, False]) # True if any element is true","title":"Common Built-ins"},{"location":"python/python/#inputoutput","text":"# User input name = input(\"Enter your name: \") age = int(input(\"Enter your age: \")) # Printing print(\"Hello, World!\") print(\"Name:\", name, \"Age:\", age) print(f\"Hello, {name}! You are {age} years old.\") print(\"Value:\", 42, sep=\" = \", end=\"\\n\\n\") # String formatting name = \"Alice\" age = 30 print(\"Name: {}, Age: {}\".format(name, age)) print(\"Name: {name}, Age: {age}\".format(name=name, age=age)) print(f\"Name: {name}, Age: {age}\") # f-strings (Python 3.6+)","title":"Input/Output"},{"location":"python/python/#string-operations","text":"","title":"String Operations"},{"location":"python/python/#string-methods","text":"text = \" Hello, World! \" # Case conversion text.upper() # \" HELLO, WORLD! \" text.lower() # \" hello, world! \" text.title() # \" Hello, World! \" text.capitalize() # \" hello, world! \" text.swapcase() # \" hELLO, wORLD! \" # Whitespace handling text.strip() # \"Hello, World!\" text.lstrip() # \"Hello, World! \" text.rstrip() # \" Hello, World!\" # Searching and checking text.find(\"World\") # Index of substring (or -1) text.index(\"World\") # Index of substring (raises ValueError) text.count(\"l\") # Count occurrences text.startswith(\" H\") # True text.endswith(\"! \") # True \"123\".isdigit() # True \"abc\".isalpha() # True \"abc123\".isalnum() # True # Splitting and joining \"a,b,c\".split(\",\") # [\"a\", \"b\", \"c\"] \"hello world\".split() # [\"hello\", \"world\"] \"-\".join([\"a\", \"b\", \"c\"]) # \"a-b-c\" # Replacement text.replace(\"World\", \"Python\") # \" Hello, Python! \" # Formatting \"The value is {:.2f}\".format(3.14159) # \"The value is 3.14\" f\"The value is {3.14159:.2f}\" # \"The value is 3.14\"","title":"String Methods"},{"location":"python/python/#string-slicing-and-indexing","text":"text = \"Hello, World!\" # Indexing text[0] # \"H\" text[-1] # \"!\" text[7] # \"W\" # Slicing text[0:5] # \"Hello\" text[7:] # \"World!\" text[:5] # \"Hello\" text[::2] # \"Hlo ol!\" text[::-1] # \"!dlroW ,olleH\" (reversed)","title":"String Slicing and Indexing"},{"location":"python/python/#list-comprehensions-and-generators","text":"","title":"List Comprehensions and Generators"},{"location":"python/python/#list-comprehensions","text":"# Basic list comprehension squares = [x**2 for x in range(10)] # With condition evens = [x for x in range(20) if x % 2 == 0] # Nested loops pairs = [(x, y) for x in range(3) for y in range(3) if x != y] # Processing strings words = [\"hello\", \"world\", \"python\"] lengths = [len(word) for word in words] upper_words = [word.upper() for word in words if len(word) > 4]","title":"List Comprehensions"},{"location":"python/python/#dictionary-and-set-comprehensions","text":"# Dictionary comprehension squares = {x: x**2 for x in range(5)} word_lengths = {word: len(word) for word in [\"hello\", \"world\"]} # Set comprehension unique_lengths = {len(word) for word in [\"hello\", \"world\", \"hi\"]}","title":"Dictionary and Set Comprehensions"},{"location":"python/python/#generator-expressions","text":"# Generator expression (lazy evaluation) squares_gen = (x**2 for x in range(10)) # Generator function def fibonacci(n): a, b = 0, 1 for _ in range(n): yield a a, b = b, a + b # Using generators for num in fibonacci(10): print(num) # Generator with yield from def flatten(nested_list): for sublist in nested_list: if isinstance(sublist, list): yield from flatten(sublist) else: yield sublist nested = [[1, 2], [3, [4, 5]], 6] flat = list(flatten(nested)) # [1, 2, 3, 4, 5, 6]","title":"Generator Expressions"},{"location":"python/python/#context-managers","text":"","title":"Context Managers"},{"location":"python/python/#using-context-managers","text":"# File handling with context manager with open(\"file.txt\", \"r\") as file: content = file.read() # File is automatically closed # Multiple context managers with open(\"input.txt\", \"r\") as infile, open(\"output.txt\", \"w\") as outfile: outfile.write(infile.read())","title":"Using Context Managers"},{"location":"python/python/#creating-context-managers","text":"# Using contextlib from contextlib import contextmanager @contextmanager def timer(): import time start = time.time() try: yield finally: end = time.time() print(f\"Elapsed time: {end - start:.2f} seconds\") # Usage with timer(): # Some time-consuming operation sum(range(1000000)) # Class-based context manager class DatabaseConnection: def __enter__(self): print(\"Connecting to database\") return self def __exit__(self, exc_type, exc_val, exc_tb): print(\"Closing database connection\") return False # Don't suppress exceptions with DatabaseConnection() as db: print(\"Using database connection\")","title":"Creating Context Managers"},{"location":"python/python/#regular-expressions","text":"","title":"Regular Expressions"},{"location":"python/python/#basic-regex-operations","text":"import re # Pattern matching pattern = r\"\\d+\" # One or more digits text = \"I have 5 apples and 10 oranges\" # Search for first match match = re.search(pattern, text) if match: print(match.group()) # \"5\" # Find all matches matches = re.findall(pattern, text) # [\"5\", \"10\"] # Match at beginning of string match = re.match(r\"\\w+\", \"Hello World\") # \"Hello\" # Split by pattern parts = re.split(r\"\\s+\", \"Hello World Python\") # [\"Hello\", \"World\", \"Python\"] # Replace patterns result = re.sub(r\"\\d+\", \"X\", text) # \"I have X apples and X oranges\"","title":"Basic Regex Operations"},{"location":"python/python/#common-regex-patterns","text":"# Email validation (simplified) email_pattern = r\"[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}\" # Phone number (US format) phone_pattern = r\"\\(\\d{3}\\)\\s\\d{3}-\\d{4}\" # URL pattern url_pattern = r\"https?://[^\\s]+\" # Date pattern (YYYY-MM-DD) date_pattern = r\"\\d{4}-\\d{2}-\\d{2}\" # Compiled patterns for efficiency compiled_email = re.compile(email_pattern) result = compiled_email.search(\"Contact us at info@example.com\")","title":"Common Regex Patterns"},{"location":"python/python/#working-with-dates-and-times","text":"","title":"Working with Dates and Times"},{"location":"python/python/#datetime-module","text":"from datetime import datetime, date, time, timedelta # Current date and time now = datetime.now() today = date.today() current_time = datetime.now().time() # Creating specific dates birthday = date(1990, 5, 15) meeting_time = datetime(2023, 12, 25, 14, 30) # Formatting dates formatted = now.strftime(\"%Y-%m-%d %H:%M:%S\") formatted_date = today.strftime(\"%B %d, %Y\") # Parsing strings to dates parsed = datetime.strptime(\"2023-12-25 14:30\", \"%Y-%m-%d %H:%M\") # Date arithmetic tomorrow = today + timedelta(days=1) week_ago = now - timedelta(weeks=1) in_2_hours = now + timedelta(hours=2) # Date comparisons if birthday < today: print(\"Birthday has passed this year\")","title":"datetime Module"},{"location":"python/python/#time-module","text":"import time # Current timestamp timestamp = time.time() # Sleep/pause execution time.sleep(2) # Pause for 2 seconds # Measure execution time start_time = time.time() # ... some operation ... end_time = time.time() elapsed = end_time - start_time","title":"time Module"},{"location":"python/python/#error-handling-best-practices","text":"","title":"Error Handling Best Practices"},{"location":"python/python/#specific-exception-handling","text":"def safe_divide(a, b): try: return a / b except TypeError: print(\"Both arguments must be numbers\") return None except ZeroDivisionError: print(\"Cannot divide by zero\") return None except Exception as e: print(f\"Unexpected error: {e}\") return None def read_config_file(filename): try: with open(filename, 'r') as file: return json.load(file) except FileNotFoundError: print(f\"Config file {filename} not found\") return {} except json.JSONDecodeError as e: print(f\"Invalid JSON in config file: {e}\") return {} except PermissionError: print(f\"Permission denied reading {filename}\") return {}","title":"Specific Exception Handling"},{"location":"python/python/#common-patterns","text":"","title":"Common Patterns"},{"location":"python/python/#singleton-pattern","text":"class Singleton: _instance = None def __new__(cls): if cls._instance is None: cls._instance = super().__new__(cls) return cls._instance","title":"Singleton Pattern"},{"location":"python/python/#factory-pattern","text":"class Animal: def speak(self): pass class Dog(Animal): def speak(self): return \"Woof!\" class Cat(Animal): def speak(self): return \"Meow!\" def create_animal(animal_type): animals = { 'dog': Dog, 'cat': Cat } return animals.get(animal_type.lower(), Animal)()","title":"Factory Pattern"},{"location":"python/python/#performance-tips","text":"Use built-in functions : sum() , max() , min() are optimized List comprehensions : Generally faster than equivalent loops Use join() for string concatenation : Instead of += in loops Use set for membership testing : O(1) vs O(n) for lists Use collections.defaultdict : Avoid checking if keys exist Use generators : For memory-efficient iteration over large datasets Profile your code : Use cProfile and timeit","title":"Performance Tips"},{"location":"python/python/#type-hints-and-annotations","text":"","title":"Type Hints and Annotations"},{"location":"python/python/#basic-type-hints","text":"from typing import List, Dict, Optional, Union, Callable, Tuple # Function with type hints def greet(name: str, age: int) -> str: return f\"Hello {name}, you are {age} years old\" # Variable annotations count: int = 0 names: List[str] = [\"Alice\", \"Bob\"] scores: Dict[str, float] = {\"Alice\": 95.5, \"Bob\": 87.2} # Optional and Union types def find_user(user_id: int) -> Optional[str]: # Returns string or None return users.get(user_id) def process_data(data: Union[str, int]) -> str: # Accepts string or int return str(data).upper() # Function type hints def apply_operation(func: Callable[[int, int], int], x: int, y: int) -> int: return func(x, y) # Generic types from typing import TypeVar T = TypeVar('T') def first_item(items: List[T]) -> Optional[T]: return items[0] if items else None","title":"Basic Type Hints"},{"location":"python/python/#advanced-type-hints","text":"from typing import Protocol, Literal, Final # Protocol for structural typing class Drawable(Protocol): def draw(self) -> None: ... # Literal types def set_mode(mode: Literal['read', 'write', 'append']) -> None: pass # Final variables (constants) API_KEY: Final[str] = \"secret-key\" # Class with type hints class User: def __init__(self, name: str, email: str) -> None: self.name = name self.email = email def get_info(self) -> Dict[str, str]: return {\"name\": self.name, \"email\": self.email}","title":"Advanced Type Hints"},{"location":"python/python/#dataclasses","text":"","title":"Dataclasses"},{"location":"python/python/#basic-dataclasses","text":"from dataclasses import dataclass, field from typing import List @dataclass class Person: name: str age: int email: str = \"\" # Default value def greet(self) -> str: return f\"Hello, I'm {self.name}\" # Usage person = Person(\"Alice\", 30, \"alice@example.com\") print(person.name) # Alice # With post-init processing @dataclass class Rectangle: width: float height: float area: float = field(init=False) # Computed field def __post_init__(self): self.area = self.width * self.height # Frozen dataclass (immutable) @dataclass(frozen=True) class Point: x: float y: float # With default factory @dataclass class Team: name: str members: List[str] = field(default_factory=list)","title":"Basic Dataclasses"},{"location":"python/python/#async-programming","text":"","title":"Async Programming"},{"location":"python/python/#basic-asyncawait","text":"import asyncio import aiohttp from typing import List # Async function async def fetch_data(url: str) -> str: async with aiohttp.ClientSession() as session: async with session.get(url) as response: return await response.text() # Running async code async def main(): data = await fetch_data(\"https://api.example.com\") print(data) # Run the main function asyncio.run(main()) # Concurrent execution async def fetch_multiple(urls: List[str]) -> List[str]: tasks = [fetch_data(url) for url in urls] results = await asyncio.gather(*tasks) return results # Async generator async def async_counter(max_count: int): for i in range(max_count): yield i await asyncio.sleep(0.1) # Simulate async work # Using async generator async def use_async_generator(): async for number in async_counter(5): print(number)","title":"Basic Async/Await"},{"location":"python/python/#collections-module","text":"","title":"Collections Module"},{"location":"python/python/#specialized-data-structures","text":"from collections import defaultdict, Counter, deque, namedtuple, OrderedDict # defaultdict - provides default values for missing keys dd = defaultdict(list) dd['fruits'].append('apple') # No KeyError dd['fruits'].append('banana') dd_int = defaultdict(int) dd_int['count'] += 1 # Starts at 0 # Counter - count occurrences text = \"hello world\" counter = Counter(text) print(counter['l']) # 3 print(counter.most_common(3)) # [('l', 3), ('o', 2), ...] # Count items in list items = ['apple', 'banana', 'apple', 'orange', 'banana', 'apple'] item_counts = Counter(items) # deque - double-ended queue (efficient append/pop from both ends) dq = deque([1, 2, 3]) dq.appendleft(0) # [0, 1, 2, 3] dq.append(4) # [0, 1, 2, 3, 4] dq.popleft() # [1, 2, 3, 4] dq.pop() # [1, 2, 3] # Rotating dq.rotate(1) # [3, 1, 2] dq.rotate(-1) # [1, 2, 3] # OrderedDict - dict that remembers insertion order # Note: Since Python 3.7, standard dicts also remember insertion order. # OrderedDict is still useful for its move_to_end() method and equality behavior. od = OrderedDict() od['a'] = 1 od['b'] = 2 od['c'] = 3 # namedtuple - immutable classes Point = namedtuple('Point', ['x', 'y']) p = Point(10, 20) print(p.x, p.y) # 10 20","title":"Specialized Data Structures"},{"location":"python/python/#itertools","text":"","title":"Itertools"},{"location":"python/python/#advanced-iteration-patterns","text":"import itertools # Infinite iterators counter = itertools.count(10, 2) # 10, 12, 14, 16, ... cycle_data = itertools.cycle(['A', 'B', 'C']) # A, B, C, A, B, C, ... repeated = itertools.repeat('hello', 3) # 'hello', 'hello', 'hello' # Finite iterators data = [1, 2, 3, 4, 5] # Chain multiple iterables chained = itertools.chain([1, 2], [3, 4], [5, 6]) # 1, 2, 3, 4, 5, 6 # Combinations and permutations combos = list(itertools.combinations([1, 2, 3], 2)) # [(1, 2), (1, 3), (2, 3)] perms = list(itertools.permutations([1, 2, 3], 2)) # [(1, 2), (1, 3), (2, 1), ...] # Groupby data = [('a', 1), ('a', 2), ('b', 3), ('b', 4), ('c', 5)] for key, group in itertools.groupby(data, key=lambda x: x[0]): print(f\"{key}: {list(group)}\") # Take while condition is true numbers = [1, 3, 5, 8, 9, 11, 13] odds = list(itertools.takewhile(lambda x: x % 2 == 1, numbers)) # [1, 3, 5] # Drop while condition is true rest = list(itertools.dropwhile(lambda x: x % 2 == 1, numbers)) # [8, 9, 11, 13] # Product (cartesian product) colors = ['red', 'blue'] sizes = ['S', 'M', 'L'] variants = list(itertools.product(colors, sizes)) # [('red', 'S'), ('red', 'M'), ('red', 'L'), ('blue', 'S'), ...]","title":"Advanced Iteration Patterns"},{"location":"python/python/#pathlib-modern-file-handling","text":"","title":"Pathlib (Modern File Handling)"},{"location":"python/python/#path-operations","text":"from pathlib import Path import os # Creating paths current_dir = Path.cwd() home_dir = Path.home() file_path = Path(\"data/file.txt\") absolute_path = Path(\"/usr/local/bin/python\") # Path manipulation file_path = Path(\"documents/projects/my_project/data.txt\") print(file_path.parent) # documents/projects/my_project print(file_path.name) # data.txt print(file_path.stem) # data print(file_path.suffix) # .txt print(file_path.parts) # ('documents', 'projects', 'my_project', 'data.txt') # Joining paths project_dir = Path(\"projects\") config_file = project_dir / \"config\" / \"settings.json\" # File operations if file_path.exists(): content = file_path.read_text() lines = file_path.read_text().splitlines() # Write to file output_path = Path(\"output.txt\") output_path.write_text(\"Hello, World!\") # Directory operations data_dir = Path(\"data\") data_dir.mkdir(parents=True, exist_ok=True) # Create directory # List directory contents for item in data_dir.iterdir(): if item.is_file(): print(f\"File: {item.name}\") elif item.is_dir(): print(f\"Directory: {item.name}\") # Glob patterns python_files = list(Path(\".\").glob(\"*.py\")) all_python_files = list(Path(\".\").rglob(\"*.py\")) # Recursive","title":"Path Operations"},{"location":"python/python/#logging","text":"","title":"Logging"},{"location":"python/python/#basic-logging","text":"import logging # Basic configuration logging.basicConfig( level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s', handlers=[ logging.FileHandler('app.log'), logging.StreamHandler() ] ) # Create logger logger = logging.getLogger(__name__) # Log levels logger.debug(\"Debug message\") # Not shown with INFO level logger.info(\"Info message\") logger.warning(\"Warning message\") logger.error(\"Error message\") logger.critical(\"Critical message\") # Logging with variables name = \"Alice\" age = 30 logger.info(f\"User {name} is {age} years old\") # Exception logging try: result = 10 / 0 except ZeroDivisionError: logger.exception(\"Division by zero occurred\") # Includes traceback","title":"Basic Logging"},{"location":"python/python/#advanced-logging","text":"import logging.config # Dictionary configuration LOGGING_CONFIG = { 'version': 1, 'disable_existing_loggers': False, 'formatters': { 'standard': { 'format': '%(asctime)s [%(levelname)s] %(name)s: %(message)s' }, }, 'handlers': { 'file': { 'level': 'INFO', 'class': 'logging.handlers.RotatingFileHandler', 'filename': 'app.log', 'maxBytes': 1024*1024*5, # 5MB 'backupCount': 3, 'formatter': 'standard', }, 'console': { 'level': 'DEBUG', 'class': 'logging.StreamHandler', 'formatter': 'standard', }, }, 'root': { 'handlers': ['file', 'console'], 'level': 'INFO', } } logging.config.dictConfig(LOGGING_CONFIG) logger = logging.getLogger(__name__)","title":"Advanced Logging"},{"location":"python/python/#command-line-arguments","text":"","title":"Command Line Arguments"},{"location":"python/python/#using-argparse","text":"import argparse def main(): parser = argparse.ArgumentParser(description='Process some files.') # Positional arguments parser.add_argument('filename', help='Input filename') # Optional arguments parser.add_argument('-o', '--output', help='Output filename') parser.add_argument('-v', '--verbose', action='store_true', help='Verbose output') parser.add_argument('--count', type=int, default=1, help='Number of times to process') parser.add_argument('--format', choices=['json', 'csv', 'xml'], default='json') # Parse arguments args = parser.parse_args() print(f\"Input file: {args.filename}\") if args.output: print(f\"Output file: {args.output}\") if args.verbose: print(\"Verbose mode enabled\") print(f\"Processing {args.count} times in {args.format} format\") if __name__ == \"__main__\": main() # Usage examples: # python script.py input.txt # python script.py input.txt -o output.txt --verbose --count 3 --format csv","title":"Using argparse"},{"location":"python/python/#testing","text":"","title":"Testing"},{"location":"python/python/#using-unittest","text":"import unittest from mymodule import Calculator class TestCalculator(unittest.TestCase): def setUp(self): \"\"\"Set up test fixtures before each test method.\"\"\" self.calc = Calculator() def test_add(self): \"\"\"Test addition method.\"\"\" result = self.calc.add(2, 3) self.assertEqual(result, 5) def test_divide_by_zero(self): \"\"\"Test division by zero raises exception.\"\"\" with self.assertRaises(ValueError): self.calc.divide(10, 0) def test_multiple_operations(self): \"\"\"Test multiple operations.\"\"\" self.assertEqual(self.calc.add(2, 3), 5) self.assertEqual(self.calc.subtract(10, 4), 6) self.assertEqual(self.calc.multiply(3, 7), 21) def tearDown(self): \"\"\"Clean up after each test method.\"\"\" pass # Run tests if __name__ == '__main__': unittest.main() # Or run from the command line: # python -m unittest discover # Common assertions # self.assertEqual(a, b) # a == b # self.assertNotEqual(a, b) # a != b # self.assertTrue(x) # bool(x) is True # self.assertFalse(x) # bool(x) is False # self.assertIs(a, b) # a is b # self.assertIsNot(a, b) # a is not b # self.assertIsNone(x) # x is None # self.assertIn(a, b) # a in b # self.assertGreater(a, b) # a > b # self.assertRaises(exc, fun, *args)","title":"Using unittest"},{"location":"python/python/#using-pytest-alternative","text":"import pytest from mymodule import Calculator # Fixture for test setup @pytest.fixture def calculator(): return Calculator() def test_add(calculator): assert calculator.add(2, 3) == 5 def test_divide_by_zero(calculator): with pytest.raises(ValueError): calculator.divide(10, 0) # Parametrized tests @pytest.mark.parametrize(\"a,b,expected\", [ (2, 3, 5), (1, 1, 2), (-1, 1, 0), (0, 0, 0), ]) def test_add_parametrized(calculator, a, b, expected): assert calculator.add(a, b) == expected # Run with: pytest test_file.py","title":"Using pytest (Alternative)"},{"location":"python/python/#virtual-environments-and-package-management","text":"","title":"Virtual Environments and Package Management"},{"location":"python/python/#creating-virtual-environments","text":"# Using venv (built-in) python -m venv myenv source myenv/bin/activate # Linux/Mac myenv\\Scripts\\activate # Windows deactivate # Exit virtual environment # Using virtualenv pip install virtualenv virtualenv myenv source myenv/bin/activate # Using conda conda create --name myenv python=3.9 conda activate myenv conda deactivate","title":"Creating Virtual Environments"},{"location":"python/python/#package-management","text":"# Install packages pip install requests pip install requests==2.28.0 # Specific version pip install requests>=2.25.0 # Minimum version # Install from requirements file pip install -r requirements.txt # Create requirements file pip freeze > requirements.txt # Install in development mode pip install -e . # Upgrade packages pip install --upgrade requests pip list --outdated","title":"Package Management"},{"location":"python/python/#requirementstxt-example","text":"requests==2.28.0 pandas>=1.4.0 numpy>=1.21.0,<2.0.0 pytest>=7.0.0 black==22.6.0","title":"requirements.txt example"},{"location":"python/python/#common-third-party-libraries","text":"","title":"Common Third-Party Libraries"},{"location":"python/python/#requests-http-client","text":"import requests import json # GET request response = requests.get('https://api.github.com/users/octocat') if response.status_code == 200: data = response.json() print(data['name']) # POST request payload = {'key1': 'value1', 'key2': 'value2'} response = requests.post('https://httpbin.org/post', json=payload) # With headers and authentication headers = {'Authorization': 'Bearer token123'} response = requests.get('https://api.example.com/data', headers=headers) # Session for multiple requests session = requests.Session() session.headers.update({'User-Agent': 'MyApp/1.0'}) response = session.get('https://api.example.com')","title":"Requests (HTTP Client)"},{"location":"python/python/#basic-data-analysis-pandas","text":"import pandas as pd import numpy as np # Create DataFrame data = { 'name': ['Alice', 'Bob', 'Charlie'], 'age': [25, 30, 35], 'city': ['NYC', 'LA', 'Chicago'] } df = pd.DataFrame(data) # Read from files df = pd.read_csv('data.csv') df = pd.read_json('data.json') df = pd.read_excel('data.xlsx') # Basic operations print(df.head()) # First 5 rows print(df.info()) # Data info print(df.describe()) # Statistics # Selecting data ages = df['age'] # Single column subset = df[['name', 'age']] # Multiple columns filtered = df[df['age'] > 25] # Filter rows # Save data df.to_csv('output.csv', index=False) df.to_json('output.json')","title":"Basic Data Analysis (Pandas)"},{"location":"python/python/#best-practices","text":"Follow PEP 8 : Python style guide Use meaningful variable names : user_count not uc Write docstrings : Document functions and classes Use type hints : Help with code clarity and tools Handle exceptions gracefully : Don't use bare except: Use context managers : For resource management Keep functions small : Single responsibility principle Use virtual environments : Isolate project dependencies Test your code : Write unit tests Use version control : Git for tracking changes Use pathlib : Instead of os.path for file operations Prefer f-strings : For string formatting in Python 3.6+ Use dataclasses : For simple data containers Use async/await : For I/O-bound operations Profile before optimizing : Use cProfile, timeit, or py-spy","title":"Best Practices"},{"location":"python/pytorch/","text":"PyTorch Installation # CPU only pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu # CUDA (check https://pytorch.org for your CUDA version) pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121 # AMD ROCm pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/rocm5.6 # Intel GPU (XPU) pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/xpu # Development version (nightly) pip install --pre torch torchvision torchaudio --index-url https://download.pytorch.org/whl/nightly/cpu Import Essentials import torch import torch.nn as nn import torch.optim as optim import torch.nn.functional as F from torch.utils.data import DataLoader, Dataset import torchvision import torchvision.transforms as transforms import numpy as np Tensor Basics Creating Tensors # From data x = torch.tensor([1, 2, 3]) x = torch.tensor([[1, 2], [3, 4]], dtype=torch.float32) # Zeros and ones x = torch.zeros(3, 4) x = torch.ones(2, 3) x = torch.eye(3) # identity matrix # Random tensors x = torch.randn(2, 3) # normal distribution x = torch.rand(2, 3) # uniform [0, 1) x = torch.randint(0, 10, (2, 3)) # random integers # From numpy numpy_array = np.array([1, 2, 3]) x = torch.from_numpy(numpy_array) # Ranges x = torch.arange(0, 10, 2) # [0, 2, 4, 6, 8] x = torch.linspace(0, 1, 5) # [0, 0.25, 0.5, 0.75, 1.0] Tensor Properties x = torch.randn(3, 4, 5) print(x.shape) # torch.Size([3, 4, 5]) print(x.size()) # torch.Size([3, 4, 5]) print(x.dtype) # torch.float32 print(x.device) # cpu or cuda:0 print(x.ndim) # 3 print(x.numel()) # 60 (total elements) Tensor Operations # Arithmetic x = torch.tensor([1, 2, 3]) y = torch.tensor([4, 5, 6]) z = x + y # or torch.add(x, y) z = x - y # or torch.sub(x, y) z = x * y # element-wise multiplication z = x / y # element-wise division z = x @ y # dot product z = torch.matmul(x, y) # matrix multiplication # In-place operations (end with _) x.add_(1) # adds 1 to x in-place x.mul_(2) # multiplies x by 2 in-place Reshaping and Indexing x = torch.randn(4, 4) # Reshaping x = x.view(16) # or x.view(-1) x = x.view(2, 8) x = x.reshape(4, 4) # more flexible than view x = x.squeeze() # remove dimensions of size 1 x = x.unsqueeze(0) # add dimension at index 0 # Indexing x[0, 1] # element at row 0, col 1 x[:, 1] # all rows, column 1 x[1, :] # row 1, all columns x[0:2, 1:3] # submatrix # Advanced indexing mask = x > 0 x[mask] # elements where mask is True Device Management # Check device availability device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') print(f\"Using device: {device}\") # Move tensors to device x = torch.randn(3, 3) x = x.to(device) # or x = x.cuda() if torch.cuda.is_available() else x # Create tensors directly on device x = torch.randn(3, 3, device=device) Neural Networks Basic Neural Network class SimpleNet(nn.Module): def __init__(self, input_size, hidden_size, output_size): super(SimpleNet, self).__init__() self.fc1 = nn.Linear(input_size, hidden_size) self.fc2 = nn.Linear(hidden_size, output_size) self.relu = nn.ReLU() self.dropout = nn.Dropout(0.2) def forward(self, x): x = self.fc1(x) x = self.relu(x) x = self.dropout(x) x = self.fc2(x) return x # Create model model = SimpleNet(784, 128, 10) print(model) Convolutional Neural Network class ConvNet(nn.Module): def __init__(self, num_classes=10): super(ConvNet, self).__init__() self.conv1 = nn.Conv2d(3, 16, 3, padding=1) self.conv2 = nn.Conv2d(16, 32, 3, padding=1) self.pool = nn.MaxPool2d(2, 2) self.fc1 = nn.Linear(32 * 8 * 8, 128) self.fc2 = nn.Linear(128, num_classes) self.dropout = nn.Dropout(0.5) def forward(self, x): x = self.pool(F.relu(self.conv1(x))) x = self.pool(F.relu(self.conv2(x))) x = x.view(-1, 32 * 8 * 8) # flatten x = F.relu(self.fc1(x)) x = self.dropout(x) x = self.fc2(x) return x Common Layers # Linear layers nn.Linear(in_features, out_features) nn.Linear(784, 10, bias=False) # Convolutional layers nn.Conv1d(in_channels, out_channels, kernel_size) nn.Conv2d(1, 32, 3, stride=1, padding=1) nn.Conv3d(1, 16, 3) # Pooling layers nn.MaxPool2d(kernel_size=2) nn.AvgPool2d(kernel_size=2, stride=2) nn.AdaptiveAvgPool2d((1, 1)) # Normalization nn.BatchNorm1d(num_features) nn.BatchNorm2d(num_features) nn.LayerNorm(normalized_shape) # Activation functions nn.ReLU() nn.LeakyReLU(negative_slope=0.01) nn.Sigmoid() nn.Tanh() nn.Softmax(dim=1) # Regularization nn.Dropout(p=0.5) nn.Dropout2d(p=0.5) Loss Functions # Classification criterion = nn.CrossEntropyLoss() criterion = nn.BCELoss() # Binary cross entropy criterion = nn.BCEWithLogitsLoss() # BCE with sigmoid # Regression criterion = nn.MSELoss() # Mean squared error criterion = nn.L1Loss() # Mean absolute error criterion = nn.SmoothL1Loss() # Huber loss # Custom loss example class CustomLoss(nn.Module): def __init__(self): super(CustomLoss, self).__init__() def forward(self, predictions, targets): return torch.mean((predictions - targets) ** 2) Optimizers # Common optimizers optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9, weight_decay=1e-4) optimizer = optim.Adam(model.parameters(), lr=0.001, betas=(0.9, 0.999)) optimizer = optim.AdamW(model.parameters(), lr=0.001, weight_decay=0.01) optimizer = optim.RMSprop(model.parameters(), lr=0.01, alpha=0.9) # Learning rate schedulers scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=30, gamma=0.1) scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=10) scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=50) Training Loop def train_model(model, train_loader, criterion, optimizer, num_epochs, device): model.train() for epoch in range(num_epochs): running_loss = 0.0 for batch_idx, (data, targets) in enumerate(train_loader): # Move data to device data, targets = data.to(device), targets.to(device) # Zero gradients optimizer.zero_grad() # Forward pass outputs = model(data) loss = criterion(outputs, targets) # Backward pass loss.backward() optimizer.step() running_loss += loss.item() if batch_idx % 100 == 0: print(f'Epoch {epoch+1}/{num_epochs}, ' f'Batch {batch_idx}/{len(train_loader)}, ' f'Loss: {loss.item():.4f}') # Optional: step scheduler # scheduler.step() epoch_loss = running_loss / len(train_loader) print(f'Epoch {epoch+1} average loss: {epoch_loss:.4f}') # Usage train_model(model, train_loader, criterion, optimizer, num_epochs=10, device=device) Evaluation def evaluate_model(model, test_loader, device): model.eval() correct = 0 total = 0 test_loss = 0 with torch.no_grad(): for data, targets in test_loader: data, targets = data.to(device), targets.to(device) outputs = model(data) test_loss += F.cross_entropy(outputs, targets, reduction='sum').item() _, predicted = torch.max(outputs.data, 1) total += targets.size(0) correct += (predicted == targets).sum().item() accuracy = 100 * correct / total avg_loss = test_loss / total print(f'Test Accuracy: {accuracy:.2f}%') print(f'Test Loss: {avg_loss:.4f}') return accuracy, avg_loss Data Loading Custom Dataset class CustomDataset(Dataset): def __init__(self, data, labels, transform=None): self.data = data self.labels = labels self.transform = transform def __len__(self): return len(self.data) def __getitem__(self, idx): sample = self.data[idx] label = self.labels[idx] if self.transform: sample = self.transform(sample) return sample, label # Usage dataset = CustomDataset(data, labels, transform=transforms.ToTensor()) dataloader = DataLoader(dataset, batch_size=32, shuffle=True, num_workers=4) Data Transforms from torchvision import transforms # Common transforms transform = transforms.Compose([ transforms.Resize((224, 224)), transforms.RandomHorizontalFlip(p=0.5), transforms.RandomRotation(degrees=10), transforms.ColorJitter(brightness=0.2, contrast=0.2), transforms.ToTensor(), transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]) ]) # For evaluation (no data augmentation) test_transform = transforms.Compose([ transforms.Resize((224, 224)), transforms.ToTensor(), transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]) ]) Model Saving and Loading # Save model torch.save(model.state_dict(), 'model_weights.pth') torch.save(model, 'complete_model.pth') # Save checkpoint checkpoint = { 'epoch': epoch, 'model_state_dict': model.state_dict(), 'optimizer_state_dict': optimizer.state_dict(), 'loss': loss, } torch.save(checkpoint, 'checkpoint.pth') # Load model model.load_state_dict(torch.load('model_weights.pth', map_location=device)) model = torch.load('complete_model.pth', map_location=device) # Load checkpoint checkpoint = torch.load('checkpoint.pth', map_location=device) model.load_state_dict(checkpoint['model_state_dict']) optimizer.load_state_dict(checkpoint['optimizer_state_dict']) epoch = checkpoint['epoch'] loss = checkpoint['loss'] Autograd and Gradients # Enable/disable gradients x = torch.randn(3, requires_grad=True) # Forward pass y = x.sum() # Backward pass y.backward() print(x.grad) # Gradient context managers with torch.no_grad(): # Operations here won't track gradients y = model(x) # Temporarily enable gradients with torch.enable_grad(): # Operations here will track gradients pass # Manual gradient computation def custom_backward(x): x.retain_grad() y = x ** 2 y.backward(torch.ones_like(y)) return x.grad Mixed Precision Training from torch.amp import autocast, GradScaler # Initialize scaler scaler = GradScaler() def train_with_amp(model, train_loader, criterion, optimizer, device): model.train() for data, targets in train_loader: data, targets = data.to(device), targets.to(device) optimizer.zero_grad() # Use autocast for forward pass with autocast(device_type='cuda'): outputs = model(data) loss = criterion(outputs, targets) # Scale loss and backward scaler.scale(loss).backward() scaler.step(optimizer) scaler.update() torch.compile (PyTorch 2.0+) # Optimize model with torch.compile model = torch.compile(model) # With specific backend model = torch.compile(model, backend=\"inductor\") # For inference only @torch.compile def inference_function(x): return torch.sin(x).cos() # Disable compilation for debugging model = torch.compile(model, disable=True) Model Utilities Parameter Counting def count_parameters(model): return sum(p.numel() for p in model.parameters() if p.requires_grad) print(f\"Model has {count_parameters(model):,} trainable parameters\") Model Summary def model_summary(model, input_size): def register_hook(module): def hook(module, input, output): class_name = str(module.__class__).split(\".\")[-1].split(\"'\")[0] module_idx = len(summary) m_key = f\"{class_name}-{module_idx+1}\" summary[m_key] = { \"input_shape\": list(input[0].size()), \"output_shape\": list(output.size()), \"nb_params\": sum([param.nelement() for param in module.parameters()]) } if not isinstance(module, nn.Sequential) and not isinstance(module, nn.ModuleList): hooks.append(module.register_forward_hook(hook)) device = next(model.parameters()).device summary = {} hooks = [] model.apply(register_hook) # Make a forward pass x = torch.randn(*input_size).to(device) model(x) # Remove hooks for h in hooks: h.remove() return summary Transfer Learning import torchvision.models as models # Load pretrained model model = models.resnet18(pretrained=True) # Freeze parameters for param in model.parameters(): param.requires_grad = False # Replace final layer num_features = model.fc.in_features model.fc = nn.Linear(num_features, num_classes) # Only train final layer optimizer = optim.Adam(model.fc.parameters(), lr=0.001) # Fine-tuning: unfreeze some layers for param in model.layer4.parameters(): param.requires_grad = True Common Patterns Early Stopping class EarlyStopping: def __init__(self, patience=7, min_delta=0, restore_best_weights=True): self.patience = patience self.min_delta = min_delta self.restore_best_weights = restore_best_weights self.best_loss = None self.counter = 0 self.best_weights = None def __call__(self, val_loss, model): if self.best_loss is None: self.best_loss = val_loss self.save_checkpoint(model) elif val_loss < self.best_loss - self.min_delta: self.best_loss = val_loss self.counter = 0 self.save_checkpoint(model) else: self.counter += 1 if self.counter >= self.patience: if self.restore_best_weights: model.load_state_dict(self.best_weights) return True return False def save_checkpoint(self, model): self.best_weights = model.state_dict().copy() Gradient Clipping # During training loss.backward() torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0) optimizer.step() Learning Rate Finding def find_lr(model, train_loader, optimizer, criterion, device): lrs = [] losses = [] lr = 1e-7 for data, targets in train_loader: data, targets = data.to(device), targets.to(device) optimizer.param_groups[0]['lr'] = lr optimizer.zero_grad() outputs = model(data) loss = criterion(outputs, targets) loss.backward() optimizer.step() lrs.append(lr) losses.append(loss.item()) lr *= 1.1 if lr > 1: break return lrs, losses Debugging Tips Check for NaN/Inf def check_for_nan(tensor, name=\"tensor\"): if torch.isnan(tensor).any(): print(f\"NaN detected in {name}\") if torch.isinf(tensor).any(): print(f\"Inf detected in {name}\") Monitor Gradients def monitor_gradients(model): for name, param in model.named_parameters(): if param.grad is not None: grad_norm = param.grad.norm() print(f\"{name}: {grad_norm:.4f}\") Memory Usage def print_gpu_memory(): if torch.cuda.is_available(): print(f\"GPU memory allocated: {torch.cuda.memory_allocated() / 1024**2:.1f} MB\") print(f\"GPU memory cached: {torch.cuda.memory_reserved() / 1024**2:.1f} MB\") Performance Tips Use torch.compile() for PyTorch 2.0+ performance gains Use mixed precision training with AMP for faster training Set torch.backends.cudnn.benchmark = True for consistent input sizes Use pin_memory=True in DataLoader for faster GPU transfer Use appropriate num_workers in DataLoader (typically 2-4x number of GPUs) Use torch.no_grad() during inference to save memory Consider using torch.jit.script() for model optimization Use torch.utils.checkpoint for memory-efficient training of large models","title":"PyTorch"},{"location":"python/pytorch/#pytorch","text":"","title":"PyTorch"},{"location":"python/pytorch/#installation","text":"# CPU only pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu # CUDA (check https://pytorch.org for your CUDA version) pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121 # AMD ROCm pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/rocm5.6 # Intel GPU (XPU) pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/xpu # Development version (nightly) pip install --pre torch torchvision torchaudio --index-url https://download.pytorch.org/whl/nightly/cpu","title":"Installation"},{"location":"python/pytorch/#import-essentials","text":"import torch import torch.nn as nn import torch.optim as optim import torch.nn.functional as F from torch.utils.data import DataLoader, Dataset import torchvision import torchvision.transforms as transforms import numpy as np","title":"Import Essentials"},{"location":"python/pytorch/#tensor-basics","text":"","title":"Tensor Basics"},{"location":"python/pytorch/#creating-tensors","text":"# From data x = torch.tensor([1, 2, 3]) x = torch.tensor([[1, 2], [3, 4]], dtype=torch.float32) # Zeros and ones x = torch.zeros(3, 4) x = torch.ones(2, 3) x = torch.eye(3) # identity matrix # Random tensors x = torch.randn(2, 3) # normal distribution x = torch.rand(2, 3) # uniform [0, 1) x = torch.randint(0, 10, (2, 3)) # random integers # From numpy numpy_array = np.array([1, 2, 3]) x = torch.from_numpy(numpy_array) # Ranges x = torch.arange(0, 10, 2) # [0, 2, 4, 6, 8] x = torch.linspace(0, 1, 5) # [0, 0.25, 0.5, 0.75, 1.0]","title":"Creating Tensors"},{"location":"python/pytorch/#tensor-properties","text":"x = torch.randn(3, 4, 5) print(x.shape) # torch.Size([3, 4, 5]) print(x.size()) # torch.Size([3, 4, 5]) print(x.dtype) # torch.float32 print(x.device) # cpu or cuda:0 print(x.ndim) # 3 print(x.numel()) # 60 (total elements)","title":"Tensor Properties"},{"location":"python/pytorch/#tensor-operations","text":"# Arithmetic x = torch.tensor([1, 2, 3]) y = torch.tensor([4, 5, 6]) z = x + y # or torch.add(x, y) z = x - y # or torch.sub(x, y) z = x * y # element-wise multiplication z = x / y # element-wise division z = x @ y # dot product z = torch.matmul(x, y) # matrix multiplication # In-place operations (end with _) x.add_(1) # adds 1 to x in-place x.mul_(2) # multiplies x by 2 in-place","title":"Tensor Operations"},{"location":"python/pytorch/#reshaping-and-indexing","text":"x = torch.randn(4, 4) # Reshaping x = x.view(16) # or x.view(-1) x = x.view(2, 8) x = x.reshape(4, 4) # more flexible than view x = x.squeeze() # remove dimensions of size 1 x = x.unsqueeze(0) # add dimension at index 0 # Indexing x[0, 1] # element at row 0, col 1 x[:, 1] # all rows, column 1 x[1, :] # row 1, all columns x[0:2, 1:3] # submatrix # Advanced indexing mask = x > 0 x[mask] # elements where mask is True","title":"Reshaping and Indexing"},{"location":"python/pytorch/#device-management","text":"# Check device availability device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') print(f\"Using device: {device}\") # Move tensors to device x = torch.randn(3, 3) x = x.to(device) # or x = x.cuda() if torch.cuda.is_available() else x # Create tensors directly on device x = torch.randn(3, 3, device=device)","title":"Device Management"},{"location":"python/pytorch/#neural-networks","text":"","title":"Neural Networks"},{"location":"python/pytorch/#basic-neural-network","text":"class SimpleNet(nn.Module): def __init__(self, input_size, hidden_size, output_size): super(SimpleNet, self).__init__() self.fc1 = nn.Linear(input_size, hidden_size) self.fc2 = nn.Linear(hidden_size, output_size) self.relu = nn.ReLU() self.dropout = nn.Dropout(0.2) def forward(self, x): x = self.fc1(x) x = self.relu(x) x = self.dropout(x) x = self.fc2(x) return x # Create model model = SimpleNet(784, 128, 10) print(model)","title":"Basic Neural Network"},{"location":"python/pytorch/#convolutional-neural-network","text":"class ConvNet(nn.Module): def __init__(self, num_classes=10): super(ConvNet, self).__init__() self.conv1 = nn.Conv2d(3, 16, 3, padding=1) self.conv2 = nn.Conv2d(16, 32, 3, padding=1) self.pool = nn.MaxPool2d(2, 2) self.fc1 = nn.Linear(32 * 8 * 8, 128) self.fc2 = nn.Linear(128, num_classes) self.dropout = nn.Dropout(0.5) def forward(self, x): x = self.pool(F.relu(self.conv1(x))) x = self.pool(F.relu(self.conv2(x))) x = x.view(-1, 32 * 8 * 8) # flatten x = F.relu(self.fc1(x)) x = self.dropout(x) x = self.fc2(x) return x","title":"Convolutional Neural Network"},{"location":"python/pytorch/#common-layers","text":"# Linear layers nn.Linear(in_features, out_features) nn.Linear(784, 10, bias=False) # Convolutional layers nn.Conv1d(in_channels, out_channels, kernel_size) nn.Conv2d(1, 32, 3, stride=1, padding=1) nn.Conv3d(1, 16, 3) # Pooling layers nn.MaxPool2d(kernel_size=2) nn.AvgPool2d(kernel_size=2, stride=2) nn.AdaptiveAvgPool2d((1, 1)) # Normalization nn.BatchNorm1d(num_features) nn.BatchNorm2d(num_features) nn.LayerNorm(normalized_shape) # Activation functions nn.ReLU() nn.LeakyReLU(negative_slope=0.01) nn.Sigmoid() nn.Tanh() nn.Softmax(dim=1) # Regularization nn.Dropout(p=0.5) nn.Dropout2d(p=0.5)","title":"Common Layers"},{"location":"python/pytorch/#loss-functions","text":"# Classification criterion = nn.CrossEntropyLoss() criterion = nn.BCELoss() # Binary cross entropy criterion = nn.BCEWithLogitsLoss() # BCE with sigmoid # Regression criterion = nn.MSELoss() # Mean squared error criterion = nn.L1Loss() # Mean absolute error criterion = nn.SmoothL1Loss() # Huber loss # Custom loss example class CustomLoss(nn.Module): def __init__(self): super(CustomLoss, self).__init__() def forward(self, predictions, targets): return torch.mean((predictions - targets) ** 2)","title":"Loss Functions"},{"location":"python/pytorch/#optimizers","text":"# Common optimizers optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9, weight_decay=1e-4) optimizer = optim.Adam(model.parameters(), lr=0.001, betas=(0.9, 0.999)) optimizer = optim.AdamW(model.parameters(), lr=0.001, weight_decay=0.01) optimizer = optim.RMSprop(model.parameters(), lr=0.01, alpha=0.9) # Learning rate schedulers scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=30, gamma=0.1) scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=10) scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=50)","title":"Optimizers"},{"location":"python/pytorch/#training-loop","text":"def train_model(model, train_loader, criterion, optimizer, num_epochs, device): model.train() for epoch in range(num_epochs): running_loss = 0.0 for batch_idx, (data, targets) in enumerate(train_loader): # Move data to device data, targets = data.to(device), targets.to(device) # Zero gradients optimizer.zero_grad() # Forward pass outputs = model(data) loss = criterion(outputs, targets) # Backward pass loss.backward() optimizer.step() running_loss += loss.item() if batch_idx % 100 == 0: print(f'Epoch {epoch+1}/{num_epochs}, ' f'Batch {batch_idx}/{len(train_loader)}, ' f'Loss: {loss.item():.4f}') # Optional: step scheduler # scheduler.step() epoch_loss = running_loss / len(train_loader) print(f'Epoch {epoch+1} average loss: {epoch_loss:.4f}') # Usage train_model(model, train_loader, criterion, optimizer, num_epochs=10, device=device)","title":"Training Loop"},{"location":"python/pytorch/#evaluation","text":"def evaluate_model(model, test_loader, device): model.eval() correct = 0 total = 0 test_loss = 0 with torch.no_grad(): for data, targets in test_loader: data, targets = data.to(device), targets.to(device) outputs = model(data) test_loss += F.cross_entropy(outputs, targets, reduction='sum').item() _, predicted = torch.max(outputs.data, 1) total += targets.size(0) correct += (predicted == targets).sum().item() accuracy = 100 * correct / total avg_loss = test_loss / total print(f'Test Accuracy: {accuracy:.2f}%') print(f'Test Loss: {avg_loss:.4f}') return accuracy, avg_loss","title":"Evaluation"},{"location":"python/pytorch/#data-loading","text":"","title":"Data Loading"},{"location":"python/pytorch/#custom-dataset","text":"class CustomDataset(Dataset): def __init__(self, data, labels, transform=None): self.data = data self.labels = labels self.transform = transform def __len__(self): return len(self.data) def __getitem__(self, idx): sample = self.data[idx] label = self.labels[idx] if self.transform: sample = self.transform(sample) return sample, label # Usage dataset = CustomDataset(data, labels, transform=transforms.ToTensor()) dataloader = DataLoader(dataset, batch_size=32, shuffle=True, num_workers=4)","title":"Custom Dataset"},{"location":"python/pytorch/#data-transforms","text":"from torchvision import transforms # Common transforms transform = transforms.Compose([ transforms.Resize((224, 224)), transforms.RandomHorizontalFlip(p=0.5), transforms.RandomRotation(degrees=10), transforms.ColorJitter(brightness=0.2, contrast=0.2), transforms.ToTensor(), transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]) ]) # For evaluation (no data augmentation) test_transform = transforms.Compose([ transforms.Resize((224, 224)), transforms.ToTensor(), transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]) ])","title":"Data Transforms"},{"location":"python/pytorch/#model-saving-and-loading","text":"# Save model torch.save(model.state_dict(), 'model_weights.pth') torch.save(model, 'complete_model.pth') # Save checkpoint checkpoint = { 'epoch': epoch, 'model_state_dict': model.state_dict(), 'optimizer_state_dict': optimizer.state_dict(), 'loss': loss, } torch.save(checkpoint, 'checkpoint.pth') # Load model model.load_state_dict(torch.load('model_weights.pth', map_location=device)) model = torch.load('complete_model.pth', map_location=device) # Load checkpoint checkpoint = torch.load('checkpoint.pth', map_location=device) model.load_state_dict(checkpoint['model_state_dict']) optimizer.load_state_dict(checkpoint['optimizer_state_dict']) epoch = checkpoint['epoch'] loss = checkpoint['loss']","title":"Model Saving and Loading"},{"location":"python/pytorch/#autograd-and-gradients","text":"# Enable/disable gradients x = torch.randn(3, requires_grad=True) # Forward pass y = x.sum() # Backward pass y.backward() print(x.grad) # Gradient context managers with torch.no_grad(): # Operations here won't track gradients y = model(x) # Temporarily enable gradients with torch.enable_grad(): # Operations here will track gradients pass # Manual gradient computation def custom_backward(x): x.retain_grad() y = x ** 2 y.backward(torch.ones_like(y)) return x.grad","title":"Autograd and Gradients"},{"location":"python/pytorch/#mixed-precision-training","text":"from torch.amp import autocast, GradScaler # Initialize scaler scaler = GradScaler() def train_with_amp(model, train_loader, criterion, optimizer, device): model.train() for data, targets in train_loader: data, targets = data.to(device), targets.to(device) optimizer.zero_grad() # Use autocast for forward pass with autocast(device_type='cuda'): outputs = model(data) loss = criterion(outputs, targets) # Scale loss and backward scaler.scale(loss).backward() scaler.step(optimizer) scaler.update()","title":"Mixed Precision Training"},{"location":"python/pytorch/#torchcompile-pytorch-20","text":"# Optimize model with torch.compile model = torch.compile(model) # With specific backend model = torch.compile(model, backend=\"inductor\") # For inference only @torch.compile def inference_function(x): return torch.sin(x).cos() # Disable compilation for debugging model = torch.compile(model, disable=True)","title":"torch.compile (PyTorch 2.0+)"},{"location":"python/pytorch/#model-utilities","text":"","title":"Model Utilities"},{"location":"python/pytorch/#parameter-counting","text":"def count_parameters(model): return sum(p.numel() for p in model.parameters() if p.requires_grad) print(f\"Model has {count_parameters(model):,} trainable parameters\")","title":"Parameter Counting"},{"location":"python/pytorch/#model-summary","text":"def model_summary(model, input_size): def register_hook(module): def hook(module, input, output): class_name = str(module.__class__).split(\".\")[-1].split(\"'\")[0] module_idx = len(summary) m_key = f\"{class_name}-{module_idx+1}\" summary[m_key] = { \"input_shape\": list(input[0].size()), \"output_shape\": list(output.size()), \"nb_params\": sum([param.nelement() for param in module.parameters()]) } if not isinstance(module, nn.Sequential) and not isinstance(module, nn.ModuleList): hooks.append(module.register_forward_hook(hook)) device = next(model.parameters()).device summary = {} hooks = [] model.apply(register_hook) # Make a forward pass x = torch.randn(*input_size).to(device) model(x) # Remove hooks for h in hooks: h.remove() return summary","title":"Model Summary"},{"location":"python/pytorch/#transfer-learning","text":"import torchvision.models as models # Load pretrained model model = models.resnet18(pretrained=True) # Freeze parameters for param in model.parameters(): param.requires_grad = False # Replace final layer num_features = model.fc.in_features model.fc = nn.Linear(num_features, num_classes) # Only train final layer optimizer = optim.Adam(model.fc.parameters(), lr=0.001) # Fine-tuning: unfreeze some layers for param in model.layer4.parameters(): param.requires_grad = True","title":"Transfer Learning"},{"location":"python/pytorch/#common-patterns","text":"","title":"Common Patterns"},{"location":"python/pytorch/#early-stopping","text":"class EarlyStopping: def __init__(self, patience=7, min_delta=0, restore_best_weights=True): self.patience = patience self.min_delta = min_delta self.restore_best_weights = restore_best_weights self.best_loss = None self.counter = 0 self.best_weights = None def __call__(self, val_loss, model): if self.best_loss is None: self.best_loss = val_loss self.save_checkpoint(model) elif val_loss < self.best_loss - self.min_delta: self.best_loss = val_loss self.counter = 0 self.save_checkpoint(model) else: self.counter += 1 if self.counter >= self.patience: if self.restore_best_weights: model.load_state_dict(self.best_weights) return True return False def save_checkpoint(self, model): self.best_weights = model.state_dict().copy()","title":"Early Stopping"},{"location":"python/pytorch/#gradient-clipping","text":"# During training loss.backward() torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0) optimizer.step()","title":"Gradient Clipping"},{"location":"python/pytorch/#learning-rate-finding","text":"def find_lr(model, train_loader, optimizer, criterion, device): lrs = [] losses = [] lr = 1e-7 for data, targets in train_loader: data, targets = data.to(device), targets.to(device) optimizer.param_groups[0]['lr'] = lr optimizer.zero_grad() outputs = model(data) loss = criterion(outputs, targets) loss.backward() optimizer.step() lrs.append(lr) losses.append(loss.item()) lr *= 1.1 if lr > 1: break return lrs, losses","title":"Learning Rate Finding"},{"location":"python/pytorch/#debugging-tips","text":"","title":"Debugging Tips"},{"location":"python/pytorch/#check-for-naninf","text":"def check_for_nan(tensor, name=\"tensor\"): if torch.isnan(tensor).any(): print(f\"NaN detected in {name}\") if torch.isinf(tensor).any(): print(f\"Inf detected in {name}\")","title":"Check for NaN/Inf"},{"location":"python/pytorch/#monitor-gradients","text":"def monitor_gradients(model): for name, param in model.named_parameters(): if param.grad is not None: grad_norm = param.grad.norm() print(f\"{name}: {grad_norm:.4f}\")","title":"Monitor Gradients"},{"location":"python/pytorch/#memory-usage","text":"def print_gpu_memory(): if torch.cuda.is_available(): print(f\"GPU memory allocated: {torch.cuda.memory_allocated() / 1024**2:.1f} MB\") print(f\"GPU memory cached: {torch.cuda.memory_reserved() / 1024**2:.1f} MB\")","title":"Memory Usage"},{"location":"python/pytorch/#performance-tips","text":"Use torch.compile() for PyTorch 2.0+ performance gains Use mixed precision training with AMP for faster training Set torch.backends.cudnn.benchmark = True for consistent input sizes Use pin_memory=True in DataLoader for faster GPU transfer Use appropriate num_workers in DataLoader (typically 2-4x number of GPUs) Use torch.no_grad() during inference to save memory Consider using torch.jit.script() for model optimization Use torch.utils.checkpoint for memory-efficient training of large models","title":"Performance Tips"},{"location":"python/scikit-learn/","text":"Scikit-learn Installation pip install scikit-learn # Or with conda conda install -c conda-forge scikit-learn Import import sklearn from sklearn import datasets, model_selection, preprocessing, metrics import numpy as np import pandas as pd Basic Workflow 1. Load/Create Data from sklearn.datasets import load_iris, make_classification, make_regression # Built-in datasets iris = load_iris() X, y = iris.data, iris.target # Generate synthetic data X, y = make_classification(n_samples=1000, n_features=20, random_state=42) X, y = make_regression(n_samples=1000, n_features=10, random_state=42) 2. Train-Test Split from sklearn.model_selection import train_test_split X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.2, random_state=42, stratify=y ) 3. Preprocessing from sklearn.preprocessing import StandardScaler, MinMaxScaler, LabelEncoder # Scaling scaler = StandardScaler() X_train_scaled = scaler.fit_transform(X_train) X_test_scaled = scaler.transform(X_test) # Alternative scalers minmax_scaler = MinMaxScaler() X_normalized = minmax_scaler.fit_transform(X) 4. Model Training and Prediction from sklearn.ensemble import RandomForestClassifier from sklearn.linear_model import LogisticRegression # Classification clf = RandomForestClassifier(random_state=42) clf.fit(X_train, y_train) y_pred = clf.predict(X_test) y_proba = clf.predict_proba(X_test) # probability estimates Classification Algorithms Logistic Regression from sklearn.linear_model import LogisticRegression lr = LogisticRegression(random_state=42) lr.fit(X_train, y_train) y_pred = lr.predict(X_test) Random Forest from sklearn.ensemble import RandomForestClassifier rf = RandomForestClassifier(n_estimators=100, random_state=42) rf.fit(X_train, y_train) feature_importance = rf.feature_importances_ Support Vector Machine from sklearn.svm import SVC svm = SVC(kernel='rbf', random_state=42) svm.fit(X_train, y_train) y_pred = svm.predict(X_test) Gradient Boosting from sklearn.ensemble import GradientBoostingClassifier gb = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, random_state=42) gb.fit(X_train, y_train) Decision Trees from sklearn.tree import DecisionTreeClassifier dt = DecisionTreeClassifier(max_depth=5, random_state=42) dt.fit(X_train, y_train) Naive Bayes from sklearn.naive_bayes import GaussianNB, MultinomialNB nb = GaussianNB() nb.fit(X_train, y_train) k-Nearest Neighbors from sklearn.neighbors import KNeighborsClassifier knn = KNeighborsClassifier(n_neighbors=5) knn.fit(X_train, y_train) Regression Algorithms Linear Regression from sklearn.linear_model import LinearRegression, Ridge, Lasso # Simple linear regression lr = LinearRegression() lr.fit(X_train, y_train) # Ridge regression (L2 regularization) ridge = Ridge(alpha=1.0) ridge.fit(X_train, y_train) # Lasso regression (L1 regularization) lasso = Lasso(alpha=0.1) lasso.fit(X_train, y_train) Random Forest Regressor from sklearn.ensemble import RandomForestRegressor rf_reg = RandomForestRegressor(n_estimators=100, random_state=42) rf_reg.fit(X_train, y_train) y_pred = rf_reg.predict(X_test) Support Vector Regression from sklearn.svm import SVR svr = SVR(kernel='rbf', C=100, gamma=0.1) svr.fit(X_train, y_train) Clustering K-Means from sklearn.cluster import KMeans kmeans = KMeans(n_clusters=3, random_state=42) cluster_labels = kmeans.fit_predict(X) centroids = kmeans.cluster_centers_ Hierarchical Clustering from sklearn.cluster import AgglomerativeClustering hierarchical = AgglomerativeClustering(n_clusters=3) cluster_labels = hierarchical.fit_predict(X) DBSCAN from sklearn.cluster import DBSCAN dbscan = DBSCAN(eps=0.5, min_samples=5) cluster_labels = dbscan.fit_predict(X) Dimensionality Reduction Principal Component Analysis (PCA) from sklearn.decomposition import PCA pca = PCA(n_components=2) X_pca = pca.fit_transform(X) explained_variance = pca.explained_variance_ratio_ t-SNE from sklearn.manifold import TSNE tsne = TSNE(n_components=2, random_state=42) X_tsne = tsne.fit_transform(X) Linear Discriminant Analysis from sklearn.discriminant_analysis import LinearDiscriminantAnalysis lda = LinearDiscriminantAnalysis(n_components=2) X_lda = lda.fit_transform(X, y) Model Evaluation Classification Metrics from sklearn.metrics import ( accuracy_score, precision_score, recall_score, f1_score, classification_report, confusion_matrix, roc_auc_score ) # Basic metrics accuracy = accuracy_score(y_test, y_pred) precision = precision_score(y_test, y_pred, average='weighted') recall = recall_score(y_test, y_pred, average='weighted') f1 = f1_score(y_test, y_pred, average='weighted') # Detailed report report = classification_report(y_test, y_pred) cm = confusion_matrix(y_test, y_pred) # ROC AUC (for binary/multiclass) auc = roc_auc_score(y_test, y_proba, multi_class='ovr') Regression Metrics from sklearn.metrics import ( mean_squared_error, mean_absolute_error, r2_score ) mse = mean_squared_error(y_test, y_pred) mae = mean_absolute_error(y_test, y_pred) r2 = r2_score(y_test, y_pred) rmse = np.sqrt(mse) Cross-Validation from sklearn.model_selection import cross_val_score, cross_validate # Simple cross-validation scores = cross_val_score(clf, X, y, cv=5) print(f\"CV scores: {scores.mean():.3f} (+/- {scores.std() * 2:.3f})\") # Cross-validation with multiple metrics scoring = ['accuracy', 'precision_macro', 'recall_macro'] cv_results = cross_validate(clf, X, y, cv=5, scoring=scoring) Hyperparameter Tuning Grid Search from sklearn.model_selection import GridSearchCV param_grid = { 'n_estimators': [50, 100, 200], 'max_depth': [3, 5, 10], 'min_samples_split': [2, 5, 10] } grid_search = GridSearchCV( RandomForestClassifier(random_state=42), param_grid, cv=5, scoring='accuracy', n_jobs=-1 ) grid_search.fit(X_train, y_train) best_params = grid_search.best_params_ best_score = grid_search.best_score_ Randomized Search from sklearn.model_selection import RandomizedSearchCV from scipy.stats import randint param_dist = { 'n_estimators': randint(10, 100), 'max_depth': randint(1, 10) } random_search = RandomizedSearchCV( RandomForestClassifier(random_state=42), param_distributions=param_dist, n_iter=20, cv=5, random_state=42 ) random_search.fit(X_train, y_train) Feature Engineering Feature Selection from sklearn.feature_selection import ( SelectKBest, f_classif, RFE, SelectFromModel ) # Univariate selection selector = SelectKBest(score_func=f_classif, k=10) X_selected = selector.fit_transform(X, y) # Recursive Feature Elimination rfe = RFE(estimator=LogisticRegression(), n_features_to_select=10) X_rfe = rfe.fit_transform(X, y) # Model-based selection sfm = SelectFromModel(RandomForestClassifier()) X_sfm = sfm.fit_transform(X, y) Polynomial Features from sklearn.preprocessing import PolynomialFeatures poly = PolynomialFeatures(degree=2, include_bias=False) X_poly = poly.fit_transform(X) Pipelines from sklearn.pipeline import Pipeline, make_pipeline # Create pipeline pipe = Pipeline([ ('scaler', StandardScaler()), ('selector', SelectKBest(k=10)), ('classifier', RandomForestClassifier()) ]) # Alternative syntax pipe = make_pipeline( StandardScaler(), SelectKBest(k=10), RandomForestClassifier() ) # Fit and predict pipe.fit(X_train, y_train) y_pred = pipe.predict(X_test) # Grid search with pipeline param_grid = { 'selector__k': [5, 10, 15], 'classifier__n_estimators': [50, 100] } grid_search = GridSearchCV(pipe, param_grid, cv=5) Advanced Features Column Transformer from sklearn.compose import ColumnTransformer from sklearn.preprocessing import OneHotEncoder # For mixed data types numeric_features = ['age', 'fare'] categorical_features = ['sex', 'class'] preprocessor = ColumnTransformer( transformers=[ ('num', StandardScaler(), numeric_features), ('cat', OneHotEncoder(), categorical_features) ] ) # Complete pipeline clf = Pipeline(steps=[ ('preprocessor', preprocessor), ('classifier', LogisticRegression()) ]) Ensemble Methods from sklearn.ensemble import VotingClassifier, BaggingClassifier # Voting classifier estimators = [ ('lr', LogisticRegression()), ('rf', RandomForestClassifier()), ('svc', SVC(probability=True)) ] voting_clf = VotingClassifier(estimators, voting='soft') # Bagging bagging_clf = BaggingClassifier( base_estimator=DecisionTreeClassifier(), n_estimators=10, random_state=42 ) Model Persistence import joblib import pickle # Save model joblib.dump(clf, 'model.pkl') # Load model loaded_model = joblib.load('model.pkl') # Alternative with pickle with open('model.pkl', 'wb') as f: pickle.dump(clf, f) with open('model.pkl', 'rb') as f: loaded_model = pickle.load(f) Working with Text Data Text Preprocessing from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer # Bag of Words count_vec = CountVectorizer(max_features=1000, stop_words='english') X_counts = count_vec.fit_transform(text_data) # TF-IDF tfidf_vec = TfidfVectorizer(max_features=1000, stop_words='english') X_tfidf = tfidf_vec.fit_transform(text_data) Model Interpretation Feature Importance # For tree-based models importance = clf.feature_importances_ feature_names = iris.feature_names feature_importance = pd.DataFrame({ 'feature': feature_names, 'importance': importance }).sort_values('importance', ascending=False) # For linear models coefficients = lr.coef_[0] Permutation Importance from sklearn.inspection import permutation_importance perm_importance = permutation_importance(clf, X_test, y_test, n_repeats=10, random_state=42) Common Pitfalls and Best Practices Data Leakage Prevention # Correct: fit on training, transform on both scaler = StandardScaler() X_train_scaled = scaler.fit_transform(X_train) X_test_scaled = scaler.transform(X_test) # Don't fit on test! # Use pipelines to prevent leakage pipe = Pipeline([ ('scaler', StandardScaler()), ('model', LogisticRegression()) ]) Handling Imbalanced Data from sklearn.utils.class_weight import compute_class_weight # Class weights class_weights = compute_class_weight('balanced', classes=np.unique(y), y=y) clf = RandomForestClassifier(class_weight='balanced') # SMOTE (requires imbalanced-learn) # from imblearn.over_sampling import SMOTE # smote = SMOTE(random_state=42) # X_resampled, y_resampled = smote.fit_resample(X, y) Version Information import sklearn sklearn.show_versions() # Display versions of sklearn and dependencies Performance Tips Use n_jobs=-1 for parallel processing where available Use sparse matrices for high-dimensional sparse data Consider feature scaling for distance-based algorithms Use random_state parameters for reproducibility Profile your code and use appropriate algorithms for data size Consider using partial_fit for online learning with large datasets","title":"Scikit-learn"},{"location":"python/scikit-learn/#scikit-learn","text":"","title":"Scikit-learn"},{"location":"python/scikit-learn/#installation","text":"pip install scikit-learn # Or with conda conda install -c conda-forge scikit-learn","title":"Installation"},{"location":"python/scikit-learn/#import","text":"import sklearn from sklearn import datasets, model_selection, preprocessing, metrics import numpy as np import pandas as pd","title":"Import"},{"location":"python/scikit-learn/#basic-workflow","text":"","title":"Basic Workflow"},{"location":"python/scikit-learn/#1-loadcreate-data","text":"from sklearn.datasets import load_iris, make_classification, make_regression # Built-in datasets iris = load_iris() X, y = iris.data, iris.target # Generate synthetic data X, y = make_classification(n_samples=1000, n_features=20, random_state=42) X, y = make_regression(n_samples=1000, n_features=10, random_state=42)","title":"1. Load/Create Data"},{"location":"python/scikit-learn/#2-train-test-split","text":"from sklearn.model_selection import train_test_split X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.2, random_state=42, stratify=y )","title":"2. Train-Test Split"},{"location":"python/scikit-learn/#3-preprocessing","text":"from sklearn.preprocessing import StandardScaler, MinMaxScaler, LabelEncoder # Scaling scaler = StandardScaler() X_train_scaled = scaler.fit_transform(X_train) X_test_scaled = scaler.transform(X_test) # Alternative scalers minmax_scaler = MinMaxScaler() X_normalized = minmax_scaler.fit_transform(X)","title":"3. Preprocessing"},{"location":"python/scikit-learn/#4-model-training-and-prediction","text":"from sklearn.ensemble import RandomForestClassifier from sklearn.linear_model import LogisticRegression # Classification clf = RandomForestClassifier(random_state=42) clf.fit(X_train, y_train) y_pred = clf.predict(X_test) y_proba = clf.predict_proba(X_test) # probability estimates","title":"4. Model Training and Prediction"},{"location":"python/scikit-learn/#classification-algorithms","text":"","title":"Classification Algorithms"},{"location":"python/scikit-learn/#logistic-regression","text":"from sklearn.linear_model import LogisticRegression lr = LogisticRegression(random_state=42) lr.fit(X_train, y_train) y_pred = lr.predict(X_test)","title":"Logistic Regression"},{"location":"python/scikit-learn/#random-forest","text":"from sklearn.ensemble import RandomForestClassifier rf = RandomForestClassifier(n_estimators=100, random_state=42) rf.fit(X_train, y_train) feature_importance = rf.feature_importances_","title":"Random Forest"},{"location":"python/scikit-learn/#support-vector-machine","text":"from sklearn.svm import SVC svm = SVC(kernel='rbf', random_state=42) svm.fit(X_train, y_train) y_pred = svm.predict(X_test)","title":"Support Vector Machine"},{"location":"python/scikit-learn/#gradient-boosting","text":"from sklearn.ensemble import GradientBoostingClassifier gb = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, random_state=42) gb.fit(X_train, y_train)","title":"Gradient Boosting"},{"location":"python/scikit-learn/#decision-trees","text":"from sklearn.tree import DecisionTreeClassifier dt = DecisionTreeClassifier(max_depth=5, random_state=42) dt.fit(X_train, y_train)","title":"Decision Trees"},{"location":"python/scikit-learn/#naive-bayes","text":"from sklearn.naive_bayes import GaussianNB, MultinomialNB nb = GaussianNB() nb.fit(X_train, y_train)","title":"Naive Bayes"},{"location":"python/scikit-learn/#k-nearest-neighbors","text":"from sklearn.neighbors import KNeighborsClassifier knn = KNeighborsClassifier(n_neighbors=5) knn.fit(X_train, y_train)","title":"k-Nearest Neighbors"},{"location":"python/scikit-learn/#regression-algorithms","text":"","title":"Regression Algorithms"},{"location":"python/scikit-learn/#linear-regression","text":"from sklearn.linear_model import LinearRegression, Ridge, Lasso # Simple linear regression lr = LinearRegression() lr.fit(X_train, y_train) # Ridge regression (L2 regularization) ridge = Ridge(alpha=1.0) ridge.fit(X_train, y_train) # Lasso regression (L1 regularization) lasso = Lasso(alpha=0.1) lasso.fit(X_train, y_train)","title":"Linear Regression"},{"location":"python/scikit-learn/#random-forest-regressor","text":"from sklearn.ensemble import RandomForestRegressor rf_reg = RandomForestRegressor(n_estimators=100, random_state=42) rf_reg.fit(X_train, y_train) y_pred = rf_reg.predict(X_test)","title":"Random Forest Regressor"},{"location":"python/scikit-learn/#support-vector-regression","text":"from sklearn.svm import SVR svr = SVR(kernel='rbf', C=100, gamma=0.1) svr.fit(X_train, y_train)","title":"Support Vector Regression"},{"location":"python/scikit-learn/#clustering","text":"","title":"Clustering"},{"location":"python/scikit-learn/#k-means","text":"from sklearn.cluster import KMeans kmeans = KMeans(n_clusters=3, random_state=42) cluster_labels = kmeans.fit_predict(X) centroids = kmeans.cluster_centers_","title":"K-Means"},{"location":"python/scikit-learn/#hierarchical-clustering","text":"from sklearn.cluster import AgglomerativeClustering hierarchical = AgglomerativeClustering(n_clusters=3) cluster_labels = hierarchical.fit_predict(X)","title":"Hierarchical Clustering"},{"location":"python/scikit-learn/#dbscan","text":"from sklearn.cluster import DBSCAN dbscan = DBSCAN(eps=0.5, min_samples=5) cluster_labels = dbscan.fit_predict(X)","title":"DBSCAN"},{"location":"python/scikit-learn/#dimensionality-reduction","text":"","title":"Dimensionality Reduction"},{"location":"python/scikit-learn/#principal-component-analysis-pca","text":"from sklearn.decomposition import PCA pca = PCA(n_components=2) X_pca = pca.fit_transform(X) explained_variance = pca.explained_variance_ratio_","title":"Principal Component Analysis (PCA)"},{"location":"python/scikit-learn/#t-sne","text":"from sklearn.manifold import TSNE tsne = TSNE(n_components=2, random_state=42) X_tsne = tsne.fit_transform(X)","title":"t-SNE"},{"location":"python/scikit-learn/#linear-discriminant-analysis","text":"from sklearn.discriminant_analysis import LinearDiscriminantAnalysis lda = LinearDiscriminantAnalysis(n_components=2) X_lda = lda.fit_transform(X, y)","title":"Linear Discriminant Analysis"},{"location":"python/scikit-learn/#model-evaluation","text":"","title":"Model Evaluation"},{"location":"python/scikit-learn/#classification-metrics","text":"from sklearn.metrics import ( accuracy_score, precision_score, recall_score, f1_score, classification_report, confusion_matrix, roc_auc_score ) # Basic metrics accuracy = accuracy_score(y_test, y_pred) precision = precision_score(y_test, y_pred, average='weighted') recall = recall_score(y_test, y_pred, average='weighted') f1 = f1_score(y_test, y_pred, average='weighted') # Detailed report report = classification_report(y_test, y_pred) cm = confusion_matrix(y_test, y_pred) # ROC AUC (for binary/multiclass) auc = roc_auc_score(y_test, y_proba, multi_class='ovr')","title":"Classification Metrics"},{"location":"python/scikit-learn/#regression-metrics","text":"from sklearn.metrics import ( mean_squared_error, mean_absolute_error, r2_score ) mse = mean_squared_error(y_test, y_pred) mae = mean_absolute_error(y_test, y_pred) r2 = r2_score(y_test, y_pred) rmse = np.sqrt(mse)","title":"Regression Metrics"},{"location":"python/scikit-learn/#cross-validation","text":"from sklearn.model_selection import cross_val_score, cross_validate # Simple cross-validation scores = cross_val_score(clf, X, y, cv=5) print(f\"CV scores: {scores.mean():.3f} (+/- {scores.std() * 2:.3f})\") # Cross-validation with multiple metrics scoring = ['accuracy', 'precision_macro', 'recall_macro'] cv_results = cross_validate(clf, X, y, cv=5, scoring=scoring)","title":"Cross-Validation"},{"location":"python/scikit-learn/#hyperparameter-tuning","text":"","title":"Hyperparameter Tuning"},{"location":"python/scikit-learn/#grid-search","text":"from sklearn.model_selection import GridSearchCV param_grid = { 'n_estimators': [50, 100, 200], 'max_depth': [3, 5, 10], 'min_samples_split': [2, 5, 10] } grid_search = GridSearchCV( RandomForestClassifier(random_state=42), param_grid, cv=5, scoring='accuracy', n_jobs=-1 ) grid_search.fit(X_train, y_train) best_params = grid_search.best_params_ best_score = grid_search.best_score_","title":"Grid Search"},{"location":"python/scikit-learn/#randomized-search","text":"from sklearn.model_selection import RandomizedSearchCV from scipy.stats import randint param_dist = { 'n_estimators': randint(10, 100), 'max_depth': randint(1, 10) } random_search = RandomizedSearchCV( RandomForestClassifier(random_state=42), param_distributions=param_dist, n_iter=20, cv=5, random_state=42 ) random_search.fit(X_train, y_train)","title":"Randomized Search"},{"location":"python/scikit-learn/#feature-engineering","text":"","title":"Feature Engineering"},{"location":"python/scikit-learn/#feature-selection","text":"from sklearn.feature_selection import ( SelectKBest, f_classif, RFE, SelectFromModel ) # Univariate selection selector = SelectKBest(score_func=f_classif, k=10) X_selected = selector.fit_transform(X, y) # Recursive Feature Elimination rfe = RFE(estimator=LogisticRegression(), n_features_to_select=10) X_rfe = rfe.fit_transform(X, y) # Model-based selection sfm = SelectFromModel(RandomForestClassifier()) X_sfm = sfm.fit_transform(X, y)","title":"Feature Selection"},{"location":"python/scikit-learn/#polynomial-features","text":"from sklearn.preprocessing import PolynomialFeatures poly = PolynomialFeatures(degree=2, include_bias=False) X_poly = poly.fit_transform(X)","title":"Polynomial Features"},{"location":"python/scikit-learn/#pipelines","text":"from sklearn.pipeline import Pipeline, make_pipeline # Create pipeline pipe = Pipeline([ ('scaler', StandardScaler()), ('selector', SelectKBest(k=10)), ('classifier', RandomForestClassifier()) ]) # Alternative syntax pipe = make_pipeline( StandardScaler(), SelectKBest(k=10), RandomForestClassifier() ) # Fit and predict pipe.fit(X_train, y_train) y_pred = pipe.predict(X_test) # Grid search with pipeline param_grid = { 'selector__k': [5, 10, 15], 'classifier__n_estimators': [50, 100] } grid_search = GridSearchCV(pipe, param_grid, cv=5)","title":"Pipelines"},{"location":"python/scikit-learn/#advanced-features","text":"","title":"Advanced Features"},{"location":"python/scikit-learn/#column-transformer","text":"from sklearn.compose import ColumnTransformer from sklearn.preprocessing import OneHotEncoder # For mixed data types numeric_features = ['age', 'fare'] categorical_features = ['sex', 'class'] preprocessor = ColumnTransformer( transformers=[ ('num', StandardScaler(), numeric_features), ('cat', OneHotEncoder(), categorical_features) ] ) # Complete pipeline clf = Pipeline(steps=[ ('preprocessor', preprocessor), ('classifier', LogisticRegression()) ])","title":"Column Transformer"},{"location":"python/scikit-learn/#ensemble-methods","text":"from sklearn.ensemble import VotingClassifier, BaggingClassifier # Voting classifier estimators = [ ('lr', LogisticRegression()), ('rf', RandomForestClassifier()), ('svc', SVC(probability=True)) ] voting_clf = VotingClassifier(estimators, voting='soft') # Bagging bagging_clf = BaggingClassifier( base_estimator=DecisionTreeClassifier(), n_estimators=10, random_state=42 )","title":"Ensemble Methods"},{"location":"python/scikit-learn/#model-persistence","text":"import joblib import pickle # Save model joblib.dump(clf, 'model.pkl') # Load model loaded_model = joblib.load('model.pkl') # Alternative with pickle with open('model.pkl', 'wb') as f: pickle.dump(clf, f) with open('model.pkl', 'rb') as f: loaded_model = pickle.load(f)","title":"Model Persistence"},{"location":"python/scikit-learn/#working-with-text-data","text":"","title":"Working with Text Data"},{"location":"python/scikit-learn/#text-preprocessing","text":"from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer # Bag of Words count_vec = CountVectorizer(max_features=1000, stop_words='english') X_counts = count_vec.fit_transform(text_data) # TF-IDF tfidf_vec = TfidfVectorizer(max_features=1000, stop_words='english') X_tfidf = tfidf_vec.fit_transform(text_data)","title":"Text Preprocessing"},{"location":"python/scikit-learn/#model-interpretation","text":"","title":"Model Interpretation"},{"location":"python/scikit-learn/#feature-importance","text":"# For tree-based models importance = clf.feature_importances_ feature_names = iris.feature_names feature_importance = pd.DataFrame({ 'feature': feature_names, 'importance': importance }).sort_values('importance', ascending=False) # For linear models coefficients = lr.coef_[0]","title":"Feature Importance"},{"location":"python/scikit-learn/#permutation-importance","text":"from sklearn.inspection import permutation_importance perm_importance = permutation_importance(clf, X_test, y_test, n_repeats=10, random_state=42)","title":"Permutation Importance"},{"location":"python/scikit-learn/#common-pitfalls-and-best-practices","text":"","title":"Common Pitfalls and Best Practices"},{"location":"python/scikit-learn/#data-leakage-prevention","text":"# Correct: fit on training, transform on both scaler = StandardScaler() X_train_scaled = scaler.fit_transform(X_train) X_test_scaled = scaler.transform(X_test) # Don't fit on test! # Use pipelines to prevent leakage pipe = Pipeline([ ('scaler', StandardScaler()), ('model', LogisticRegression()) ])","title":"Data Leakage Prevention"},{"location":"python/scikit-learn/#handling-imbalanced-data","text":"from sklearn.utils.class_weight import compute_class_weight # Class weights class_weights = compute_class_weight('balanced', classes=np.unique(y), y=y) clf = RandomForestClassifier(class_weight='balanced') # SMOTE (requires imbalanced-learn) # from imblearn.over_sampling import SMOTE # smote = SMOTE(random_state=42) # X_resampled, y_resampled = smote.fit_resample(X, y)","title":"Handling Imbalanced Data"},{"location":"python/scikit-learn/#version-information","text":"import sklearn sklearn.show_versions() # Display versions of sklearn and dependencies","title":"Version Information"},{"location":"python/scikit-learn/#performance-tips","text":"Use n_jobs=-1 for parallel processing where available Use sparse matrices for high-dimensional sparse data Consider feature scaling for distance-based algorithms Use random_state parameters for reproducibility Profile your code and use appropriate algorithms for data size Consider using partial_fit for online learning with large datasets","title":"Performance Tips"},{"location":"python/scipy/","text":"SciPy Installation # Basic installation pip install scipy # With all optional dependencies pip install scipy[all] # Check version python -c \"import scipy; print(scipy.__version__)\" # Check available submodules python -c \"import scipy; print([x for x in dir(scipy) if not x.startswith('_')])\" Basic Setup # Essential imports import numpy as np import scipy as sp from scipy import stats, optimize, integrate, linalg, signal, interpolate # Common import pattern for specific modules from scipy.stats import norm, t, chi2, pearsonr from scipy.optimize import minimize, curve_fit from scipy.signal import find_peaks, periodogram from scipy.interpolate import interp1d Core Functionality Statistics Module ( scipy.stats ) Continuous Distributions from scipy.stats import norm, t, chi2, f, uniform, expon, gamma, beta # Normal distribution mean, std = 0, 1 x = np.linspace(-3, 3, 100) # Probability density function (PDF) pdf_values = norm.pdf(x, mean, std) # Cumulative distribution function (CDF) cdf_values = norm.cdf(x, mean, std) # Percent point function (inverse CDF) percentiles = norm.ppf([0.05, 0.5, 0.95], mean, std) # Random variates samples = norm.rvs(mean, std, size=1000) # Summary statistics print(f\"Mean: {norm.mean(mean, std)}\") print(f\"Variance: {norm.var(mean, std)}\") print(f\"Standard deviation: {norm.std(mean, std)}\") Discrete Distributions from scipy.stats import binom, poisson, hypergeom, geom # Binomial distribution n, p = 10, 0.3 k = np.arange(0, 11) # Probability mass function (PMF) pmf_values = binom.pmf(k, n, p) # CDF for discrete distributions cdf_values = binom.cdf(k, n, p) # Random samples samples = binom.rvs(n, p, size=1000) # Poisson distribution lam = 3.5 # lambda parameter k = np.arange(0, 15) pmf_poisson = poisson.pmf(k, lam) Statistical Tests from scipy.stats import ttest_1samp, ttest_ind, ttest_rel, chi2_contingency from scipy.stats import pearsonr, spearmanr, kendalltau, mannwhitneyu # One-sample t-test data = np.random.normal(5, 2, 100) statistic, p_value = ttest_1samp(data, popmean=4.5) print(f\"t-statistic: {statistic:.4f}, p-value: {p_value:.4f}\") # Two-sample t-test (independent) group1 = np.random.normal(5, 2, 50) group2 = np.random.normal(5.5, 2, 50) stat, p = ttest_ind(group1, group2) # Paired t-test before = np.random.normal(100, 15, 30) after = before + np.random.normal(2, 5, 30) stat, p = ttest_rel(before, after) # Correlation tests x = np.random.normal(0, 1, 100) y = 2*x + np.random.normal(0, 0.5, 100) # Pearson correlation corr_pearson, p_pearson = pearsonr(x, y) # Spearman rank correlation corr_spearman, p_spearman = spearmanr(x, y) # Kendall's tau tau, p_kendall = kendalltau(x, y) # Mann-Whitney U test (non-parametric) stat, p = mannwhitneyu(group1, group2, alternative='two-sided') Chi-square Tests from scipy.stats import chi2_contingency, chisquare # Chi-square test of independence contingency_table = np.array([[10, 20, 30], [15, 25, 35], [20, 30, 40]]) chi2_stat, p_value, dof, expected = chi2_contingency(contingency_table) # Goodness of fit test observed = [16, 18, 16, 14, 12, 12] expected = [16, 16, 16, 16, 16, 16] chi2_stat, p_value = chisquare(observed, expected) Optimization Module ( scipy.optimize ) Function Minimization from scipy.optimize import minimize, minimize_scalar, differential_evolution # Scalar function minimization def f(x): return (x - 2)**2 result = minimize_scalar(f) print(f\"Minimum at x = {result.x:.4f}, f(x) = {result.fun:.4f}\") # Multivariable function minimization def rosenbrock(x): return 100*(x[1] - x[0]**2)**2 + (1 - x[0])**2 # Initial guess x0 = [0, 0] # Minimize using different methods result_bfgs = minimize(rosenbrock, x0, method='BFGS') result_nm = minimize(rosenbrock, x0, method='Nelder-Mead') print(f\"BFGS result: {result_bfgs.x}\") print(f\"Nelder-Mead result: {result_nm.x}\") # With bounds bounds = [(0, 2), (0, 2)] result_bounded = minimize(rosenbrock, x0, method='L-BFGS-B', bounds=bounds) # Global optimization result_global = differential_evolution(rosenbrock, bounds) Root Finding from scipy.optimize import root, fsolve, brentq # Single variable root finding def equation(x): return x**3 - 2*x - 5 # Brent's method (requires bracketing interval) root_brent = brentq(equation, 2, 3) # Multi-variable root finding def system_equations(vars): x, y = vars eq1 = x**2 + y**2 - 1 eq2 = x - y**2 return [eq1, eq2] # Initial guess initial_guess = [0.5, 0.5] solution = fsolve(system_equations, initial_guess) # Using root function (more options) sol = root(system_equations, initial_guess, method='hybr') Curve Fitting from scipy.optimize import curve_fit # Define model function def exponential_model(x, a, b, c): return a * np.exp(b * x) + c # Generate sample data with noise x_data = np.linspace(0, 4, 50) y_true = exponential_model(x_data, 2.5, 1.3, 0.5) y_data = y_true + 0.2 * np.random.normal(size=len(x_data)) # Fit the curve popt, pcov = curve_fit(exponential_model, x_data, y_data) a_fit, b_fit, c_fit = popt # Parameter uncertainties param_errors = np.sqrt(np.diag(pcov)) print(f\"Fitted parameters: a={a_fit:.3f}\u00b1{param_errors[0]:.3f}, \" f\"b={b_fit:.3f}\u00b1{param_errors[1]:.3f}, c={c_fit:.3f}\u00b1{param_errors[2]:.3f}\") # Plot results y_fit = exponential_model(x_data, *popt) import matplotlib.pyplot as plt plt.plot(x_data, y_data, 'o', label='Data') plt.plot(x_data, y_fit, '-', label='Fitted curve') plt.legend() Linear Algebra Module ( scipy.linalg ) Basic Operations from scipy.linalg import solve, det, inv, eig, svd, norm, cholesky # System of linear equations Ax = b A = np.array([[3, 2, -1], [2, -2, 4], [-1, 0.5, -1]]) b = np.array([1, -2, 0]) # Solve the system x = solve(A, b) print(f\"Solution: {x}\") # Matrix determinant determinant = det(A) # Matrix inverse A_inv = inv(A) # Verify: A * A_inv should be identity identity_check = np.allclose(A @ A_inv, np.eye(3)) Eigenvalues and Eigenvectors # Eigendecomposition eigenvalues, eigenvectors = eig(A) print(f\"Eigenvalues: {eigenvalues}\") # Singular Value Decomposition U, s, Vt = svd(A) print(f\"Singular values: {s}\") # Matrix norms frobenius_norm = norm(A, 'fro') spectral_norm = norm(A, 2) l1_norm = norm(A, 1) Decompositions from scipy.linalg import lu, qr, cholesky, schur # LU decomposition P, L, U = lu(A) # QR decomposition Q, R = qr(A) # Cholesky decomposition (for positive definite matrices) # Create a positive definite matrix A_pd = A.T @ A L_chol = cholesky(A_pd, lower=True) # Schur decomposition T, Z = schur(A) Signal Processing Module ( scipy.signal ) Filtering from scipy.signal import butter, filtfilt, savgol_filter, medfilt # Create sample signal fs = 1000 # Sampling frequency t = np.linspace(0, 1, fs, endpoint=False) signal = np.sin(2*np.pi*5*t) + 0.5*np.sin(2*np.pi*25*t) + np.random.normal(0, 0.1, len(t)) # Butterworth filter def butter_lowpass_filter(data, cutoff, fs, order=4): nyquist = 0.5 * fs normal_cutoff = cutoff / nyquist b, a = butter(order, normal_cutoff, btype='low', analog=False) filtered_data = filtfilt(b, a, data) return filtered_data # Apply low-pass filter cutoff_freq = 10 # Hz filtered_signal = butter_lowpass_filter(signal, cutoff_freq, fs) # Savitzky-Golay filter (good for smoothing) window_length = 51 # Must be odd poly_order = 3 smoothed_signal = savgol_filter(signal, window_length, poly_order) # Median filter (good for removing spikes) kernel_size = 5 median_filtered = medfilt(signal, kernel_size) Spectral Analysis from scipy.signal import periodogram, welch, spectrogram from scipy.fft import fft, fftfreq # Periodogram (power spectral density) frequencies, psd = periodogram(signal, fs) # Welch's method (averaged periodogram) f_welch, psd_welch = welch(signal, fs, nperseg=256) # Spectrogram (time-frequency analysis) f_spec, t_spec, Sxx = spectrogram(signal, fs, nperseg=256) # FFT fft_values = fft(signal) fft_freq = fftfreq(len(signal), 1/fs) # Plot spectrum import matplotlib.pyplot as plt plt.figure(figsize=(12, 4)) plt.subplot(131) plt.plot(t[:500], signal[:500]) plt.title('Time Domain') plt.xlabel('Time (s)') plt.subplot(132) plt.semilogy(frequencies, psd) plt.title('Power Spectral Density') plt.xlabel('Frequency (Hz)') plt.subplot(133) plt.pcolormesh(t_spec, f_spec, 10*np.log10(Sxx), shading='gouraud') plt.title('Spectrogram') plt.ylabel('Frequency (Hz)') plt.xlabel('Time (s)') plt.tight_layout() Peak Finding from scipy.signal import find_peaks, peak_widths, peak_prominences # Generate signal with peaks x = np.linspace(0, 10, 1000) signal_peaks = np.sin(x) + 0.5*np.sin(3*x) + 0.2*np.random.randn(1000) # Find peaks peaks, properties = find_peaks(signal_peaks, height=0.5, distance=20) # Peak properties widths = peak_widths(signal_peaks, peaks, rel_height=0.5) prominences = peak_prominences(signal_peaks, peaks) # Plot results plt.figure(figsize=(12, 6)) plt.plot(x, signal_peaks, label='Signal') plt.plot(x[peaks], signal_peaks[peaks], 'ro', label='Peaks') plt.legend() Integration Module ( scipy.integrate ) Numerical Integration from scipy.integrate import quad, dblquad, tplquad, odeint, solve_ivp # Single integral def integrand(x): return np.exp(-x**2) # Integrate from 0 to infinity result, error = quad(integrand, 0, np.inf) print(f\"\u222b\u2080^\u221e e^(-x\u00b2) dx = {result:.6f} \u00b1 {error:.2e}\") # Double integral def integrand_2d(y, x): return x*y**2 # Integrate over rectangle [0,1] \u00d7 [0,2] result_2d, error_2d = dblquad(integrand_2d, 0, 1, lambda x: 0, lambda x: 2) # Triple integral def integrand_3d(z, y, x): return x*y*z result_3d, error_3d = tplquad(integrand_3d, 0, 1, lambda x: 0, lambda x: 1, lambda x, y: 0, lambda x, y: 1) Ordinary Differential Equations (ODEs) from scipy.integrate import odeint, solve_ivp # Solve dy/dt = -2y with initial condition y(0) = 1 def dydt(y, t): return -2*y t = np.linspace(0, 2, 100) y0 = 1 solution = odeint(dydt, y0, t) # System of ODEs: Lotka-Volterra (predator-prey) def lotka_volterra(t, z, a, b, c, d): x, y = z return [a*x - b*x*y, -c*y + d*x*y] # Parameters a, b, c, d = 1.0, 0.1, 1.5, 0.075 initial_conditions = [10, 5] # [prey, predator] t_span = (0, 15) t_eval = np.linspace(0, 15, 1000) # Solve using solve_ivp (more modern interface) sol = solve_ivp(lotka_volterra, t_span, initial_conditions, t_eval=t_eval, args=(a, b, c, d), dense_output=True) # Plot phase portrait plt.figure(figsize=(12, 5)) plt.subplot(121) plt.plot(sol.t, sol.y[0], label='Prey') plt.plot(sol.t, sol.y[1], label='Predator') plt.xlabel('Time') plt.ylabel('Population') plt.legend() plt.subplot(122) plt.plot(sol.y[0], sol.y[1]) plt.xlabel('Prey') plt.ylabel('Predator') plt.title('Phase Portrait') Interpolation Module ( scipy.interpolate ) 1D Interpolation from scipy.interpolate import interp1d, UnivariateSpline, CubicSpline # Sample data x = np.linspace(0, 10, 11) y = np.sin(x) # Different interpolation methods f_linear = interp1d(x, y, kind='linear') f_cubic = interp1d(x, y, kind='cubic') f_spline = UnivariateSpline(x, y, s=0) # s=0 for interpolation f_cubic_spline = CubicSpline(x, y) # Evaluate at new points x_new = np.linspace(0, 10, 100) y_linear = f_linear(x_new) y_cubic = f_cubic(x_new) y_spline = f_spline(x_new) y_cubic_spline = f_cubic_spline(x_new) # Plot comparison plt.figure(figsize=(10, 6)) plt.plot(x, y, 'o', label='Data points') plt.plot(x_new, y_linear, '-', label='Linear') plt.plot(x_new, y_cubic, '--', label='Cubic') plt.plot(x_new, y_spline, '-.', label='Spline') plt.plot(x_new, y_cubic_spline, ':', label='Cubic Spline') plt.legend() plt.title('Interpolation Methods Comparison') 2D Interpolation from scipy.interpolate import griddata, RegularGridInterpolator # Scattered data interpolation np.random.seed(42) points = np.random.rand(100, 2) * 10 values = np.sin(points[:, 0]) * np.cos(points[:, 1]) # Create regular grid xi = np.linspace(0, 10, 50) yi = np.linspace(0, 10, 50) xi_grid, yi_grid = np.meshgrid(xi, yi) # Interpolate using different methods zi_nearest = griddata(points, values, (xi_grid, yi_grid), method='nearest') zi_linear = griddata(points, values, (xi_grid, yi_grid), method='linear') zi_cubic = griddata(points, values, (xi_grid, yi_grid), method='cubic') # Regular grid interpolation (faster for regular grids) x_reg = np.linspace(0, 10, 20) y_reg = np.linspace(0, 10, 20) X_reg, Y_reg = np.meshgrid(x_reg, y_reg) Z_reg = np.sin(X_reg) * np.cos(Y_reg) interp_func = RegularGridInterpolator((x_reg, y_reg), Z_reg) new_points = np.column_stack([xi_grid.ravel(), yi_grid.ravel()]) zi_reg = interp_func(new_points).reshape(xi_grid.shape) Advanced Features Spatial Algorithms ( scipy.spatial ) from scipy.spatial import distance, KDTree, ConvexHull, Voronoi from scipy.spatial.distance import pdist, squareform # Distance calculations points = np.random.rand(10, 2) # Pairwise distances distances = pdist(points) distance_matrix = squareform(distances) # Different distance metrics euclidean_dist = pdist(points, metric='euclidean') manhattan_dist = pdist(points, metric='manhattan') cosine_dist = pdist(points, metric='cosine') # KD-Tree for nearest neighbor searches tree = KDTree(points) # Find k nearest neighbors query_point = [0.5, 0.5] distances, indices = tree.query(query_point, k=3) # Convex Hull hull = ConvexHull(points) hull_points = points[hull.vertices] # Voronoi diagram vor = Voronoi(points) Sparse Matrices ( scipy.sparse ) from scipy.sparse import csr_matrix, csc_matrix, diags, eye from scipy.sparse.linalg import spsolve # Create sparse matrix row = np.array([0, 0, 1, 2, 2, 2]) col = np.array([0, 2, 1, 0, 1, 2]) data = np.array([1, 2, 3, 4, 5, 6]) # Compressed Sparse Row matrix sparse_matrix = csr_matrix((data, (row, col)), shape=(3, 3)) # Create diagonal sparse matrix diag_sparse = diags([1, 2, 3], offsets=[0], shape=(3, 3)) # Sparse identity matrix sparse_eye = eye(1000, format='csr') # Solve sparse linear system A_sparse = csr_matrix([[1, 2], [3, 4]]) b = np.array([1, 2]) x = spsolve(A_sparse, b) FFT Module ( scipy.fft ) from scipy.fft import fft, ifft, fft2, ifft2, fftfreq, rfft # 1D FFT signal = np.sin(2*np.pi*5*np.linspace(0, 1, 1000)) fft_signal = fft(signal) freq = fftfreq(len(signal), 1/1000) # Real FFT (for real-valued signals) rfft_signal = rfft(signal) rfreq = fftfreq(len(signal), 1/1000)[:len(rfft_signal)] # 2D FFT image = np.random.rand(100, 100) fft2_image = fft2(image) ifft2_image = ifft2(fft2_image) # Should recover original # Verify reconstruction reconstruction_error = np.max(np.abs(image - ifft2_image.real)) print(f\"Reconstruction error: {reconstruction_error:.2e}\") Common Use Cases Statistical Analysis Workflow # Complete statistical analysis example import pandas as pd from scipy import stats # Generate sample data np.random.seed(42) group_a = np.random.normal(100, 15, 50) group_b = np.random.normal(105, 15, 50) # Descriptive statistics print(\"Group A:\") print(f\"Mean: {np.mean(group_a):.2f}, Std: {np.std(group_a, ddof=1):.2f}\") print(\"Group B:\") print(f\"Mean: {np.mean(group_b):.2f}, Std: {np.std(group_b, ddof=1):.2f}\") # Test for normality _, p_a = stats.shapiro(group_a) _, p_b = stats.shapiro(group_b) print(f\"\\nNormality tests (Shapiro-Wilk):\") print(f\"Group A p-value: {p_a:.4f}\") print(f\"Group B p-value: {p_b:.4f}\") # Test for equal variances _, p_levene = stats.levene(group_a, group_b) print(f\"\\nEqual variances test (Levene): p-value = {p_levene:.4f}\") # Choose appropriate t-test if p_levene > 0.05: # Equal variances t_stat, p_ttest = stats.ttest_ind(group_a, group_b, equal_var=True) print(f\"\\nStudent's t-test: t = {t_stat:.4f}, p = {p_ttest:.4f}\") else: # Unequal variances t_stat, p_ttest = stats.ttest_ind(group_a, group_b, equal_var=False) print(f\"\\nWelch's t-test: t = {t_stat:.4f}, p = {p_ttest:.4f}\") # Effect size (Cohen's d) pooled_std = np.sqrt(((len(group_a)-1)*np.var(group_a, ddof=1) + (len(group_b)-1)*np.var(group_b, ddof=1)) / (len(group_a) + len(group_b) - 2)) cohens_d = (np.mean(group_a) - np.mean(group_b)) / pooled_std print(f\"Cohen's d: {cohens_d:.4f}\") Signal Processing Pipeline # Complete signal processing example from scipy import signal import matplotlib.pyplot as plt # Generate noisy signal fs = 1000 t = np.linspace(0, 2, 2*fs, endpoint=False) clean_signal = (np.sin(2*np.pi*10*t) + 0.5*np.sin(2*np.pi*20*t) + 0.3*np.sin(2*np.pi*30*t)) noisy_signal = clean_signal + 0.2*np.random.randn(len(t)) # Design and apply filters # Low-pass filter sos_low = signal.butter(4, 25, btype='low', fs=fs, output='sos') filtered_low = signal.sosfiltfilt(sos_low, noisy_signal) # Band-pass filter sos_band = signal.butter(4, [15, 25], btype='band', fs=fs, output='sos') filtered_band = signal.sosfiltfilt(sos_band, noisy_signal) # Spectral analysis f, psd = signal.welch(noisy_signal, fs, nperseg=1024) f_clean, psd_clean = signal.welch(clean_signal, fs, nperseg=1024) f_filt, psd_filt = signal.welch(filtered_low, fs, nperseg=1024) # Find peaks in filtered signal peaks, properties = signal.find_peaks(filtered_low, height=0.5, distance=50) # Plot results fig, axes = plt.subplots(2, 2, figsize=(15, 10)) # Time domain axes[0,0].plot(t[:500], noisy_signal[:500], alpha=0.7, label='Noisy') axes[0,0].plot(t[:500], filtered_low[:500], label='Filtered') axes[0,0].set_title('Time Domain') axes[0,0].legend() # Frequency domain axes[0,1].semilogy(f, psd, alpha=0.7, label='Noisy') axes[0,1].semilogy(f_filt, psd_filt, label='Filtered') axes[0,1].set_title('Power Spectral Density') axes[0,1].legend() # Peak detection axes[1,0].plot(filtered_low[:1000]) axes[1,0].plot(peaks[peaks<1000], filtered_low[peaks[peaks<1000]], 'ro') axes[1,0].set_title('Peak Detection') # Spectrogram f_spec, t_spec, Sxx = signal.spectrogram(noisy_signal, fs, nperseg=256) axes[1,1].pcolormesh(t_spec, f_spec, 10*np.log10(Sxx), shading='gouraud') axes[1,1].set_title('Spectrogram') axes[1,1].set_ylabel('Frequency (Hz)') axes[1,1].set_xlabel('Time (s)') plt.tight_layout() Optimization Problem # Multi-modal optimization example from scipy.optimize import minimize, differential_evolution, basinhopping # Define a complex function with multiple local minima def complex_function(x): x1, x2 = x return (x1**2 + x2 - 11)**2 + (x1 + x2**2 - 7)**2 # Local optimization (may get stuck in local minima) x0 = [0, 0] result_local = minimize(complex_function, x0, method='BFGS') # Global optimization methods bounds = [(-5, 5), (-5, 5)] result_global = differential_evolution(complex_function, bounds, seed=42) # Basin-hopping (another global method) minimizer_kwargs = {\"method\": \"BFGS\"} result_basinhopping = basinhopping(complex_function, x0, minimizer_kwargs=minimizer_kwargs, niter=100, T=1.0, stepsize=0.5) print(\"Local minimum (BFGS):\", result_local.x, \"f =\", result_local.fun) print(\"Global minimum (DE):\", result_global.x, \"f =\", result_global.fun) print(\"Basin-hopping result:\", result_basinhopping.x, \"f =\", result_basinhopping.fun) # Visualize the function and minima x1_range = np.linspace(-5, 5, 100) x2_range = np.linspace(-5, 5, 100) X1, X2 = np.meshgrid(x1_range, x2_range) Z = complex_function([X1, X2]) plt.figure(figsize=(10, 8)) contour = plt.contour(X1, X2, Z, levels=50) plt.colorbar(contour) plt.plot(result_local.x[0], result_local.x[1], 'ro', markersize=10, label='Local min') plt.plot(result_global.x[0], result_global.x[1], 'go', markersize=10, label='Global min') plt.xlabel('x1') plt.ylabel('x2') plt.title('Function Landscape with Optimization Results') plt.legend() Integration with Other Libraries NumPy Integration # SciPy functions work seamlessly with NumPy arrays data = np.random.exponential(2, 1000) # Fit distribution params = stats.expon.fit(data) print(f\"Fitted parameters: scale = {params[1]:.4f}\") # Kolmogorov-Smirnov test ks_stat, p_value = stats.kstest(data, lambda x: stats.expon.cdf(x, *params)) print(f\"K-S test: statistic = {ks_stat:.4f}, p-value = {p_value:.4f}\") Matplotlib Integration # Visualization with matplotlib fig, axes = plt.subplots(2, 2, figsize=(12, 10)) # Q-Q plot stats.probplot(data, dist=\"expon\", plot=axes[0,0]) axes[0,0].set_title(\"Q-Q Plot\") # Histogram with fitted PDF axes[0,1].hist(data, bins=50, density=True, alpha=0.7, label='Data') x_fit = np.linspace(0, np.max(data), 100) axes[0,1].plot(x_fit, stats.expon.pdf(x_fit, *params), 'r-', lw=2, label='Fitted PDF') axes[0,1].legend() axes[0,1].set_title(\"Histogram with Fitted Distribution\") # CDF comparison sorted_data = np.sort(data) empirical_cdf = np.arange(1, len(data)+1) / len(data) theoretical_cdf = stats.expon.cdf(sorted_data, *params) axes[1,0].plot(sorted_data, empirical_cdf, label='Empirical CDF') axes[1,0].plot(sorted_data, theoretical_cdf, 'r-', label='Theoretical CDF') axes[1,0].legend() axes[1,0].set_title(\"CDF Comparison\") plt.tight_layout() Best Practices Performance Tips # Use vectorized operations # Good x = np.linspace(0, 10, 1000000) y = stats.norm.pdf(x, 0, 1) # Avoid loops when possible # Bad (slow) # y = np.array([stats.norm.pdf(xi, 0, 1) for xi in x]) # Use appropriate data types data_float32 = np.random.rand(10000).astype(np.float32) data_float64 = np.random.rand(10000).astype(np.float64) # Profile your code for bottlenecks import cProfile cProfile.run('stats.ttest_ind(group_a, group_b)') Memory Management # For large datasets, consider chunking def process_large_dataset(data, chunk_size=10000): results = [] for i in range(0, len(data), chunk_size): chunk = data[i:i+chunk_size] result = stats.describe(chunk) results.append(result) return results # Use sparse matrices for sparse data from scipy.sparse import csr_matrix # Instead of dense matrix with many zeros # dense = np.zeros((10000, 10000)) # Use sparse representation sparse = csr_matrix((10000, 10000)) Error Handling # Handle numerical issues def safe_division(a, b): try: result = a / b if np.isnan(result) or np.isinf(result): return None return result except ZeroDivisionError: return None # Check for convergence in optimization result = minimize(rosenbrock, x0, method='BFGS') if result.success: print(f\"Optimization successful: {result.x}\") else: print(f\"Optimization failed: {result.message}\") # Validate statistical test assumptions def check_normality(data, alpha=0.05): statistic, p_value = stats.shapiro(data) is_normal = p_value > alpha return is_normal, p_value Quick Reference Key Modules Module Purpose Common Functions scipy.stats Statistics norm , ttest_ind , pearsonr , chi2_contingency scipy.optimize Optimization minimize , curve_fit , fsolve scipy.linalg Linear algebra solve , eig , svd , cholesky scipy.signal Signal processing butter , filtfilt , find_peaks , periodogram scipy.interpolate Interpolation interp1d , griddata , CubicSpline scipy.integrate Integration quad , solve_ivp , odeint scipy.spatial Spatial algorithms distance , KDTree , ConvexHull scipy.sparse Sparse matrices csr_matrix , spsolve Statistical Tests Quick Guide Test Function Use Case One-sample t-test ttest_1samp Compare sample mean to population mean Two-sample t-test ttest_ind Compare two independent groups Paired t-test ttest_rel Compare paired/dependent samples Mann-Whitney U mannwhitneyu Non-parametric comparison of two groups Wilcoxon signed-rank wilcoxon Non-parametric paired test Chi-square chi2_contingency Test independence in contingency tables Kolmogorov-Smirnov kstest Test goodness of fit to distribution Shapiro-Wilk shapiro Test for normality Levene's test levene Test for equal variances Distribution Quick Reference Distribution Function Parameters Normal norm loc (mean), scale (std) Student's t t df (degrees of freedom) Chi-square chi2 df (degrees of freedom) F-distribution f dfn , dfd (degrees of freedom) Binomial binom n (trials), p (probability) Poisson poisson mu (rate parameter) Exponential expon scale (1/rate) Uniform uniform loc (lower), scale (range)","title":"SciPy"},{"location":"python/scipy/#scipy","text":"","title":"SciPy"},{"location":"python/scipy/#installation","text":"# Basic installation pip install scipy # With all optional dependencies pip install scipy[all] # Check version python -c \"import scipy; print(scipy.__version__)\" # Check available submodules python -c \"import scipy; print([x for x in dir(scipy) if not x.startswith('_')])\"","title":"Installation"},{"location":"python/scipy/#basic-setup","text":"# Essential imports import numpy as np import scipy as sp from scipy import stats, optimize, integrate, linalg, signal, interpolate # Common import pattern for specific modules from scipy.stats import norm, t, chi2, pearsonr from scipy.optimize import minimize, curve_fit from scipy.signal import find_peaks, periodogram from scipy.interpolate import interp1d","title":"Basic Setup"},{"location":"python/scipy/#core-functionality","text":"","title":"Core Functionality"},{"location":"python/scipy/#statistics-module-scipystats","text":"","title":"Statistics Module (scipy.stats)"},{"location":"python/scipy/#continuous-distributions","text":"from scipy.stats import norm, t, chi2, f, uniform, expon, gamma, beta # Normal distribution mean, std = 0, 1 x = np.linspace(-3, 3, 100) # Probability density function (PDF) pdf_values = norm.pdf(x, mean, std) # Cumulative distribution function (CDF) cdf_values = norm.cdf(x, mean, std) # Percent point function (inverse CDF) percentiles = norm.ppf([0.05, 0.5, 0.95], mean, std) # Random variates samples = norm.rvs(mean, std, size=1000) # Summary statistics print(f\"Mean: {norm.mean(mean, std)}\") print(f\"Variance: {norm.var(mean, std)}\") print(f\"Standard deviation: {norm.std(mean, std)}\")","title":"Continuous Distributions"},{"location":"python/scipy/#discrete-distributions","text":"from scipy.stats import binom, poisson, hypergeom, geom # Binomial distribution n, p = 10, 0.3 k = np.arange(0, 11) # Probability mass function (PMF) pmf_values = binom.pmf(k, n, p) # CDF for discrete distributions cdf_values = binom.cdf(k, n, p) # Random samples samples = binom.rvs(n, p, size=1000) # Poisson distribution lam = 3.5 # lambda parameter k = np.arange(0, 15) pmf_poisson = poisson.pmf(k, lam)","title":"Discrete Distributions"},{"location":"python/scipy/#statistical-tests","text":"from scipy.stats import ttest_1samp, ttest_ind, ttest_rel, chi2_contingency from scipy.stats import pearsonr, spearmanr, kendalltau, mannwhitneyu # One-sample t-test data = np.random.normal(5, 2, 100) statistic, p_value = ttest_1samp(data, popmean=4.5) print(f\"t-statistic: {statistic:.4f}, p-value: {p_value:.4f}\") # Two-sample t-test (independent) group1 = np.random.normal(5, 2, 50) group2 = np.random.normal(5.5, 2, 50) stat, p = ttest_ind(group1, group2) # Paired t-test before = np.random.normal(100, 15, 30) after = before + np.random.normal(2, 5, 30) stat, p = ttest_rel(before, after) # Correlation tests x = np.random.normal(0, 1, 100) y = 2*x + np.random.normal(0, 0.5, 100) # Pearson correlation corr_pearson, p_pearson = pearsonr(x, y) # Spearman rank correlation corr_spearman, p_spearman = spearmanr(x, y) # Kendall's tau tau, p_kendall = kendalltau(x, y) # Mann-Whitney U test (non-parametric) stat, p = mannwhitneyu(group1, group2, alternative='two-sided')","title":"Statistical Tests"},{"location":"python/scipy/#chi-square-tests","text":"from scipy.stats import chi2_contingency, chisquare # Chi-square test of independence contingency_table = np.array([[10, 20, 30], [15, 25, 35], [20, 30, 40]]) chi2_stat, p_value, dof, expected = chi2_contingency(contingency_table) # Goodness of fit test observed = [16, 18, 16, 14, 12, 12] expected = [16, 16, 16, 16, 16, 16] chi2_stat, p_value = chisquare(observed, expected)","title":"Chi-square Tests"},{"location":"python/scipy/#optimization-module-scipyoptimize","text":"","title":"Optimization Module (scipy.optimize)"},{"location":"python/scipy/#function-minimization","text":"from scipy.optimize import minimize, minimize_scalar, differential_evolution # Scalar function minimization def f(x): return (x - 2)**2 result = minimize_scalar(f) print(f\"Minimum at x = {result.x:.4f}, f(x) = {result.fun:.4f}\") # Multivariable function minimization def rosenbrock(x): return 100*(x[1] - x[0]**2)**2 + (1 - x[0])**2 # Initial guess x0 = [0, 0] # Minimize using different methods result_bfgs = minimize(rosenbrock, x0, method='BFGS') result_nm = minimize(rosenbrock, x0, method='Nelder-Mead') print(f\"BFGS result: {result_bfgs.x}\") print(f\"Nelder-Mead result: {result_nm.x}\") # With bounds bounds = [(0, 2), (0, 2)] result_bounded = minimize(rosenbrock, x0, method='L-BFGS-B', bounds=bounds) # Global optimization result_global = differential_evolution(rosenbrock, bounds)","title":"Function Minimization"},{"location":"python/scipy/#root-finding","text":"from scipy.optimize import root, fsolve, brentq # Single variable root finding def equation(x): return x**3 - 2*x - 5 # Brent's method (requires bracketing interval) root_brent = brentq(equation, 2, 3) # Multi-variable root finding def system_equations(vars): x, y = vars eq1 = x**2 + y**2 - 1 eq2 = x - y**2 return [eq1, eq2] # Initial guess initial_guess = [0.5, 0.5] solution = fsolve(system_equations, initial_guess) # Using root function (more options) sol = root(system_equations, initial_guess, method='hybr')","title":"Root Finding"},{"location":"python/scipy/#curve-fitting","text":"from scipy.optimize import curve_fit # Define model function def exponential_model(x, a, b, c): return a * np.exp(b * x) + c # Generate sample data with noise x_data = np.linspace(0, 4, 50) y_true = exponential_model(x_data, 2.5, 1.3, 0.5) y_data = y_true + 0.2 * np.random.normal(size=len(x_data)) # Fit the curve popt, pcov = curve_fit(exponential_model, x_data, y_data) a_fit, b_fit, c_fit = popt # Parameter uncertainties param_errors = np.sqrt(np.diag(pcov)) print(f\"Fitted parameters: a={a_fit:.3f}\u00b1{param_errors[0]:.3f}, \" f\"b={b_fit:.3f}\u00b1{param_errors[1]:.3f}, c={c_fit:.3f}\u00b1{param_errors[2]:.3f}\") # Plot results y_fit = exponential_model(x_data, *popt) import matplotlib.pyplot as plt plt.plot(x_data, y_data, 'o', label='Data') plt.plot(x_data, y_fit, '-', label='Fitted curve') plt.legend()","title":"Curve Fitting"},{"location":"python/scipy/#linear-algebra-module-scipylinalg","text":"","title":"Linear Algebra Module (scipy.linalg)"},{"location":"python/scipy/#basic-operations","text":"from scipy.linalg import solve, det, inv, eig, svd, norm, cholesky # System of linear equations Ax = b A = np.array([[3, 2, -1], [2, -2, 4], [-1, 0.5, -1]]) b = np.array([1, -2, 0]) # Solve the system x = solve(A, b) print(f\"Solution: {x}\") # Matrix determinant determinant = det(A) # Matrix inverse A_inv = inv(A) # Verify: A * A_inv should be identity identity_check = np.allclose(A @ A_inv, np.eye(3))","title":"Basic Operations"},{"location":"python/scipy/#eigenvalues-and-eigenvectors","text":"# Eigendecomposition eigenvalues, eigenvectors = eig(A) print(f\"Eigenvalues: {eigenvalues}\") # Singular Value Decomposition U, s, Vt = svd(A) print(f\"Singular values: {s}\") # Matrix norms frobenius_norm = norm(A, 'fro') spectral_norm = norm(A, 2) l1_norm = norm(A, 1)","title":"Eigenvalues and Eigenvectors"},{"location":"python/scipy/#decompositions","text":"from scipy.linalg import lu, qr, cholesky, schur # LU decomposition P, L, U = lu(A) # QR decomposition Q, R = qr(A) # Cholesky decomposition (for positive definite matrices) # Create a positive definite matrix A_pd = A.T @ A L_chol = cholesky(A_pd, lower=True) # Schur decomposition T, Z = schur(A)","title":"Decompositions"},{"location":"python/scipy/#signal-processing-module-scipysignal","text":"","title":"Signal Processing Module (scipy.signal)"},{"location":"python/scipy/#filtering","text":"from scipy.signal import butter, filtfilt, savgol_filter, medfilt # Create sample signal fs = 1000 # Sampling frequency t = np.linspace(0, 1, fs, endpoint=False) signal = np.sin(2*np.pi*5*t) + 0.5*np.sin(2*np.pi*25*t) + np.random.normal(0, 0.1, len(t)) # Butterworth filter def butter_lowpass_filter(data, cutoff, fs, order=4): nyquist = 0.5 * fs normal_cutoff = cutoff / nyquist b, a = butter(order, normal_cutoff, btype='low', analog=False) filtered_data = filtfilt(b, a, data) return filtered_data # Apply low-pass filter cutoff_freq = 10 # Hz filtered_signal = butter_lowpass_filter(signal, cutoff_freq, fs) # Savitzky-Golay filter (good for smoothing) window_length = 51 # Must be odd poly_order = 3 smoothed_signal = savgol_filter(signal, window_length, poly_order) # Median filter (good for removing spikes) kernel_size = 5 median_filtered = medfilt(signal, kernel_size)","title":"Filtering"},{"location":"python/scipy/#spectral-analysis","text":"from scipy.signal import periodogram, welch, spectrogram from scipy.fft import fft, fftfreq # Periodogram (power spectral density) frequencies, psd = periodogram(signal, fs) # Welch's method (averaged periodogram) f_welch, psd_welch = welch(signal, fs, nperseg=256) # Spectrogram (time-frequency analysis) f_spec, t_spec, Sxx = spectrogram(signal, fs, nperseg=256) # FFT fft_values = fft(signal) fft_freq = fftfreq(len(signal), 1/fs) # Plot spectrum import matplotlib.pyplot as plt plt.figure(figsize=(12, 4)) plt.subplot(131) plt.plot(t[:500], signal[:500]) plt.title('Time Domain') plt.xlabel('Time (s)') plt.subplot(132) plt.semilogy(frequencies, psd) plt.title('Power Spectral Density') plt.xlabel('Frequency (Hz)') plt.subplot(133) plt.pcolormesh(t_spec, f_spec, 10*np.log10(Sxx), shading='gouraud') plt.title('Spectrogram') plt.ylabel('Frequency (Hz)') plt.xlabel('Time (s)') plt.tight_layout()","title":"Spectral Analysis"},{"location":"python/scipy/#peak-finding","text":"from scipy.signal import find_peaks, peak_widths, peak_prominences # Generate signal with peaks x = np.linspace(0, 10, 1000) signal_peaks = np.sin(x) + 0.5*np.sin(3*x) + 0.2*np.random.randn(1000) # Find peaks peaks, properties = find_peaks(signal_peaks, height=0.5, distance=20) # Peak properties widths = peak_widths(signal_peaks, peaks, rel_height=0.5) prominences = peak_prominences(signal_peaks, peaks) # Plot results plt.figure(figsize=(12, 6)) plt.plot(x, signal_peaks, label='Signal') plt.plot(x[peaks], signal_peaks[peaks], 'ro', label='Peaks') plt.legend()","title":"Peak Finding"},{"location":"python/scipy/#integration-module-scipyintegrate","text":"","title":"Integration Module (scipy.integrate)"},{"location":"python/scipy/#numerical-integration","text":"from scipy.integrate import quad, dblquad, tplquad, odeint, solve_ivp # Single integral def integrand(x): return np.exp(-x**2) # Integrate from 0 to infinity result, error = quad(integrand, 0, np.inf) print(f\"\u222b\u2080^\u221e e^(-x\u00b2) dx = {result:.6f} \u00b1 {error:.2e}\") # Double integral def integrand_2d(y, x): return x*y**2 # Integrate over rectangle [0,1] \u00d7 [0,2] result_2d, error_2d = dblquad(integrand_2d, 0, 1, lambda x: 0, lambda x: 2) # Triple integral def integrand_3d(z, y, x): return x*y*z result_3d, error_3d = tplquad(integrand_3d, 0, 1, lambda x: 0, lambda x: 1, lambda x, y: 0, lambda x, y: 1)","title":"Numerical Integration"},{"location":"python/scipy/#ordinary-differential-equations-odes","text":"from scipy.integrate import odeint, solve_ivp # Solve dy/dt = -2y with initial condition y(0) = 1 def dydt(y, t): return -2*y t = np.linspace(0, 2, 100) y0 = 1 solution = odeint(dydt, y0, t) # System of ODEs: Lotka-Volterra (predator-prey) def lotka_volterra(t, z, a, b, c, d): x, y = z return [a*x - b*x*y, -c*y + d*x*y] # Parameters a, b, c, d = 1.0, 0.1, 1.5, 0.075 initial_conditions = [10, 5] # [prey, predator] t_span = (0, 15) t_eval = np.linspace(0, 15, 1000) # Solve using solve_ivp (more modern interface) sol = solve_ivp(lotka_volterra, t_span, initial_conditions, t_eval=t_eval, args=(a, b, c, d), dense_output=True) # Plot phase portrait plt.figure(figsize=(12, 5)) plt.subplot(121) plt.plot(sol.t, sol.y[0], label='Prey') plt.plot(sol.t, sol.y[1], label='Predator') plt.xlabel('Time') plt.ylabel('Population') plt.legend() plt.subplot(122) plt.plot(sol.y[0], sol.y[1]) plt.xlabel('Prey') plt.ylabel('Predator') plt.title('Phase Portrait')","title":"Ordinary Differential Equations (ODEs)"},{"location":"python/scipy/#interpolation-module-scipyinterpolate","text":"","title":"Interpolation Module (scipy.interpolate)"},{"location":"python/scipy/#1d-interpolation","text":"from scipy.interpolate import interp1d, UnivariateSpline, CubicSpline # Sample data x = np.linspace(0, 10, 11) y = np.sin(x) # Different interpolation methods f_linear = interp1d(x, y, kind='linear') f_cubic = interp1d(x, y, kind='cubic') f_spline = UnivariateSpline(x, y, s=0) # s=0 for interpolation f_cubic_spline = CubicSpline(x, y) # Evaluate at new points x_new = np.linspace(0, 10, 100) y_linear = f_linear(x_new) y_cubic = f_cubic(x_new) y_spline = f_spline(x_new) y_cubic_spline = f_cubic_spline(x_new) # Plot comparison plt.figure(figsize=(10, 6)) plt.plot(x, y, 'o', label='Data points') plt.plot(x_new, y_linear, '-', label='Linear') plt.plot(x_new, y_cubic, '--', label='Cubic') plt.plot(x_new, y_spline, '-.', label='Spline') plt.plot(x_new, y_cubic_spline, ':', label='Cubic Spline') plt.legend() plt.title('Interpolation Methods Comparison')","title":"1D Interpolation"},{"location":"python/scipy/#2d-interpolation","text":"from scipy.interpolate import griddata, RegularGridInterpolator # Scattered data interpolation np.random.seed(42) points = np.random.rand(100, 2) * 10 values = np.sin(points[:, 0]) * np.cos(points[:, 1]) # Create regular grid xi = np.linspace(0, 10, 50) yi = np.linspace(0, 10, 50) xi_grid, yi_grid = np.meshgrid(xi, yi) # Interpolate using different methods zi_nearest = griddata(points, values, (xi_grid, yi_grid), method='nearest') zi_linear = griddata(points, values, (xi_grid, yi_grid), method='linear') zi_cubic = griddata(points, values, (xi_grid, yi_grid), method='cubic') # Regular grid interpolation (faster for regular grids) x_reg = np.linspace(0, 10, 20) y_reg = np.linspace(0, 10, 20) X_reg, Y_reg = np.meshgrid(x_reg, y_reg) Z_reg = np.sin(X_reg) * np.cos(Y_reg) interp_func = RegularGridInterpolator((x_reg, y_reg), Z_reg) new_points = np.column_stack([xi_grid.ravel(), yi_grid.ravel()]) zi_reg = interp_func(new_points).reshape(xi_grid.shape)","title":"2D Interpolation"},{"location":"python/scipy/#advanced-features","text":"","title":"Advanced Features"},{"location":"python/scipy/#spatial-algorithms-scipyspatial","text":"from scipy.spatial import distance, KDTree, ConvexHull, Voronoi from scipy.spatial.distance import pdist, squareform # Distance calculations points = np.random.rand(10, 2) # Pairwise distances distances = pdist(points) distance_matrix = squareform(distances) # Different distance metrics euclidean_dist = pdist(points, metric='euclidean') manhattan_dist = pdist(points, metric='manhattan') cosine_dist = pdist(points, metric='cosine') # KD-Tree for nearest neighbor searches tree = KDTree(points) # Find k nearest neighbors query_point = [0.5, 0.5] distances, indices = tree.query(query_point, k=3) # Convex Hull hull = ConvexHull(points) hull_points = points[hull.vertices] # Voronoi diagram vor = Voronoi(points)","title":"Spatial Algorithms (scipy.spatial)"},{"location":"python/scipy/#sparse-matrices-scipysparse","text":"from scipy.sparse import csr_matrix, csc_matrix, diags, eye from scipy.sparse.linalg import spsolve # Create sparse matrix row = np.array([0, 0, 1, 2, 2, 2]) col = np.array([0, 2, 1, 0, 1, 2]) data = np.array([1, 2, 3, 4, 5, 6]) # Compressed Sparse Row matrix sparse_matrix = csr_matrix((data, (row, col)), shape=(3, 3)) # Create diagonal sparse matrix diag_sparse = diags([1, 2, 3], offsets=[0], shape=(3, 3)) # Sparse identity matrix sparse_eye = eye(1000, format='csr') # Solve sparse linear system A_sparse = csr_matrix([[1, 2], [3, 4]]) b = np.array([1, 2]) x = spsolve(A_sparse, b)","title":"Sparse Matrices (scipy.sparse)"},{"location":"python/scipy/#fft-module-scipyfft","text":"from scipy.fft import fft, ifft, fft2, ifft2, fftfreq, rfft # 1D FFT signal = np.sin(2*np.pi*5*np.linspace(0, 1, 1000)) fft_signal = fft(signal) freq = fftfreq(len(signal), 1/1000) # Real FFT (for real-valued signals) rfft_signal = rfft(signal) rfreq = fftfreq(len(signal), 1/1000)[:len(rfft_signal)] # 2D FFT image = np.random.rand(100, 100) fft2_image = fft2(image) ifft2_image = ifft2(fft2_image) # Should recover original # Verify reconstruction reconstruction_error = np.max(np.abs(image - ifft2_image.real)) print(f\"Reconstruction error: {reconstruction_error:.2e}\")","title":"FFT Module (scipy.fft)"},{"location":"python/scipy/#common-use-cases","text":"","title":"Common Use Cases"},{"location":"python/scipy/#statistical-analysis-workflow","text":"# Complete statistical analysis example import pandas as pd from scipy import stats # Generate sample data np.random.seed(42) group_a = np.random.normal(100, 15, 50) group_b = np.random.normal(105, 15, 50) # Descriptive statistics print(\"Group A:\") print(f\"Mean: {np.mean(group_a):.2f}, Std: {np.std(group_a, ddof=1):.2f}\") print(\"Group B:\") print(f\"Mean: {np.mean(group_b):.2f}, Std: {np.std(group_b, ddof=1):.2f}\") # Test for normality _, p_a = stats.shapiro(group_a) _, p_b = stats.shapiro(group_b) print(f\"\\nNormality tests (Shapiro-Wilk):\") print(f\"Group A p-value: {p_a:.4f}\") print(f\"Group B p-value: {p_b:.4f}\") # Test for equal variances _, p_levene = stats.levene(group_a, group_b) print(f\"\\nEqual variances test (Levene): p-value = {p_levene:.4f}\") # Choose appropriate t-test if p_levene > 0.05: # Equal variances t_stat, p_ttest = stats.ttest_ind(group_a, group_b, equal_var=True) print(f\"\\nStudent's t-test: t = {t_stat:.4f}, p = {p_ttest:.4f}\") else: # Unequal variances t_stat, p_ttest = stats.ttest_ind(group_a, group_b, equal_var=False) print(f\"\\nWelch's t-test: t = {t_stat:.4f}, p = {p_ttest:.4f}\") # Effect size (Cohen's d) pooled_std = np.sqrt(((len(group_a)-1)*np.var(group_a, ddof=1) + (len(group_b)-1)*np.var(group_b, ddof=1)) / (len(group_a) + len(group_b) - 2)) cohens_d = (np.mean(group_a) - np.mean(group_b)) / pooled_std print(f\"Cohen's d: {cohens_d:.4f}\")","title":"Statistical Analysis Workflow"},{"location":"python/scipy/#signal-processing-pipeline","text":"# Complete signal processing example from scipy import signal import matplotlib.pyplot as plt # Generate noisy signal fs = 1000 t = np.linspace(0, 2, 2*fs, endpoint=False) clean_signal = (np.sin(2*np.pi*10*t) + 0.5*np.sin(2*np.pi*20*t) + 0.3*np.sin(2*np.pi*30*t)) noisy_signal = clean_signal + 0.2*np.random.randn(len(t)) # Design and apply filters # Low-pass filter sos_low = signal.butter(4, 25, btype='low', fs=fs, output='sos') filtered_low = signal.sosfiltfilt(sos_low, noisy_signal) # Band-pass filter sos_band = signal.butter(4, [15, 25], btype='band', fs=fs, output='sos') filtered_band = signal.sosfiltfilt(sos_band, noisy_signal) # Spectral analysis f, psd = signal.welch(noisy_signal, fs, nperseg=1024) f_clean, psd_clean = signal.welch(clean_signal, fs, nperseg=1024) f_filt, psd_filt = signal.welch(filtered_low, fs, nperseg=1024) # Find peaks in filtered signal peaks, properties = signal.find_peaks(filtered_low, height=0.5, distance=50) # Plot results fig, axes = plt.subplots(2, 2, figsize=(15, 10)) # Time domain axes[0,0].plot(t[:500], noisy_signal[:500], alpha=0.7, label='Noisy') axes[0,0].plot(t[:500], filtered_low[:500], label='Filtered') axes[0,0].set_title('Time Domain') axes[0,0].legend() # Frequency domain axes[0,1].semilogy(f, psd, alpha=0.7, label='Noisy') axes[0,1].semilogy(f_filt, psd_filt, label='Filtered') axes[0,1].set_title('Power Spectral Density') axes[0,1].legend() # Peak detection axes[1,0].plot(filtered_low[:1000]) axes[1,0].plot(peaks[peaks<1000], filtered_low[peaks[peaks<1000]], 'ro') axes[1,0].set_title('Peak Detection') # Spectrogram f_spec, t_spec, Sxx = signal.spectrogram(noisy_signal, fs, nperseg=256) axes[1,1].pcolormesh(t_spec, f_spec, 10*np.log10(Sxx), shading='gouraud') axes[1,1].set_title('Spectrogram') axes[1,1].set_ylabel('Frequency (Hz)') axes[1,1].set_xlabel('Time (s)') plt.tight_layout()","title":"Signal Processing Pipeline"},{"location":"python/scipy/#optimization-problem","text":"# Multi-modal optimization example from scipy.optimize import minimize, differential_evolution, basinhopping # Define a complex function with multiple local minima def complex_function(x): x1, x2 = x return (x1**2 + x2 - 11)**2 + (x1 + x2**2 - 7)**2 # Local optimization (may get stuck in local minima) x0 = [0, 0] result_local = minimize(complex_function, x0, method='BFGS') # Global optimization methods bounds = [(-5, 5), (-5, 5)] result_global = differential_evolution(complex_function, bounds, seed=42) # Basin-hopping (another global method) minimizer_kwargs = {\"method\": \"BFGS\"} result_basinhopping = basinhopping(complex_function, x0, minimizer_kwargs=minimizer_kwargs, niter=100, T=1.0, stepsize=0.5) print(\"Local minimum (BFGS):\", result_local.x, \"f =\", result_local.fun) print(\"Global minimum (DE):\", result_global.x, \"f =\", result_global.fun) print(\"Basin-hopping result:\", result_basinhopping.x, \"f =\", result_basinhopping.fun) # Visualize the function and minima x1_range = np.linspace(-5, 5, 100) x2_range = np.linspace(-5, 5, 100) X1, X2 = np.meshgrid(x1_range, x2_range) Z = complex_function([X1, X2]) plt.figure(figsize=(10, 8)) contour = plt.contour(X1, X2, Z, levels=50) plt.colorbar(contour) plt.plot(result_local.x[0], result_local.x[1], 'ro', markersize=10, label='Local min') plt.plot(result_global.x[0], result_global.x[1], 'go', markersize=10, label='Global min') plt.xlabel('x1') plt.ylabel('x2') plt.title('Function Landscape with Optimization Results') plt.legend()","title":"Optimization Problem"},{"location":"python/scipy/#integration-with-other-libraries","text":"","title":"Integration with Other Libraries"},{"location":"python/scipy/#numpy-integration","text":"# SciPy functions work seamlessly with NumPy arrays data = np.random.exponential(2, 1000) # Fit distribution params = stats.expon.fit(data) print(f\"Fitted parameters: scale = {params[1]:.4f}\") # Kolmogorov-Smirnov test ks_stat, p_value = stats.kstest(data, lambda x: stats.expon.cdf(x, *params)) print(f\"K-S test: statistic = {ks_stat:.4f}, p-value = {p_value:.4f}\")","title":"NumPy Integration"},{"location":"python/scipy/#matplotlib-integration","text":"# Visualization with matplotlib fig, axes = plt.subplots(2, 2, figsize=(12, 10)) # Q-Q plot stats.probplot(data, dist=\"expon\", plot=axes[0,0]) axes[0,0].set_title(\"Q-Q Plot\") # Histogram with fitted PDF axes[0,1].hist(data, bins=50, density=True, alpha=0.7, label='Data') x_fit = np.linspace(0, np.max(data), 100) axes[0,1].plot(x_fit, stats.expon.pdf(x_fit, *params), 'r-', lw=2, label='Fitted PDF') axes[0,1].legend() axes[0,1].set_title(\"Histogram with Fitted Distribution\") # CDF comparison sorted_data = np.sort(data) empirical_cdf = np.arange(1, len(data)+1) / len(data) theoretical_cdf = stats.expon.cdf(sorted_data, *params) axes[1,0].plot(sorted_data, empirical_cdf, label='Empirical CDF') axes[1,0].plot(sorted_data, theoretical_cdf, 'r-', label='Theoretical CDF') axes[1,0].legend() axes[1,0].set_title(\"CDF Comparison\") plt.tight_layout()","title":"Matplotlib Integration"},{"location":"python/scipy/#best-practices","text":"","title":"Best Practices"},{"location":"python/scipy/#performance-tips","text":"# Use vectorized operations # Good x = np.linspace(0, 10, 1000000) y = stats.norm.pdf(x, 0, 1) # Avoid loops when possible # Bad (slow) # y = np.array([stats.norm.pdf(xi, 0, 1) for xi in x]) # Use appropriate data types data_float32 = np.random.rand(10000).astype(np.float32) data_float64 = np.random.rand(10000).astype(np.float64) # Profile your code for bottlenecks import cProfile cProfile.run('stats.ttest_ind(group_a, group_b)')","title":"Performance Tips"},{"location":"python/scipy/#memory-management","text":"# For large datasets, consider chunking def process_large_dataset(data, chunk_size=10000): results = [] for i in range(0, len(data), chunk_size): chunk = data[i:i+chunk_size] result = stats.describe(chunk) results.append(result) return results # Use sparse matrices for sparse data from scipy.sparse import csr_matrix # Instead of dense matrix with many zeros # dense = np.zeros((10000, 10000)) # Use sparse representation sparse = csr_matrix((10000, 10000))","title":"Memory Management"},{"location":"python/scipy/#error-handling","text":"# Handle numerical issues def safe_division(a, b): try: result = a / b if np.isnan(result) or np.isinf(result): return None return result except ZeroDivisionError: return None # Check for convergence in optimization result = minimize(rosenbrock, x0, method='BFGS') if result.success: print(f\"Optimization successful: {result.x}\") else: print(f\"Optimization failed: {result.message}\") # Validate statistical test assumptions def check_normality(data, alpha=0.05): statistic, p_value = stats.shapiro(data) is_normal = p_value > alpha return is_normal, p_value","title":"Error Handling"},{"location":"python/scipy/#quick-reference","text":"","title":"Quick Reference"},{"location":"python/scipy/#key-modules","text":"Module Purpose Common Functions scipy.stats Statistics norm , ttest_ind , pearsonr , chi2_contingency scipy.optimize Optimization minimize , curve_fit , fsolve scipy.linalg Linear algebra solve , eig , svd , cholesky scipy.signal Signal processing butter , filtfilt , find_peaks , periodogram scipy.interpolate Interpolation interp1d , griddata , CubicSpline scipy.integrate Integration quad , solve_ivp , odeint scipy.spatial Spatial algorithms distance , KDTree , ConvexHull scipy.sparse Sparse matrices csr_matrix , spsolve","title":"Key Modules"},{"location":"python/scipy/#statistical-tests-quick-guide","text":"Test Function Use Case One-sample t-test ttest_1samp Compare sample mean to population mean Two-sample t-test ttest_ind Compare two independent groups Paired t-test ttest_rel Compare paired/dependent samples Mann-Whitney U mannwhitneyu Non-parametric comparison of two groups Wilcoxon signed-rank wilcoxon Non-parametric paired test Chi-square chi2_contingency Test independence in contingency tables Kolmogorov-Smirnov kstest Test goodness of fit to distribution Shapiro-Wilk shapiro Test for normality Levene's test levene Test for equal variances","title":"Statistical Tests Quick Guide"},{"location":"python/scipy/#distribution-quick-reference","text":"Distribution Function Parameters Normal norm loc (mean), scale (std) Student's t t df (degrees of freedom) Chi-square chi2 df (degrees of freedom) F-distribution f dfn , dfd (degrees of freedom) Binomial binom n (trials), p (probability) Poisson poisson mu (rate parameter) Exponential expon scale (1/rate) Uniform uniform loc (lower), scale (range)","title":"Distribution Quick Reference"},{"location":"python/seaborn/","text":"Seaborn Installation # Basic installation pip install seaborn # With all optional dependencies pip install seaborn[all] # Development version pip install git+https://github.com/mwaskom/seaborn.git # Check version python -c \"import seaborn as sns; print(sns.__version__)\" # List available datasets python -c \"import seaborn as sns; print(sns.get_dataset_names())\" Basic Setup # Essential imports import seaborn as sns import matplotlib.pyplot as plt import pandas as pd import numpy as np # Apply default theme sns.set_theme() # Alternative: set specific style sns.set_theme(style=\"whitegrid\", palette=\"pastel\") # Load sample dataset tips = sns.load_dataset(\"tips\") flights = sns.load_dataset(\"flights\") iris = sns.load_dataset(\"iris\") penguins = sns.load_dataset(\"penguins\") Core Functionality Built-in Datasets # Available datasets dataset_names = sns.get_dataset_names() print(dataset_names) # Load specific datasets tips = sns.load_dataset(\"tips\") # Restaurant tips flights = sns.load_dataset(\"flights\") # Airline passenger data iris = sns.load_dataset(\"iris\") # Iris flower measurements penguins = sns.load_dataset(\"penguins\") # Palmer penguin data mpg = sns.load_dataset(\"mpg\") # Car fuel efficiency titanic = sns.load_dataset(\"titanic\") # Titanic passenger data diamonds = sns.load_dataset(\"diamonds\") # Diamond characteristics fmri = sns.load_dataset(\"fmri\") # fMRI brain imaging data # Explore dataset structure print(tips.head()) print(tips.info()) print(tips.describe()) Figure-Level vs Axes-Level Functions # Figure-level functions (create entire figure with subplots) sns.relplot() # Relationships (scatter, line) sns.displot() # Distributions (hist, kde, ecdf) sns.catplot() # Categorical (bar, box, violin, etc.) sns.lmplot() # Linear model fits sns.FacetGrid() # General-purpose faceting # Axes-level functions (work with matplotlib axes) sns.scatterplot() # Scatter plot sns.lineplot() # Line plot sns.histplot() # Histogram sns.kdeplot() # Kernel density estimate sns.boxplot() # Box plot sns.barplot() # Bar plot sns.heatmap() # Heat map Relational Plots Scatter Plots # Basic scatter plot sns.scatterplot(data=tips, x=\"total_bill\", y=\"tip\") # With categorical encoding sns.scatterplot(data=tips, x=\"total_bill\", y=\"tip\", hue=\"time\", style=\"smoker\") # With size encoding sns.scatterplot(data=tips, x=\"total_bill\", y=\"tip\", size=\"size\", hue=\"time\") # Figure-level with faceting sns.relplot(data=tips, x=\"total_bill\", y=\"tip\", col=\"time\", hue=\"smoker\", style=\"smoker\") # Advanced customization sns.relplot(data=tips, x=\"total_bill\", y=\"tip\", hue=\"time\", size=\"size\", style=\"sex\", palette=[\"blue\", \"red\"], sizes=(20, 200), height=5, aspect=1.2) Line Plots # Basic line plot fmri = sns.load_dataset(\"fmri\") sns.lineplot(data=fmri, x=\"timepoint\", y=\"signal\") # With confidence intervals sns.lineplot(data=fmri, x=\"timepoint\", y=\"signal\", hue=\"event\") # Multiple grouping variables sns.lineplot(data=fmri, x=\"timepoint\", y=\"signal\", hue=\"region\", style=\"event\") # Figure-level line plots with faceting sns.relplot(data=fmri, kind=\"line\", x=\"timepoint\", y=\"signal\", col=\"region\", hue=\"event\", style=\"event\") # Time series with dates flights_wide = flights.pivot(index=\"year\", columns=\"month\", values=\"passengers\") flights_wide.index = pd.date_range(\"1949\", periods=12, freq=\"AS\") sns.lineplot(data=flights_wide.T) Distribution Plots Histograms # Basic histogram sns.histplot(data=penguins, x=\"flipper_length_mm\") # With grouping sns.histplot(data=penguins, x=\"flipper_length_mm\", hue=\"species\") # Stacked histogram sns.histplot(data=penguins, x=\"flipper_length_mm\", hue=\"species\", multiple=\"stack\") # Density histogram sns.histplot(data=penguins, x=\"flipper_length_mm\", stat=\"density\") # 2D histogram sns.histplot(data=penguins, x=\"flipper_length_mm\", y=\"bill_length_mm\") # Figure-level distributions sns.displot(data=penguins, x=\"flipper_length_mm\", col=\"species\") sns.displot(data=penguins, x=\"flipper_length_mm\", hue=\"species\", kind=\"kde\") KDE Plots # Basic KDE sns.kdeplot(data=penguins, x=\"flipper_length_mm\") # Multiple distributions sns.kdeplot(data=penguins, x=\"flipper_length_mm\", hue=\"species\") # Filled KDE sns.kdeplot(data=penguins, x=\"flipper_length_mm\", hue=\"species\", fill=True) # 2D KDE sns.kdeplot(data=penguins, x=\"flipper_length_mm\", y=\"bill_length_mm\") # Bivariate with contours sns.kdeplot(data=penguins, x=\"flipper_length_mm\", y=\"bill_length_mm\", levels=5, thresh=0.1) # Combined histogram and KDE sns.histplot(data=penguins, x=\"flipper_length_mm\", kde=True) ECDF Plots # Empirical Cumulative Distribution Function sns.ecdfplot(data=penguins, x=\"flipper_length_mm\") # With grouping sns.ecdfplot(data=penguins, x=\"flipper_length_mm\", hue=\"species\") # Complementary ECDF sns.ecdfplot(data=penguins, x=\"flipper_length_mm\", complementary=True) # Figure-level ECDF sns.displot(data=penguins, x=\"flipper_length_mm\", kind=\"ecdf\", col=\"species\", height=4) Categorical Plots Bar Plots # Basic bar plot (shows mean with confidence interval) sns.barplot(data=tips, x=\"day\", y=\"total_bill\") # With grouping sns.barplot(data=tips, x=\"day\", y=\"total_bill\", hue=\"time\") # Different estimator sns.barplot(data=tips, x=\"day\", y=\"total_bill\", estimator=np.median) # Count plot (frequency of categories) sns.countplot(data=tips, x=\"day\") sns.countplot(data=tips, x=\"day\", hue=\"time\") # Horizontal bar plot sns.barplot(data=tips, x=\"total_bill\", y=\"day\", orient=\"h\") Box and Violin Plots # Box plots sns.boxplot(data=tips, x=\"day\", y=\"total_bill\") sns.boxplot(data=tips, x=\"day\", y=\"total_bill\", hue=\"smoker\") # Violin plots sns.violinplot(data=tips, x=\"day\", y=\"total_bill\") sns.violinplot(data=tips, x=\"day\", y=\"total_bill\", hue=\"smoker\", split=True) # Box plot with strip plot overlay sns.boxplot(data=tips, x=\"day\", y=\"total_bill\", color=\"lightgray\") sns.stripplot(data=tips, x=\"day\", y=\"total_bill\", size=4, jitter=True) Point and Strip Plots # Strip plot (categorical scatter) sns.stripplot(data=tips, x=\"day\", y=\"total_bill\") # Swarm plot (non-overlapping points) sns.swarmplot(data=tips, x=\"day\", y=\"total_bill\") # Point plot (connect means) sns.pointplot(data=tips, x=\"day\", y=\"total_bill\", hue=\"time\") # Figure-level categorical plots sns.catplot(data=tips, x=\"day\", y=\"total_bill\", kind=\"violin\", col=\"time\", hue=\"smoker\") sns.catplot(data=tips, x=\"day\", y=\"total_bill\", kind=\"swarm\", row=\"time\", col=\"sex\") Statistical Visualizations Regression Plots # Simple linear regression sns.regplot(data=tips, x=\"total_bill\", y=\"tip\") # Without regression line sns.regplot(data=tips, x=\"total_bill\", y=\"tip\", fit_reg=False) # Different regression order sns.regplot(data=tips, x=\"total_bill\", y=\"tip\", order=2) # Logistic regression sns.regplot(data=tips, x=\"total_bill\", y=\"tip\", logistic=True) # Linear model plot with faceting sns.lmplot(data=tips, x=\"total_bill\", y=\"tip\", col=\"time\", hue=\"smoker\") # Residual plots sns.residplot(data=tips, x=\"total_bill\", y=\"tip\") Pair Plots # Pairwise relationships sns.pairplot(data=iris) # With categorical encoding sns.pairplot(data=iris, hue=\"species\") # Subset of variables sns.pairplot(data=iris, vars=[\"sepal_length\", \"sepal_width\"], hue=\"species\") # Different plot types on diagonal sns.pairplot(data=iris, hue=\"species\", diag_kind=\"kde\") # Custom plot types sns.pairplot(data=iris, hue=\"species\", plot_kws={\"alpha\": 0.6}, diag_kws={\"shade\": True}) Joint Plots # Basic joint plot sns.jointplot(data=tips, x=\"total_bill\", y=\"tip\") # Different plot types sns.jointplot(data=tips, x=\"total_bill\", y=\"tip\", kind=\"reg\") sns.jointplot(data=tips, x=\"total_bill\", y=\"tip\", kind=\"hex\") sns.jointplot(data=tips, x=\"total_bill\", y=\"tip\", kind=\"kde\") # With categorical data sns.jointplot(data=penguins, x=\"flipper_length_mm\", y=\"bill_length_mm\", hue=\"species\") # Custom marginal plots g = sns.jointplot(data=penguins, x=\"flipper_length_mm\", y=\"bill_length_mm\") g.plot_joint(sns.kdeplot, color=\"r\", zorder=0, levels=6) g.plot_marginals(sns.rugplot, color=\"r\", height=-0.15) Multi-plot Grids FacetGrid # Create FacetGrid g = sns.FacetGrid(tips, col=\"time\", row=\"smoker\", margin_titles=True) # Map function to each facet g.map(sns.scatterplot, \"total_bill\", \"tip\", alpha=0.7) g.add_legend() # Different functions for different positions g = sns.FacetGrid(tips, col=\"time\", hue=\"smoker\") g.map(plt.scatter, \"total_bill\", \"tip\", alpha=0.7) g.add_legend() # Custom function def scatter_with_corr(x, y, **kwargs): ax = plt.gca() corr = np.corrcoef(x, y)[0, 1] ax.annotate(f'r = {corr:.2f}', xy=(0.1, 0.9), xycoords=ax.transAxes) ax.scatter(x, y, **kwargs) g = sns.FacetGrid(tips, col=\"time\") g.map(scatter_with_corr, \"total_bill\", \"tip\") PairGrid # Create PairGrid g = sns.PairGrid(iris, hue=\"species\") # Map different plot types g.map_diag(sns.histplot) g.map_offdiag(sns.scatterplot) g.add_legend() # Different plots for upper and lower triangles g = sns.PairGrid(iris) g.map_upper(sns.scatterplot) g.map_lower(sns.kdeplot, fill=True) g.map_diag(sns.histplot, kde=True) JointGrid # Create JointGrid g = sns.JointGrid(data=penguins, x=\"flipper_length_mm\", y=\"bill_length_mm\") # Add plots g.plot(sns.scatterplot, sns.histplot) # Custom styling g = sns.JointGrid(data=penguins, x=\"flipper_length_mm\", y=\"bill_length_mm\") g.plot(sns.scatterplot, sns.histplot, alpha=0.7, edgecolor=\".2\", linewidth=0.5) # Mixed plot types g = sns.JointGrid(data=penguins, x=\"flipper_length_mm\", y=\"bill_length_mm\") g.plot(sns.regplot, sns.boxplot) Heat Maps Basic Heat Maps # Correlation matrix corr = tips.corr(numeric_only=True) sns.heatmap(corr) # With annotations sns.heatmap(corr, annot=True, cmap='coolwarm', center=0) # Custom formatting sns.heatmap(corr, annot=True, fmt='.2f', square=True, linewidths=0.5, cbar_kws={\"shrink\": 0.8}) # Pivot table heatmap flights_pivot = flights.pivot(index=\"month\", columns=\"year\", values=\"passengers\") sns.heatmap(flights_pivot, cmap=\"YlOrRd\") Cluster Map # Hierarchical clustering iris_num = iris.select_dtypes(include=[np.number]) sns.clustermap(iris_num, cmap='viridis', standard_scale=1) # With annotations sns.clustermap(corr, annot=True, cmap='RdBu_r', center=0) # Control clustering sns.clustermap(flights_pivot, col_cluster=False, cmap='Blues') Styling and Themes Built-in Themes # Available styles print(sns.axes_style.__doc__) # Set different styles styles = ['darkgrid', 'whitegrid', 'dark', 'white', 'ticks'] for style in styles: sns.set_theme(style=style) plt.figure(figsize=(6, 4)) sns.lineplot(data=fmri.query('region==\"frontal\"'), x=\"timepoint\", y=\"signal\", hue=\"event\") plt.title(f'Style: {style}') plt.show() Color Palettes # Qualitative palettes sns.color_palette(\"deep\") # Default seaborn colors sns.color_palette(\"muted\") # Muted version sns.color_palette(\"bright\") # Bright version sns.color_palette(\"pastel\") # Pastel version sns.color_palette(\"dark\") # Dark version # Sequential palettes sns.color_palette(\"Blues\") # Single hue sns.color_palette(\"viridis\") # Perceptually uniform sns.color_palette(\"rocket\") # Seaborn sequential # Diverging palettes sns.color_palette(\"RdBu\") # Red-Blue diverging sns.color_palette(\"coolwarm\") # Cool-warm sns.color_palette(\"vlag\") # Seaborn diverging # Custom palettes colors = [\"#FF6B6B\", \"#4ECDC4\", \"#45B7D1\", \"#96CEB4\", \"#FFEAA7\"] sns.set_palette(colors) # Using palettes in plots sns.scatterplot(data=tips, x=\"total_bill\", y=\"tip\", hue=\"time\", palette=\"viridis\") Contexts (Scaling) # Available contexts contexts = ['paper', 'notebook', 'talk', 'poster'] for context in contexts: sns.set_context(context) plt.figure(figsize=(8, 6)) sns.boxplot(data=tips, x=\"day\", y=\"total_bill\") plt.title(f'Context: {context}') plt.show() # Custom scaling sns.set_context(\"notebook\", font_scale=1.5, rc={\"lines.linewidth\": 2.5}) Custom Styling # Custom theme dictionary custom_theme = { \"axes.spines.right\": False, \"axes.spines.top\": False, \"axes.grid\": True, \"axes.grid.alpha\": 0.3, \"grid.linewidth\": 0.8, \"font.family\": [\"serif\"], \"font.size\": 12 } # Apply custom theme with sns.axes_style(custom_theme): sns.scatterplot(data=tips, x=\"total_bill\", y=\"tip\", hue=\"time\") # Persistent custom theme sns.set_theme(rc=custom_theme) Despining # Remove spines sns.despine() # Remove top and right sns.despine(left=True) # Also remove left sns.despine(offset=10) # Offset spines sns.despine(trim=True) # Trim spines to data range # In context plt.figure(figsize=(8, 6)) sns.boxplot(data=tips, x=\"day\", y=\"total_bill\") sns.despine(offset=5, trim=True) Advanced Features Custom Color Maps and Normalization # Custom discrete palette from matplotlib.colors import ListedColormap custom_colors = [\"#FF6B6B\", \"#4ECDC4\", \"#45B7D1\"] custom_cmap = ListedColormap(custom_colors) # Use in heatmap sns.heatmap(flights_pivot, cmap=custom_cmap) # Color normalization from matplotlib.colors import LogNorm, PowerNorm # Log normalization for highly skewed data sns.heatmap(flights_pivot, norm=LogNorm()) # Power normalization sns.heatmap(flights_pivot, norm=PowerNorm(gamma=0.5)) Statistical Annotations # Add statistical annotations manually from scipy import stats fig, ax = plt.subplots() sns.boxplot(data=tips, x=\"time\", y=\"total_bill\", ax=ax) # Perform statistical test lunch_bills = tips[tips['time'] == 'Lunch']['total_bill'] dinner_bills = tips[tips['time'] == 'Dinner']['total_bill'] t_stat, p_value = stats.ttest_ind(lunch_bills, dinner_bills) # Add annotation ax.text(0.5, 0.95, f'p-value: {p_value:.4f}', transform=ax.transAxes, ha='center', va='top', bbox=dict(boxstyle='round', facecolor='white', alpha=0.8)) Interactive Elements # Using matplotlib widgets with seaborn from matplotlib.widgets import CheckButtons # Create plot fig, ax = plt.subplots(figsize=(10, 6)) species_list = penguins['species'].unique() lines = [] for species in species_list: data = penguins[penguins['species'] == species] line = ax.scatter(data['flipper_length_mm'], data['bill_length_mm'], label=species, alpha=0.7) lines.append(line) # Add checkboxes rax = plt.axes([0.02, 0.5, 0.15, 0.15]) check = CheckButtons(rax, species_list, [True] * len(species_list)) def toggle_species(label): index = species_list.tolist().index(label) lines[index].set_visible(not lines[index].get_visible()) plt.draw() check.on_clicked(toggle_species) ax.legend() plt.show() Integration with Other Libraries Pandas Integration # Direct pandas plotting with seaborn style sns.set_theme() tips.plot(x='total_bill', y='tip', kind='scatter') # Using pandas groupby with seaborn grouped_data = tips.groupby(['day', 'time'])['total_bill'].mean().reset_index() sns.barplot(data=grouped_data, x='day', y='total_bill', hue='time') # Melting data for seaborn tips_long = pd.melt(tips, id_vars=['time', 'day'], value_vars=['total_bill', 'tip']) sns.boxplot(data=tips_long, x='variable', y='value', hue='time') Statistical Testing Integration from scipy.stats import ttest_ind import statannotations.stats as stats_annotations # Statistical annotations on plots ax = sns.boxplot(data=tips, x='time', y='total_bill') # Add significance testing box_pairs = [('Lunch', 'Dinner')] annotator = stats_annotations.Annotator(ax, box_pairs, data=tips, x='time', y='total_bill') annotator.configure(test='t-test_ind', text_format='star') annotator.apply_and_annotate() Machine Learning Integration from sklearn.datasets import load_digits from sklearn.decomposition import PCA from sklearn.cluster import KMeans # Load data digits = load_digits() X, y = digits.data, digits.target # PCA pca = PCA(n_components=2) X_pca = pca.fit_transform(X) # K-means clustering kmeans = KMeans(n_clusters=10, random_state=42) clusters = kmeans.fit_predict(X) # Create DataFrame for seaborn df_ml = pd.DataFrame({ 'PC1': X_pca[:, 0], 'PC2': X_pca[:, 1], 'True_Label': y, 'Cluster': clusters }) # Visualize fig, axes = plt.subplots(1, 2, figsize=(15, 6)) sns.scatterplot(data=df_ml, x='PC1', y='PC2', hue='True_Label', palette='tab10', ax=axes[0]) axes[0].set_title('True Labels') sns.scatterplot(data=df_ml, x='PC1', y='PC2', hue='Cluster', palette='tab10', ax=axes[1]) axes[1].set_title('K-means Clusters') plt.tight_layout() Common Use Cases Exploratory Data Analysis def explore_dataset(df, target_column=None): \"\"\"Comprehensive EDA function using seaborn\"\"\" # Dataset overview print(f\"Dataset shape: {df.shape}\") print(f\"Missing values:\\n{df.isnull().sum()}\") # Numeric columns numeric_cols = df.select_dtypes(include=[np.number]).columns # Categorical columns cat_cols = df.select_dtypes(include=['object', 'category']).columns # Correlation heatmap if len(numeric_cols) > 1: plt.figure(figsize=(10, 8)) sns.heatmap(df[numeric_cols].corr(), annot=True, cmap='coolwarm', center=0) plt.title('Correlation Matrix') plt.tight_layout() plt.show() # Distribution plots if len(numeric_cols) > 0: n_cols = min(3, len(numeric_cols)) n_rows = (len(numeric_cols) + n_cols - 1) // n_cols fig, axes = plt.subplots(n_rows, n_cols, figsize=(15, 5*n_rows)) axes = axes.flatten() if n_rows > 1 else [axes] for i, col in enumerate(numeric_cols): if target_column and target_column in df.columns: sns.histplot(data=df, x=col, hue=target_column, ax=axes[i], kde=True) else: sns.histplot(data=df, x=col, ax=axes[i], kde=True) axes[i].set_title(f'Distribution of {col}') plt.tight_layout() plt.show() # Pairplot if len(numeric_cols) > 1 and len(numeric_cols) <= 6: if target_column and target_column in df.columns: sns.pairplot(df, vars=numeric_cols, hue=target_column) else: sns.pairplot(df[numeric_cols]) plt.show() # Usage explore_dataset(tips, target_column='time') Time Series Visualization # Prepare time series data np.random.seed(42) dates = pd.date_range('2020-01-01', periods=365, freq='D') values = np.cumsum(np.random.randn(365)) + 100 ts_data = pd.DataFrame({'date': dates, 'value': values}) ts_data['month'] = ts_data['date'].dt.month ts_data['day_of_week'] = ts_data['date'].dt.day_name() # Time series plots fig, axes = plt.subplots(3, 1, figsize=(15, 12)) # Line plot sns.lineplot(data=ts_data, x='date', y='value', ax=axes[0]) axes[0].set_title('Time Series') # Monthly boxplot sns.boxplot(data=ts_data, x='month', y='value', ax=axes[1]) axes[1].set_title('Monthly Distribution') # Day of week pattern day_order = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday'] sns.boxplot(data=ts_data, x='day_of_week', y='value', order=day_order, ax=axes[2]) axes[2].set_title('Day of Week Pattern') axes[2].tick_params(axis='x', rotation=45) plt.tight_layout() plt.show() Scientific Publication Plots def publication_plot(): \"\"\"Create publication-ready plots\"\"\" # Set publication style sns.set_theme(style=\"white\", context=\"paper\", font_scale=1.2) # Create figure with specific size (for journal requirements) fig = plt.figure(figsize=(8.5, 11)) # US Letter size # Multiple subplots gs = fig.add_gridspec(3, 2, height_ratios=[1, 1, 1.2]) # Plot A: Scatter with regression ax1 = fig.add_subplot(gs[0, 0]) sns.scatterplot(data=tips, x=\"total_bill\", y=\"tip\", alpha=0.6, ax=ax1) sns.regplot(data=tips, x=\"total_bill\", y=\"tip\", scatter=False, color='red', ax=ax1) ax1.set_title('A', fontweight='bold', loc='left') ax1.set_xlabel('Total Bill ($)') ax1.set_ylabel('Tip ($)') # Plot B: Box plot with statistics ax2 = fig.add_subplot(gs[0, 1]) sns.boxplot(data=tips, x=\"time\", y=\"total_bill\", ax=ax2) ax2.set_title('B', fontweight='bold', loc='left') ax2.set_xlabel('Time') ax2.set_ylabel('Total Bill ($)') # Plot C: Violin plot ax3 = fig.add_subplot(gs[1, :]) sns.violinplot(data=tips, x=\"day\", y=\"total_bill\", hue=\"time\", ax=ax3) ax3.set_title('C', fontweight='bold', loc='left') ax3.set_xlabel('Day of Week') ax3.set_ylabel('Total Bill ($)') # Plot D: Correlation heatmap ax4 = fig.add_subplot(gs[2, :]) corr = tips.select_dtypes(include=[np.number]).corr() sns.heatmap(corr, annot=True, cmap='RdBu_r', center=0, ax=ax4, square=True, fmt='.2f') ax4.set_title('D', fontweight='bold', loc='left') # Remove spines for cleaner look for ax in [ax1, ax2, ax3]: sns.despine(ax=ax) plt.tight_layout() return fig # Create and save publication plot fig = publication_plot() fig.savefig('publication_plot.pdf', dpi=300, bbox_inches='tight', facecolor='white', edgecolor='none') plt.show() Best Practices Performance Tips # Use appropriate figure sizes sns.set_context(\"notebook\") # Instead of making everything larger # Efficient color palettes # Good: Use built-in palettes sns.set_palette(\"husl\") # Avoid: Creating custom palettes repeatedly in loops # for i in range(100): # custom_palette = [\"#FF6B6B\", \"#4ECDC4\", \"#45B7D1\"] # Inefficient # Batch processing for multiple plots def create_multiple_plots(data, columns): \"\"\"Efficiently create multiple plots\"\"\" n_cols = len(columns) fig, axes = plt.subplots(1, n_cols, figsize=(5*n_cols, 5)) for i, col in enumerate(columns): ax = axes[i] if n_cols > 1 else axes sns.histplot(data=data, x=col, ax=ax) ax.set_title(col) plt.tight_layout() return fig Memory Management # For large datasets, sample data def plot_large_dataset(df, sample_size=10000): \"\"\"Handle large datasets efficiently\"\"\" if len(df) > sample_size: df_sample = df.sample(n=sample_size, random_state=42) print(f\"Sampling {sample_size} rows from {len(df)} total rows\") else: df_sample = df return sns.scatterplot(data=df_sample, x='x', y='y') # Close figures to free memory plt.close('all') # Close all figures plt.close(fig) # Close specific figure Aesthetic Consistency # Create consistent style function def set_publication_style(): \"\"\"Set consistent publication-ready style\"\"\" sns.set_theme( style=\"white\", context=\"paper\", font_scale=1.2, rc={ \"axes.spines.right\": False, \"axes.spines.top\": False, \"axes.grid\": True, \"axes.grid.alpha\": 0.3, \"figure.facecolor\": \"white\", \"axes.facecolor\": \"white\" } ) # Use consistent color schemes COLORS = { 'primary': '#1f77b4', 'secondary': '#ff7f0e', 'success': '#2ca02c', 'danger': '#d62728', 'warning': '#ff7f0e', 'info': '#17a2b8', 'light': '#f8f9fa', 'dark': '#343a40' } # Apply consistent colors sns.scatterplot(data=tips, x=\"total_bill\", y=\"tip\", color=COLORS['primary']) Troubleshooting Common Issues Data Format Issues # Ensure proper data types def prepare_data_for_seaborn(df): \"\"\"Prepare DataFrame for seaborn plotting\"\"\" df = df.copy() # Convert categorical variables for col in df.select_dtypes(include=['object']).columns: if df[col].nunique() < 10: # Arbitrary threshold df[col] = df[col].astype('category') # Handle datetime columns datetime_cols = df.select_dtypes(include=['datetime64']).columns for col in datetime_cols: df[f'{col}_year'] = df[col].dt.year df[f'{col}_month'] = df[col].dt.month return df # Handle missing values def handle_missing_data(df, strategy='drop'): \"\"\"Handle missing data for plotting\"\"\" if strategy == 'drop': return df.dropna() elif strategy == 'fill_numeric': df_clean = df.copy() numeric_cols = df_clean.select_dtypes(include=[np.number]).columns df_clean[numeric_cols] = df_clean[numeric_cols].fillna(df_clean[numeric_cols].mean()) return df_clean return df Plot Customization Issues # Fix overlapping labels def fix_overlapping_labels(ax): \"\"\"Fix common label overlap issues\"\"\" plt.setp(ax.get_xticklabels(), rotation=45, ha='right') plt.tight_layout() # Handle legend issues def fix_legend_issues(ax, title=None, loc='best'): \"\"\"Standardize legend appearance\"\"\" legend = ax.legend(title=title, loc=loc, frameon=True, fancybox=True, shadow=True) legend.get_frame().set_facecolor('white') legend.get_frame().set_alpha(0.9) # Consistent axis formatting def format_axes(ax, xlabel=None, ylabel=None, title=None): \"\"\"Apply consistent axis formatting\"\"\" if xlabel: ax.set_xlabel(xlabel, fontweight='bold') if ylabel: ax.set_ylabel(ylabel, fontweight='bold') if title: ax.set_title(title, fontweight='bold', pad=20) # Format tick labels ax.tick_params(axis='both', which='major', labelsize=10) return ax Quick Reference Essential Functions Function Purpose Example sns.scatterplot() Scatter plot sns.scatterplot(data=df, x='x', y='y', hue='category') sns.lineplot() Line plot sns.lineplot(data=df, x='time', y='value') sns.histplot() Histogram sns.histplot(data=df, x='values', hue='group') sns.boxplot() Box plot sns.boxplot(data=df, x='category', y='values') sns.heatmap() Heat map sns.heatmap(df.corr(), annot=True) sns.pairplot() Pair plot sns.pairplot(data=df, hue='species') Figure-Level Functions Function Axes-Level Equivalent Use Case sns.relplot() sns.scatterplot() , sns.lineplot() Relationships with faceting sns.displot() sns.histplot() , sns.kdeplot() , sns.ecdfplot() Distributions with faceting sns.catplot() sns.boxplot() , sns.violinplot() , etc. Categories with faceting sns.lmplot() sns.regplot() Linear models with faceting Common Parameters Parameter Purpose Values data DataFrame pandas DataFrame x , y Variables to plot Column names hue Grouping variable (color) Column name style Grouping variable (style) Column name size Grouping variable (size) Column name col , row Faceting variables Column names palette Color palette 'viridis', 'Set1', custom list alpha Transparency 0.0 to 1.0 Color Palettes Type Examples Use Case Qualitative 'Set1', 'tab10', 'husl' Categorical data Sequential 'viridis', 'Blues', 'rocket' Ordered data Diverging 'RdBu', 'coolwarm', 'vlag' Data with meaningful center Styling Contexts Context Use Case Relative Size paper Journal figures Smallest notebook Jupyter notebooks Default talk Presentations Larger poster Conference posters Largest","title":"Seaborn"},{"location":"python/seaborn/#seaborn","text":"","title":"Seaborn"},{"location":"python/seaborn/#installation","text":"# Basic installation pip install seaborn # With all optional dependencies pip install seaborn[all] # Development version pip install git+https://github.com/mwaskom/seaborn.git # Check version python -c \"import seaborn as sns; print(sns.__version__)\" # List available datasets python -c \"import seaborn as sns; print(sns.get_dataset_names())\"","title":"Installation"},{"location":"python/seaborn/#basic-setup","text":"# Essential imports import seaborn as sns import matplotlib.pyplot as plt import pandas as pd import numpy as np # Apply default theme sns.set_theme() # Alternative: set specific style sns.set_theme(style=\"whitegrid\", palette=\"pastel\") # Load sample dataset tips = sns.load_dataset(\"tips\") flights = sns.load_dataset(\"flights\") iris = sns.load_dataset(\"iris\") penguins = sns.load_dataset(\"penguins\")","title":"Basic Setup"},{"location":"python/seaborn/#core-functionality","text":"","title":"Core Functionality"},{"location":"python/seaborn/#built-in-datasets","text":"# Available datasets dataset_names = sns.get_dataset_names() print(dataset_names) # Load specific datasets tips = sns.load_dataset(\"tips\") # Restaurant tips flights = sns.load_dataset(\"flights\") # Airline passenger data iris = sns.load_dataset(\"iris\") # Iris flower measurements penguins = sns.load_dataset(\"penguins\") # Palmer penguin data mpg = sns.load_dataset(\"mpg\") # Car fuel efficiency titanic = sns.load_dataset(\"titanic\") # Titanic passenger data diamonds = sns.load_dataset(\"diamonds\") # Diamond characteristics fmri = sns.load_dataset(\"fmri\") # fMRI brain imaging data # Explore dataset structure print(tips.head()) print(tips.info()) print(tips.describe())","title":"Built-in Datasets"},{"location":"python/seaborn/#figure-level-vs-axes-level-functions","text":"# Figure-level functions (create entire figure with subplots) sns.relplot() # Relationships (scatter, line) sns.displot() # Distributions (hist, kde, ecdf) sns.catplot() # Categorical (bar, box, violin, etc.) sns.lmplot() # Linear model fits sns.FacetGrid() # General-purpose faceting # Axes-level functions (work with matplotlib axes) sns.scatterplot() # Scatter plot sns.lineplot() # Line plot sns.histplot() # Histogram sns.kdeplot() # Kernel density estimate sns.boxplot() # Box plot sns.barplot() # Bar plot sns.heatmap() # Heat map","title":"Figure-Level vs Axes-Level Functions"},{"location":"python/seaborn/#relational-plots","text":"","title":"Relational Plots"},{"location":"python/seaborn/#scatter-plots","text":"# Basic scatter plot sns.scatterplot(data=tips, x=\"total_bill\", y=\"tip\") # With categorical encoding sns.scatterplot(data=tips, x=\"total_bill\", y=\"tip\", hue=\"time\", style=\"smoker\") # With size encoding sns.scatterplot(data=tips, x=\"total_bill\", y=\"tip\", size=\"size\", hue=\"time\") # Figure-level with faceting sns.relplot(data=tips, x=\"total_bill\", y=\"tip\", col=\"time\", hue=\"smoker\", style=\"smoker\") # Advanced customization sns.relplot(data=tips, x=\"total_bill\", y=\"tip\", hue=\"time\", size=\"size\", style=\"sex\", palette=[\"blue\", \"red\"], sizes=(20, 200), height=5, aspect=1.2)","title":"Scatter Plots"},{"location":"python/seaborn/#line-plots","text":"# Basic line plot fmri = sns.load_dataset(\"fmri\") sns.lineplot(data=fmri, x=\"timepoint\", y=\"signal\") # With confidence intervals sns.lineplot(data=fmri, x=\"timepoint\", y=\"signal\", hue=\"event\") # Multiple grouping variables sns.lineplot(data=fmri, x=\"timepoint\", y=\"signal\", hue=\"region\", style=\"event\") # Figure-level line plots with faceting sns.relplot(data=fmri, kind=\"line\", x=\"timepoint\", y=\"signal\", col=\"region\", hue=\"event\", style=\"event\") # Time series with dates flights_wide = flights.pivot(index=\"year\", columns=\"month\", values=\"passengers\") flights_wide.index = pd.date_range(\"1949\", periods=12, freq=\"AS\") sns.lineplot(data=flights_wide.T)","title":"Line Plots"},{"location":"python/seaborn/#distribution-plots","text":"","title":"Distribution Plots"},{"location":"python/seaborn/#histograms","text":"# Basic histogram sns.histplot(data=penguins, x=\"flipper_length_mm\") # With grouping sns.histplot(data=penguins, x=\"flipper_length_mm\", hue=\"species\") # Stacked histogram sns.histplot(data=penguins, x=\"flipper_length_mm\", hue=\"species\", multiple=\"stack\") # Density histogram sns.histplot(data=penguins, x=\"flipper_length_mm\", stat=\"density\") # 2D histogram sns.histplot(data=penguins, x=\"flipper_length_mm\", y=\"bill_length_mm\") # Figure-level distributions sns.displot(data=penguins, x=\"flipper_length_mm\", col=\"species\") sns.displot(data=penguins, x=\"flipper_length_mm\", hue=\"species\", kind=\"kde\")","title":"Histograms"},{"location":"python/seaborn/#kde-plots","text":"# Basic KDE sns.kdeplot(data=penguins, x=\"flipper_length_mm\") # Multiple distributions sns.kdeplot(data=penguins, x=\"flipper_length_mm\", hue=\"species\") # Filled KDE sns.kdeplot(data=penguins, x=\"flipper_length_mm\", hue=\"species\", fill=True) # 2D KDE sns.kdeplot(data=penguins, x=\"flipper_length_mm\", y=\"bill_length_mm\") # Bivariate with contours sns.kdeplot(data=penguins, x=\"flipper_length_mm\", y=\"bill_length_mm\", levels=5, thresh=0.1) # Combined histogram and KDE sns.histplot(data=penguins, x=\"flipper_length_mm\", kde=True)","title":"KDE Plots"},{"location":"python/seaborn/#ecdf-plots","text":"# Empirical Cumulative Distribution Function sns.ecdfplot(data=penguins, x=\"flipper_length_mm\") # With grouping sns.ecdfplot(data=penguins, x=\"flipper_length_mm\", hue=\"species\") # Complementary ECDF sns.ecdfplot(data=penguins, x=\"flipper_length_mm\", complementary=True) # Figure-level ECDF sns.displot(data=penguins, x=\"flipper_length_mm\", kind=\"ecdf\", col=\"species\", height=4)","title":"ECDF Plots"},{"location":"python/seaborn/#categorical-plots","text":"","title":"Categorical Plots"},{"location":"python/seaborn/#bar-plots","text":"# Basic bar plot (shows mean with confidence interval) sns.barplot(data=tips, x=\"day\", y=\"total_bill\") # With grouping sns.barplot(data=tips, x=\"day\", y=\"total_bill\", hue=\"time\") # Different estimator sns.barplot(data=tips, x=\"day\", y=\"total_bill\", estimator=np.median) # Count plot (frequency of categories) sns.countplot(data=tips, x=\"day\") sns.countplot(data=tips, x=\"day\", hue=\"time\") # Horizontal bar plot sns.barplot(data=tips, x=\"total_bill\", y=\"day\", orient=\"h\")","title":"Bar Plots"},{"location":"python/seaborn/#box-and-violin-plots","text":"# Box plots sns.boxplot(data=tips, x=\"day\", y=\"total_bill\") sns.boxplot(data=tips, x=\"day\", y=\"total_bill\", hue=\"smoker\") # Violin plots sns.violinplot(data=tips, x=\"day\", y=\"total_bill\") sns.violinplot(data=tips, x=\"day\", y=\"total_bill\", hue=\"smoker\", split=True) # Box plot with strip plot overlay sns.boxplot(data=tips, x=\"day\", y=\"total_bill\", color=\"lightgray\") sns.stripplot(data=tips, x=\"day\", y=\"total_bill\", size=4, jitter=True)","title":"Box and Violin Plots"},{"location":"python/seaborn/#point-and-strip-plots","text":"# Strip plot (categorical scatter) sns.stripplot(data=tips, x=\"day\", y=\"total_bill\") # Swarm plot (non-overlapping points) sns.swarmplot(data=tips, x=\"day\", y=\"total_bill\") # Point plot (connect means) sns.pointplot(data=tips, x=\"day\", y=\"total_bill\", hue=\"time\") # Figure-level categorical plots sns.catplot(data=tips, x=\"day\", y=\"total_bill\", kind=\"violin\", col=\"time\", hue=\"smoker\") sns.catplot(data=tips, x=\"day\", y=\"total_bill\", kind=\"swarm\", row=\"time\", col=\"sex\")","title":"Point and Strip Plots"},{"location":"python/seaborn/#statistical-visualizations","text":"","title":"Statistical Visualizations"},{"location":"python/seaborn/#regression-plots","text":"# Simple linear regression sns.regplot(data=tips, x=\"total_bill\", y=\"tip\") # Without regression line sns.regplot(data=tips, x=\"total_bill\", y=\"tip\", fit_reg=False) # Different regression order sns.regplot(data=tips, x=\"total_bill\", y=\"tip\", order=2) # Logistic regression sns.regplot(data=tips, x=\"total_bill\", y=\"tip\", logistic=True) # Linear model plot with faceting sns.lmplot(data=tips, x=\"total_bill\", y=\"tip\", col=\"time\", hue=\"smoker\") # Residual plots sns.residplot(data=tips, x=\"total_bill\", y=\"tip\")","title":"Regression Plots"},{"location":"python/seaborn/#pair-plots","text":"# Pairwise relationships sns.pairplot(data=iris) # With categorical encoding sns.pairplot(data=iris, hue=\"species\") # Subset of variables sns.pairplot(data=iris, vars=[\"sepal_length\", \"sepal_width\"], hue=\"species\") # Different plot types on diagonal sns.pairplot(data=iris, hue=\"species\", diag_kind=\"kde\") # Custom plot types sns.pairplot(data=iris, hue=\"species\", plot_kws={\"alpha\": 0.6}, diag_kws={\"shade\": True})","title":"Pair Plots"},{"location":"python/seaborn/#joint-plots","text":"# Basic joint plot sns.jointplot(data=tips, x=\"total_bill\", y=\"tip\") # Different plot types sns.jointplot(data=tips, x=\"total_bill\", y=\"tip\", kind=\"reg\") sns.jointplot(data=tips, x=\"total_bill\", y=\"tip\", kind=\"hex\") sns.jointplot(data=tips, x=\"total_bill\", y=\"tip\", kind=\"kde\") # With categorical data sns.jointplot(data=penguins, x=\"flipper_length_mm\", y=\"bill_length_mm\", hue=\"species\") # Custom marginal plots g = sns.jointplot(data=penguins, x=\"flipper_length_mm\", y=\"bill_length_mm\") g.plot_joint(sns.kdeplot, color=\"r\", zorder=0, levels=6) g.plot_marginals(sns.rugplot, color=\"r\", height=-0.15)","title":"Joint Plots"},{"location":"python/seaborn/#multi-plot-grids","text":"","title":"Multi-plot Grids"},{"location":"python/seaborn/#facetgrid","text":"# Create FacetGrid g = sns.FacetGrid(tips, col=\"time\", row=\"smoker\", margin_titles=True) # Map function to each facet g.map(sns.scatterplot, \"total_bill\", \"tip\", alpha=0.7) g.add_legend() # Different functions for different positions g = sns.FacetGrid(tips, col=\"time\", hue=\"smoker\") g.map(plt.scatter, \"total_bill\", \"tip\", alpha=0.7) g.add_legend() # Custom function def scatter_with_corr(x, y, **kwargs): ax = plt.gca() corr = np.corrcoef(x, y)[0, 1] ax.annotate(f'r = {corr:.2f}', xy=(0.1, 0.9), xycoords=ax.transAxes) ax.scatter(x, y, **kwargs) g = sns.FacetGrid(tips, col=\"time\") g.map(scatter_with_corr, \"total_bill\", \"tip\")","title":"FacetGrid"},{"location":"python/seaborn/#pairgrid","text":"# Create PairGrid g = sns.PairGrid(iris, hue=\"species\") # Map different plot types g.map_diag(sns.histplot) g.map_offdiag(sns.scatterplot) g.add_legend() # Different plots for upper and lower triangles g = sns.PairGrid(iris) g.map_upper(sns.scatterplot) g.map_lower(sns.kdeplot, fill=True) g.map_diag(sns.histplot, kde=True)","title":"PairGrid"},{"location":"python/seaborn/#jointgrid","text":"# Create JointGrid g = sns.JointGrid(data=penguins, x=\"flipper_length_mm\", y=\"bill_length_mm\") # Add plots g.plot(sns.scatterplot, sns.histplot) # Custom styling g = sns.JointGrid(data=penguins, x=\"flipper_length_mm\", y=\"bill_length_mm\") g.plot(sns.scatterplot, sns.histplot, alpha=0.7, edgecolor=\".2\", linewidth=0.5) # Mixed plot types g = sns.JointGrid(data=penguins, x=\"flipper_length_mm\", y=\"bill_length_mm\") g.plot(sns.regplot, sns.boxplot)","title":"JointGrid"},{"location":"python/seaborn/#heat-maps","text":"","title":"Heat Maps"},{"location":"python/seaborn/#basic-heat-maps","text":"# Correlation matrix corr = tips.corr(numeric_only=True) sns.heatmap(corr) # With annotations sns.heatmap(corr, annot=True, cmap='coolwarm', center=0) # Custom formatting sns.heatmap(corr, annot=True, fmt='.2f', square=True, linewidths=0.5, cbar_kws={\"shrink\": 0.8}) # Pivot table heatmap flights_pivot = flights.pivot(index=\"month\", columns=\"year\", values=\"passengers\") sns.heatmap(flights_pivot, cmap=\"YlOrRd\")","title":"Basic Heat Maps"},{"location":"python/seaborn/#cluster-map","text":"# Hierarchical clustering iris_num = iris.select_dtypes(include=[np.number]) sns.clustermap(iris_num, cmap='viridis', standard_scale=1) # With annotations sns.clustermap(corr, annot=True, cmap='RdBu_r', center=0) # Control clustering sns.clustermap(flights_pivot, col_cluster=False, cmap='Blues')","title":"Cluster Map"},{"location":"python/seaborn/#styling-and-themes","text":"","title":"Styling and Themes"},{"location":"python/seaborn/#built-in-themes","text":"# Available styles print(sns.axes_style.__doc__) # Set different styles styles = ['darkgrid', 'whitegrid', 'dark', 'white', 'ticks'] for style in styles: sns.set_theme(style=style) plt.figure(figsize=(6, 4)) sns.lineplot(data=fmri.query('region==\"frontal\"'), x=\"timepoint\", y=\"signal\", hue=\"event\") plt.title(f'Style: {style}') plt.show()","title":"Built-in Themes"},{"location":"python/seaborn/#color-palettes","text":"# Qualitative palettes sns.color_palette(\"deep\") # Default seaborn colors sns.color_palette(\"muted\") # Muted version sns.color_palette(\"bright\") # Bright version sns.color_palette(\"pastel\") # Pastel version sns.color_palette(\"dark\") # Dark version # Sequential palettes sns.color_palette(\"Blues\") # Single hue sns.color_palette(\"viridis\") # Perceptually uniform sns.color_palette(\"rocket\") # Seaborn sequential # Diverging palettes sns.color_palette(\"RdBu\") # Red-Blue diverging sns.color_palette(\"coolwarm\") # Cool-warm sns.color_palette(\"vlag\") # Seaborn diverging # Custom palettes colors = [\"#FF6B6B\", \"#4ECDC4\", \"#45B7D1\", \"#96CEB4\", \"#FFEAA7\"] sns.set_palette(colors) # Using palettes in plots sns.scatterplot(data=tips, x=\"total_bill\", y=\"tip\", hue=\"time\", palette=\"viridis\")","title":"Color Palettes"},{"location":"python/seaborn/#contexts-scaling","text":"# Available contexts contexts = ['paper', 'notebook', 'talk', 'poster'] for context in contexts: sns.set_context(context) plt.figure(figsize=(8, 6)) sns.boxplot(data=tips, x=\"day\", y=\"total_bill\") plt.title(f'Context: {context}') plt.show() # Custom scaling sns.set_context(\"notebook\", font_scale=1.5, rc={\"lines.linewidth\": 2.5})","title":"Contexts (Scaling)"},{"location":"python/seaborn/#custom-styling","text":"# Custom theme dictionary custom_theme = { \"axes.spines.right\": False, \"axes.spines.top\": False, \"axes.grid\": True, \"axes.grid.alpha\": 0.3, \"grid.linewidth\": 0.8, \"font.family\": [\"serif\"], \"font.size\": 12 } # Apply custom theme with sns.axes_style(custom_theme): sns.scatterplot(data=tips, x=\"total_bill\", y=\"tip\", hue=\"time\") # Persistent custom theme sns.set_theme(rc=custom_theme)","title":"Custom Styling"},{"location":"python/seaborn/#despining","text":"# Remove spines sns.despine() # Remove top and right sns.despine(left=True) # Also remove left sns.despine(offset=10) # Offset spines sns.despine(trim=True) # Trim spines to data range # In context plt.figure(figsize=(8, 6)) sns.boxplot(data=tips, x=\"day\", y=\"total_bill\") sns.despine(offset=5, trim=True)","title":"Despining"},{"location":"python/seaborn/#advanced-features","text":"","title":"Advanced Features"},{"location":"python/seaborn/#custom-color-maps-and-normalization","text":"# Custom discrete palette from matplotlib.colors import ListedColormap custom_colors = [\"#FF6B6B\", \"#4ECDC4\", \"#45B7D1\"] custom_cmap = ListedColormap(custom_colors) # Use in heatmap sns.heatmap(flights_pivot, cmap=custom_cmap) # Color normalization from matplotlib.colors import LogNorm, PowerNorm # Log normalization for highly skewed data sns.heatmap(flights_pivot, norm=LogNorm()) # Power normalization sns.heatmap(flights_pivot, norm=PowerNorm(gamma=0.5))","title":"Custom Color Maps and Normalization"},{"location":"python/seaborn/#statistical-annotations","text":"# Add statistical annotations manually from scipy import stats fig, ax = plt.subplots() sns.boxplot(data=tips, x=\"time\", y=\"total_bill\", ax=ax) # Perform statistical test lunch_bills = tips[tips['time'] == 'Lunch']['total_bill'] dinner_bills = tips[tips['time'] == 'Dinner']['total_bill'] t_stat, p_value = stats.ttest_ind(lunch_bills, dinner_bills) # Add annotation ax.text(0.5, 0.95, f'p-value: {p_value:.4f}', transform=ax.transAxes, ha='center', va='top', bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))","title":"Statistical Annotations"},{"location":"python/seaborn/#interactive-elements","text":"# Using matplotlib widgets with seaborn from matplotlib.widgets import CheckButtons # Create plot fig, ax = plt.subplots(figsize=(10, 6)) species_list = penguins['species'].unique() lines = [] for species in species_list: data = penguins[penguins['species'] == species] line = ax.scatter(data['flipper_length_mm'], data['bill_length_mm'], label=species, alpha=0.7) lines.append(line) # Add checkboxes rax = plt.axes([0.02, 0.5, 0.15, 0.15]) check = CheckButtons(rax, species_list, [True] * len(species_list)) def toggle_species(label): index = species_list.tolist().index(label) lines[index].set_visible(not lines[index].get_visible()) plt.draw() check.on_clicked(toggle_species) ax.legend() plt.show()","title":"Interactive Elements"},{"location":"python/seaborn/#integration-with-other-libraries","text":"","title":"Integration with Other Libraries"},{"location":"python/seaborn/#pandas-integration","text":"# Direct pandas plotting with seaborn style sns.set_theme() tips.plot(x='total_bill', y='tip', kind='scatter') # Using pandas groupby with seaborn grouped_data = tips.groupby(['day', 'time'])['total_bill'].mean().reset_index() sns.barplot(data=grouped_data, x='day', y='total_bill', hue='time') # Melting data for seaborn tips_long = pd.melt(tips, id_vars=['time', 'day'], value_vars=['total_bill', 'tip']) sns.boxplot(data=tips_long, x='variable', y='value', hue='time')","title":"Pandas Integration"},{"location":"python/seaborn/#statistical-testing-integration","text":"from scipy.stats import ttest_ind import statannotations.stats as stats_annotations # Statistical annotations on plots ax = sns.boxplot(data=tips, x='time', y='total_bill') # Add significance testing box_pairs = [('Lunch', 'Dinner')] annotator = stats_annotations.Annotator(ax, box_pairs, data=tips, x='time', y='total_bill') annotator.configure(test='t-test_ind', text_format='star') annotator.apply_and_annotate()","title":"Statistical Testing Integration"},{"location":"python/seaborn/#machine-learning-integration","text":"from sklearn.datasets import load_digits from sklearn.decomposition import PCA from sklearn.cluster import KMeans # Load data digits = load_digits() X, y = digits.data, digits.target # PCA pca = PCA(n_components=2) X_pca = pca.fit_transform(X) # K-means clustering kmeans = KMeans(n_clusters=10, random_state=42) clusters = kmeans.fit_predict(X) # Create DataFrame for seaborn df_ml = pd.DataFrame({ 'PC1': X_pca[:, 0], 'PC2': X_pca[:, 1], 'True_Label': y, 'Cluster': clusters }) # Visualize fig, axes = plt.subplots(1, 2, figsize=(15, 6)) sns.scatterplot(data=df_ml, x='PC1', y='PC2', hue='True_Label', palette='tab10', ax=axes[0]) axes[0].set_title('True Labels') sns.scatterplot(data=df_ml, x='PC1', y='PC2', hue='Cluster', palette='tab10', ax=axes[1]) axes[1].set_title('K-means Clusters') plt.tight_layout()","title":"Machine Learning Integration"},{"location":"python/seaborn/#common-use-cases","text":"","title":"Common Use Cases"},{"location":"python/seaborn/#exploratory-data-analysis","text":"def explore_dataset(df, target_column=None): \"\"\"Comprehensive EDA function using seaborn\"\"\" # Dataset overview print(f\"Dataset shape: {df.shape}\") print(f\"Missing values:\\n{df.isnull().sum()}\") # Numeric columns numeric_cols = df.select_dtypes(include=[np.number]).columns # Categorical columns cat_cols = df.select_dtypes(include=['object', 'category']).columns # Correlation heatmap if len(numeric_cols) > 1: plt.figure(figsize=(10, 8)) sns.heatmap(df[numeric_cols].corr(), annot=True, cmap='coolwarm', center=0) plt.title('Correlation Matrix') plt.tight_layout() plt.show() # Distribution plots if len(numeric_cols) > 0: n_cols = min(3, len(numeric_cols)) n_rows = (len(numeric_cols) + n_cols - 1) // n_cols fig, axes = plt.subplots(n_rows, n_cols, figsize=(15, 5*n_rows)) axes = axes.flatten() if n_rows > 1 else [axes] for i, col in enumerate(numeric_cols): if target_column and target_column in df.columns: sns.histplot(data=df, x=col, hue=target_column, ax=axes[i], kde=True) else: sns.histplot(data=df, x=col, ax=axes[i], kde=True) axes[i].set_title(f'Distribution of {col}') plt.tight_layout() plt.show() # Pairplot if len(numeric_cols) > 1 and len(numeric_cols) <= 6: if target_column and target_column in df.columns: sns.pairplot(df, vars=numeric_cols, hue=target_column) else: sns.pairplot(df[numeric_cols]) plt.show() # Usage explore_dataset(tips, target_column='time')","title":"Exploratory Data Analysis"},{"location":"python/seaborn/#time-series-visualization","text":"# Prepare time series data np.random.seed(42) dates = pd.date_range('2020-01-01', periods=365, freq='D') values = np.cumsum(np.random.randn(365)) + 100 ts_data = pd.DataFrame({'date': dates, 'value': values}) ts_data['month'] = ts_data['date'].dt.month ts_data['day_of_week'] = ts_data['date'].dt.day_name() # Time series plots fig, axes = plt.subplots(3, 1, figsize=(15, 12)) # Line plot sns.lineplot(data=ts_data, x='date', y='value', ax=axes[0]) axes[0].set_title('Time Series') # Monthly boxplot sns.boxplot(data=ts_data, x='month', y='value', ax=axes[1]) axes[1].set_title('Monthly Distribution') # Day of week pattern day_order = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday'] sns.boxplot(data=ts_data, x='day_of_week', y='value', order=day_order, ax=axes[2]) axes[2].set_title('Day of Week Pattern') axes[2].tick_params(axis='x', rotation=45) plt.tight_layout() plt.show()","title":"Time Series Visualization"},{"location":"python/seaborn/#scientific-publication-plots","text":"def publication_plot(): \"\"\"Create publication-ready plots\"\"\" # Set publication style sns.set_theme(style=\"white\", context=\"paper\", font_scale=1.2) # Create figure with specific size (for journal requirements) fig = plt.figure(figsize=(8.5, 11)) # US Letter size # Multiple subplots gs = fig.add_gridspec(3, 2, height_ratios=[1, 1, 1.2]) # Plot A: Scatter with regression ax1 = fig.add_subplot(gs[0, 0]) sns.scatterplot(data=tips, x=\"total_bill\", y=\"tip\", alpha=0.6, ax=ax1) sns.regplot(data=tips, x=\"total_bill\", y=\"tip\", scatter=False, color='red', ax=ax1) ax1.set_title('A', fontweight='bold', loc='left') ax1.set_xlabel('Total Bill ($)') ax1.set_ylabel('Tip ($)') # Plot B: Box plot with statistics ax2 = fig.add_subplot(gs[0, 1]) sns.boxplot(data=tips, x=\"time\", y=\"total_bill\", ax=ax2) ax2.set_title('B', fontweight='bold', loc='left') ax2.set_xlabel('Time') ax2.set_ylabel('Total Bill ($)') # Plot C: Violin plot ax3 = fig.add_subplot(gs[1, :]) sns.violinplot(data=tips, x=\"day\", y=\"total_bill\", hue=\"time\", ax=ax3) ax3.set_title('C', fontweight='bold', loc='left') ax3.set_xlabel('Day of Week') ax3.set_ylabel('Total Bill ($)') # Plot D: Correlation heatmap ax4 = fig.add_subplot(gs[2, :]) corr = tips.select_dtypes(include=[np.number]).corr() sns.heatmap(corr, annot=True, cmap='RdBu_r', center=0, ax=ax4, square=True, fmt='.2f') ax4.set_title('D', fontweight='bold', loc='left') # Remove spines for cleaner look for ax in [ax1, ax2, ax3]: sns.despine(ax=ax) plt.tight_layout() return fig # Create and save publication plot fig = publication_plot() fig.savefig('publication_plot.pdf', dpi=300, bbox_inches='tight', facecolor='white', edgecolor='none') plt.show()","title":"Scientific Publication Plots"},{"location":"python/seaborn/#best-practices","text":"","title":"Best Practices"},{"location":"python/seaborn/#performance-tips","text":"# Use appropriate figure sizes sns.set_context(\"notebook\") # Instead of making everything larger # Efficient color palettes # Good: Use built-in palettes sns.set_palette(\"husl\") # Avoid: Creating custom palettes repeatedly in loops # for i in range(100): # custom_palette = [\"#FF6B6B\", \"#4ECDC4\", \"#45B7D1\"] # Inefficient # Batch processing for multiple plots def create_multiple_plots(data, columns): \"\"\"Efficiently create multiple plots\"\"\" n_cols = len(columns) fig, axes = plt.subplots(1, n_cols, figsize=(5*n_cols, 5)) for i, col in enumerate(columns): ax = axes[i] if n_cols > 1 else axes sns.histplot(data=data, x=col, ax=ax) ax.set_title(col) plt.tight_layout() return fig","title":"Performance Tips"},{"location":"python/seaborn/#memory-management","text":"# For large datasets, sample data def plot_large_dataset(df, sample_size=10000): \"\"\"Handle large datasets efficiently\"\"\" if len(df) > sample_size: df_sample = df.sample(n=sample_size, random_state=42) print(f\"Sampling {sample_size} rows from {len(df)} total rows\") else: df_sample = df return sns.scatterplot(data=df_sample, x='x', y='y') # Close figures to free memory plt.close('all') # Close all figures plt.close(fig) # Close specific figure","title":"Memory Management"},{"location":"python/seaborn/#aesthetic-consistency","text":"# Create consistent style function def set_publication_style(): \"\"\"Set consistent publication-ready style\"\"\" sns.set_theme( style=\"white\", context=\"paper\", font_scale=1.2, rc={ \"axes.spines.right\": False, \"axes.spines.top\": False, \"axes.grid\": True, \"axes.grid.alpha\": 0.3, \"figure.facecolor\": \"white\", \"axes.facecolor\": \"white\" } ) # Use consistent color schemes COLORS = { 'primary': '#1f77b4', 'secondary': '#ff7f0e', 'success': '#2ca02c', 'danger': '#d62728', 'warning': '#ff7f0e', 'info': '#17a2b8', 'light': '#f8f9fa', 'dark': '#343a40' } # Apply consistent colors sns.scatterplot(data=tips, x=\"total_bill\", y=\"tip\", color=COLORS['primary'])","title":"Aesthetic Consistency"},{"location":"python/seaborn/#troubleshooting-common-issues","text":"","title":"Troubleshooting Common Issues"},{"location":"python/seaborn/#data-format-issues","text":"# Ensure proper data types def prepare_data_for_seaborn(df): \"\"\"Prepare DataFrame for seaborn plotting\"\"\" df = df.copy() # Convert categorical variables for col in df.select_dtypes(include=['object']).columns: if df[col].nunique() < 10: # Arbitrary threshold df[col] = df[col].astype('category') # Handle datetime columns datetime_cols = df.select_dtypes(include=['datetime64']).columns for col in datetime_cols: df[f'{col}_year'] = df[col].dt.year df[f'{col}_month'] = df[col].dt.month return df # Handle missing values def handle_missing_data(df, strategy='drop'): \"\"\"Handle missing data for plotting\"\"\" if strategy == 'drop': return df.dropna() elif strategy == 'fill_numeric': df_clean = df.copy() numeric_cols = df_clean.select_dtypes(include=[np.number]).columns df_clean[numeric_cols] = df_clean[numeric_cols].fillna(df_clean[numeric_cols].mean()) return df_clean return df","title":"Data Format Issues"},{"location":"python/seaborn/#plot-customization-issues","text":"# Fix overlapping labels def fix_overlapping_labels(ax): \"\"\"Fix common label overlap issues\"\"\" plt.setp(ax.get_xticklabels(), rotation=45, ha='right') plt.tight_layout() # Handle legend issues def fix_legend_issues(ax, title=None, loc='best'): \"\"\"Standardize legend appearance\"\"\" legend = ax.legend(title=title, loc=loc, frameon=True, fancybox=True, shadow=True) legend.get_frame().set_facecolor('white') legend.get_frame().set_alpha(0.9) # Consistent axis formatting def format_axes(ax, xlabel=None, ylabel=None, title=None): \"\"\"Apply consistent axis formatting\"\"\" if xlabel: ax.set_xlabel(xlabel, fontweight='bold') if ylabel: ax.set_ylabel(ylabel, fontweight='bold') if title: ax.set_title(title, fontweight='bold', pad=20) # Format tick labels ax.tick_params(axis='both', which='major', labelsize=10) return ax","title":"Plot Customization Issues"},{"location":"python/seaborn/#quick-reference","text":"","title":"Quick Reference"},{"location":"python/seaborn/#essential-functions","text":"Function Purpose Example sns.scatterplot() Scatter plot sns.scatterplot(data=df, x='x', y='y', hue='category') sns.lineplot() Line plot sns.lineplot(data=df, x='time', y='value') sns.histplot() Histogram sns.histplot(data=df, x='values', hue='group') sns.boxplot() Box plot sns.boxplot(data=df, x='category', y='values') sns.heatmap() Heat map sns.heatmap(df.corr(), annot=True) sns.pairplot() Pair plot sns.pairplot(data=df, hue='species')","title":"Essential Functions"},{"location":"python/seaborn/#figure-level-functions","text":"Function Axes-Level Equivalent Use Case sns.relplot() sns.scatterplot() , sns.lineplot() Relationships with faceting sns.displot() sns.histplot() , sns.kdeplot() , sns.ecdfplot() Distributions with faceting sns.catplot() sns.boxplot() , sns.violinplot() , etc. Categories with faceting sns.lmplot() sns.regplot() Linear models with faceting","title":"Figure-Level Functions"},{"location":"python/seaborn/#common-parameters","text":"Parameter Purpose Values data DataFrame pandas DataFrame x , y Variables to plot Column names hue Grouping variable (color) Column name style Grouping variable (style) Column name size Grouping variable (size) Column name col , row Faceting variables Column names palette Color palette 'viridis', 'Set1', custom list alpha Transparency 0.0 to 1.0","title":"Common Parameters"},{"location":"python/seaborn/#color-palettes_1","text":"Type Examples Use Case Qualitative 'Set1', 'tab10', 'husl' Categorical data Sequential 'viridis', 'Blues', 'rocket' Ordered data Diverging 'RdBu', 'coolwarm', 'vlag' Data with meaningful center","title":"Color Palettes"},{"location":"python/seaborn/#styling-contexts","text":"Context Use Case Relative Size paper Journal figures Smallest notebook Jupyter notebooks Default talk Presentations Larger poster Conference posters Largest","title":"Styling Contexts"},{"location":"python/sentence-transformers/","text":"Sentence-Transformers (UKPLab) Sentence-Transformers is a Python framework for state-of-the-art sentence, text, and image embeddings. It provides an easy way to compute dense vector representations for sentences, paragraphs, and images, enabling semantic similarity computation, clustering, and semantic search. Installation # Basic installation pip install sentence-transformers # With optional dependencies pip install sentence-transformers[train] # Development version pip install git+https://github.com/UKPLab/sentence-transformers.git # With specific backends pip install sentence-transformers torch torchvision pip install sentence-transformers tensorflow Basic Setup from sentence_transformers import SentenceTransformer, util, InputExample, losses from sentence_transformers.cross_encoder import CrossEncoder from sentence_transformers.evaluation import EmbeddingSimilarityEvaluator import numpy as np import torch from sklearn.metrics.pairwise import cosine_similarity from scipy.spatial.distance import cdist Core Functionality Loading Models # Popular pre-trained models model = SentenceTransformer('all-MiniLM-L6-v2') # Good balance of quality vs speed model = SentenceTransformer('all-mpnet-base-v2') # High quality model = SentenceTransformer('paraphrase-MiniLM-L6-v2') # Paraphrase detection model = SentenceTransformer('multi-qa-MiniLM-L6-cos-v1') # Question answering # Multilingual models model = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2') model = SentenceTransformer('distiluse-base-multilingual-cased-v2') # Specialized models model = SentenceTransformer('msmarco-distilbert-base-v4') # Web search model = SentenceTransformer('nli-distilroberta-base-v2') # Natural language inference # Load from local path model = SentenceTransformer('/path/to/model') # Load with specific device model = SentenceTransformer('all-MiniLM-L6-v2', device='cuda') Basic Encoding # Single sentence encoding sentence = \"This is a sample sentence.\" embedding = model.encode(sentence) print(f\"Embedding shape: {embedding.shape}\") # (384,) for MiniLM models # Multiple sentences sentences = [ \"The weather is lovely today.\", \"It's so sunny outside!\", \"He drove to the stadium.\" ] embeddings = model.encode(sentences) print(f\"Embeddings shape: {embeddings.shape}\") # (3, 384) # Batch processing with progress bar embeddings = model.encode(sentences, show_progress_bar=True) # Convert to tensor embeddings = model.encode(sentences, convert_to_tensor=True) print(type(embeddings)) # torch.Tensor # Normalize embeddings (for cosine similarity) embeddings = model.encode(sentences, normalize_embeddings=True) Similarity Computation # Compute similarity matrix sentences = [ \"The weather is lovely today.\", \"It's so sunny outside!\", \"He drove to the stadium.\" ] embeddings = model.encode(sentences) # Cosine similarity similarities = model.similarity(embeddings, embeddings) print(similarities) # tensor([[1.0000, 0.6660, 0.1046], # [0.6660, 1.0000, 0.1411], # [0.1046, 0.1411, 1.0000]]) # Pairwise similarity similarities = util.pytorch_cos_sim(embeddings, embeddings) # Find most similar pairs pairs = [] for i in range(len(similarities)): for j in range(i+1, len(similarities)): pairs.append((i, j, similarities[i][j].item())) # Sort by similarity pairs.sort(key=lambda x: x[2], reverse=True) print(f\"Most similar pair: sentences {pairs[0][0]} and {pairs[0][1]} with score {pairs[0][2]:.4f}\") Common Use Cases Semantic Search import numpy as np # Create a corpus of documents corpus = [ \"A man is eating food.\", \"A man is eating a piece of bread.\", \"The girl is carrying a baby.\", \"A man is riding a horse.\", \"A woman is playing violin.\", \"Two men pushed carts through the woods.\", \"A man is riding a white horse on an enclosed ground.\", \"A monkey is playing drums.\", \"A cheetah is running behind its prey.\" ] # Encode corpus corpus_embeddings = model.encode(corpus, convert_to_tensor=True) # Query queries = [ \"A man is eating pasta.\", \"Someone in a gorilla costume is playing a set of drums.\", \"A cheetah chases prey on across a field.\" ] # Find the closest 5 sentences to each query top_k = min(5, len(corpus)) for query in queries: query_embedding = model.encode(query, convert_to_tensor=True) # Compute cosine-similarities between query and corpus cos_scores = util.cos_sim(query_embedding, corpus_embeddings)[0] # Sort results top_results = torch.topk(cos_scores, k=top_k) print(f\"\\nQuery: {query}\") print(f\"Top {top_k} most similar sentences in corpus:\") for score, idx in zip(top_results[0], top_results[1]): print(f\"(Score: {score:.4f}) {corpus[idx]}\") Advanced Semantic Search with Faiss import faiss import numpy as np def create_faiss_index(embeddings): \"\"\"Create FAISS index for fast similarity search\"\"\" dimension = embeddings.shape[1] # Create index index = faiss.IndexFlatIP(dimension) # Inner product (cosine with normalized vectors) # Normalize embeddings for cosine similarity embeddings_np = embeddings.cpu().numpy() if hasattr(embeddings, 'cpu') else embeddings faiss.normalize_L2(embeddings_np) # Add embeddings to index index.add(embeddings_np.astype('float32')) return index def semantic_search_faiss(query, model, index, corpus, top_k=5): \"\"\"Perform semantic search using FAISS\"\"\" # Encode query query_embedding = model.encode([query]) # Normalize faiss.normalize_L2(query_embedding) # Search scores, indices = index.search(query_embedding.astype('float32'), top_k) results = [] for score, idx in zip(scores[0], indices[0]): results.append({ 'score': float(score), 'text': corpus[idx], 'index': int(idx) }) return results # Usage corpus_embeddings = model.encode(corpus, convert_to_tensor=True) index = create_faiss_index(corpus_embeddings) query = \"A person is eating food\" results = semantic_search_faiss(query, model, index, corpus) print(f\"Query: {query}\") for result in results: print(f\"Score: {result['score']:.4f} - {result['text']}\") Clustering from sklearn.cluster import KMeans import matplotlib.pyplot as plt # Sample sentences for clustering sentences = [ # Sports \"The football game was exciting.\", \"Basketball is my favorite sport.\", \"Tennis requires good coordination.\", # Food \"This pizza tastes amazing.\", \"I love cooking Italian food.\", \"The restaurant serves great pasta.\", # Technology \"Machine learning is fascinating.\", \"AI will change the world.\", \"Programming languages are evolving.\", # Weather \"It's a beautiful sunny day.\", \"The weather is getting cold.\", \"Rain is expected tomorrow.\" ] # Get embeddings embeddings = model.encode(sentences) # Perform clustering num_clusters = 4 kmeans = KMeans(n_clusters=num_clusters, random_state=42) cluster_assignments = kmeans.fit_predict(embeddings) # Group sentences by cluster clustered_sentences = {} for sentence_id, cluster_id in enumerate(cluster_assignments): if cluster_id not in clustered_sentences: clustered_sentences[cluster_id] = [] clustered_sentences[cluster_id].append(sentences[sentence_id]) # Print results for cluster_id, cluster_sentences in clustered_sentences.items(): print(f\"Cluster {cluster_id + 1}:\") for sentence in cluster_sentences: print(f\" - {sentence}\") print() Paraphrase Detection def find_paraphrases(sentences, threshold=0.7): \"\"\"Find paraphrases in a list of sentences\"\"\" embeddings = model.encode(sentences) similarity_matrix = util.cos_sim(embeddings, embeddings) paraphrases = [] for i in range(len(sentences)): for j in range(i+1, len(sentences)): similarity = similarity_matrix[i][j].item() if similarity > threshold: paraphrases.append({ 'sentence1': sentences[i], 'sentence2': sentences[j], 'similarity': similarity }) return sorted(paraphrases, key=lambda x: x['similarity'], reverse=True) # Example sentences with some paraphrases test_sentences = [ \"The cat is sleeping on the couch.\", \"A feline is resting on the sofa.\", \"The dog is barking loudly.\", \"The weather is nice today.\", \"It's a beautiful day outside.\", \"The car is red.\", \"The canine is making loud sounds.\" ] paraphrases = find_paraphrases(test_sentences, threshold=0.6) print(\"Potential paraphrases found:\") for para in paraphrases: print(f\"Similarity: {para['similarity']:.3f}\") print(f\"1: {para['sentence1']}\") print(f\"2: {para['sentence2']}\") print(\"-\" * 50) Question Answering with Retrieval def qa_retrieval_system(questions, contexts, model, top_k=3): \"\"\"Simple QA retrieval system using sentence embeddings\"\"\" # Encode all contexts context_embeddings = model.encode(contexts, convert_to_tensor=True) results = [] for question in questions: # Encode question question_embedding = model.encode(question, convert_to_tensor=True) # Find most similar contexts similarities = util.cos_sim(question_embedding, context_embeddings)[0] top_indices = torch.topk(similarities, k=min(top_k, len(contexts)))[1] # Get top contexts top_contexts = [contexts[idx] for idx in top_indices] top_scores = [similarities[idx].item() for idx in top_indices] results.append({ 'question': question, 'top_contexts': list(zip(top_contexts, top_scores)) }) return results # Example usage contexts = [ \"Paris is the capital of France and its largest city.\", \"London is the capital of England and the United Kingdom.\", \"Berlin is the capital of Germany.\", \"Madrid is the capital of Spain.\", \"Rome is the capital of Italy and home to Vatican City.\", \"Tokyo is the capital of Japan and the world's most populous metropolitan area.\" ] questions = [ \"What is the capital of France?\", \"Which city is the capital of Germany?\", \"Tell me about the capital of Italy.\" ] qa_results = qa_retrieval_system(questions, contexts, model) for result in qa_results: print(f\"Question: {result['question']}\") print(\"Most relevant contexts:\") for context, score in result['top_contexts']: print(f\" Score: {score:.3f} - {context}\") print() Advanced Features Custom Model Training from sentence_transformers import InputExample, losses from torch.utils.data import DataLoader # Prepare training data train_examples = [ InputExample(texts=['My first sentence', 'My second sentence'], label=0.8), InputExample(texts=['Another pair', 'Completely different'], label=0.3) ] # Create DataLoader train_dataloader = DataLoader(train_examples, shuffle=True, batch_size=16) # Define loss function train_loss = losses.CosineSimilarityLoss(model) # Training model.fit( train_objectives=[(train_dataloader, train_loss)], epochs=1, warmup_steps=100, output_path='./my-sentence-transformer' ) # For triplet training (anchor, positive, negative) train_examples_triplet = [ InputExample(texts=['Anchor sentence', 'Positive sentence', 'Negative sentence']) ] train_dataloader_triplet = DataLoader(train_examples_triplet, shuffle=True, batch_size=16) train_loss_triplet = losses.TripletLoss(model) model.fit( train_objectives=[(train_dataloader_triplet, train_loss_triplet)], epochs=1, output_path='./my-triplet-model' ) Cross-Encoders for Reranking from sentence_transformers.cross_encoder import CrossEncoder # Load cross-encoder model cross_encoder = CrossEncoder('ms-marco-MiniLM-L-6-v2') def rerank_results(query, candidates, cross_encoder, top_k=5): \"\"\"Rerank search results using a cross-encoder\"\"\" # Create query-candidate pairs pairs = [[query, candidate] for candidate in candidates] # Get cross-encoder scores scores = cross_encoder.predict(pairs) # Sort by score ranked_results = sorted(zip(candidates, scores), key=lambda x: x[1], reverse=True) return ranked_results[:top_k] # Example: Two-stage retrieval and reranking def two_stage_search(query, corpus, bi_encoder, cross_encoder, retrieve_top_k=20, rerank_top_k=5): \"\"\"Two-stage search: bi-encoder retrieval + cross-encoder reranking\"\"\" # Stage 1: Fast retrieval with bi-encoder query_embedding = bi_encoder.encode(query, convert_to_tensor=True) corpus_embeddings = bi_encoder.encode(corpus, convert_to_tensor=True) cos_scores = util.cos_sim(query_embedding, corpus_embeddings)[0] top_results = torch.topk(cos_scores, k=min(retrieve_top_k, len(corpus))) # Get candidate texts candidates = [corpus[idx] for idx in top_results[1]] # Stage 2: Reranking with cross-encoder reranked = rerank_results(query, candidates, cross_encoder, rerank_top_k) return reranked # Usage query = \"Information about machine learning\" corpus = [ \"Machine learning is a subset of artificial intelligence.\", \"Deep learning uses neural networks with many layers.\", \"Natural language processing helps computers understand text.\", \"Computer vision enables machines to interpret visual information.\", \"Reinforcement learning trains agents through trial and error.\" ] bi_encoder = SentenceTransformer('all-MiniLM-L6-v2') cross_encoder = CrossEncoder('ms-marco-MiniLM-L-6-v2') results = two_stage_search(query, corpus, bi_encoder, cross_encoder) print(f\"Query: {query}\") print(\"Reranked results:\") for i, (text, score) in enumerate(results, 1): print(f\"{i}. Score: {score:.4f} - {text}\") Multi-lingual Embeddings # Load multilingual model multilingual_model = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2') # Sentences in different languages sentences = [ \"Hello, how are you?\", # English \"Hola, \u00bfc\u00f3mo est\u00e1s?\", # Spanish \"Bonjour, comment allez-vous?\", # French \"Hallo, wie geht es dir?\", # German \"Ciao, come stai?\", # Italian \"\u3053\u3093\u306b\u3061\u306f\u3001\u5143\u6c17\u3067\u3059\u304b\uff1f\", # Japanese \"\u4f60\u597d\uff0c\u4f60\u597d\u5417\uff1f\" # Chinese ] # Get embeddings embeddings = multilingual_model.encode(sentences) # Compute similarity matrix similarity_matrix = util.cos_sim(embeddings, embeddings) print(\"Cross-lingual similarity matrix:\") for i, sent1 in enumerate(sentences): for j, sent2 in enumerate(sentences): if i != j: sim = similarity_matrix[i][j].item() if sim > 0.5: # Only show high similarities print(f\"Similarity: {sim:.3f}\") print(f\" '{sent1}' <-> '{sent2}'\") Working with Images (CLIP) from sentence_transformers import SentenceTransformer from PIL import Image import requests from io import BytesIO # Load CLIP model clip_model = SentenceTransformer('clip-ViT-B-32') # Load images image_urls = [ \"https://example.com/cat.jpg\", \"https://example.com/dog.jpg\" ] images = [] for url in image_urls: response = requests.get(url) img = Image.open(BytesIO(response.content)) images.append(img) # Text descriptions texts = [ \"A photo of a cat\", \"A photo of a dog\", \"A picture of a bird\", \"An image of a car\" ] # Get embeddings image_embeddings = clip_model.encode(images) text_embeddings = clip_model.encode(texts) # Compute similarity between images and texts similarities = util.cos_sim(image_embeddings, text_embeddings) print(\"Image-Text Similarities:\") for i, img_url in enumerate(image_urls): print(f\"\\nImage {i+1}: {img_url}\") for j, text in enumerate(texts): sim = similarities[i][j].item() print(f\" '{text}': {sim:.3f}\") Integration with Other Libraries With Pandas for Data Analysis import pandas as pd # Create sample dataset data = { 'text': [ \"I love this product! It's amazing!\", \"Great quality and fast shipping.\", \"Terrible experience, would not recommend.\", \"Average product, nothing special.\", \"Outstanding customer service!\" ], 'rating': [5, 4, 1, 3, 5] } df = pd.DataFrame(data) # Add embeddings embeddings = model.encode(df['text'].tolist()) df['embedding'] = embeddings.tolist() # Find similar reviews def find_similar_reviews(query_text, df, model, top_k=3): query_embedding = model.encode([query_text]) # Compute similarities similarities = [] for i, row in df.iterrows(): sim = cosine_similarity([query_embedding[0]], [row['embedding']])[0][0] similarities.append(sim) df['similarity'] = similarities return df.nlargest(top_k, 'similarity')[['text', 'rating', 'similarity']] # Usage query = \"excellent customer support\" similar_reviews = find_similar_reviews(query, df, model) print(similar_reviews) With Streamlit for Web Apps import streamlit as st import plotly.express as px from sklearn.manifold import TSNE st.title(\"Sentence Similarity Explorer\") # Text input user_texts = st.text_area(\"Enter sentences (one per line):\", value=\"The weather is nice today.\\nIt's a beautiful day.\\nThe car is red.\") if user_texts: sentences = [s.strip() for s in user_texts.split('\\n') if s.strip()] # Compute embeddings embeddings = model.encode(sentences) # Compute similarity matrix similarity_matrix = util.cos_sim(embeddings, embeddings).numpy() # Display similarity matrix st.subheader(\"Similarity Matrix\") fig = px.imshow(similarity_matrix, labels=dict(x=\"Sentences\", y=\"Sentences\"), text_auto=True) st.plotly_chart(fig) # 2D visualization using t-SNE if len(sentences) > 2: st.subheader(\"2D Embedding Visualization\") tsne = TSNE(n_components=2, random_state=42) embeddings_2d = tsne.fit_transform(embeddings) fig_scatter = px.scatter(x=embeddings_2d[:, 0], y=embeddings_2d[:, 1], hover_data=[sentences], title=\"Sentence Embeddings (t-SNE)\") st.plotly_chart(fig_scatter) Best Practices Performance Optimization # 1. Use appropriate model sizes models_by_performance = { 'fastest': 'all-MiniLM-L6-v2', 'balanced': 'all-mpnet-base-v2', 'highest_quality': 'sentence-transformers/gtr-t5-large' } # 2. Batch processing for large datasets def encode_large_dataset(texts, model, batch_size=32): \"\"\"Efficiently encode large datasets\"\"\" embeddings = [] for i in range(0, len(texts), batch_size): batch = texts[i:i + batch_size] batch_embeddings = model.encode(batch, show_progress_bar=False) embeddings.extend(batch_embeddings) return np.array(embeddings) # 3. Use appropriate precision embeddings = model.encode(sentences, precision='float32') # vs 'float64' # 4. Normalize embeddings if using cosine similarity embeddings = model.encode(sentences, normalize_embeddings=True) # 5. Use GPU when available device = 'cuda' if torch.cuda.is_available() else 'cpu' model = SentenceTransformer('all-MiniLM-L6-v2', device=device) Memory Management import gc from typing import Iterator, List def process_large_corpus(corpus: List[str], model: SentenceTransformer, batch_size: int = 1000) -> Iterator[np.ndarray]: \"\"\"Process large corpus in chunks to manage memory\"\"\" for i in range(0, len(corpus), batch_size): batch = corpus[i:i + batch_size] # Encode batch embeddings = model.encode(batch, convert_to_numpy=True) yield embeddings # Clean up gc.collect() # Usage for very large datasets def save_embeddings_chunked(corpus, model, output_path, batch_size=1000): \"\"\"Save embeddings for large corpus in chunks\"\"\" all_embeddings = [] for chunk_embeddings in process_large_corpus(corpus, model, batch_size): all_embeddings.append(chunk_embeddings) # Concatenate all embeddings final_embeddings = np.vstack(all_embeddings) np.save(output_path, final_embeddings) return final_embeddings Model Selection Guidelines def recommend_model(use_case, performance_priority='balanced'): \"\"\"Recommend model based on use case and performance requirements\"\"\" recommendations = { 'semantic_search': { 'fast': 'all-MiniLM-L6-v2', 'balanced': 'all-mpnet-base-v2', 'quality': 'sentence-transformers/gtr-t5-large' }, 'question_answering': { 'fast': 'multi-qa-MiniLM-L6-cos-v1', 'balanced': 'multi-qa-mpnet-base-cos-v1', 'quality': 'sentence-transformers/gtr-t5-xl' }, 'paraphrase_detection': { 'fast': 'paraphrase-MiniLM-L6-v2', 'balanced': 'paraphrase-mpnet-base-v2', 'quality': 'sentence-transformers/gtr-t5-large' }, 'multilingual': { 'fast': 'paraphrase-multilingual-MiniLM-L12-v2', 'balanced': 'sentence-transformers/LaBSE', 'quality': 'sentence-transformers/paraphrase-multilingual-mpnet-base-v2' } } return recommendations.get(use_case, {}).get(performance_priority, 'all-MiniLM-L6-v2') # Usage model_name = recommend_model('semantic_search', 'fast') print(f\"Recommended model: {model_name}\") Real-world Examples Complete Semantic Search Engine import json import pickle from pathlib import Path from typing import List, Dict, Any class SemanticSearchEngine: def __init__(self, model_name='all-MiniLM-L6-v2'): self.model = SentenceTransformer(model_name) self.documents = [] self.embeddings = None self.index = None def add_documents(self, documents: List[Dict[str, Any]]): \"\"\"Add documents to the search engine\"\"\" self.documents.extend(documents) # Extract text for embedding texts = [doc.get('text', str(doc)) for doc in documents] # Compute embeddings new_embeddings = self.model.encode(texts, convert_to_tensor=True) if self.embeddings is None: self.embeddings = new_embeddings else: self.embeddings = torch.cat([self.embeddings, new_embeddings], dim=0) def search(self, query: str, top_k: int = 5) -> List[Dict[str, Any]]: \"\"\"Search for similar documents\"\"\" if self.embeddings is None: return [] # Encode query query_embedding = self.model.encode(query, convert_to_tensor=True) # Compute similarities cos_scores = util.cos_sim(query_embedding, self.embeddings)[0] # Get top results top_results = torch.topk(cos_scores, k=min(top_k, len(self.documents))) results = [] for score, idx in zip(top_results[0], top_results[1]): doc = self.documents[idx.item()].copy() doc['similarity_score'] = score.item() results.append(doc) return results def save(self, path: str): \"\"\"Save the search engine state\"\"\" state = { 'documents': self.documents, 'embeddings': self.embeddings.cpu().numpy() if self.embeddings is not None else None, 'model_name': self.model._modules['0'].auto_model.config._name_or_path } with open(path, 'wb') as f: pickle.dump(state, f) def load(self, path: str): \"\"\"Load the search engine state\"\"\" with open(path, 'rb') as f: state = pickle.load(f) self.documents = state['documents'] if state['embeddings'] is not None: self.embeddings = torch.tensor(state['embeddings']) # Usage example search_engine = SemanticSearchEngine() # Add documents documents = [ {\"title\": \"Machine Learning Basics\", \"text\": \"Introduction to machine learning algorithms and concepts\", \"category\": \"AI\"}, {\"title\": \"Python Programming\", \"text\": \"Learn Python programming from scratch\", \"category\": \"Programming\"}, {\"title\": \"Data Science Guide\", \"text\": \"Comprehensive guide to data science and analytics\", \"category\": \"Data\"}, {\"title\": \"Neural Networks\", \"text\": \"Deep learning and neural network architectures\", \"category\": \"AI\"}, ] search_engine.add_documents(documents) # Search results = search_engine.search(\"artificial intelligence and machine learning\", top_k=3) print(\"Search Results:\") for i, result in enumerate(results, 1): print(f\"{i}. {result['title']} (Score: {result['similarity_score']:.3f})\") print(f\" Category: {result['category']}\") print(f\" Text: {result['text']}\") print() # Save for later use search_engine.save(\"my_search_engine.pkl\") Document Clustering and Topic Analysis from sklearn.cluster import KMeans from sklearn.decomposition import PCA import matplotlib.pyplot as plt class DocumentAnalyzer: def __init__(self, model_name='all-mpnet-base-v2'): self.model = SentenceTransformer(model_name) def analyze_documents(self, documents, num_clusters=5): \"\"\"Analyze documents: embeddings, clustering, and visualization\"\"\" # Get embeddings embeddings = self.model.encode(documents, show_progress_bar=True) # Perform clustering kmeans = KMeans(n_clusters=num_clusters, random_state=42) cluster_labels = kmeans.fit_predict(embeddings) # Dimensionality reduction for visualization pca = PCA(n_components=2, random_state=42) embeddings_2d = pca.fit_transform(embeddings) # Create results results = { 'documents': documents, 'embeddings': embeddings, 'cluster_labels': cluster_labels, 'embeddings_2d': embeddings_2d, 'cluster_centers': kmeans.cluster_centers_ } return results def visualize_clusters(self, results): \"\"\"Visualize document clusters\"\"\" plt.figure(figsize=(12, 8)) scatter = plt.scatter(results['embeddings_2d'][:, 0], results['embeddings_2d'][:, 1], c=results['cluster_labels'], cmap='tab10', alpha=0.7) plt.colorbar(scatter) plt.title('Document Clusters (2D PCA)') plt.xlabel('PCA Component 1') plt.ylabel('PCA Component 2') # Add some document texts as annotations for i in range(0, len(results['documents']), max(1, len(results['documents'])//10)): plt.annotate(results['documents'][i][:30] + '...', (results['embeddings_2d'][i, 0], results['embeddings_2d'][i, 1]), fontsize=8, alpha=0.7) plt.tight_layout() plt.show() def get_cluster_summaries(self, results, max_examples=3): \"\"\"Get representative examples for each cluster\"\"\" summaries = {} for cluster_id in range(len(set(results['cluster_labels']))): # Get documents in this cluster cluster_docs = [doc for i, doc in enumerate(results['documents']) if results['cluster_labels'][i] == cluster_id] # Get embeddings for this cluster cluster_embeddings = results['embeddings'][results['cluster_labels'] == cluster_id] cluster_center = results['cluster_centers'][cluster_id] # Find most representative documents (closest to center) distances = np.linalg.norm(cluster_embeddings - cluster_center, axis=1) closest_indices = np.argsort(distances)[:max_examples] representative_docs = [cluster_docs[idx] for idx in closest_indices] summaries[f'Cluster {cluster_id}'] = { 'size': len(cluster_docs), 'representative_docs': representative_docs } return summaries # Example usage analyzer = DocumentAnalyzer() # Sample documents (in practice, load from your data source) documents = [ \"Machine learning algorithms for data analysis\", \"Python programming tutorial for beginners\", \"Natural language processing with transformers\", \"Web development using React and Node.js\", \"Deep learning neural networks architecture\", \"Database design and SQL optimization\", \"Computer vision and image recognition\", \"JavaScript frameworks comparison\", \"Data science workflow and best practices\", \"Mobile app development with Flutter\" ] # Analyze documents results = analyzer.analyze_documents(documents, num_clusters=3) # Visualize analyzer.visualize_clusters(results) # Get cluster summaries summaries = analyzer.get_cluster_summaries(results) print(\"Cluster Analysis:\") for cluster_name, info in summaries.items(): print(f\"\\n{cluster_name} ({info['size']} documents):\") for doc in info['representative_docs']: print(f\" - {doc}\") This comprehensive cheat sheet covers the essential aspects of Sentence-Transformers. The library excels at creating meaningful vector representations of text, enabling powerful semantic search, similarity computation, and clustering applications. Its ease of use and extensive model collection make it ideal for both research and production use cases.","title":"Sentence-Transformers (UKPLab)"},{"location":"python/sentence-transformers/#sentence-transformers-ukplab","text":"Sentence-Transformers is a Python framework for state-of-the-art sentence, text, and image embeddings. It provides an easy way to compute dense vector representations for sentences, paragraphs, and images, enabling semantic similarity computation, clustering, and semantic search.","title":"Sentence-Transformers (UKPLab)"},{"location":"python/sentence-transformers/#installation","text":"# Basic installation pip install sentence-transformers # With optional dependencies pip install sentence-transformers[train] # Development version pip install git+https://github.com/UKPLab/sentence-transformers.git # With specific backends pip install sentence-transformers torch torchvision pip install sentence-transformers tensorflow","title":"Installation"},{"location":"python/sentence-transformers/#basic-setup","text":"from sentence_transformers import SentenceTransformer, util, InputExample, losses from sentence_transformers.cross_encoder import CrossEncoder from sentence_transformers.evaluation import EmbeddingSimilarityEvaluator import numpy as np import torch from sklearn.metrics.pairwise import cosine_similarity from scipy.spatial.distance import cdist","title":"Basic Setup"},{"location":"python/sentence-transformers/#core-functionality","text":"","title":"Core Functionality"},{"location":"python/sentence-transformers/#loading-models","text":"# Popular pre-trained models model = SentenceTransformer('all-MiniLM-L6-v2') # Good balance of quality vs speed model = SentenceTransformer('all-mpnet-base-v2') # High quality model = SentenceTransformer('paraphrase-MiniLM-L6-v2') # Paraphrase detection model = SentenceTransformer('multi-qa-MiniLM-L6-cos-v1') # Question answering # Multilingual models model = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2') model = SentenceTransformer('distiluse-base-multilingual-cased-v2') # Specialized models model = SentenceTransformer('msmarco-distilbert-base-v4') # Web search model = SentenceTransformer('nli-distilroberta-base-v2') # Natural language inference # Load from local path model = SentenceTransformer('/path/to/model') # Load with specific device model = SentenceTransformer('all-MiniLM-L6-v2', device='cuda')","title":"Loading Models"},{"location":"python/sentence-transformers/#basic-encoding","text":"# Single sentence encoding sentence = \"This is a sample sentence.\" embedding = model.encode(sentence) print(f\"Embedding shape: {embedding.shape}\") # (384,) for MiniLM models # Multiple sentences sentences = [ \"The weather is lovely today.\", \"It's so sunny outside!\", \"He drove to the stadium.\" ] embeddings = model.encode(sentences) print(f\"Embeddings shape: {embeddings.shape}\") # (3, 384) # Batch processing with progress bar embeddings = model.encode(sentences, show_progress_bar=True) # Convert to tensor embeddings = model.encode(sentences, convert_to_tensor=True) print(type(embeddings)) # torch.Tensor # Normalize embeddings (for cosine similarity) embeddings = model.encode(sentences, normalize_embeddings=True)","title":"Basic Encoding"},{"location":"python/sentence-transformers/#similarity-computation","text":"# Compute similarity matrix sentences = [ \"The weather is lovely today.\", \"It's so sunny outside!\", \"He drove to the stadium.\" ] embeddings = model.encode(sentences) # Cosine similarity similarities = model.similarity(embeddings, embeddings) print(similarities) # tensor([[1.0000, 0.6660, 0.1046], # [0.6660, 1.0000, 0.1411], # [0.1046, 0.1411, 1.0000]]) # Pairwise similarity similarities = util.pytorch_cos_sim(embeddings, embeddings) # Find most similar pairs pairs = [] for i in range(len(similarities)): for j in range(i+1, len(similarities)): pairs.append((i, j, similarities[i][j].item())) # Sort by similarity pairs.sort(key=lambda x: x[2], reverse=True) print(f\"Most similar pair: sentences {pairs[0][0]} and {pairs[0][1]} with score {pairs[0][2]:.4f}\")","title":"Similarity Computation"},{"location":"python/sentence-transformers/#common-use-cases","text":"","title":"Common Use Cases"},{"location":"python/sentence-transformers/#semantic-search","text":"import numpy as np # Create a corpus of documents corpus = [ \"A man is eating food.\", \"A man is eating a piece of bread.\", \"The girl is carrying a baby.\", \"A man is riding a horse.\", \"A woman is playing violin.\", \"Two men pushed carts through the woods.\", \"A man is riding a white horse on an enclosed ground.\", \"A monkey is playing drums.\", \"A cheetah is running behind its prey.\" ] # Encode corpus corpus_embeddings = model.encode(corpus, convert_to_tensor=True) # Query queries = [ \"A man is eating pasta.\", \"Someone in a gorilla costume is playing a set of drums.\", \"A cheetah chases prey on across a field.\" ] # Find the closest 5 sentences to each query top_k = min(5, len(corpus)) for query in queries: query_embedding = model.encode(query, convert_to_tensor=True) # Compute cosine-similarities between query and corpus cos_scores = util.cos_sim(query_embedding, corpus_embeddings)[0] # Sort results top_results = torch.topk(cos_scores, k=top_k) print(f\"\\nQuery: {query}\") print(f\"Top {top_k} most similar sentences in corpus:\") for score, idx in zip(top_results[0], top_results[1]): print(f\"(Score: {score:.4f}) {corpus[idx]}\")","title":"Semantic Search"},{"location":"python/sentence-transformers/#advanced-semantic-search-with-faiss","text":"import faiss import numpy as np def create_faiss_index(embeddings): \"\"\"Create FAISS index for fast similarity search\"\"\" dimension = embeddings.shape[1] # Create index index = faiss.IndexFlatIP(dimension) # Inner product (cosine with normalized vectors) # Normalize embeddings for cosine similarity embeddings_np = embeddings.cpu().numpy() if hasattr(embeddings, 'cpu') else embeddings faiss.normalize_L2(embeddings_np) # Add embeddings to index index.add(embeddings_np.astype('float32')) return index def semantic_search_faiss(query, model, index, corpus, top_k=5): \"\"\"Perform semantic search using FAISS\"\"\" # Encode query query_embedding = model.encode([query]) # Normalize faiss.normalize_L2(query_embedding) # Search scores, indices = index.search(query_embedding.astype('float32'), top_k) results = [] for score, idx in zip(scores[0], indices[0]): results.append({ 'score': float(score), 'text': corpus[idx], 'index': int(idx) }) return results # Usage corpus_embeddings = model.encode(corpus, convert_to_tensor=True) index = create_faiss_index(corpus_embeddings) query = \"A person is eating food\" results = semantic_search_faiss(query, model, index, corpus) print(f\"Query: {query}\") for result in results: print(f\"Score: {result['score']:.4f} - {result['text']}\")","title":"Advanced Semantic Search with Faiss"},{"location":"python/sentence-transformers/#clustering","text":"from sklearn.cluster import KMeans import matplotlib.pyplot as plt # Sample sentences for clustering sentences = [ # Sports \"The football game was exciting.\", \"Basketball is my favorite sport.\", \"Tennis requires good coordination.\", # Food \"This pizza tastes amazing.\", \"I love cooking Italian food.\", \"The restaurant serves great pasta.\", # Technology \"Machine learning is fascinating.\", \"AI will change the world.\", \"Programming languages are evolving.\", # Weather \"It's a beautiful sunny day.\", \"The weather is getting cold.\", \"Rain is expected tomorrow.\" ] # Get embeddings embeddings = model.encode(sentences) # Perform clustering num_clusters = 4 kmeans = KMeans(n_clusters=num_clusters, random_state=42) cluster_assignments = kmeans.fit_predict(embeddings) # Group sentences by cluster clustered_sentences = {} for sentence_id, cluster_id in enumerate(cluster_assignments): if cluster_id not in clustered_sentences: clustered_sentences[cluster_id] = [] clustered_sentences[cluster_id].append(sentences[sentence_id]) # Print results for cluster_id, cluster_sentences in clustered_sentences.items(): print(f\"Cluster {cluster_id + 1}:\") for sentence in cluster_sentences: print(f\" - {sentence}\") print()","title":"Clustering"},{"location":"python/sentence-transformers/#paraphrase-detection","text":"def find_paraphrases(sentences, threshold=0.7): \"\"\"Find paraphrases in a list of sentences\"\"\" embeddings = model.encode(sentences) similarity_matrix = util.cos_sim(embeddings, embeddings) paraphrases = [] for i in range(len(sentences)): for j in range(i+1, len(sentences)): similarity = similarity_matrix[i][j].item() if similarity > threshold: paraphrases.append({ 'sentence1': sentences[i], 'sentence2': sentences[j], 'similarity': similarity }) return sorted(paraphrases, key=lambda x: x['similarity'], reverse=True) # Example sentences with some paraphrases test_sentences = [ \"The cat is sleeping on the couch.\", \"A feline is resting on the sofa.\", \"The dog is barking loudly.\", \"The weather is nice today.\", \"It's a beautiful day outside.\", \"The car is red.\", \"The canine is making loud sounds.\" ] paraphrases = find_paraphrases(test_sentences, threshold=0.6) print(\"Potential paraphrases found:\") for para in paraphrases: print(f\"Similarity: {para['similarity']:.3f}\") print(f\"1: {para['sentence1']}\") print(f\"2: {para['sentence2']}\") print(\"-\" * 50)","title":"Paraphrase Detection"},{"location":"python/sentence-transformers/#question-answering-with-retrieval","text":"def qa_retrieval_system(questions, contexts, model, top_k=3): \"\"\"Simple QA retrieval system using sentence embeddings\"\"\" # Encode all contexts context_embeddings = model.encode(contexts, convert_to_tensor=True) results = [] for question in questions: # Encode question question_embedding = model.encode(question, convert_to_tensor=True) # Find most similar contexts similarities = util.cos_sim(question_embedding, context_embeddings)[0] top_indices = torch.topk(similarities, k=min(top_k, len(contexts)))[1] # Get top contexts top_contexts = [contexts[idx] for idx in top_indices] top_scores = [similarities[idx].item() for idx in top_indices] results.append({ 'question': question, 'top_contexts': list(zip(top_contexts, top_scores)) }) return results # Example usage contexts = [ \"Paris is the capital of France and its largest city.\", \"London is the capital of England and the United Kingdom.\", \"Berlin is the capital of Germany.\", \"Madrid is the capital of Spain.\", \"Rome is the capital of Italy and home to Vatican City.\", \"Tokyo is the capital of Japan and the world's most populous metropolitan area.\" ] questions = [ \"What is the capital of France?\", \"Which city is the capital of Germany?\", \"Tell me about the capital of Italy.\" ] qa_results = qa_retrieval_system(questions, contexts, model) for result in qa_results: print(f\"Question: {result['question']}\") print(\"Most relevant contexts:\") for context, score in result['top_contexts']: print(f\" Score: {score:.3f} - {context}\") print()","title":"Question Answering with Retrieval"},{"location":"python/sentence-transformers/#advanced-features","text":"","title":"Advanced Features"},{"location":"python/sentence-transformers/#custom-model-training","text":"from sentence_transformers import InputExample, losses from torch.utils.data import DataLoader # Prepare training data train_examples = [ InputExample(texts=['My first sentence', 'My second sentence'], label=0.8), InputExample(texts=['Another pair', 'Completely different'], label=0.3) ] # Create DataLoader train_dataloader = DataLoader(train_examples, shuffle=True, batch_size=16) # Define loss function train_loss = losses.CosineSimilarityLoss(model) # Training model.fit( train_objectives=[(train_dataloader, train_loss)], epochs=1, warmup_steps=100, output_path='./my-sentence-transformer' ) # For triplet training (anchor, positive, negative) train_examples_triplet = [ InputExample(texts=['Anchor sentence', 'Positive sentence', 'Negative sentence']) ] train_dataloader_triplet = DataLoader(train_examples_triplet, shuffle=True, batch_size=16) train_loss_triplet = losses.TripletLoss(model) model.fit( train_objectives=[(train_dataloader_triplet, train_loss_triplet)], epochs=1, output_path='./my-triplet-model' )","title":"Custom Model Training"},{"location":"python/sentence-transformers/#cross-encoders-for-reranking","text":"from sentence_transformers.cross_encoder import CrossEncoder # Load cross-encoder model cross_encoder = CrossEncoder('ms-marco-MiniLM-L-6-v2') def rerank_results(query, candidates, cross_encoder, top_k=5): \"\"\"Rerank search results using a cross-encoder\"\"\" # Create query-candidate pairs pairs = [[query, candidate] for candidate in candidates] # Get cross-encoder scores scores = cross_encoder.predict(pairs) # Sort by score ranked_results = sorted(zip(candidates, scores), key=lambda x: x[1], reverse=True) return ranked_results[:top_k] # Example: Two-stage retrieval and reranking def two_stage_search(query, corpus, bi_encoder, cross_encoder, retrieve_top_k=20, rerank_top_k=5): \"\"\"Two-stage search: bi-encoder retrieval + cross-encoder reranking\"\"\" # Stage 1: Fast retrieval with bi-encoder query_embedding = bi_encoder.encode(query, convert_to_tensor=True) corpus_embeddings = bi_encoder.encode(corpus, convert_to_tensor=True) cos_scores = util.cos_sim(query_embedding, corpus_embeddings)[0] top_results = torch.topk(cos_scores, k=min(retrieve_top_k, len(corpus))) # Get candidate texts candidates = [corpus[idx] for idx in top_results[1]] # Stage 2: Reranking with cross-encoder reranked = rerank_results(query, candidates, cross_encoder, rerank_top_k) return reranked # Usage query = \"Information about machine learning\" corpus = [ \"Machine learning is a subset of artificial intelligence.\", \"Deep learning uses neural networks with many layers.\", \"Natural language processing helps computers understand text.\", \"Computer vision enables machines to interpret visual information.\", \"Reinforcement learning trains agents through trial and error.\" ] bi_encoder = SentenceTransformer('all-MiniLM-L6-v2') cross_encoder = CrossEncoder('ms-marco-MiniLM-L-6-v2') results = two_stage_search(query, corpus, bi_encoder, cross_encoder) print(f\"Query: {query}\") print(\"Reranked results:\") for i, (text, score) in enumerate(results, 1): print(f\"{i}. Score: {score:.4f} - {text}\")","title":"Cross-Encoders for Reranking"},{"location":"python/sentence-transformers/#multi-lingual-embeddings","text":"# Load multilingual model multilingual_model = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2') # Sentences in different languages sentences = [ \"Hello, how are you?\", # English \"Hola, \u00bfc\u00f3mo est\u00e1s?\", # Spanish \"Bonjour, comment allez-vous?\", # French \"Hallo, wie geht es dir?\", # German \"Ciao, come stai?\", # Italian \"\u3053\u3093\u306b\u3061\u306f\u3001\u5143\u6c17\u3067\u3059\u304b\uff1f\", # Japanese \"\u4f60\u597d\uff0c\u4f60\u597d\u5417\uff1f\" # Chinese ] # Get embeddings embeddings = multilingual_model.encode(sentences) # Compute similarity matrix similarity_matrix = util.cos_sim(embeddings, embeddings) print(\"Cross-lingual similarity matrix:\") for i, sent1 in enumerate(sentences): for j, sent2 in enumerate(sentences): if i != j: sim = similarity_matrix[i][j].item() if sim > 0.5: # Only show high similarities print(f\"Similarity: {sim:.3f}\") print(f\" '{sent1}' <-> '{sent2}'\")","title":"Multi-lingual Embeddings"},{"location":"python/sentence-transformers/#working-with-images-clip","text":"from sentence_transformers import SentenceTransformer from PIL import Image import requests from io import BytesIO # Load CLIP model clip_model = SentenceTransformer('clip-ViT-B-32') # Load images image_urls = [ \"https://example.com/cat.jpg\", \"https://example.com/dog.jpg\" ] images = [] for url in image_urls: response = requests.get(url) img = Image.open(BytesIO(response.content)) images.append(img) # Text descriptions texts = [ \"A photo of a cat\", \"A photo of a dog\", \"A picture of a bird\", \"An image of a car\" ] # Get embeddings image_embeddings = clip_model.encode(images) text_embeddings = clip_model.encode(texts) # Compute similarity between images and texts similarities = util.cos_sim(image_embeddings, text_embeddings) print(\"Image-Text Similarities:\") for i, img_url in enumerate(image_urls): print(f\"\\nImage {i+1}: {img_url}\") for j, text in enumerate(texts): sim = similarities[i][j].item() print(f\" '{text}': {sim:.3f}\")","title":"Working with Images (CLIP)"},{"location":"python/sentence-transformers/#integration-with-other-libraries","text":"","title":"Integration with Other Libraries"},{"location":"python/sentence-transformers/#with-pandas-for-data-analysis","text":"import pandas as pd # Create sample dataset data = { 'text': [ \"I love this product! It's amazing!\", \"Great quality and fast shipping.\", \"Terrible experience, would not recommend.\", \"Average product, nothing special.\", \"Outstanding customer service!\" ], 'rating': [5, 4, 1, 3, 5] } df = pd.DataFrame(data) # Add embeddings embeddings = model.encode(df['text'].tolist()) df['embedding'] = embeddings.tolist() # Find similar reviews def find_similar_reviews(query_text, df, model, top_k=3): query_embedding = model.encode([query_text]) # Compute similarities similarities = [] for i, row in df.iterrows(): sim = cosine_similarity([query_embedding[0]], [row['embedding']])[0][0] similarities.append(sim) df['similarity'] = similarities return df.nlargest(top_k, 'similarity')[['text', 'rating', 'similarity']] # Usage query = \"excellent customer support\" similar_reviews = find_similar_reviews(query, df, model) print(similar_reviews)","title":"With Pandas for Data Analysis"},{"location":"python/sentence-transformers/#with-streamlit-for-web-apps","text":"import streamlit as st import plotly.express as px from sklearn.manifold import TSNE st.title(\"Sentence Similarity Explorer\") # Text input user_texts = st.text_area(\"Enter sentences (one per line):\", value=\"The weather is nice today.\\nIt's a beautiful day.\\nThe car is red.\") if user_texts: sentences = [s.strip() for s in user_texts.split('\\n') if s.strip()] # Compute embeddings embeddings = model.encode(sentences) # Compute similarity matrix similarity_matrix = util.cos_sim(embeddings, embeddings).numpy() # Display similarity matrix st.subheader(\"Similarity Matrix\") fig = px.imshow(similarity_matrix, labels=dict(x=\"Sentences\", y=\"Sentences\"), text_auto=True) st.plotly_chart(fig) # 2D visualization using t-SNE if len(sentences) > 2: st.subheader(\"2D Embedding Visualization\") tsne = TSNE(n_components=2, random_state=42) embeddings_2d = tsne.fit_transform(embeddings) fig_scatter = px.scatter(x=embeddings_2d[:, 0], y=embeddings_2d[:, 1], hover_data=[sentences], title=\"Sentence Embeddings (t-SNE)\") st.plotly_chart(fig_scatter)","title":"With Streamlit for Web Apps"},{"location":"python/sentence-transformers/#best-practices","text":"","title":"Best Practices"},{"location":"python/sentence-transformers/#performance-optimization","text":"# 1. Use appropriate model sizes models_by_performance = { 'fastest': 'all-MiniLM-L6-v2', 'balanced': 'all-mpnet-base-v2', 'highest_quality': 'sentence-transformers/gtr-t5-large' } # 2. Batch processing for large datasets def encode_large_dataset(texts, model, batch_size=32): \"\"\"Efficiently encode large datasets\"\"\" embeddings = [] for i in range(0, len(texts), batch_size): batch = texts[i:i + batch_size] batch_embeddings = model.encode(batch, show_progress_bar=False) embeddings.extend(batch_embeddings) return np.array(embeddings) # 3. Use appropriate precision embeddings = model.encode(sentences, precision='float32') # vs 'float64' # 4. Normalize embeddings if using cosine similarity embeddings = model.encode(sentences, normalize_embeddings=True) # 5. Use GPU when available device = 'cuda' if torch.cuda.is_available() else 'cpu' model = SentenceTransformer('all-MiniLM-L6-v2', device=device)","title":"Performance Optimization"},{"location":"python/sentence-transformers/#memory-management","text":"import gc from typing import Iterator, List def process_large_corpus(corpus: List[str], model: SentenceTransformer, batch_size: int = 1000) -> Iterator[np.ndarray]: \"\"\"Process large corpus in chunks to manage memory\"\"\" for i in range(0, len(corpus), batch_size): batch = corpus[i:i + batch_size] # Encode batch embeddings = model.encode(batch, convert_to_numpy=True) yield embeddings # Clean up gc.collect() # Usage for very large datasets def save_embeddings_chunked(corpus, model, output_path, batch_size=1000): \"\"\"Save embeddings for large corpus in chunks\"\"\" all_embeddings = [] for chunk_embeddings in process_large_corpus(corpus, model, batch_size): all_embeddings.append(chunk_embeddings) # Concatenate all embeddings final_embeddings = np.vstack(all_embeddings) np.save(output_path, final_embeddings) return final_embeddings","title":"Memory Management"},{"location":"python/sentence-transformers/#model-selection-guidelines","text":"def recommend_model(use_case, performance_priority='balanced'): \"\"\"Recommend model based on use case and performance requirements\"\"\" recommendations = { 'semantic_search': { 'fast': 'all-MiniLM-L6-v2', 'balanced': 'all-mpnet-base-v2', 'quality': 'sentence-transformers/gtr-t5-large' }, 'question_answering': { 'fast': 'multi-qa-MiniLM-L6-cos-v1', 'balanced': 'multi-qa-mpnet-base-cos-v1', 'quality': 'sentence-transformers/gtr-t5-xl' }, 'paraphrase_detection': { 'fast': 'paraphrase-MiniLM-L6-v2', 'balanced': 'paraphrase-mpnet-base-v2', 'quality': 'sentence-transformers/gtr-t5-large' }, 'multilingual': { 'fast': 'paraphrase-multilingual-MiniLM-L12-v2', 'balanced': 'sentence-transformers/LaBSE', 'quality': 'sentence-transformers/paraphrase-multilingual-mpnet-base-v2' } } return recommendations.get(use_case, {}).get(performance_priority, 'all-MiniLM-L6-v2') # Usage model_name = recommend_model('semantic_search', 'fast') print(f\"Recommended model: {model_name}\")","title":"Model Selection Guidelines"},{"location":"python/sentence-transformers/#real-world-examples","text":"","title":"Real-world Examples"},{"location":"python/sentence-transformers/#complete-semantic-search-engine","text":"import json import pickle from pathlib import Path from typing import List, Dict, Any class SemanticSearchEngine: def __init__(self, model_name='all-MiniLM-L6-v2'): self.model = SentenceTransformer(model_name) self.documents = [] self.embeddings = None self.index = None def add_documents(self, documents: List[Dict[str, Any]]): \"\"\"Add documents to the search engine\"\"\" self.documents.extend(documents) # Extract text for embedding texts = [doc.get('text', str(doc)) for doc in documents] # Compute embeddings new_embeddings = self.model.encode(texts, convert_to_tensor=True) if self.embeddings is None: self.embeddings = new_embeddings else: self.embeddings = torch.cat([self.embeddings, new_embeddings], dim=0) def search(self, query: str, top_k: int = 5) -> List[Dict[str, Any]]: \"\"\"Search for similar documents\"\"\" if self.embeddings is None: return [] # Encode query query_embedding = self.model.encode(query, convert_to_tensor=True) # Compute similarities cos_scores = util.cos_sim(query_embedding, self.embeddings)[0] # Get top results top_results = torch.topk(cos_scores, k=min(top_k, len(self.documents))) results = [] for score, idx in zip(top_results[0], top_results[1]): doc = self.documents[idx.item()].copy() doc['similarity_score'] = score.item() results.append(doc) return results def save(self, path: str): \"\"\"Save the search engine state\"\"\" state = { 'documents': self.documents, 'embeddings': self.embeddings.cpu().numpy() if self.embeddings is not None else None, 'model_name': self.model._modules['0'].auto_model.config._name_or_path } with open(path, 'wb') as f: pickle.dump(state, f) def load(self, path: str): \"\"\"Load the search engine state\"\"\" with open(path, 'rb') as f: state = pickle.load(f) self.documents = state['documents'] if state['embeddings'] is not None: self.embeddings = torch.tensor(state['embeddings']) # Usage example search_engine = SemanticSearchEngine() # Add documents documents = [ {\"title\": \"Machine Learning Basics\", \"text\": \"Introduction to machine learning algorithms and concepts\", \"category\": \"AI\"}, {\"title\": \"Python Programming\", \"text\": \"Learn Python programming from scratch\", \"category\": \"Programming\"}, {\"title\": \"Data Science Guide\", \"text\": \"Comprehensive guide to data science and analytics\", \"category\": \"Data\"}, {\"title\": \"Neural Networks\", \"text\": \"Deep learning and neural network architectures\", \"category\": \"AI\"}, ] search_engine.add_documents(documents) # Search results = search_engine.search(\"artificial intelligence and machine learning\", top_k=3) print(\"Search Results:\") for i, result in enumerate(results, 1): print(f\"{i}. {result['title']} (Score: {result['similarity_score']:.3f})\") print(f\" Category: {result['category']}\") print(f\" Text: {result['text']}\") print() # Save for later use search_engine.save(\"my_search_engine.pkl\")","title":"Complete Semantic Search Engine"},{"location":"python/sentence-transformers/#document-clustering-and-topic-analysis","text":"from sklearn.cluster import KMeans from sklearn.decomposition import PCA import matplotlib.pyplot as plt class DocumentAnalyzer: def __init__(self, model_name='all-mpnet-base-v2'): self.model = SentenceTransformer(model_name) def analyze_documents(self, documents, num_clusters=5): \"\"\"Analyze documents: embeddings, clustering, and visualization\"\"\" # Get embeddings embeddings = self.model.encode(documents, show_progress_bar=True) # Perform clustering kmeans = KMeans(n_clusters=num_clusters, random_state=42) cluster_labels = kmeans.fit_predict(embeddings) # Dimensionality reduction for visualization pca = PCA(n_components=2, random_state=42) embeddings_2d = pca.fit_transform(embeddings) # Create results results = { 'documents': documents, 'embeddings': embeddings, 'cluster_labels': cluster_labels, 'embeddings_2d': embeddings_2d, 'cluster_centers': kmeans.cluster_centers_ } return results def visualize_clusters(self, results): \"\"\"Visualize document clusters\"\"\" plt.figure(figsize=(12, 8)) scatter = plt.scatter(results['embeddings_2d'][:, 0], results['embeddings_2d'][:, 1], c=results['cluster_labels'], cmap='tab10', alpha=0.7) plt.colorbar(scatter) plt.title('Document Clusters (2D PCA)') plt.xlabel('PCA Component 1') plt.ylabel('PCA Component 2') # Add some document texts as annotations for i in range(0, len(results['documents']), max(1, len(results['documents'])//10)): plt.annotate(results['documents'][i][:30] + '...', (results['embeddings_2d'][i, 0], results['embeddings_2d'][i, 1]), fontsize=8, alpha=0.7) plt.tight_layout() plt.show() def get_cluster_summaries(self, results, max_examples=3): \"\"\"Get representative examples for each cluster\"\"\" summaries = {} for cluster_id in range(len(set(results['cluster_labels']))): # Get documents in this cluster cluster_docs = [doc for i, doc in enumerate(results['documents']) if results['cluster_labels'][i] == cluster_id] # Get embeddings for this cluster cluster_embeddings = results['embeddings'][results['cluster_labels'] == cluster_id] cluster_center = results['cluster_centers'][cluster_id] # Find most representative documents (closest to center) distances = np.linalg.norm(cluster_embeddings - cluster_center, axis=1) closest_indices = np.argsort(distances)[:max_examples] representative_docs = [cluster_docs[idx] for idx in closest_indices] summaries[f'Cluster {cluster_id}'] = { 'size': len(cluster_docs), 'representative_docs': representative_docs } return summaries # Example usage analyzer = DocumentAnalyzer() # Sample documents (in practice, load from your data source) documents = [ \"Machine learning algorithms for data analysis\", \"Python programming tutorial for beginners\", \"Natural language processing with transformers\", \"Web development using React and Node.js\", \"Deep learning neural networks architecture\", \"Database design and SQL optimization\", \"Computer vision and image recognition\", \"JavaScript frameworks comparison\", \"Data science workflow and best practices\", \"Mobile app development with Flutter\" ] # Analyze documents results = analyzer.analyze_documents(documents, num_clusters=3) # Visualize analyzer.visualize_clusters(results) # Get cluster summaries summaries = analyzer.get_cluster_summaries(results) print(\"Cluster Analysis:\") for cluster_name, info in summaries.items(): print(f\"\\n{cluster_name} ({info['size']} documents):\") for doc in info['representative_docs']: print(f\" - {doc}\") This comprehensive cheat sheet covers the essential aspects of Sentence-Transformers. The library excels at creating meaningful vector representations of text, enabling powerful semantic search, similarity computation, and clustering applications. Its ease of use and extensive model collection make it ideal for both research and production use cases.","title":"Document Clustering and Topic Analysis"},{"location":"python/tensorflow/","text":"TensorFlow Installation # CPU only pip install tensorflow # GPU support (requires CUDA) pip install tensorflow[and-cuda] # Development version pip install tf-nightly # Specific version pip install tensorflow==2.15.0 # Verify installation python -c \"import tensorflow as tf; print(tf.__version__)\" Import Essentials import tensorflow as tf import numpy as np import matplotlib.pyplot as plt from tensorflow import keras from tensorflow.keras import layers import tensorflow_datasets as tfds Tensor Basics Creating Tensors # From Python lists tensor = tf.constant([1, 2, 3, 4]) matrix = tf.constant([[1, 2], [3, 4]]) # Zeros and ones zeros = tf.zeros([3, 4]) ones = tf.ones([2, 3]) identity = tf.eye(3) # Random tensors random_normal = tf.random.normal([3, 3]) random_uniform = tf.random.uniform([2, 2], minval=0, maxval=1) # From numpy numpy_array = np.array([1, 2, 3]) tensor_from_numpy = tf.constant(numpy_array) # Range tensors range_tensor = tf.range(10) linspace = tf.linspace(0.0, 1.0, 5) Tensor Properties tensor = tf.random.normal([3, 4, 5]) print(tensor.shape) # TensorShape([3, 4, 5]) print(tensor.dtype) # tf.float32 print(tensor.numpy()) # convert to numpy array print(tf.rank(tensor)) # number of dimensions (3) print(tf.size(tensor)) # total number of elements (60) Tensor Operations a = tf.constant([1, 2, 3]) b = tf.constant([4, 5, 6]) # Arithmetic operations c = a + b # tf.add(a, b) c = a - b # tf.subtract(a, b) c = a * b # element-wise multiplication c = a / b # element-wise division c = tf.matmul(a, b) # matrix multiplication c = a @ b # alternative matrix multiplication # Reductions tf.reduce_sum(tensor) # sum all elements tf.reduce_mean(tensor) # mean of all elements tf.reduce_max(tensor) # maximum element tf.reduce_min(tensor) # minimum element tf.reduce_sum(tensor, axis=1) # sum along axis 1 Reshaping and Indexing tensor = tf.random.normal([12]) # Reshaping reshaped = tf.reshape(tensor, [3, 4]) expanded = tf.expand_dims(tensor, axis=0) # add dimension squeezed = tf.squeeze(expanded) # remove dimension # Indexing and slicing tensor[0] # first element tensor[1:4] # slice tensor[:, 1] # all rows, column 1 tensor[..., -1] # last element along last axis # Advanced indexing tf.gather(tensor, indices=[0, 2, 4]) # gather specific indices tf.boolean_mask(tensor, tensor > 0) # boolean masking Variables and GradientTape Variables # Creating variables var = tf.Variable(3.0, name=\"my_variable\") matrix_var = tf.Variable([[1.0, 2.0], [3.0, 4.0]]) # Updating variables var.assign(5.0) var.assign_add(2.0) # add 2 to current value var.assign_sub(1.0) # subtract 1 from current value Automatic Differentiation # Using GradientTape for automatic differentiation x = tf.Variable(3.0) with tf.GradientTape() as tape: y = x**2 + 2*x + 1 # Compute gradient dy_dx = tape.gradient(y, x) # dy/dx = 2*x + 2 = 8 # Multiple variables x1 = tf.Variable(2.0) x2 = tf.Variable(3.0) with tf.GradientTape() as tape: y = x1**2 + x2**2 gradients = tape.gradient(y, [x1, x2]) Neural Networks with Keras Sequential Model model = tf.keras.Sequential([ layers.Dense(128, activation='relu', input_shape=(784,)), layers.Dropout(0.2), layers.Dense(64, activation='relu'), layers.Dense(10, activation='softmax') ]) # Alternative syntax model = tf.keras.Sequential() model.add(layers.Dense(128, activation='relu', input_shape=(784,))) model.add(layers.Dropout(0.2)) model.add(layers.Dense(10, activation='softmax')) Functional API inputs = layers.Input(shape=(784,)) x = layers.Dense(128, activation='relu')(inputs) x = layers.Dropout(0.2)(x) x = layers.Dense(64, activation='relu')(x) outputs = layers.Dense(10, activation='softmax')(x) model = tf.keras.Model(inputs=inputs, outputs=outputs) Custom Model (Subclassing) class MyModel(tf.keras.Model): def __init__(self, num_classes=10): super(MyModel, self).__init__() self.dense1 = layers.Dense(128, activation='relu') self.dropout = layers.Dropout(0.2) self.dense2 = layers.Dense(num_classes, activation='softmax') def call(self, inputs, training=None): x = self.dense1(inputs) x = self.dropout(x, training=training) return self.dense2(x) model = MyModel() Common Layers Dense (Fully Connected) layers.Dense(64, activation='relu') layers.Dense(10, activation='softmax', use_bias=False) Convolutional Layers layers.Conv1D(32, 3, activation='relu') layers.Conv2D(32, (3, 3), activation='relu', padding='same') layers.Conv3D(16, (3, 3, 3), activation='relu') # Separable convolutions layers.SeparableConv2D(64, (3, 3), activation='relu') layers.DepthwiseConv2D((3, 3), activation='relu') Pooling Layers layers.MaxPooling2D((2, 2)) layers.AveragePooling2D((2, 2)) layers.GlobalMaxPooling2D() layers.GlobalAveragePooling2D() Recurrent Layers layers.SimpleRNN(32) layers.LSTM(64, return_sequences=True) layers.GRU(32, dropout=0.2, recurrent_dropout=0.2) layers.Bidirectional(layers.LSTM(32)) Normalization and Regularization layers.BatchNormalization() layers.LayerNormalization() layers.Dropout(0.5) layers.AlphaDropout(0.1) # for SELU activation Activation Layers layers.ReLU() layers.LeakyReLU(alpha=0.3) layers.ELU(alpha=1.0) layers.Softmax() layers.Activation('tanh') Model Compilation and Training Compile Model model.compile( optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'] ) # Custom optimizer model.compile( optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), loss=tf.keras.losses.SparseCategoricalCrossentropy(), metrics=[tf.keras.metrics.SparseCategoricalAccuracy()] ) Training # Basic training history = model.fit( x_train, y_train, batch_size=32, epochs=10, validation_data=(x_val, y_val), verbose=1 ) # With callbacks callbacks = [ tf.keras.callbacks.EarlyStopping(patience=3, restore_best_weights=True), tf.keras.callbacks.ReduceLROnPlateau(factor=0.2, patience=2), tf.keras.callbacks.ModelCheckpoint('best_model.h5', save_best_only=True) ] model.fit( x_train, y_train, validation_data=(x_val, y_val), epochs=50, callbacks=callbacks ) Data Loading and Preprocessing tf.data API # From arrays dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train)) dataset = dataset.batch(32).shuffle(1000).prefetch(tf.data.AUTOTUNE) # From files dataset = tf.data.Dataset.list_files(\"path/to/images/*.jpg\") dataset = dataset.map(preprocess_function) dataset = dataset.batch(32).prefetch(tf.data.AUTOTUNE) # Image data from directory train_ds = tf.keras.utils.image_dataset_from_directory( 'path/to/train', validation_split=0.2, subset=\"training\", seed=123, image_size=(180, 180), batch_size=32 ) Data Augmentation data_augmentation = tf.keras.Sequential([ layers.RandomFlip(\"horizontal\"), layers.RandomRotation(0.1), layers.RandomZoom(0.1), layers.RandomContrast(0.1), ]) # Apply to model model = tf.keras.Sequential([ data_augmentation, layers.Rescaling(1./255), layers.Conv2D(32, 3, activation='relu'), # ... rest of model ]) Loss Functions and Optimizers Common Loss Functions # Classification tf.keras.losses.BinaryCrossentropy() tf.keras.losses.CategoricalCrossentropy() tf.keras.losses.SparseCategoricalCrossentropy() # Regression tf.keras.losses.MeanSquaredError() tf.keras.losses.MeanAbsoluteError() tf.keras.losses.Huber() # Custom loss @tf.function def custom_loss(y_true, y_pred): return tf.reduce_mean(tf.square(y_true - y_pred)) Optimizers tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.9) tf.keras.optimizers.Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999) tf.keras.optimizers.AdamW(learning_rate=0.001, weight_decay=0.01) tf.keras.optimizers.RMSprop(learning_rate=0.001) tf.keras.optimizers.Adagrad(learning_rate=0.01) # Learning rate schedules initial_learning_rate = 0.1 lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay( initial_learning_rate, decay_steps=100000, decay_rate=0.96, staircase=True ) optimizer = tf.keras.optimizers.SGD(learning_rate=lr_schedule) Model Evaluation and Prediction Evaluation # Evaluate model loss, accuracy = model.evaluate(x_test, y_test, verbose=0) print(f\"Test accuracy: {accuracy:.4f}\") # Custom metrics test_loss = tf.keras.metrics.Mean() test_accuracy = tf.keras.metrics.SparseCategoricalAccuracy() @tf.function def test_step(images, labels): predictions = model(images, training=False) t_loss = loss_object(labels, predictions) test_loss(t_loss) test_accuracy(labels, predictions) Predictions predictions = model.predict(x_test) predicted_classes = np.argmax(predictions, axis=1) # Prediction on single sample single_prediction = model.predict(tf.expand_dims(single_image, 0)) Model Saving and Loading Save/Load Entire Model # Save model model.save('my_model.h5') # HDF5 format model.save('my_model') # SavedModel format # Load model loaded_model = tf.keras.models.load_model('my_model.h5') loaded_model = tf.keras.models.load_model('my_model') Save/Load Weights Only # Save weights model.save_weights('model_weights.h5') # Load weights model.load_weights('model_weights.h5') Checkpoints checkpoint_path = \"training_checkpoints/cp.ckpt\" checkpoint_dir = os.path.dirname(checkpoint_path) cp_callback = tf.keras.callbacks.ModelCheckpoint( filepath=checkpoint_path, save_weights_only=True, verbose=1 ) # Load latest checkpoint latest = tf.train.latest_checkpoint(checkpoint_dir) model.load_weights(latest) Custom Training Loops Basic Custom Training @tf.function def train_step(images, labels): with tf.GradientTape() as tape: predictions = model(images, training=True) loss = loss_object(labels, predictions) gradients = tape.gradient(loss, model.trainable_variables) optimizer.apply_gradients(zip(gradients, model.trainable_variables)) train_loss(loss) train_accuracy(labels, predictions) # Training loop for epoch in range(EPOCHS): train_loss.reset_states() train_accuracy.reset_states() for images, labels in train_ds: train_step(images, labels) print(f'Epoch {epoch + 1}, ' f'Loss: {train_loss.result():.4f}, ' f'Accuracy: {train_accuracy.result():.4f}') Transfer Learning Using Pre-trained Models # Load pre-trained model base_model = tf.keras.applications.VGG16( weights='imagenet', include_top=False, input_shape=(224, 224, 3) ) # Freeze base model base_model.trainable = False # Add custom head model = tf.keras.Sequential([ base_model, layers.GlobalAveragePooling2D(), layers.Dense(128, activation='relu'), layers.Dense(num_classes, activation='softmax') ]) # Fine-tuning: unfreeze some layers base_model.trainable = True fine_tune_at = 100 for layer in base_model.layers[:fine_tune_at]: layer.trainable = False TensorBoard Integration Setting up TensorBoard # TensorBoard callback log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\") tensorboard_callback = tf.keras.callbacks.TensorBoard( log_dir=log_dir, histogram_freq=1 ) model.fit( x_train, y_train, epochs=10, validation_data=(x_val, y_val), callbacks=[tensorboard_callback] ) # Custom scalars with tf.summary.create_file_writer(log_dir).as_default(): tf.summary.scalar('learning_rate', lr, step=epoch) tf.summary.scalar('accuracy', acc, step=epoch) TensorFlow Lite (Mobile/Edge Deployment) Convert to TensorFlow Lite # Convert Keras model to TensorFlow Lite converter = tf.lite.TFLiteConverter.from_keras_model(model) tflite_model = converter.convert() # Save the model with open('model.tflite', 'wb') as f: f.write(tflite_model) # Quantization for smaller model size converter.optimizations = [tf.lite.Optimize.DEFAULT] tflite_quantized_model = converter.convert() Run TensorFlow Lite Model # Load TensorFlow Lite model interpreter = tf.lite.Interpreter(model_path=\"model.tflite\") interpreter.allocate_tensors() # Get input and output tensors input_details = interpreter.get_input_details() output_details = interpreter.get_output_details() # Test the model input_data = np.array(test_image, dtype=np.float32) interpreter.set_tensor(input_details[0]['index'], input_data) interpreter.invoke() output_data = interpreter.get_tensor(output_details[0]['index']) Advanced Features Mixed Precision Training # Enable mixed precision policy = tf.keras.mixed_precision.Policy('mixed_float16') tf.keras.mixed_precision.set_global_policy(policy) # Loss scaling for numerical stability optimizer = tf.keras.optimizers.Adam() optimizer = tf.keras.mixed_precision.LossScaleOptimizer(optimizer) # In custom training loop with tf.GradientTape() as tape: predictions = model(x, training=True) loss = compute_loss(y, predictions) scaled_loss = optimizer.get_scaled_loss(loss) scaled_gradients = tape.gradient(scaled_loss, model.trainable_variables) gradients = optimizer.get_unscaled_gradients(scaled_gradients) optimizer.apply_gradients(zip(gradients, model.trainable_variables)) Distributed Training # Multi-GPU strategy strategy = tf.distribute.MirroredStrategy() with strategy.scope(): model = create_model() model.compile( optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'] ) # Multi-worker strategy strategy = tf.distribute.MultiWorkerMirroredStrategy() with strategy.scope(): multi_worker_dataset = strategy.distribute_datasets_from_function( dataset_fn ) multi_worker_model = create_model() Model Optimization # Pruning import tensorflow_model_optimization as tfmot prune_low_magnitude = tfmot.sparsity.keras.prune_low_magnitude pruning_params = { 'pruning_schedule': tfmot.sparsity.keras.PolynomialDecay( initial_sparsity=0.50, final_sparsity=0.80, begin_step=0, end_step=end_step ) } model_for_pruning = prune_low_magnitude(model, **pruning_params) # Quantization-aware training quantize_model = tfmot.quantization.keras.quantize_model q_aware_model = quantize_model(model) Debugging and Performance Profiling # Profile with TensorBoard tf.profiler.experimental.start(log_dir) # ... training code ... tf.profiler.experimental.stop() # Profile specific functions with tf.profiler.experimental.Trace('train', step_num=step): train_step() Memory Management # Limit GPU memory growth gpus = tf.config.experimental.list_physical_devices('GPU') if gpus: try: for gpu in gpus: tf.config.experimental.set_memory_growth(gpu, True) except RuntimeError as e: print(e) # Set memory limit tf.config.experimental.set_virtual_device_configuration( gpus[0], [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=1024)] ) Common Patterns and Best Practices Use tf.function for performance optimization Enable mixed precision for faster training on modern GPUs Use tf.data for efficient data loading and preprocessing Implement proper validation and early stopping Save model checkpoints regularly Use TensorBoard for monitoring training progress Apply data augmentation to improve generalization Consider transfer learning for faster convergence Use appropriate batch sizes based on available memory Normalize input data for better training stability","title":"TensorFlow"},{"location":"python/tensorflow/#tensorflow","text":"","title":"TensorFlow"},{"location":"python/tensorflow/#installation","text":"# CPU only pip install tensorflow # GPU support (requires CUDA) pip install tensorflow[and-cuda] # Development version pip install tf-nightly # Specific version pip install tensorflow==2.15.0 # Verify installation python -c \"import tensorflow as tf; print(tf.__version__)\"","title":"Installation"},{"location":"python/tensorflow/#import-essentials","text":"import tensorflow as tf import numpy as np import matplotlib.pyplot as plt from tensorflow import keras from tensorflow.keras import layers import tensorflow_datasets as tfds","title":"Import Essentials"},{"location":"python/tensorflow/#tensor-basics","text":"","title":"Tensor Basics"},{"location":"python/tensorflow/#creating-tensors","text":"# From Python lists tensor = tf.constant([1, 2, 3, 4]) matrix = tf.constant([[1, 2], [3, 4]]) # Zeros and ones zeros = tf.zeros([3, 4]) ones = tf.ones([2, 3]) identity = tf.eye(3) # Random tensors random_normal = tf.random.normal([3, 3]) random_uniform = tf.random.uniform([2, 2], minval=0, maxval=1) # From numpy numpy_array = np.array([1, 2, 3]) tensor_from_numpy = tf.constant(numpy_array) # Range tensors range_tensor = tf.range(10) linspace = tf.linspace(0.0, 1.0, 5)","title":"Creating Tensors"},{"location":"python/tensorflow/#tensor-properties","text":"tensor = tf.random.normal([3, 4, 5]) print(tensor.shape) # TensorShape([3, 4, 5]) print(tensor.dtype) # tf.float32 print(tensor.numpy()) # convert to numpy array print(tf.rank(tensor)) # number of dimensions (3) print(tf.size(tensor)) # total number of elements (60)","title":"Tensor Properties"},{"location":"python/tensorflow/#tensor-operations","text":"a = tf.constant([1, 2, 3]) b = tf.constant([4, 5, 6]) # Arithmetic operations c = a + b # tf.add(a, b) c = a - b # tf.subtract(a, b) c = a * b # element-wise multiplication c = a / b # element-wise division c = tf.matmul(a, b) # matrix multiplication c = a @ b # alternative matrix multiplication # Reductions tf.reduce_sum(tensor) # sum all elements tf.reduce_mean(tensor) # mean of all elements tf.reduce_max(tensor) # maximum element tf.reduce_min(tensor) # minimum element tf.reduce_sum(tensor, axis=1) # sum along axis 1","title":"Tensor Operations"},{"location":"python/tensorflow/#reshaping-and-indexing","text":"tensor = tf.random.normal([12]) # Reshaping reshaped = tf.reshape(tensor, [3, 4]) expanded = tf.expand_dims(tensor, axis=0) # add dimension squeezed = tf.squeeze(expanded) # remove dimension # Indexing and slicing tensor[0] # first element tensor[1:4] # slice tensor[:, 1] # all rows, column 1 tensor[..., -1] # last element along last axis # Advanced indexing tf.gather(tensor, indices=[0, 2, 4]) # gather specific indices tf.boolean_mask(tensor, tensor > 0) # boolean masking","title":"Reshaping and Indexing"},{"location":"python/tensorflow/#variables-and-gradienttape","text":"","title":"Variables and GradientTape"},{"location":"python/tensorflow/#variables","text":"# Creating variables var = tf.Variable(3.0, name=\"my_variable\") matrix_var = tf.Variable([[1.0, 2.0], [3.0, 4.0]]) # Updating variables var.assign(5.0) var.assign_add(2.0) # add 2 to current value var.assign_sub(1.0) # subtract 1 from current value","title":"Variables"},{"location":"python/tensorflow/#automatic-differentiation","text":"# Using GradientTape for automatic differentiation x = tf.Variable(3.0) with tf.GradientTape() as tape: y = x**2 + 2*x + 1 # Compute gradient dy_dx = tape.gradient(y, x) # dy/dx = 2*x + 2 = 8 # Multiple variables x1 = tf.Variable(2.0) x2 = tf.Variable(3.0) with tf.GradientTape() as tape: y = x1**2 + x2**2 gradients = tape.gradient(y, [x1, x2])","title":"Automatic Differentiation"},{"location":"python/tensorflow/#neural-networks-with-keras","text":"","title":"Neural Networks with Keras"},{"location":"python/tensorflow/#sequential-model","text":"model = tf.keras.Sequential([ layers.Dense(128, activation='relu', input_shape=(784,)), layers.Dropout(0.2), layers.Dense(64, activation='relu'), layers.Dense(10, activation='softmax') ]) # Alternative syntax model = tf.keras.Sequential() model.add(layers.Dense(128, activation='relu', input_shape=(784,))) model.add(layers.Dropout(0.2)) model.add(layers.Dense(10, activation='softmax'))","title":"Sequential Model"},{"location":"python/tensorflow/#functional-api","text":"inputs = layers.Input(shape=(784,)) x = layers.Dense(128, activation='relu')(inputs) x = layers.Dropout(0.2)(x) x = layers.Dense(64, activation='relu')(x) outputs = layers.Dense(10, activation='softmax')(x) model = tf.keras.Model(inputs=inputs, outputs=outputs)","title":"Functional API"},{"location":"python/tensorflow/#custom-model-subclassing","text":"class MyModel(tf.keras.Model): def __init__(self, num_classes=10): super(MyModel, self).__init__() self.dense1 = layers.Dense(128, activation='relu') self.dropout = layers.Dropout(0.2) self.dense2 = layers.Dense(num_classes, activation='softmax') def call(self, inputs, training=None): x = self.dense1(inputs) x = self.dropout(x, training=training) return self.dense2(x) model = MyModel()","title":"Custom Model (Subclassing)"},{"location":"python/tensorflow/#common-layers","text":"","title":"Common Layers"},{"location":"python/tensorflow/#dense-fully-connected","text":"layers.Dense(64, activation='relu') layers.Dense(10, activation='softmax', use_bias=False)","title":"Dense (Fully Connected)"},{"location":"python/tensorflow/#convolutional-layers","text":"layers.Conv1D(32, 3, activation='relu') layers.Conv2D(32, (3, 3), activation='relu', padding='same') layers.Conv3D(16, (3, 3, 3), activation='relu') # Separable convolutions layers.SeparableConv2D(64, (3, 3), activation='relu') layers.DepthwiseConv2D((3, 3), activation='relu')","title":"Convolutional Layers"},{"location":"python/tensorflow/#pooling-layers","text":"layers.MaxPooling2D((2, 2)) layers.AveragePooling2D((2, 2)) layers.GlobalMaxPooling2D() layers.GlobalAveragePooling2D()","title":"Pooling Layers"},{"location":"python/tensorflow/#recurrent-layers","text":"layers.SimpleRNN(32) layers.LSTM(64, return_sequences=True) layers.GRU(32, dropout=0.2, recurrent_dropout=0.2) layers.Bidirectional(layers.LSTM(32))","title":"Recurrent Layers"},{"location":"python/tensorflow/#normalization-and-regularization","text":"layers.BatchNormalization() layers.LayerNormalization() layers.Dropout(0.5) layers.AlphaDropout(0.1) # for SELU activation","title":"Normalization and Regularization"},{"location":"python/tensorflow/#activation-layers","text":"layers.ReLU() layers.LeakyReLU(alpha=0.3) layers.ELU(alpha=1.0) layers.Softmax() layers.Activation('tanh')","title":"Activation Layers"},{"location":"python/tensorflow/#model-compilation-and-training","text":"","title":"Model Compilation and Training"},{"location":"python/tensorflow/#compile-model","text":"model.compile( optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'] ) # Custom optimizer model.compile( optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), loss=tf.keras.losses.SparseCategoricalCrossentropy(), metrics=[tf.keras.metrics.SparseCategoricalAccuracy()] )","title":"Compile Model"},{"location":"python/tensorflow/#training","text":"# Basic training history = model.fit( x_train, y_train, batch_size=32, epochs=10, validation_data=(x_val, y_val), verbose=1 ) # With callbacks callbacks = [ tf.keras.callbacks.EarlyStopping(patience=3, restore_best_weights=True), tf.keras.callbacks.ReduceLROnPlateau(factor=0.2, patience=2), tf.keras.callbacks.ModelCheckpoint('best_model.h5', save_best_only=True) ] model.fit( x_train, y_train, validation_data=(x_val, y_val), epochs=50, callbacks=callbacks )","title":"Training"},{"location":"python/tensorflow/#data-loading-and-preprocessing","text":"","title":"Data Loading and Preprocessing"},{"location":"python/tensorflow/#tfdata-api","text":"# From arrays dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train)) dataset = dataset.batch(32).shuffle(1000).prefetch(tf.data.AUTOTUNE) # From files dataset = tf.data.Dataset.list_files(\"path/to/images/*.jpg\") dataset = dataset.map(preprocess_function) dataset = dataset.batch(32).prefetch(tf.data.AUTOTUNE) # Image data from directory train_ds = tf.keras.utils.image_dataset_from_directory( 'path/to/train', validation_split=0.2, subset=\"training\", seed=123, image_size=(180, 180), batch_size=32 )","title":"tf.data API"},{"location":"python/tensorflow/#data-augmentation","text":"data_augmentation = tf.keras.Sequential([ layers.RandomFlip(\"horizontal\"), layers.RandomRotation(0.1), layers.RandomZoom(0.1), layers.RandomContrast(0.1), ]) # Apply to model model = tf.keras.Sequential([ data_augmentation, layers.Rescaling(1./255), layers.Conv2D(32, 3, activation='relu'), # ... rest of model ])","title":"Data Augmentation"},{"location":"python/tensorflow/#loss-functions-and-optimizers","text":"","title":"Loss Functions and Optimizers"},{"location":"python/tensorflow/#common-loss-functions","text":"# Classification tf.keras.losses.BinaryCrossentropy() tf.keras.losses.CategoricalCrossentropy() tf.keras.losses.SparseCategoricalCrossentropy() # Regression tf.keras.losses.MeanSquaredError() tf.keras.losses.MeanAbsoluteError() tf.keras.losses.Huber() # Custom loss @tf.function def custom_loss(y_true, y_pred): return tf.reduce_mean(tf.square(y_true - y_pred))","title":"Common Loss Functions"},{"location":"python/tensorflow/#optimizers","text":"tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.9) tf.keras.optimizers.Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999) tf.keras.optimizers.AdamW(learning_rate=0.001, weight_decay=0.01) tf.keras.optimizers.RMSprop(learning_rate=0.001) tf.keras.optimizers.Adagrad(learning_rate=0.01) # Learning rate schedules initial_learning_rate = 0.1 lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay( initial_learning_rate, decay_steps=100000, decay_rate=0.96, staircase=True ) optimizer = tf.keras.optimizers.SGD(learning_rate=lr_schedule)","title":"Optimizers"},{"location":"python/tensorflow/#model-evaluation-and-prediction","text":"","title":"Model Evaluation and Prediction"},{"location":"python/tensorflow/#evaluation","text":"# Evaluate model loss, accuracy = model.evaluate(x_test, y_test, verbose=0) print(f\"Test accuracy: {accuracy:.4f}\") # Custom metrics test_loss = tf.keras.metrics.Mean() test_accuracy = tf.keras.metrics.SparseCategoricalAccuracy() @tf.function def test_step(images, labels): predictions = model(images, training=False) t_loss = loss_object(labels, predictions) test_loss(t_loss) test_accuracy(labels, predictions)","title":"Evaluation"},{"location":"python/tensorflow/#predictions","text":"predictions = model.predict(x_test) predicted_classes = np.argmax(predictions, axis=1) # Prediction on single sample single_prediction = model.predict(tf.expand_dims(single_image, 0))","title":"Predictions"},{"location":"python/tensorflow/#model-saving-and-loading","text":"","title":"Model Saving and Loading"},{"location":"python/tensorflow/#saveload-entire-model","text":"# Save model model.save('my_model.h5') # HDF5 format model.save('my_model') # SavedModel format # Load model loaded_model = tf.keras.models.load_model('my_model.h5') loaded_model = tf.keras.models.load_model('my_model')","title":"Save/Load Entire Model"},{"location":"python/tensorflow/#saveload-weights-only","text":"# Save weights model.save_weights('model_weights.h5') # Load weights model.load_weights('model_weights.h5')","title":"Save/Load Weights Only"},{"location":"python/tensorflow/#checkpoints","text":"checkpoint_path = \"training_checkpoints/cp.ckpt\" checkpoint_dir = os.path.dirname(checkpoint_path) cp_callback = tf.keras.callbacks.ModelCheckpoint( filepath=checkpoint_path, save_weights_only=True, verbose=1 ) # Load latest checkpoint latest = tf.train.latest_checkpoint(checkpoint_dir) model.load_weights(latest)","title":"Checkpoints"},{"location":"python/tensorflow/#custom-training-loops","text":"","title":"Custom Training Loops"},{"location":"python/tensorflow/#basic-custom-training","text":"@tf.function def train_step(images, labels): with tf.GradientTape() as tape: predictions = model(images, training=True) loss = loss_object(labels, predictions) gradients = tape.gradient(loss, model.trainable_variables) optimizer.apply_gradients(zip(gradients, model.trainable_variables)) train_loss(loss) train_accuracy(labels, predictions) # Training loop for epoch in range(EPOCHS): train_loss.reset_states() train_accuracy.reset_states() for images, labels in train_ds: train_step(images, labels) print(f'Epoch {epoch + 1}, ' f'Loss: {train_loss.result():.4f}, ' f'Accuracy: {train_accuracy.result():.4f}')","title":"Basic Custom Training"},{"location":"python/tensorflow/#transfer-learning","text":"","title":"Transfer Learning"},{"location":"python/tensorflow/#using-pre-trained-models","text":"# Load pre-trained model base_model = tf.keras.applications.VGG16( weights='imagenet', include_top=False, input_shape=(224, 224, 3) ) # Freeze base model base_model.trainable = False # Add custom head model = tf.keras.Sequential([ base_model, layers.GlobalAveragePooling2D(), layers.Dense(128, activation='relu'), layers.Dense(num_classes, activation='softmax') ]) # Fine-tuning: unfreeze some layers base_model.trainable = True fine_tune_at = 100 for layer in base_model.layers[:fine_tune_at]: layer.trainable = False","title":"Using Pre-trained Models"},{"location":"python/tensorflow/#tensorboard-integration","text":"","title":"TensorBoard Integration"},{"location":"python/tensorflow/#setting-up-tensorboard","text":"# TensorBoard callback log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\") tensorboard_callback = tf.keras.callbacks.TensorBoard( log_dir=log_dir, histogram_freq=1 ) model.fit( x_train, y_train, epochs=10, validation_data=(x_val, y_val), callbacks=[tensorboard_callback] ) # Custom scalars with tf.summary.create_file_writer(log_dir).as_default(): tf.summary.scalar('learning_rate', lr, step=epoch) tf.summary.scalar('accuracy', acc, step=epoch)","title":"Setting up TensorBoard"},{"location":"python/tensorflow/#tensorflow-lite-mobileedge-deployment","text":"","title":"TensorFlow Lite (Mobile/Edge Deployment)"},{"location":"python/tensorflow/#convert-to-tensorflow-lite","text":"# Convert Keras model to TensorFlow Lite converter = tf.lite.TFLiteConverter.from_keras_model(model) tflite_model = converter.convert() # Save the model with open('model.tflite', 'wb') as f: f.write(tflite_model) # Quantization for smaller model size converter.optimizations = [tf.lite.Optimize.DEFAULT] tflite_quantized_model = converter.convert()","title":"Convert to TensorFlow Lite"},{"location":"python/tensorflow/#run-tensorflow-lite-model","text":"# Load TensorFlow Lite model interpreter = tf.lite.Interpreter(model_path=\"model.tflite\") interpreter.allocate_tensors() # Get input and output tensors input_details = interpreter.get_input_details() output_details = interpreter.get_output_details() # Test the model input_data = np.array(test_image, dtype=np.float32) interpreter.set_tensor(input_details[0]['index'], input_data) interpreter.invoke() output_data = interpreter.get_tensor(output_details[0]['index'])","title":"Run TensorFlow Lite Model"},{"location":"python/tensorflow/#advanced-features","text":"","title":"Advanced Features"},{"location":"python/tensorflow/#mixed-precision-training","text":"# Enable mixed precision policy = tf.keras.mixed_precision.Policy('mixed_float16') tf.keras.mixed_precision.set_global_policy(policy) # Loss scaling for numerical stability optimizer = tf.keras.optimizers.Adam() optimizer = tf.keras.mixed_precision.LossScaleOptimizer(optimizer) # In custom training loop with tf.GradientTape() as tape: predictions = model(x, training=True) loss = compute_loss(y, predictions) scaled_loss = optimizer.get_scaled_loss(loss) scaled_gradients = tape.gradient(scaled_loss, model.trainable_variables) gradients = optimizer.get_unscaled_gradients(scaled_gradients) optimizer.apply_gradients(zip(gradients, model.trainable_variables))","title":"Mixed Precision Training"},{"location":"python/tensorflow/#distributed-training","text":"# Multi-GPU strategy strategy = tf.distribute.MirroredStrategy() with strategy.scope(): model = create_model() model.compile( optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'] ) # Multi-worker strategy strategy = tf.distribute.MultiWorkerMirroredStrategy() with strategy.scope(): multi_worker_dataset = strategy.distribute_datasets_from_function( dataset_fn ) multi_worker_model = create_model()","title":"Distributed Training"},{"location":"python/tensorflow/#model-optimization","text":"# Pruning import tensorflow_model_optimization as tfmot prune_low_magnitude = tfmot.sparsity.keras.prune_low_magnitude pruning_params = { 'pruning_schedule': tfmot.sparsity.keras.PolynomialDecay( initial_sparsity=0.50, final_sparsity=0.80, begin_step=0, end_step=end_step ) } model_for_pruning = prune_low_magnitude(model, **pruning_params) # Quantization-aware training quantize_model = tfmot.quantization.keras.quantize_model q_aware_model = quantize_model(model)","title":"Model Optimization"},{"location":"python/tensorflow/#debugging-and-performance","text":"","title":"Debugging and Performance"},{"location":"python/tensorflow/#profiling","text":"# Profile with TensorBoard tf.profiler.experimental.start(log_dir) # ... training code ... tf.profiler.experimental.stop() # Profile specific functions with tf.profiler.experimental.Trace('train', step_num=step): train_step()","title":"Profiling"},{"location":"python/tensorflow/#memory-management","text":"# Limit GPU memory growth gpus = tf.config.experimental.list_physical_devices('GPU') if gpus: try: for gpu in gpus: tf.config.experimental.set_memory_growth(gpu, True) except RuntimeError as e: print(e) # Set memory limit tf.config.experimental.set_virtual_device_configuration( gpus[0], [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=1024)] )","title":"Memory Management"},{"location":"python/tensorflow/#common-patterns-and-best-practices","text":"Use tf.function for performance optimization Enable mixed precision for faster training on modern GPUs Use tf.data for efficient data loading and preprocessing Implement proper validation and early stopping Save model checkpoints regularly Use TensorBoard for monitoring training progress Apply data augmentation to improve generalization Consider transfer learning for faster convergence Use appropriate batch sizes based on available memory Normalize input data for better training stability","title":"Common Patterns and Best Practices"},{"location":"python/torchvision/","text":"TorchVision TorchVision is PyTorch's computer vision library, providing datasets, model architectures, and common image transformations for computer vision tasks. It includes pre-trained models, data loading utilities, and transforms for efficient computer vision pipelines. Installation # Basic installation with PyTorch pip install torch torchvision # With CUDA support (check PyTorch website for correct version) pip install torch torchvision --extra-index-url https://download.pytorch.org/whl/cu118 # Development version pip install git+https://github.com/pytorch/vision.git # With additional dependencies pip install torchvision pillow matplotlib opencv-python Basic Setup import torch import torchvision import torchvision.transforms as transforms import torchvision.datasets as datasets import torchvision.models as models from torchvision.utils import make_grid, save_image from torch.utils.data import DataLoader import matplotlib.pyplot as plt import numpy as np from PIL import Image # Check versions print(f\"TorchVision version: {torchvision.__version__}\") print(f\"PyTorch version: {torch.__version__}\") Core Functionality Image Transforms # Basic transforms transform = transforms.Compose([ transforms.Resize(256), # Resize to 256x256 transforms.CenterCrop(224), # Center crop to 224x224 transforms.ToTensor(), # Convert PIL to tensor [0,1] transforms.Normalize( # Normalize with ImageNet stats mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225] ) ]) # Data augmentation transforms train_transform = transforms.Compose([ transforms.RandomResizedCrop(224), # Random crop and resize transforms.RandomHorizontalFlip(p=0.5), # Random horizontal flip transforms.ColorJitter( # Random color changes brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1 ), transforms.RandomRotation(10), # Random rotation \u00b110 degrees transforms.ToTensor(), transforms.Normalize( mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225] ) ]) # Validation/test transforms (no augmentation) val_transform = transforms.Compose([ transforms.Resize(256), transforms.CenterCrop(224), transforms.ToTensor(), transforms.Normalize( mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225] ) ]) # Apply transforms to an image image = Image.open(\"path/to/image.jpg\") transformed_image = transform(image) print(f\"Original size: {image.size}\") print(f\"Transformed shape: {transformed_image.shape}\") # [C, H, W] Advanced Transforms # Geometric transforms geometric_transforms = transforms.Compose([ transforms.RandomAffine( degrees=15, # Rotation translate=(0.1, 0.1), # Translation scale=(0.8, 1.2), # Scale shear=10 # Shear ), transforms.RandomPerspective( distortion_scale=0.2, p=0.5 ), transforms.ElasticTransform(alpha=250.0, sigma=5.0) # Elastic deformation ]) # Advanced color transforms color_transforms = transforms.Compose([ transforms.RandomAutocontrast(p=0.5), transforms.RandomEqualize(p=0.5), transforms.RandomPosterize(bits=2, p=0.5), transforms.RandomSolarize(threshold=128, p=0.5), transforms.RandomAdjustSharpness(sharpness_factor=2, p=0.5) ]) # Cutout/Erasing augmentation erase_transform = transforms.Compose([ transforms.ToTensor(), transforms.RandomErasing( p=0.5, scale=(0.02, 0.33), ratio=(0.3, 3.3), value=0 ) ]) # Mix multiple transforms strong_augment = transforms.Compose([ transforms.RandomResizedCrop(224), transforms.RandomHorizontalFlip(), color_transforms, transforms.ToTensor(), transforms.RandomErasing(p=0.25), transforms.Normalize( mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225] ) ]) Built-in Datasets # CIFAR-10 dataset cifar10_train = datasets.CIFAR10( root='./data', train=True, download=True, transform=train_transform ) cifar10_test = datasets.CIFAR10( root='./data', train=False, download=True, transform=val_transform ) # ImageNet dataset (requires downloaded data) imagenet_train = datasets.ImageNet( root='./data/imagenet', split='train', transform=train_transform ) # COCO dataset coco_train = datasets.CocoDetection( root='./data/coco/train2017', annFile='./data/coco/annotations/instances_train2017.json', transform=transforms.ToTensor() ) # Custom dataset from folder structure custom_dataset = datasets.ImageFolder( root='./data/custom', # Folder with subdirectories for each class transform=train_transform ) # Data loaders train_loader = DataLoader( cifar10_train, batch_size=32, shuffle=True, num_workers=4, pin_memory=True ) test_loader = DataLoader( cifar10_test, batch_size=32, shuffle=False, num_workers=4, pin_memory=True ) # Dataset info print(f\"Training samples: {len(cifar10_train)}\") print(f\"Test samples: {len(cifar10_test)}\") print(f\"Classes: {cifar10_train.classes}\") print(f\"Number of classes: {len(cifar10_train.classes)}\") Pre-trained Models # Image Classification Models resnet50 = models.resnet50(pretrained=True) resnet101 = models.resnet101(weights=models.ResNet101_Weights.IMAGENET1K_V1) # Vision Transformers vit_b_16 = models.vit_b_16(weights=models.ViT_B_16_Weights.IMAGENET1K_V1) vit_l_16 = models.vit_l_16(weights=models.ViT_L_16_Weights.IMAGENET1K_V1) # EfficientNet models efficientnet_b0 = models.efficientnet_b0(weights=models.EfficientNet_B0_Weights.IMAGENET1K_V1) efficientnet_b7 = models.efficientnet_b7(weights=models.EfficientNet_B7_Weights.IMAGENET1K_V1) # ConvNext models convnext_tiny = models.convnext_tiny(weights=models.ConvNeXt_Tiny_Weights.IMAGENET1K_V1) convnext_base = models.convnext_base(weights=models.ConvNeXt_Base_Weights.IMAGENET1K_V1) # Object Detection Models fasterrcnn_resnet50 = models.detection.fasterrcnn_resnet50_fpn( weights=models.detection.FasterRCNN_ResNet50_FPN_Weights.COCO_V1 ) # Semantic Segmentation Models deeplabv3_resnet50 = models.segmentation.deeplabv3_resnet50( weights=models.segmentation.DeepLabV3_ResNet50_Weights.COCO_WITH_VOC_LABELS_V1 ) # Set models to evaluation mode resnet50.eval() # Modify models for different number of classes num_classes = 10 # CIFAR-10 has 10 classes resnet50.fc = torch.nn.Linear(resnet50.fc.in_features, num_classes) print(f\"Model: {resnet50.__class__.__name__}\") print(f\"Number of parameters: {sum(p.numel() for p in resnet50.parameters()):,}\") Common Use Cases Image Classification import torch.nn as nn import torch.optim as optim from torchvision import models, transforms, datasets class ImageClassifier: def __init__(self, num_classes=10, model_name='resnet50', pretrained=True): self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') # Load pre-trained model if model_name == 'resnet50': self.model = models.resnet50(pretrained=pretrained) self.model.fc = nn.Linear(self.model.fc.in_features, num_classes) elif model_name == 'vit_b_16': self.model = models.vit_b_16(pretrained=pretrained) self.model.heads.head = nn.Linear(self.model.heads.head.in_features, num_classes) self.model.to(self.device) # Loss and optimizer self.criterion = nn.CrossEntropyLoss() self.optimizer = optim.Adam(self.model.parameters(), lr=0.001) self.scheduler = optim.lr_scheduler.StepLR(self.optimizer, step_size=7, gamma=0.1) def train_epoch(self, train_loader): self.model.train() running_loss = 0.0 correct = 0 total = 0 for batch_idx, (data, target) in enumerate(train_loader): data, target = data.to(self.device), target.to(self.device) self.optimizer.zero_grad() output = self.model(data) loss = self.criterion(output, target) loss.backward() self.optimizer.step() running_loss += loss.item() _, predicted = torch.max(output.data, 1) total += target.size(0) correct += (predicted == target).sum().item() if batch_idx % 100 == 0: print(f'Batch {batch_idx}, Loss: {loss.item():.6f}') accuracy = 100 * correct / total avg_loss = running_loss / len(train_loader) return avg_loss, accuracy def evaluate(self, test_loader): self.model.eval() test_loss = 0.0 correct = 0 total = 0 with torch.no_grad(): for data, target in test_loader: data, target = data.to(self.device), target.to(self.device) output = self.model(data) test_loss += self.criterion(output, target).item() _, predicted = torch.max(output.data, 1) total += target.size(0) correct += (predicted == target).sum().item() accuracy = 100 * correct / total avg_loss = test_loss / len(test_loader) return avg_loss, accuracy def predict(self, image_path, transform, class_names): self.model.eval() # Load and transform image image = Image.open(image_path) image_tensor = transform(image).unsqueeze(0).to(self.device) with torch.no_grad(): output = self.model(image_tensor) probabilities = torch.nn.functional.softmax(output[0], dim=0) predicted_class = torch.argmax(probabilities).item() confidence = probabilities[predicted_class].item() return class_names[predicted_class], confidence, probabilities # Usage example classifier = ImageClassifier(num_classes=10, model_name='resnet50') # Training loop for epoch in range(10): train_loss, train_acc = classifier.train_epoch(train_loader) test_loss, test_acc = classifier.evaluate(test_loader) classifier.scheduler.step() print(f'Epoch {epoch+1}/10:') print(f' Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%') print(f' Test Loss: {test_loss:.4f}, Test Acc: {test_acc:.2f}%') # Single image prediction class_names = cifar10_train.classes prediction, confidence, probs = classifier.predict( 'path/to/image.jpg', val_transform, class_names ) print(f\"Prediction: {prediction} (Confidence: {confidence:.3f})\") Transfer Learning def create_transfer_learning_model(num_classes, freeze_features=True): \"\"\"Create a transfer learning model from pre-trained ResNet\"\"\" # Load pre-trained model model = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V1) # Freeze feature extraction layers (optional) if freeze_features: for param in model.parameters(): param.requires_grad = False # Replace final classification layer num_features = model.fc.in_features model.fc = nn.Sequential( nn.Dropout(0.5), nn.Linear(num_features, 512), nn.ReLU(), nn.Dropout(0.5), nn.Linear(512, num_classes) ) return model def fine_tune_model(model, train_loader, val_loader, num_epochs=25): \"\"\"Fine-tune a transfer learning model\"\"\" device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') model.to(device) # Different learning rates for different parts feature_params = [] classifier_params = [] for name, param in model.named_parameters(): if 'fc' in name: classifier_params.append(param) else: feature_params.append(param) # Optimizer with different learning rates optimizer = optim.Adam([ {'params': feature_params, 'lr': 1e-4}, {'params': classifier_params, 'lr': 1e-3} ]) criterion = nn.CrossEntropyLoss() scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=3) best_acc = 0.0 train_losses, val_losses = [], [] train_accuracies, val_accuracies = [], [] for epoch in range(num_epochs): # Training phase model.train() running_loss = 0.0 correct = 0 total = 0 for inputs, labels in train_loader: inputs, labels = inputs.to(device), labels.to(device) optimizer.zero_grad() outputs = model(inputs) loss = criterion(outputs, labels) loss.backward() optimizer.step() running_loss += loss.item() _, predicted = torch.max(outputs, 1) total += labels.size(0) correct += (predicted == labels).sum().item() train_loss = running_loss / len(train_loader) train_acc = 100 * correct / total # Validation phase model.eval() val_running_loss = 0.0 val_correct = 0 val_total = 0 with torch.no_grad(): for inputs, labels in val_loader: inputs, labels = inputs.to(device), labels.to(device) outputs = model(inputs) loss = criterion(outputs, labels) val_running_loss += loss.item() _, predicted = torch.max(outputs, 1) val_total += labels.size(0) val_correct += (predicted == labels).sum().item() val_loss = val_running_loss / len(val_loader) val_acc = 100 * val_correct / val_total scheduler.step(val_loss) # Save best model if val_acc > best_acc: best_acc = val_acc torch.save(model.state_dict(), 'best_model.pth') # Store metrics train_losses.append(train_loss) val_losses.append(val_loss) train_accuracies.append(train_acc) val_accuracies.append(val_acc) print(f'Epoch {epoch+1}/{num_epochs}:') print(f' Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%') print(f' Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%') return model, (train_losses, val_losses, train_accuracies, val_accuracies) # Usage model = create_transfer_learning_model(num_classes=10, freeze_features=False) model, metrics = fine_tune_model(model, train_loader, test_loader) Object Detection import torchvision.transforms as T from torchvision.models.detection import fasterrcnn_resnet50_fpn from torchvision.models.detection.faster_rcnn import FastRCNNPredictor class ObjectDetector: def __init__(self, num_classes=91): # COCO has 80 classes + background self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') # Load pre-trained Faster R-CNN model self.model = fasterrcnn_resnet50_fpn(pretrained=True) # Replace classifier head for custom number of classes in_features = self.model.roi_heads.box_predictor.cls_score.in_features self.model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes) self.model.to(self.device) # COCO class names (for visualization) self.coco_names = [ 'background', 'person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus', 'train', 'truck', 'boat', 'traffic light', 'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow', 'elephant', 'bear', 'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie', 'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard', 'tennis racket', 'bottle', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple', 'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair', 'couch', 'potted plant', 'bed', 'dining table', 'toilet', 'tv', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone', 'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors', 'teddy bear', 'hair drier', 'toothbrush' ] def predict(self, image_path, threshold=0.5): \"\"\"Perform object detection on an image\"\"\" self.model.eval() # Load and transform image image = Image.open(image_path).convert('RGB') transform = T.Compose([T.ToTensor()]) image_tensor = transform(image).unsqueeze(0).to(self.device) with torch.no_grad(): predictions = self.model(image_tensor) # Filter predictions by confidence threshold boxes = predictions[0]['boxes'][predictions[0]['scores'] > threshold] labels = predictions[0]['labels'][predictions[0]['scores'] > threshold] scores = predictions[0]['scores'][predictions[0]['scores'] > threshold] results = [] for box, label, score in zip(boxes, labels, scores): results.append({ 'box': box.cpu().numpy(), 'label': self.coco_names[label.item()], 'score': score.item() }) return results def visualize_predictions(self, image_path, predictions, save_path=None): \"\"\"Visualize object detection results\"\"\" import matplotlib.pyplot as plt import matplotlib.patches as patches image = Image.open(image_path) fig, ax = plt.subplots(1, 1, figsize=(12, 8)) ax.imshow(image) for pred in predictions: box = pred['box'] label = pred['label'] score = pred['score'] # Create rectangle patch rect = patches.Rectangle( (box[0], box[1]), box[2] - box[0], box[3] - box[1], linewidth=2, edgecolor='red', facecolor='none' ) ax.add_patch(rect) ax.text( box[0], box[1] - 10, f'{label}: {score:.2f}', fontsize=12, color='red', bbox=dict(boxstyle='round', facecolor='white', alpha=0.8) ) ax.set_xlim(0, image.width) ax.set_ylim(image.height, 0) ax.axis('off') if save_path: plt.savefig(save_path, bbox_inches='tight', dpi=300) plt.show() # Usage detector = ObjectDetector() predictions = detector.predict('path/to/image.jpg', threshold=0.5) print(f\"Found {len(predictions)} objects:\") for pred in predictions: print(f\" {pred['label']}: {pred['score']:.3f}\") detector.visualize_predictions('path/to/image.jpg', predictions) Image Segmentation from torchvision.models.segmentation import deeplabv3_resnet50 class SemanticSegmentation: def __init__(self, num_classes=21): # PASCAL VOC has 20 classes + background self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') # Load pre-trained DeepLabV3 model self.model = deeplabv3_resnet50(pretrained=True) # Replace classifier for custom number of classes self.model.classifier[4] = nn.Conv2d(256, num_classes, kernel_size=1) self.model.aux_classifier[4] = nn.Conv2d(256, num_classes, kernel_size=1) self.model.to(self.device) # PASCAL VOC class names self.class_names = [ 'background', 'aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'dining table', 'dog', 'horse', 'motorbike', 'person', 'potted plant', 'sheep', 'sofa', 'train', 'tv monitor' ] # Color palette for visualization self.palette = [ [0, 0, 0], [128, 0, 0], [0, 128, 0], [128, 128, 0], [0, 0, 128], [128, 0, 128], [0, 128, 128], [128, 128, 128], [64, 0, 0], [192, 0, 0], [64, 128, 0], [192, 128, 0], [64, 0, 128], [192, 0, 128], [64, 128, 128], [192, 128, 128], [0, 64, 0], [128, 64, 0], [0, 192, 0], [128, 192, 0], [0, 64, 128] ] def segment(self, image_path): \"\"\"Perform semantic segmentation on an image\"\"\" self.model.eval() # Load and transform image image = Image.open(image_path).convert('RGB') transform = transforms.Compose([ transforms.ToTensor(), transforms.Normalize( mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225] ) ]) input_tensor = transform(image).unsqueeze(0).to(self.device) with torch.no_grad(): output = self.model(input_tensor)['out'] output_predictions = output.argmax(1) # Convert to numpy mask = output_predictions.squeeze().cpu().numpy() return image, mask def visualize_segmentation(self, image, mask, alpha=0.7): \"\"\"Visualize segmentation results\"\"\" import matplotlib.pyplot as plt # Create colored mask colored_mask = np.zeros((*mask.shape, 3), dtype=np.uint8) for class_id in range(len(self.class_names)): colored_mask[mask == class_id] = self.palette[class_id] # Plot fig, axes = plt.subplots(1, 3, figsize=(15, 5)) axes[0].imshow(image) axes[0].set_title('Original Image') axes[0].axis('off') axes[1].imshow(colored_mask) axes[1].set_title('Segmentation Mask') axes[1].axis('off') # Overlay axes[2].imshow(image) axes[2].imshow(colored_mask, alpha=alpha) axes[2].set_title('Overlay') axes[2].axis('off') plt.tight_layout() plt.show() def get_class_statistics(self, mask): \"\"\"Get statistics about segmented classes\"\"\" unique_classes, counts = np.unique(mask, return_counts=True) total_pixels = mask.size stats = [] for class_id, count in zip(unique_classes, counts): if class_id < len(self.class_names): percentage = (count / total_pixels) * 100 stats.append({ 'class': self.class_names[class_id], 'pixels': count, 'percentage': percentage }) return sorted(stats, key=lambda x: x['percentage'], reverse=True) # Usage segmenter = SemanticSegmentation() image, mask = segmenter.segment('path/to/image.jpg') # Visualize results segmenter.visualize_segmentation(image, mask) # Get statistics stats = segmenter.get_class_statistics(mask) print(\"Class distribution:\") for stat in stats: if stat['percentage'] > 1.0: # Only show classes with >1% coverage print(f\" {stat['class']}: {stat['percentage']:.1f}%\") Advanced Features Custom Datasets import os import json from torch.utils.data import Dataset class CustomImageDataset(Dataset): def __init__(self, root_dir, annotation_file, transform=None): self.root_dir = root_dir self.transform = transform # Load annotations with open(annotation_file, 'r') as f: self.annotations = json.load(f) self.image_paths = list(self.annotations.keys()) def __len__(self): return len(self.image_paths) def __getitem__(self, idx): img_path = os.path.join(self.root_dir, self.image_paths[idx]) image = Image.open(img_path).convert('RGB') # Get label from annotations label = self.annotations[self.image_paths[idx]]['label'] if self.transform: image = self.transform(image) return image, label class CocoStyleDataset(Dataset): \"\"\"Dataset for COCO-style object detection annotations\"\"\" def __init__(self, root_dir, annotation_file, transform=None): self.root_dir = root_dir self.transform = transform with open(annotation_file, 'r') as f: self.coco = json.load(f) # Create mappings self.image_id_to_path = {img['id']: img['file_name'] for img in self.coco['images']} self.category_id_to_name = {cat['id']: cat['name'] for cat in self.coco['categories']} # Group annotations by image self.image_annotations = {} for ann in self.coco['annotations']: img_id = ann['image_id'] if img_id not in self.image_annotations: self.image_annotations[img_id] = [] self.image_annotations[img_id].append(ann) self.image_ids = list(self.image_id_to_path.keys()) def __len__(self): return len(self.image_ids) def __getitem__(self, idx): img_id = self.image_ids[idx] img_path = os.path.join(self.root_dir, self.image_id_to_path[img_id]) # Load image image = Image.open(img_path).convert('RGB') # Get annotations for this image annotations = self.image_annotations.get(img_id, []) # Extract boxes and labels boxes = [] labels = [] for ann in annotations: x, y, w, h = ann['bbox'] boxes.append([x, y, x + w, y + h]) labels.append(ann['category_id']) # Convert to tensors boxes = torch.tensor(boxes, dtype=torch.float32) labels = torch.tensor(labels, dtype=torch.int64) target = { 'boxes': boxes, 'labels': labels, 'image_id': torch.tensor(img_id) } if self.transform: image = self.transform(image) return image, target # Data loading utilities def create_data_loaders(train_dataset, val_dataset, batch_size=32, num_workers=4): \"\"\"Create data loaders with proper collate function for object detection\"\"\" def collate_fn(batch): return tuple(zip(*batch)) train_loader = DataLoader( train_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers, collate_fn=collate_fn, pin_memory=True ) val_loader = DataLoader( val_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers, collate_fn=collate_fn, pin_memory=True ) return train_loader, val_loader # Usage train_dataset = CustomImageDataset( root_dir='./data/train', annotation_file='./data/train_annotations.json', transform=train_transform ) val_dataset = CustomImageDataset( root_dir='./data/val', annotation_file='./data/val_annotations.json', transform=val_transform ) train_loader, val_loader = create_data_loaders(train_dataset, val_dataset) Model Interpretability from torchvision.models.feature_extraction import create_feature_extractor import torch.nn.functional as F class GradCAM: def __init__(self, model, target_layer): self.model = model self.target_layer = target_layer self.gradients = None self.activations = None # Register hooks target_layer.register_forward_hook(self.save_activation) target_layer.register_backward_hook(self.save_gradient) def save_activation(self, module, input, output): self.activations = output def save_gradient(self, module, grad_input, grad_output): self.gradients = grad_output[0] def generate_cam(self, input_image, class_idx): self.model.eval() # Forward pass output = self.model(input_image) # Backward pass self.model.zero_grad() class_score = output[:, class_idx] class_score.backward() # Generate CAM gradients = self.gradients[0] # Remove batch dimension activations = self.activations[0] # Remove batch dimension # Global average pooling of gradients weights = torch.mean(gradients, dim=(1, 2)) # Weighted combination of activation maps cam = torch.zeros(activations.shape[1:], dtype=torch.float32) for i, w in enumerate(weights): cam += w * activations[i] # Apply ReLU and normalize cam = F.relu(cam) cam = cam / torch.max(cam) return cam def visualize_gradcam(model, image_path, target_class, transform): \"\"\"Visualize GradCAM for a specific class\"\"\" import matplotlib.pyplot as plt import cv2 # Load and transform image image = Image.open(image_path).convert('RGB') input_tensor = transform(image).unsqueeze(0) # Create GradCAM target_layer = model.layer4[-1].conv2 # ResNet50 example grad_cam = GradCAM(model, target_layer) # Generate CAM cam = grad_cam.generate_cam(input_tensor, target_class) # Resize CAM to image size cam_resized = cv2.resize(cam.numpy(), (image.width, image.height)) # Visualize fig, axes = plt.subplots(1, 3, figsize=(15, 5)) axes[0].imshow(image) axes[0].set_title('Original Image') axes[0].axis('off') axes[1].imshow(cam_resized, cmap='jet') axes[1].set_title('GradCAM') axes[1].axis('off') # Overlay axes[2].imshow(image) axes[2].imshow(cam_resized, cmap='jet', alpha=0.4) axes[2].set_title('Overlay') axes[2].axis('off') plt.tight_layout() plt.show() # Feature visualization def visualize_feature_maps(model, image_path, layer_name, transform, max_channels=16): \"\"\"Visualize feature maps from a specific layer\"\"\" # Extract features feature_extractor = create_feature_extractor(model, return_nodes=[layer_name]) # Load and transform image image = Image.open(image_path).convert('RGB') input_tensor = transform(image).unsqueeze(0) # Get features with torch.no_grad(): features = feature_extractor(input_tensor)[layer_name] # Visualize feature maps features = features[0] # Remove batch dimension n_channels = min(max_channels, features.shape[0]) fig, axes = plt.subplots(4, 4, figsize=(12, 12)) axes = axes.ravel() for i in range(n_channels): feature_map = features[i].cpu().numpy() axes[i].imshow(feature_map, cmap='viridis') axes[i].set_title(f'Channel {i}') axes[i].axis('off') # Hide unused subplots for i in range(n_channels, 16): axes[i].axis('off') plt.tight_layout() plt.show() # Usage model = models.resnet50(pretrained=True) visualize_gradcam(model, 'path/to/image.jpg', target_class=281, transform=val_transform) # 281 is 'tabby cat' in ImageNet visualize_feature_maps(model, 'path/to/image.jpg', 'layer4.0.conv1', val_transform) Integration with Other Libraries With OpenCV import cv2 import numpy as np def opencv_to_tensor(cv_image): \"\"\"Convert OpenCV image to PyTorch tensor\"\"\" # OpenCV uses BGR, convert to RGB rgb_image = cv2.cvtColor(cv_image, cv2.COLOR_BGR2RGB) # Convert to PIL Image then apply transforms pil_image = Image.fromarray(rgb_image) transform = transforms.Compose([ transforms.ToTensor(), transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]) ]) return transform(pil_image).unsqueeze(0) def tensor_to_opencv(tensor): \"\"\"Convert PyTorch tensor to OpenCV image\"\"\" # Denormalize mean = torch.tensor([0.485, 0.456, 0.406]).view(3, 1, 1) std = torch.tensor([0.229, 0.224, 0.225]).view(3, 1, 1) tensor = tensor * std + mean # Clamp values and convert to numpy tensor = torch.clamp(tensor, 0, 1) image = tensor.squeeze().permute(1, 2, 0).numpy() image = (image * 255).astype(np.uint8) # Convert RGB to BGR for OpenCV return cv2.cvtColor(image, cv2.COLOR_RGB2BGR) # Real-time inference with webcam def real_time_classification(model_path, class_names): # Load model model = models.resnet50(pretrained=False) model.fc = nn.Linear(model.fc.in_features, len(class_names)) model.load_state_dict(torch.load(model_path)) model.eval() cap = cv2.VideoCapture(0) while True: ret, frame = cap.read() if not ret: break # Classify frame input_tensor = opencv_to_tensor(frame) with torch.no_grad(): outputs = model(input_tensor) probabilities = F.softmax(outputs[0], dim=0) confidence, predicted = torch.max(probabilities, 0) # Draw prediction on frame text = f\"{class_names[predicted]}: {confidence:.3f}\" cv2.putText(frame, text, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2) cv2.imshow('Classification', frame) if cv2.waitKey(1) & 0xFF == ord('q'): break cap.release() cv2.destroyAllWindows() With Matplotlib for Visualization import matplotlib.pyplot as plt from torchvision.utils import make_grid def visualize_batch(data_loader, class_names, num_images=8): \"\"\"Visualize a batch of images with labels\"\"\" # Get a batch data_iter = iter(data_loader) images, labels = next(data_iter) # Create grid grid = make_grid(images[:num_images], nrow=4, normalize=True, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]) # Convert to numpy npimg = grid.numpy() # Plot plt.figure(figsize=(12, 8)) plt.imshow(np.transpose(npimg, (1, 2, 0))) plt.axis('off') # Add labels for i in range(num_images): plt.text(i * (npimg.shape[2] // 4) + 20, 20, class_names[labels[i]], fontsize=12, color='white', bbox=dict(boxstyle='round', facecolor='black', alpha=0.7)) plt.tight_layout() plt.show() def plot_training_curves(train_losses, val_losses, train_accs, val_accs): \"\"\"Plot training and validation curves\"\"\" fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5)) # Loss curves ax1.plot(train_losses, label='Training Loss', color='blue') ax1.plot(val_losses, label='Validation Loss', color='red') ax1.set_xlabel('Epoch') ax1.set_ylabel('Loss') ax1.set_title('Training and Validation Loss') ax1.legend() ax1.grid(True) # Accuracy curves ax2.plot(train_accs, label='Training Accuracy', color='blue') ax2.plot(val_accs, label='Validation Accuracy', color='red') ax2.set_xlabel('Epoch') ax2.set_ylabel('Accuracy (%)') ax2.set_title('Training and Validation Accuracy') ax2.legend() ax2.grid(True) plt.tight_layout() plt.show() # Visualize model predictions def visualize_predictions(model, test_loader, class_names, num_images=8, device='cpu'): \"\"\"Visualize model predictions vs ground truth\"\"\" model.eval() images, labels = next(iter(test_loader)) images = images[:num_images].to(device) labels = labels[:num_images] with torch.no_grad(): outputs = model(images) _, predicted = torch.max(outputs, 1) # Create grid images = images.cpu() grid = make_grid(images, nrow=4, normalize=True, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]) # Plot plt.figure(figsize=(15, 10)) plt.imshow(np.transpose(grid.numpy(), (1, 2, 0))) plt.axis('off') # Add predictions and ground truth for i in range(num_images): pred_name = class_names[predicted[i]] true_name = class_names[labels[i]] color = 'green' if predicted[i] == labels[i] else 'red' plt.text(i % 4 * (grid.shape[2] // 4) + 10, (i // 4) * (grid.shape[1] // 2) + 30, f'True: {true_name}\\nPred: {pred_name}', fontsize=10, color=color, bbox=dict(boxstyle='round', facecolor='white', alpha=0.8)) plt.tight_layout() plt.show() # Usage visualize_batch(train_loader, cifar10_train.classes) plot_training_curves(train_losses, val_losses, train_accs, val_accs) visualize_predictions(model, test_loader, cifar10_test.classes) Best Practices Performance Optimization # 1. Use appropriate image sizes # Smaller images for faster training, larger for better accuracy resize_transforms = { 'fast': transforms.Resize(224), # Standard size 'balanced': transforms.Resize(256), # Slightly larger 'quality': transforms.Resize(384) # High resolution } # 2. Efficient data loading def create_efficient_dataloader(dataset, batch_size=32): return DataLoader( dataset, batch_size=batch_size, shuffle=True, num_workers=min(8, os.cpu_count()), # Use available CPUs pin_memory=True, # Faster GPU transfer persistent_workers=True, # Keep workers alive prefetch_factor=2 # Prefetch batches ) # 3. Mixed precision training from torch.cuda.amp import autocast, GradScaler def train_with_mixed_precision(model, train_loader, optimizer, criterion, device): scaler = GradScaler() model.train() for batch_idx, (data, target) in enumerate(train_loader): data, target = data.to(device), target.to(device) optimizer.zero_grad() # Use autocast for forward pass with autocast(): output = model(data) loss = criterion(output, target) # Scale loss and backward pass scaler.scale(loss).backward() scaler.step(optimizer) scaler.update() # 4. Memory-efficient transforms memory_efficient_transforms = transforms.Compose([ transforms.Resize(256, antialias=True), # Use antialiasing for better quality transforms.CenterCrop(224), transforms.ToTensor(), transforms.Normalize( mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225] ) ]) Model Selection and Hyperparameters # Model recommendations by use case model_recommendations = { 'fast_inference': { 'model': 'mobilenet_v3_small', 'input_size': 224, 'batch_size': 64 }, 'balanced': { 'model': 'resnet50', 'input_size': 224, 'batch_size': 32 }, 'high_accuracy': { 'model': 'efficientnet_b7', 'input_size': 600, 'batch_size': 8 }, 'transfer_learning': { 'model': 'resnet50', 'input_size': 224, 'freeze_epochs': 5, 'total_epochs': 20 } } # Hyperparameter suggestions def get_hyperparameters(dataset_size, num_classes): if dataset_size < 1000: return { 'learning_rate': 0.001, 'batch_size': 16, 'epochs': 50, 'weight_decay': 1e-4 } elif dataset_size < 10000: return { 'learning_rate': 0.01, 'batch_size': 32, 'epochs': 30, 'weight_decay': 1e-3 } else: return { 'learning_rate': 0.1, 'batch_size': 64, 'epochs': 100, 'weight_decay': 1e-4 } This comprehensive cheat sheet covers the essential aspects of TorchVision for computer vision tasks. The library provides excellent integration with PyTorch, extensive pre-trained models, and powerful data augmentation capabilities, making it ideal for both research and production computer vision applications.","title":"TorchVision"},{"location":"python/torchvision/#torchvision","text":"TorchVision is PyTorch's computer vision library, providing datasets, model architectures, and common image transformations for computer vision tasks. It includes pre-trained models, data loading utilities, and transforms for efficient computer vision pipelines.","title":"TorchVision"},{"location":"python/torchvision/#installation","text":"# Basic installation with PyTorch pip install torch torchvision # With CUDA support (check PyTorch website for correct version) pip install torch torchvision --extra-index-url https://download.pytorch.org/whl/cu118 # Development version pip install git+https://github.com/pytorch/vision.git # With additional dependencies pip install torchvision pillow matplotlib opencv-python","title":"Installation"},{"location":"python/torchvision/#basic-setup","text":"import torch import torchvision import torchvision.transforms as transforms import torchvision.datasets as datasets import torchvision.models as models from torchvision.utils import make_grid, save_image from torch.utils.data import DataLoader import matplotlib.pyplot as plt import numpy as np from PIL import Image # Check versions print(f\"TorchVision version: {torchvision.__version__}\") print(f\"PyTorch version: {torch.__version__}\")","title":"Basic Setup"},{"location":"python/torchvision/#core-functionality","text":"","title":"Core Functionality"},{"location":"python/torchvision/#image-transforms","text":"# Basic transforms transform = transforms.Compose([ transforms.Resize(256), # Resize to 256x256 transforms.CenterCrop(224), # Center crop to 224x224 transforms.ToTensor(), # Convert PIL to tensor [0,1] transforms.Normalize( # Normalize with ImageNet stats mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225] ) ]) # Data augmentation transforms train_transform = transforms.Compose([ transforms.RandomResizedCrop(224), # Random crop and resize transforms.RandomHorizontalFlip(p=0.5), # Random horizontal flip transforms.ColorJitter( # Random color changes brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1 ), transforms.RandomRotation(10), # Random rotation \u00b110 degrees transforms.ToTensor(), transforms.Normalize( mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225] ) ]) # Validation/test transforms (no augmentation) val_transform = transforms.Compose([ transforms.Resize(256), transforms.CenterCrop(224), transforms.ToTensor(), transforms.Normalize( mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225] ) ]) # Apply transforms to an image image = Image.open(\"path/to/image.jpg\") transformed_image = transform(image) print(f\"Original size: {image.size}\") print(f\"Transformed shape: {transformed_image.shape}\") # [C, H, W]","title":"Image Transforms"},{"location":"python/torchvision/#advanced-transforms","text":"# Geometric transforms geometric_transforms = transforms.Compose([ transforms.RandomAffine( degrees=15, # Rotation translate=(0.1, 0.1), # Translation scale=(0.8, 1.2), # Scale shear=10 # Shear ), transforms.RandomPerspective( distortion_scale=0.2, p=0.5 ), transforms.ElasticTransform(alpha=250.0, sigma=5.0) # Elastic deformation ]) # Advanced color transforms color_transforms = transforms.Compose([ transforms.RandomAutocontrast(p=0.5), transforms.RandomEqualize(p=0.5), transforms.RandomPosterize(bits=2, p=0.5), transforms.RandomSolarize(threshold=128, p=0.5), transforms.RandomAdjustSharpness(sharpness_factor=2, p=0.5) ]) # Cutout/Erasing augmentation erase_transform = transforms.Compose([ transforms.ToTensor(), transforms.RandomErasing( p=0.5, scale=(0.02, 0.33), ratio=(0.3, 3.3), value=0 ) ]) # Mix multiple transforms strong_augment = transforms.Compose([ transforms.RandomResizedCrop(224), transforms.RandomHorizontalFlip(), color_transforms, transforms.ToTensor(), transforms.RandomErasing(p=0.25), transforms.Normalize( mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225] ) ])","title":"Advanced Transforms"},{"location":"python/torchvision/#built-in-datasets","text":"# CIFAR-10 dataset cifar10_train = datasets.CIFAR10( root='./data', train=True, download=True, transform=train_transform ) cifar10_test = datasets.CIFAR10( root='./data', train=False, download=True, transform=val_transform ) # ImageNet dataset (requires downloaded data) imagenet_train = datasets.ImageNet( root='./data/imagenet', split='train', transform=train_transform ) # COCO dataset coco_train = datasets.CocoDetection( root='./data/coco/train2017', annFile='./data/coco/annotations/instances_train2017.json', transform=transforms.ToTensor() ) # Custom dataset from folder structure custom_dataset = datasets.ImageFolder( root='./data/custom', # Folder with subdirectories for each class transform=train_transform ) # Data loaders train_loader = DataLoader( cifar10_train, batch_size=32, shuffle=True, num_workers=4, pin_memory=True ) test_loader = DataLoader( cifar10_test, batch_size=32, shuffle=False, num_workers=4, pin_memory=True ) # Dataset info print(f\"Training samples: {len(cifar10_train)}\") print(f\"Test samples: {len(cifar10_test)}\") print(f\"Classes: {cifar10_train.classes}\") print(f\"Number of classes: {len(cifar10_train.classes)}\")","title":"Built-in Datasets"},{"location":"python/torchvision/#pre-trained-models","text":"# Image Classification Models resnet50 = models.resnet50(pretrained=True) resnet101 = models.resnet101(weights=models.ResNet101_Weights.IMAGENET1K_V1) # Vision Transformers vit_b_16 = models.vit_b_16(weights=models.ViT_B_16_Weights.IMAGENET1K_V1) vit_l_16 = models.vit_l_16(weights=models.ViT_L_16_Weights.IMAGENET1K_V1) # EfficientNet models efficientnet_b0 = models.efficientnet_b0(weights=models.EfficientNet_B0_Weights.IMAGENET1K_V1) efficientnet_b7 = models.efficientnet_b7(weights=models.EfficientNet_B7_Weights.IMAGENET1K_V1) # ConvNext models convnext_tiny = models.convnext_tiny(weights=models.ConvNeXt_Tiny_Weights.IMAGENET1K_V1) convnext_base = models.convnext_base(weights=models.ConvNeXt_Base_Weights.IMAGENET1K_V1) # Object Detection Models fasterrcnn_resnet50 = models.detection.fasterrcnn_resnet50_fpn( weights=models.detection.FasterRCNN_ResNet50_FPN_Weights.COCO_V1 ) # Semantic Segmentation Models deeplabv3_resnet50 = models.segmentation.deeplabv3_resnet50( weights=models.segmentation.DeepLabV3_ResNet50_Weights.COCO_WITH_VOC_LABELS_V1 ) # Set models to evaluation mode resnet50.eval() # Modify models for different number of classes num_classes = 10 # CIFAR-10 has 10 classes resnet50.fc = torch.nn.Linear(resnet50.fc.in_features, num_classes) print(f\"Model: {resnet50.__class__.__name__}\") print(f\"Number of parameters: {sum(p.numel() for p in resnet50.parameters()):,}\")","title":"Pre-trained Models"},{"location":"python/torchvision/#common-use-cases","text":"","title":"Common Use Cases"},{"location":"python/torchvision/#image-classification","text":"import torch.nn as nn import torch.optim as optim from torchvision import models, transforms, datasets class ImageClassifier: def __init__(self, num_classes=10, model_name='resnet50', pretrained=True): self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') # Load pre-trained model if model_name == 'resnet50': self.model = models.resnet50(pretrained=pretrained) self.model.fc = nn.Linear(self.model.fc.in_features, num_classes) elif model_name == 'vit_b_16': self.model = models.vit_b_16(pretrained=pretrained) self.model.heads.head = nn.Linear(self.model.heads.head.in_features, num_classes) self.model.to(self.device) # Loss and optimizer self.criterion = nn.CrossEntropyLoss() self.optimizer = optim.Adam(self.model.parameters(), lr=0.001) self.scheduler = optim.lr_scheduler.StepLR(self.optimizer, step_size=7, gamma=0.1) def train_epoch(self, train_loader): self.model.train() running_loss = 0.0 correct = 0 total = 0 for batch_idx, (data, target) in enumerate(train_loader): data, target = data.to(self.device), target.to(self.device) self.optimizer.zero_grad() output = self.model(data) loss = self.criterion(output, target) loss.backward() self.optimizer.step() running_loss += loss.item() _, predicted = torch.max(output.data, 1) total += target.size(0) correct += (predicted == target).sum().item() if batch_idx % 100 == 0: print(f'Batch {batch_idx}, Loss: {loss.item():.6f}') accuracy = 100 * correct / total avg_loss = running_loss / len(train_loader) return avg_loss, accuracy def evaluate(self, test_loader): self.model.eval() test_loss = 0.0 correct = 0 total = 0 with torch.no_grad(): for data, target in test_loader: data, target = data.to(self.device), target.to(self.device) output = self.model(data) test_loss += self.criterion(output, target).item() _, predicted = torch.max(output.data, 1) total += target.size(0) correct += (predicted == target).sum().item() accuracy = 100 * correct / total avg_loss = test_loss / len(test_loader) return avg_loss, accuracy def predict(self, image_path, transform, class_names): self.model.eval() # Load and transform image image = Image.open(image_path) image_tensor = transform(image).unsqueeze(0).to(self.device) with torch.no_grad(): output = self.model(image_tensor) probabilities = torch.nn.functional.softmax(output[0], dim=0) predicted_class = torch.argmax(probabilities).item() confidence = probabilities[predicted_class].item() return class_names[predicted_class], confidence, probabilities # Usage example classifier = ImageClassifier(num_classes=10, model_name='resnet50') # Training loop for epoch in range(10): train_loss, train_acc = classifier.train_epoch(train_loader) test_loss, test_acc = classifier.evaluate(test_loader) classifier.scheduler.step() print(f'Epoch {epoch+1}/10:') print(f' Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%') print(f' Test Loss: {test_loss:.4f}, Test Acc: {test_acc:.2f}%') # Single image prediction class_names = cifar10_train.classes prediction, confidence, probs = classifier.predict( 'path/to/image.jpg', val_transform, class_names ) print(f\"Prediction: {prediction} (Confidence: {confidence:.3f})\")","title":"Image Classification"},{"location":"python/torchvision/#transfer-learning","text":"def create_transfer_learning_model(num_classes, freeze_features=True): \"\"\"Create a transfer learning model from pre-trained ResNet\"\"\" # Load pre-trained model model = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V1) # Freeze feature extraction layers (optional) if freeze_features: for param in model.parameters(): param.requires_grad = False # Replace final classification layer num_features = model.fc.in_features model.fc = nn.Sequential( nn.Dropout(0.5), nn.Linear(num_features, 512), nn.ReLU(), nn.Dropout(0.5), nn.Linear(512, num_classes) ) return model def fine_tune_model(model, train_loader, val_loader, num_epochs=25): \"\"\"Fine-tune a transfer learning model\"\"\" device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') model.to(device) # Different learning rates for different parts feature_params = [] classifier_params = [] for name, param in model.named_parameters(): if 'fc' in name: classifier_params.append(param) else: feature_params.append(param) # Optimizer with different learning rates optimizer = optim.Adam([ {'params': feature_params, 'lr': 1e-4}, {'params': classifier_params, 'lr': 1e-3} ]) criterion = nn.CrossEntropyLoss() scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=3) best_acc = 0.0 train_losses, val_losses = [], [] train_accuracies, val_accuracies = [], [] for epoch in range(num_epochs): # Training phase model.train() running_loss = 0.0 correct = 0 total = 0 for inputs, labels in train_loader: inputs, labels = inputs.to(device), labels.to(device) optimizer.zero_grad() outputs = model(inputs) loss = criterion(outputs, labels) loss.backward() optimizer.step() running_loss += loss.item() _, predicted = torch.max(outputs, 1) total += labels.size(0) correct += (predicted == labels).sum().item() train_loss = running_loss / len(train_loader) train_acc = 100 * correct / total # Validation phase model.eval() val_running_loss = 0.0 val_correct = 0 val_total = 0 with torch.no_grad(): for inputs, labels in val_loader: inputs, labels = inputs.to(device), labels.to(device) outputs = model(inputs) loss = criterion(outputs, labels) val_running_loss += loss.item() _, predicted = torch.max(outputs, 1) val_total += labels.size(0) val_correct += (predicted == labels).sum().item() val_loss = val_running_loss / len(val_loader) val_acc = 100 * val_correct / val_total scheduler.step(val_loss) # Save best model if val_acc > best_acc: best_acc = val_acc torch.save(model.state_dict(), 'best_model.pth') # Store metrics train_losses.append(train_loss) val_losses.append(val_loss) train_accuracies.append(train_acc) val_accuracies.append(val_acc) print(f'Epoch {epoch+1}/{num_epochs}:') print(f' Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%') print(f' Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%') return model, (train_losses, val_losses, train_accuracies, val_accuracies) # Usage model = create_transfer_learning_model(num_classes=10, freeze_features=False) model, metrics = fine_tune_model(model, train_loader, test_loader)","title":"Transfer Learning"},{"location":"python/torchvision/#object-detection","text":"import torchvision.transforms as T from torchvision.models.detection import fasterrcnn_resnet50_fpn from torchvision.models.detection.faster_rcnn import FastRCNNPredictor class ObjectDetector: def __init__(self, num_classes=91): # COCO has 80 classes + background self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') # Load pre-trained Faster R-CNN model self.model = fasterrcnn_resnet50_fpn(pretrained=True) # Replace classifier head for custom number of classes in_features = self.model.roi_heads.box_predictor.cls_score.in_features self.model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes) self.model.to(self.device) # COCO class names (for visualization) self.coco_names = [ 'background', 'person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus', 'train', 'truck', 'boat', 'traffic light', 'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow', 'elephant', 'bear', 'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie', 'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard', 'tennis racket', 'bottle', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple', 'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair', 'couch', 'potted plant', 'bed', 'dining table', 'toilet', 'tv', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone', 'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors', 'teddy bear', 'hair drier', 'toothbrush' ] def predict(self, image_path, threshold=0.5): \"\"\"Perform object detection on an image\"\"\" self.model.eval() # Load and transform image image = Image.open(image_path).convert('RGB') transform = T.Compose([T.ToTensor()]) image_tensor = transform(image).unsqueeze(0).to(self.device) with torch.no_grad(): predictions = self.model(image_tensor) # Filter predictions by confidence threshold boxes = predictions[0]['boxes'][predictions[0]['scores'] > threshold] labels = predictions[0]['labels'][predictions[0]['scores'] > threshold] scores = predictions[0]['scores'][predictions[0]['scores'] > threshold] results = [] for box, label, score in zip(boxes, labels, scores): results.append({ 'box': box.cpu().numpy(), 'label': self.coco_names[label.item()], 'score': score.item() }) return results def visualize_predictions(self, image_path, predictions, save_path=None): \"\"\"Visualize object detection results\"\"\" import matplotlib.pyplot as plt import matplotlib.patches as patches image = Image.open(image_path) fig, ax = plt.subplots(1, 1, figsize=(12, 8)) ax.imshow(image) for pred in predictions: box = pred['box'] label = pred['label'] score = pred['score'] # Create rectangle patch rect = patches.Rectangle( (box[0], box[1]), box[2] - box[0], box[3] - box[1], linewidth=2, edgecolor='red', facecolor='none' ) ax.add_patch(rect) ax.text( box[0], box[1] - 10, f'{label}: {score:.2f}', fontsize=12, color='red', bbox=dict(boxstyle='round', facecolor='white', alpha=0.8) ) ax.set_xlim(0, image.width) ax.set_ylim(image.height, 0) ax.axis('off') if save_path: plt.savefig(save_path, bbox_inches='tight', dpi=300) plt.show() # Usage detector = ObjectDetector() predictions = detector.predict('path/to/image.jpg', threshold=0.5) print(f\"Found {len(predictions)} objects:\") for pred in predictions: print(f\" {pred['label']}: {pred['score']:.3f}\") detector.visualize_predictions('path/to/image.jpg', predictions)","title":"Object Detection"},{"location":"python/torchvision/#image-segmentation","text":"from torchvision.models.segmentation import deeplabv3_resnet50 class SemanticSegmentation: def __init__(self, num_classes=21): # PASCAL VOC has 20 classes + background self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') # Load pre-trained DeepLabV3 model self.model = deeplabv3_resnet50(pretrained=True) # Replace classifier for custom number of classes self.model.classifier[4] = nn.Conv2d(256, num_classes, kernel_size=1) self.model.aux_classifier[4] = nn.Conv2d(256, num_classes, kernel_size=1) self.model.to(self.device) # PASCAL VOC class names self.class_names = [ 'background', 'aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'dining table', 'dog', 'horse', 'motorbike', 'person', 'potted plant', 'sheep', 'sofa', 'train', 'tv monitor' ] # Color palette for visualization self.palette = [ [0, 0, 0], [128, 0, 0], [0, 128, 0], [128, 128, 0], [0, 0, 128], [128, 0, 128], [0, 128, 128], [128, 128, 128], [64, 0, 0], [192, 0, 0], [64, 128, 0], [192, 128, 0], [64, 0, 128], [192, 0, 128], [64, 128, 128], [192, 128, 128], [0, 64, 0], [128, 64, 0], [0, 192, 0], [128, 192, 0], [0, 64, 128] ] def segment(self, image_path): \"\"\"Perform semantic segmentation on an image\"\"\" self.model.eval() # Load and transform image image = Image.open(image_path).convert('RGB') transform = transforms.Compose([ transforms.ToTensor(), transforms.Normalize( mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225] ) ]) input_tensor = transform(image).unsqueeze(0).to(self.device) with torch.no_grad(): output = self.model(input_tensor)['out'] output_predictions = output.argmax(1) # Convert to numpy mask = output_predictions.squeeze().cpu().numpy() return image, mask def visualize_segmentation(self, image, mask, alpha=0.7): \"\"\"Visualize segmentation results\"\"\" import matplotlib.pyplot as plt # Create colored mask colored_mask = np.zeros((*mask.shape, 3), dtype=np.uint8) for class_id in range(len(self.class_names)): colored_mask[mask == class_id] = self.palette[class_id] # Plot fig, axes = plt.subplots(1, 3, figsize=(15, 5)) axes[0].imshow(image) axes[0].set_title('Original Image') axes[0].axis('off') axes[1].imshow(colored_mask) axes[1].set_title('Segmentation Mask') axes[1].axis('off') # Overlay axes[2].imshow(image) axes[2].imshow(colored_mask, alpha=alpha) axes[2].set_title('Overlay') axes[2].axis('off') plt.tight_layout() plt.show() def get_class_statistics(self, mask): \"\"\"Get statistics about segmented classes\"\"\" unique_classes, counts = np.unique(mask, return_counts=True) total_pixels = mask.size stats = [] for class_id, count in zip(unique_classes, counts): if class_id < len(self.class_names): percentage = (count / total_pixels) * 100 stats.append({ 'class': self.class_names[class_id], 'pixels': count, 'percentage': percentage }) return sorted(stats, key=lambda x: x['percentage'], reverse=True) # Usage segmenter = SemanticSegmentation() image, mask = segmenter.segment('path/to/image.jpg') # Visualize results segmenter.visualize_segmentation(image, mask) # Get statistics stats = segmenter.get_class_statistics(mask) print(\"Class distribution:\") for stat in stats: if stat['percentage'] > 1.0: # Only show classes with >1% coverage print(f\" {stat['class']}: {stat['percentage']:.1f}%\")","title":"Image Segmentation"},{"location":"python/torchvision/#advanced-features","text":"","title":"Advanced Features"},{"location":"python/torchvision/#custom-datasets","text":"import os import json from torch.utils.data import Dataset class CustomImageDataset(Dataset): def __init__(self, root_dir, annotation_file, transform=None): self.root_dir = root_dir self.transform = transform # Load annotations with open(annotation_file, 'r') as f: self.annotations = json.load(f) self.image_paths = list(self.annotations.keys()) def __len__(self): return len(self.image_paths) def __getitem__(self, idx): img_path = os.path.join(self.root_dir, self.image_paths[idx]) image = Image.open(img_path).convert('RGB') # Get label from annotations label = self.annotations[self.image_paths[idx]]['label'] if self.transform: image = self.transform(image) return image, label class CocoStyleDataset(Dataset): \"\"\"Dataset for COCO-style object detection annotations\"\"\" def __init__(self, root_dir, annotation_file, transform=None): self.root_dir = root_dir self.transform = transform with open(annotation_file, 'r') as f: self.coco = json.load(f) # Create mappings self.image_id_to_path = {img['id']: img['file_name'] for img in self.coco['images']} self.category_id_to_name = {cat['id']: cat['name'] for cat in self.coco['categories']} # Group annotations by image self.image_annotations = {} for ann in self.coco['annotations']: img_id = ann['image_id'] if img_id not in self.image_annotations: self.image_annotations[img_id] = [] self.image_annotations[img_id].append(ann) self.image_ids = list(self.image_id_to_path.keys()) def __len__(self): return len(self.image_ids) def __getitem__(self, idx): img_id = self.image_ids[idx] img_path = os.path.join(self.root_dir, self.image_id_to_path[img_id]) # Load image image = Image.open(img_path).convert('RGB') # Get annotations for this image annotations = self.image_annotations.get(img_id, []) # Extract boxes and labels boxes = [] labels = [] for ann in annotations: x, y, w, h = ann['bbox'] boxes.append([x, y, x + w, y + h]) labels.append(ann['category_id']) # Convert to tensors boxes = torch.tensor(boxes, dtype=torch.float32) labels = torch.tensor(labels, dtype=torch.int64) target = { 'boxes': boxes, 'labels': labels, 'image_id': torch.tensor(img_id) } if self.transform: image = self.transform(image) return image, target # Data loading utilities def create_data_loaders(train_dataset, val_dataset, batch_size=32, num_workers=4): \"\"\"Create data loaders with proper collate function for object detection\"\"\" def collate_fn(batch): return tuple(zip(*batch)) train_loader = DataLoader( train_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers, collate_fn=collate_fn, pin_memory=True ) val_loader = DataLoader( val_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers, collate_fn=collate_fn, pin_memory=True ) return train_loader, val_loader # Usage train_dataset = CustomImageDataset( root_dir='./data/train', annotation_file='./data/train_annotations.json', transform=train_transform ) val_dataset = CustomImageDataset( root_dir='./data/val', annotation_file='./data/val_annotations.json', transform=val_transform ) train_loader, val_loader = create_data_loaders(train_dataset, val_dataset)","title":"Custom Datasets"},{"location":"python/torchvision/#model-interpretability","text":"from torchvision.models.feature_extraction import create_feature_extractor import torch.nn.functional as F class GradCAM: def __init__(self, model, target_layer): self.model = model self.target_layer = target_layer self.gradients = None self.activations = None # Register hooks target_layer.register_forward_hook(self.save_activation) target_layer.register_backward_hook(self.save_gradient) def save_activation(self, module, input, output): self.activations = output def save_gradient(self, module, grad_input, grad_output): self.gradients = grad_output[0] def generate_cam(self, input_image, class_idx): self.model.eval() # Forward pass output = self.model(input_image) # Backward pass self.model.zero_grad() class_score = output[:, class_idx] class_score.backward() # Generate CAM gradients = self.gradients[0] # Remove batch dimension activations = self.activations[0] # Remove batch dimension # Global average pooling of gradients weights = torch.mean(gradients, dim=(1, 2)) # Weighted combination of activation maps cam = torch.zeros(activations.shape[1:], dtype=torch.float32) for i, w in enumerate(weights): cam += w * activations[i] # Apply ReLU and normalize cam = F.relu(cam) cam = cam / torch.max(cam) return cam def visualize_gradcam(model, image_path, target_class, transform): \"\"\"Visualize GradCAM for a specific class\"\"\" import matplotlib.pyplot as plt import cv2 # Load and transform image image = Image.open(image_path).convert('RGB') input_tensor = transform(image).unsqueeze(0) # Create GradCAM target_layer = model.layer4[-1].conv2 # ResNet50 example grad_cam = GradCAM(model, target_layer) # Generate CAM cam = grad_cam.generate_cam(input_tensor, target_class) # Resize CAM to image size cam_resized = cv2.resize(cam.numpy(), (image.width, image.height)) # Visualize fig, axes = plt.subplots(1, 3, figsize=(15, 5)) axes[0].imshow(image) axes[0].set_title('Original Image') axes[0].axis('off') axes[1].imshow(cam_resized, cmap='jet') axes[1].set_title('GradCAM') axes[1].axis('off') # Overlay axes[2].imshow(image) axes[2].imshow(cam_resized, cmap='jet', alpha=0.4) axes[2].set_title('Overlay') axes[2].axis('off') plt.tight_layout() plt.show() # Feature visualization def visualize_feature_maps(model, image_path, layer_name, transform, max_channels=16): \"\"\"Visualize feature maps from a specific layer\"\"\" # Extract features feature_extractor = create_feature_extractor(model, return_nodes=[layer_name]) # Load and transform image image = Image.open(image_path).convert('RGB') input_tensor = transform(image).unsqueeze(0) # Get features with torch.no_grad(): features = feature_extractor(input_tensor)[layer_name] # Visualize feature maps features = features[0] # Remove batch dimension n_channels = min(max_channels, features.shape[0]) fig, axes = plt.subplots(4, 4, figsize=(12, 12)) axes = axes.ravel() for i in range(n_channels): feature_map = features[i].cpu().numpy() axes[i].imshow(feature_map, cmap='viridis') axes[i].set_title(f'Channel {i}') axes[i].axis('off') # Hide unused subplots for i in range(n_channels, 16): axes[i].axis('off') plt.tight_layout() plt.show() # Usage model = models.resnet50(pretrained=True) visualize_gradcam(model, 'path/to/image.jpg', target_class=281, transform=val_transform) # 281 is 'tabby cat' in ImageNet visualize_feature_maps(model, 'path/to/image.jpg', 'layer4.0.conv1', val_transform)","title":"Model Interpretability"},{"location":"python/torchvision/#integration-with-other-libraries","text":"","title":"Integration with Other Libraries"},{"location":"python/torchvision/#with-opencv","text":"import cv2 import numpy as np def opencv_to_tensor(cv_image): \"\"\"Convert OpenCV image to PyTorch tensor\"\"\" # OpenCV uses BGR, convert to RGB rgb_image = cv2.cvtColor(cv_image, cv2.COLOR_BGR2RGB) # Convert to PIL Image then apply transforms pil_image = Image.fromarray(rgb_image) transform = transforms.Compose([ transforms.ToTensor(), transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]) ]) return transform(pil_image).unsqueeze(0) def tensor_to_opencv(tensor): \"\"\"Convert PyTorch tensor to OpenCV image\"\"\" # Denormalize mean = torch.tensor([0.485, 0.456, 0.406]).view(3, 1, 1) std = torch.tensor([0.229, 0.224, 0.225]).view(3, 1, 1) tensor = tensor * std + mean # Clamp values and convert to numpy tensor = torch.clamp(tensor, 0, 1) image = tensor.squeeze().permute(1, 2, 0).numpy() image = (image * 255).astype(np.uint8) # Convert RGB to BGR for OpenCV return cv2.cvtColor(image, cv2.COLOR_RGB2BGR) # Real-time inference with webcam def real_time_classification(model_path, class_names): # Load model model = models.resnet50(pretrained=False) model.fc = nn.Linear(model.fc.in_features, len(class_names)) model.load_state_dict(torch.load(model_path)) model.eval() cap = cv2.VideoCapture(0) while True: ret, frame = cap.read() if not ret: break # Classify frame input_tensor = opencv_to_tensor(frame) with torch.no_grad(): outputs = model(input_tensor) probabilities = F.softmax(outputs[0], dim=0) confidence, predicted = torch.max(probabilities, 0) # Draw prediction on frame text = f\"{class_names[predicted]}: {confidence:.3f}\" cv2.putText(frame, text, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2) cv2.imshow('Classification', frame) if cv2.waitKey(1) & 0xFF == ord('q'): break cap.release() cv2.destroyAllWindows()","title":"With OpenCV"},{"location":"python/torchvision/#with-matplotlib-for-visualization","text":"import matplotlib.pyplot as plt from torchvision.utils import make_grid def visualize_batch(data_loader, class_names, num_images=8): \"\"\"Visualize a batch of images with labels\"\"\" # Get a batch data_iter = iter(data_loader) images, labels = next(data_iter) # Create grid grid = make_grid(images[:num_images], nrow=4, normalize=True, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]) # Convert to numpy npimg = grid.numpy() # Plot plt.figure(figsize=(12, 8)) plt.imshow(np.transpose(npimg, (1, 2, 0))) plt.axis('off') # Add labels for i in range(num_images): plt.text(i * (npimg.shape[2] // 4) + 20, 20, class_names[labels[i]], fontsize=12, color='white', bbox=dict(boxstyle='round', facecolor='black', alpha=0.7)) plt.tight_layout() plt.show() def plot_training_curves(train_losses, val_losses, train_accs, val_accs): \"\"\"Plot training and validation curves\"\"\" fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5)) # Loss curves ax1.plot(train_losses, label='Training Loss', color='blue') ax1.plot(val_losses, label='Validation Loss', color='red') ax1.set_xlabel('Epoch') ax1.set_ylabel('Loss') ax1.set_title('Training and Validation Loss') ax1.legend() ax1.grid(True) # Accuracy curves ax2.plot(train_accs, label='Training Accuracy', color='blue') ax2.plot(val_accs, label='Validation Accuracy', color='red') ax2.set_xlabel('Epoch') ax2.set_ylabel('Accuracy (%)') ax2.set_title('Training and Validation Accuracy') ax2.legend() ax2.grid(True) plt.tight_layout() plt.show() # Visualize model predictions def visualize_predictions(model, test_loader, class_names, num_images=8, device='cpu'): \"\"\"Visualize model predictions vs ground truth\"\"\" model.eval() images, labels = next(iter(test_loader)) images = images[:num_images].to(device) labels = labels[:num_images] with torch.no_grad(): outputs = model(images) _, predicted = torch.max(outputs, 1) # Create grid images = images.cpu() grid = make_grid(images, nrow=4, normalize=True, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]) # Plot plt.figure(figsize=(15, 10)) plt.imshow(np.transpose(grid.numpy(), (1, 2, 0))) plt.axis('off') # Add predictions and ground truth for i in range(num_images): pred_name = class_names[predicted[i]] true_name = class_names[labels[i]] color = 'green' if predicted[i] == labels[i] else 'red' plt.text(i % 4 * (grid.shape[2] // 4) + 10, (i // 4) * (grid.shape[1] // 2) + 30, f'True: {true_name}\\nPred: {pred_name}', fontsize=10, color=color, bbox=dict(boxstyle='round', facecolor='white', alpha=0.8)) plt.tight_layout() plt.show() # Usage visualize_batch(train_loader, cifar10_train.classes) plot_training_curves(train_losses, val_losses, train_accs, val_accs) visualize_predictions(model, test_loader, cifar10_test.classes)","title":"With Matplotlib for Visualization"},{"location":"python/torchvision/#best-practices","text":"","title":"Best Practices"},{"location":"python/torchvision/#performance-optimization","text":"# 1. Use appropriate image sizes # Smaller images for faster training, larger for better accuracy resize_transforms = { 'fast': transforms.Resize(224), # Standard size 'balanced': transforms.Resize(256), # Slightly larger 'quality': transforms.Resize(384) # High resolution } # 2. Efficient data loading def create_efficient_dataloader(dataset, batch_size=32): return DataLoader( dataset, batch_size=batch_size, shuffle=True, num_workers=min(8, os.cpu_count()), # Use available CPUs pin_memory=True, # Faster GPU transfer persistent_workers=True, # Keep workers alive prefetch_factor=2 # Prefetch batches ) # 3. Mixed precision training from torch.cuda.amp import autocast, GradScaler def train_with_mixed_precision(model, train_loader, optimizer, criterion, device): scaler = GradScaler() model.train() for batch_idx, (data, target) in enumerate(train_loader): data, target = data.to(device), target.to(device) optimizer.zero_grad() # Use autocast for forward pass with autocast(): output = model(data) loss = criterion(output, target) # Scale loss and backward pass scaler.scale(loss).backward() scaler.step(optimizer) scaler.update() # 4. Memory-efficient transforms memory_efficient_transforms = transforms.Compose([ transforms.Resize(256, antialias=True), # Use antialiasing for better quality transforms.CenterCrop(224), transforms.ToTensor(), transforms.Normalize( mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225] ) ])","title":"Performance Optimization"},{"location":"python/torchvision/#model-selection-and-hyperparameters","text":"# Model recommendations by use case model_recommendations = { 'fast_inference': { 'model': 'mobilenet_v3_small', 'input_size': 224, 'batch_size': 64 }, 'balanced': { 'model': 'resnet50', 'input_size': 224, 'batch_size': 32 }, 'high_accuracy': { 'model': 'efficientnet_b7', 'input_size': 600, 'batch_size': 8 }, 'transfer_learning': { 'model': 'resnet50', 'input_size': 224, 'freeze_epochs': 5, 'total_epochs': 20 } } # Hyperparameter suggestions def get_hyperparameters(dataset_size, num_classes): if dataset_size < 1000: return { 'learning_rate': 0.001, 'batch_size': 16, 'epochs': 50, 'weight_decay': 1e-4 } elif dataset_size < 10000: return { 'learning_rate': 0.01, 'batch_size': 32, 'epochs': 30, 'weight_decay': 1e-3 } else: return { 'learning_rate': 0.1, 'batch_size': 64, 'epochs': 100, 'weight_decay': 1e-4 } This comprehensive cheat sheet covers the essential aspects of TorchVision for computer vision tasks. The library provides excellent integration with PyTorch, extensive pre-trained models, and powerful data augmentation capabilities, making it ideal for both research and production computer vision applications.","title":"Model Selection and Hyperparameters"},{"location":"python/transformers/","text":"Transformers (Hugging Face) Transformers is Hugging Face's flagship library providing state-of-the-art machine learning models for PyTorch, TensorFlow, and JAX. It offers thousands of pretrained models to perform tasks on different domains like text, vision, and audio. Installation # Basic installation pip install transformers # With PyTorch pip install transformers[torch] # With TensorFlow pip install transformers[tf] # With additional dependencies pip install transformers[torch,vision,audio] # Development version pip install git+https://github.com/huggingface/transformers.git # With specific backend pip install transformers torch torchvision torchaudio Basic Setup from transformers import ( AutoTokenizer, AutoModel, AutoModelForSequenceClassification, AutoModelForCausalLM, AutoModelForMaskedLM, pipeline, Trainer, TrainingArguments, BertTokenizer, BertModel, GPT2LMHeadModel, T5ForConditionalGeneration, T5Tokenizer ) import torch import numpy as np from datasets import load_dataset Core Functionality Pipeline API (Quickstart) # Sentiment analysis classifier = pipeline(\"sentiment-analysis\") result = classifier(\"I love this product!\") print(result) # [{'label': 'POSITIVE', 'score': 0.9998}] # Text generation generator = pipeline(\"text-generation\", model=\"gpt2\") result = generator(\"The future of AI is\", max_length=50, num_return_sequences=2) print(result[0]['generated_text']) # Question answering qa_pipeline = pipeline(\"question-answering\") context = \"The capital of France is Paris. Paris is known for the Eiffel Tower.\" question = \"What is the capital of France?\" answer = qa_pipeline(question=question, context=context) print(answer) # {'answer': 'Paris', 'score': 0.9999, 'start': 23, 'end': 28} # Named Entity Recognition ner = pipeline(\"ner\", aggregation_strategy=\"simple\") text = \"My name is Wolfgang and I live in Berlin\" entities = ner(text) print(entities) # Summarization summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\") article = \"Your long article text here...\" summary = summarizer(article, max_length=130, min_length=30, do_sample=False) print(summary[0]['summary_text']) # Translation translator = pipeline(\"translation_en_to_fr\") result = translator(\"Hello, how are you?\") print(result[0]['translation_text']) # Bonjour, comment allez-vous? # Fill mask unmasker = pipeline(\"fill-mask\") result = unmasker(\"Paris is the capital of <mask>.\") print(result[0]['token_str']) # France Model and Tokenizer Loading # Auto classes (recommended) model_name = \"bert-base-uncased\" tokenizer = AutoTokenizer.from_pretrained(model_name) model = AutoModel.from_pretrained(model_name) # Specific model classes tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\") model = BertModel.from_pretrained(\"bert-base-uncased\") # Loading with specific configurations from transformers import BertConfig config = BertConfig.from_pretrained(\"bert-base-uncased\") config.num_hidden_layers = 6 # Modify configuration model = BertModel.from_pretrained(\"bert-base-uncased\", config=config) # Loading from local files tokenizer = AutoTokenizer.from_pretrained(\"./my_model_directory\") model = AutoModel.from_pretrained(\"./my_model_directory\") # Loading with specific torch dtype model = AutoModel.from_pretrained( model_name, torch_dtype=torch.float16, device_map=\"auto\" ) Tokenization # Basic tokenization text = \"Hello, how are you today?\" tokens = tokenizer.tokenize(text) print(tokens) # ['hello', ',', 'how', 'are', 'you', 'today', '?'] # Encoding (text to tokens to IDs) encoding = tokenizer(text) print(encoding['input_ids']) # [101, 7592, 1010, 2129, 2024, 2017, 2651, 1029, 102] print(encoding['attention_mask']) # [1, 1, 1, 1, 1, 1, 1, 1, 1] # Batch encoding texts = [\"Hello world!\", \"How are you?\", \"Fine, thanks!\"] batch_encoding = tokenizer( texts, padding=True, truncation=True, max_length=128, return_tensors=\"pt\" # PyTorch tensors ) # Decoding (IDs back to text) decoded = tokenizer.decode(encoding['input_ids']) print(decoded) # [CLS] hello, how are you today? [SEP] # Advanced tokenization options encoding = tokenizer( text, add_special_tokens=True, # Add [CLS] and [SEP] max_length=512, # Maximum sequence length padding=\"max_length\", # Pad to max_length truncation=True, # Truncate if longer return_attention_mask=True, # Return attention masks return_token_type_ids=True, # Return token type IDs (for BERT) return_tensors=\"pt\" # Return PyTorch tensors ) Common Use Cases Text Classification from transformers import AutoModelForSequenceClassification import torch.nn.functional as F # Load model for classification model_name = \"cardiffnlp/twitter-roberta-base-sentiment-latest\" tokenizer = AutoTokenizer.from_pretrained(model_name) model = AutoModelForSequenceClassification.from_pretrained(model_name) def classify_sentiment(text): # Tokenize inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=512) # Get predictions with torch.no_grad(): outputs = model(**inputs) predictions = F.softmax(outputs.logits, dim=-1) # Get predicted class predicted_class = torch.argmax(predictions, dim=-1).item() confidence = predictions[0][predicted_class].item() # Map to labels (model specific) labels = [\"negative\", \"neutral\", \"positive\"] return { \"label\": labels[predicted_class], \"confidence\": confidence } # Usage result = classify_sentiment(\"I love this new feature!\") print(result) # {'label': 'positive', 'confidence': 0.9234} Text Generation from transformers import GPT2LMHeadModel, GPT2Tokenizer # Load GPT-2 model tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\") model = GPT2LMHeadModel.from_pretrained(\"gpt2\") # Add pad token tokenizer.pad_token = tokenizer.eos_token def generate_text(prompt, max_length=100, temperature=0.7, num_return_sequences=1): # Tokenize input inputs = tokenizer.encode(prompt, return_tensors=\"pt\") # Generate with torch.no_grad(): outputs = model.generate( inputs, max_length=max_length, temperature=temperature, num_return_sequences=num_return_sequences, do_sample=True, pad_token_id=tokenizer.eos_token_id, repetition_penalty=1.2 ) # Decode results generated_texts = [] for output in outputs: text = tokenizer.decode(output, skip_special_tokens=True) generated_texts.append(text) return generated_texts # Usage texts = generate_text(\"The future of artificial intelligence\", max_length=80) for text in texts: print(text) Question Answering from transformers import AutoModelForQuestionAnswering # Load QA model model_name = \"distilbert-base-cased-distilled-squad\" tokenizer = AutoTokenizer.from_pretrained(model_name) model = AutoModelForQuestionAnswering.from_pretrained(model_name) def answer_question(context, question): # Tokenize inputs = tokenizer.encode_plus( question, context, add_special_tokens=True, return_tensors=\"pt\", max_length=512, truncation=True ) # Get predictions with torch.no_grad(): outputs = model(**inputs) start_scores = outputs.start_logits end_scores = outputs.end_logits # Find the best answer start_idx = torch.argmax(start_scores) end_idx = torch.argmax(end_scores) + 1 # Decode answer input_ids = inputs['input_ids'][0] answer_tokens = input_ids[start_idx:end_idx] answer = tokenizer.decode(answer_tokens, skip_special_tokens=True) # Calculate confidence confidence = (start_scores[0][start_idx] + end_scores[0][end_idx-1]).item() return { \"answer\": answer, \"confidence\": confidence, \"start\": start_idx.item(), \"end\": end_idx.item() } # Usage context = \"\"\" The Transformer architecture was introduced in the paper \"Attention Is All You Need\" by Vaswani et al. in 2017. It revolutionized natural language processing by using self-attention mechanisms instead of recurrent layers. \"\"\" question = \"When was the Transformer architecture introduced?\" result = answer_question(context, question) print(result) # {'answer': '2017', 'confidence': 15.23, ...} Text Summarization from transformers import T5ForConditionalGeneration, T5Tokenizer # Load T5 model for summarization model_name = \"t5-small\" tokenizer = T5Tokenizer.from_pretrained(model_name) model = T5ForConditionalGeneration.from_pretrained(model_name) def summarize_text(text, max_length=150, min_length=50): # T5 requires task prefix input_text = \"summarize: \" + text # Tokenize inputs = tokenizer.encode( input_text, return_tensors=\"pt\", max_length=512, truncation=True ) # Generate summary with torch.no_grad(): summary_ids = model.generate( inputs, max_length=max_length, min_length=min_length, length_penalty=2.0, num_beams=4, early_stopping=True ) # Decode summary summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True) return summary # Usage article = \"\"\" Artificial Intelligence (AI) has become increasingly important in modern technology. Machine learning algorithms can now process vast amounts of data and make predictions with remarkable accuracy. Deep learning, a subset of machine learning, uses neural networks with multiple layers to learn complex patterns in data. This technology powers many applications we use daily, from search engines to recommendation systems. \"\"\" summary = summarize_text(article) print(summary) Advanced Features Fine-tuning Models from transformers import Trainer, TrainingArguments, DataCollatorWithPadding from datasets import Dataset import torch # Prepare dataset def prepare_dataset(): # Your data preparation logic texts = [\"positive example\", \"negative example\", ...] labels = [1, 0, ...] # Binary classification return Dataset.from_dict({ \"text\": texts, \"labels\": labels }) # Tokenize dataset def tokenize_function(examples): return tokenizer( examples[\"text\"], truncation=True, padding=True, max_length=128 ) # Load model for training model = AutoModelForSequenceClassification.from_pretrained( \"bert-base-uncased\", num_labels=2 ) # Prepare data train_dataset = prepare_dataset() train_dataset = train_dataset.map(tokenize_function, batched=True) # Set training arguments training_args = TrainingArguments( output_dir=\"./results\", num_train_epochs=3, per_device_train_batch_size=16, per_device_eval_batch_size=64, warmup_steps=500, weight_decay=0.01, logging_dir=\"./logs\", logging_steps=10, evaluation_strategy=\"epoch\", save_strategy=\"epoch\", load_best_model_at_end=True, metric_for_best_model=\"accuracy\", ) # Data collator data_collator = DataCollatorWithPadding(tokenizer) # Define compute metrics function from sklearn.metrics import accuracy_score, precision_recall_fscore_support def compute_metrics(eval_pred): predictions, labels = eval_pred predictions = np.argmax(predictions, axis=1) accuracy = accuracy_score(labels, predictions) precision, recall, f1, _ = precision_recall_fscore_support(labels, predictions, average='weighted') return { 'accuracy': accuracy, 'f1': f1, 'precision': precision, 'recall': recall } # Create trainer trainer = Trainer( model=model, args=training_args, train_dataset=train_dataset, eval_dataset=train_dataset, # Use validation set in practice tokenizer=tokenizer, data_collator=data_collator, compute_metrics=compute_metrics, ) # Train the model trainer.train() # Save the model trainer.save_model(\"./fine_tuned_model\") Custom Model Architecture import torch.nn as nn from transformers import BertPreTrainedModel, BertModel class CustomBertClassifier(BertPreTrainedModel): def __init__(self, config, num_labels=2): super().__init__(config) self.num_labels = num_labels self.bert = BertModel(config) self.dropout = nn.Dropout(config.hidden_dropout_prob) # Custom classifier head self.classifier = nn.Sequential( nn.Linear(config.hidden_size, 256), nn.ReLU(), nn.Dropout(0.3), nn.Linear(256, num_labels) ) self.init_weights() def forward(self, input_ids=None, attention_mask=None, token_type_ids=None, labels=None): outputs = self.bert( input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids ) pooled_output = outputs[1] # [CLS] token representation pooled_output = self.dropout(pooled_output) logits = self.classifier(pooled_output) loss = None if labels is not None: loss_fct = nn.CrossEntropyLoss() loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1)) return { 'loss': loss, 'logits': logits, 'hidden_states': outputs.hidden_states, 'attentions': outputs.attentions } # Usage config = AutoConfig.from_pretrained(\"bert-base-uncased\") model = CustomBertClassifier(config, num_labels=3) Working with Different Modalities # Vision-Language Models (CLIP) from transformers import CLIPProcessor, CLIPModel from PIL import Image import requests model = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\") processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\") # Load image url = \"http://images.cocodataset.org/val2017/000000039769.jpg\" image = Image.open(requests.get(url, stream=True).raw) # Process inputs inputs = processor( text=[\"a photo of a cat\", \"a photo of a dog\"], images=image, return_tensors=\"pt\", padding=True ) # Get similarities outputs = model(**inputs) logits_per_image = outputs.logits_per_image probs = logits_per_image.softmax(dim=1) print(probs) # Probability for each text description # Audio Models (Wav2Vec2) from transformers import Wav2Vec2Processor, Wav2Vec2ForCTC import librosa # Load audio model processor = Wav2Vec2Processor.from_pretrained(\"facebook/wav2vec2-base-960h\") model = Wav2Vec2ForCTC.from_pretrained(\"facebook/wav2vec2-base-960h\") # Process audio file audio, sampling_rate = librosa.load(\"path_to_audio.wav\", sr=16000) inputs = processor(audio, sampling_rate=16000, return_tensors=\"pt\", padding=True) # Get transcription with torch.no_grad(): logits = model(inputs.input_values).logits predicted_ids = torch.argmax(logits, dim=-1) transcription = processor.batch_decode(predicted_ids)[0] print(transcription) Integration with Other Libraries With Datasets Library from datasets import load_dataset, Dataset, DatasetDict # Load popular datasets dataset = load_dataset(\"imdb\") # Movie reviews dataset = load_dataset(\"squad\") # Question answering dataset = load_dataset(\"glue\", \"sst2\") # Sentiment analysis # Create custom dataset data = { \"text\": [\"Great movie!\", \"Terrible film.\", \"Average story.\"], \"label\": [2, 0, 1] # positive, negative, neutral } custom_dataset = Dataset.from_dict(data) # Tokenize dataset def tokenize_data(examples): return tokenizer(examples[\"text\"], truncation=True, padding=\"max_length\", max_length=128) tokenized_dataset = custom_dataset.map(tokenize_data, batched=True) # Split dataset train_test = custom_dataset.train_test_split(test_size=0.2) dataset_dict = DatasetDict({ 'train': train_test['train'], 'test': train_test['test'] }) With PyTorch Lightning import pytorch_lightning as pl from torch.utils.data import DataLoader class TransformersLightningModule(pl.LightningModule): def __init__(self, model_name=\"bert-base-uncased\", num_labels=2, learning_rate=2e-5): super().__init__() self.save_hyperparameters() self.model = AutoModelForSequenceClassification.from_pretrained( model_name, num_labels=num_labels ) self.tokenizer = AutoTokenizer.from_pretrained(model_name) def forward(self, input_ids, attention_mask, labels=None): return self.model(input_ids=input_ids, attention_mask=attention_mask, labels=labels) def training_step(self, batch, batch_idx): outputs = self(**batch) loss = outputs.loss self.log(\"train_loss\", loss) return loss def validation_step(self, batch, batch_idx): outputs = self(**batch) loss = outputs.loss self.log(\"val_loss\", loss) return loss def configure_optimizers(self): return torch.optim.AdamW(self.parameters(), lr=self.hparams.learning_rate) # Usage model = TransformersLightningModule() trainer = pl.Trainer(max_epochs=3, gpus=1 if torch.cuda.is_available() else 0) trainer.fit(model, train_dataloader, val_dataloader) With Gradio for Web Apps import gradio as gr from transformers import pipeline # Create sentiment analysis pipeline sentiment_pipeline = pipeline(\"sentiment-analysis\", model=\"cardiffnlp/twitter-roberta-base-sentiment-latest\") def analyze_sentiment(text): result = sentiment_pipeline(text)[0] return f\"Sentiment: {result['label']} (Confidence: {result['score']:.3f})\" # Create Gradio interface interface = gr.Interface( fn=analyze_sentiment, inputs=gr.Textbox(lines=3, placeholder=\"Enter text to analyze...\"), outputs=\"text\", title=\"Sentiment Analysis\", description=\"Analyze the sentiment of your text using RoBERTa model\" ) # Launch the app interface.launch() Best Practices Memory and Performance Optimization # 1. Use appropriate model sizes model = AutoModel.from_pretrained( \"distilbert-base-uncased\", # Smaller, faster alternative to BERT torch_dtype=torch.float16, # Half precision for memory efficiency device_map=\"auto\" # Automatic device placement ) # 2. Batch processing for efficiency def batch_inference(texts, batch_size=32): results = [] for i in range(0, len(texts), batch_size): batch = texts[i:i + batch_size] batch_encoding = tokenizer( batch, truncation=True, padding=True, return_tensors=\"pt\" ) with torch.no_grad(): outputs = model(**batch_encoding) results.extend(outputs.logits.cpu().numpy()) return results # 3. Gradient checkpointing for training large models model.gradient_checkpointing_enable() # 4. Use DataLoader with multiple workers from torch.utils.data import DataLoader dataloader = DataLoader( dataset, batch_size=16, num_workers=4, pin_memory=True ) Model Evaluation and Monitoring from sklearn.metrics import classification_report, confusion_matrix import matplotlib.pyplot as plt import seaborn as sns def evaluate_model(model, tokenizer, test_texts, test_labels): predictions = [] for text in test_texts: inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=128) with torch.no_grad(): outputs = model(**inputs) pred = torch.argmax(outputs.logits, dim=-1).item() predictions.append(pred) # Classification report report = classification_report(test_labels, predictions, output_dict=True) print(classification_report(test_labels, predictions)) # Confusion matrix cm = confusion_matrix(test_labels, predictions) plt.figure(figsize=(8, 6)) sns.heatmap(cm, annot=True, fmt='d', cmap='Blues') plt.title('Confusion Matrix') plt.ylabel('True Label') plt.xlabel('Predicted Label') plt.show() return report, cm # Usage report, cm = evaluate_model(model, tokenizer, test_texts, test_labels) Error Handling and Robust Inference def robust_inference(text, model, tokenizer, max_retries=3): \"\"\"Robust inference with error handling\"\"\" for attempt in range(max_retries): try: # Validate input if not isinstance(text, str) or not text.strip(): return {\"error\": \"Invalid input text\"} # Tokenize with length check inputs = tokenizer( text, return_tensors=\"pt\", truncation=True, max_length=512, padding=True ) # Check if input is too long even after truncation if inputs['input_ids'].shape[1] > 512: return {\"error\": \"Text too long even after truncation\"} # Inference with torch.no_grad(): outputs = model(**inputs) predictions = torch.nn.functional.softmax(outputs.logits, dim=-1) predicted_class = torch.argmax(predictions, dim=-1).item() confidence = predictions[0][predicted_class].item() return { \"prediction\": predicted_class, \"confidence\": confidence, \"success\": True } except Exception as e: if attempt == max_retries - 1: return {\"error\": f\"Inference failed after {max_retries} attempts: {str(e)}\"} time.sleep(0.1) # Brief pause before retry return {\"error\": \"Maximum retries exceeded\"} Real-world Examples Complete Text Classification System class TextClassificationSystem: def __init__(self, model_name=\"distilbert-base-uncased\", num_labels=3): self.tokenizer = AutoTokenizer.from_pretrained(model_name) self.model = AutoModelForSequenceClassification.from_pretrained( model_name, num_labels=num_labels ) self.label_map = {0: \"negative\", 1: \"neutral\", 2: \"positive\"} def preprocess_text(self, text): \"\"\"Clean and preprocess text\"\"\" import re text = re.sub(r'http\\S+', '', text) # Remove URLs text = re.sub(r'@\\w+', '', text) # Remove mentions text = re.sub(r'#\\w+', '', text) # Remove hashtags text = re.sub(r'\\s+', ' ', text) # Normalize whitespace return text.strip() def predict(self, text): \"\"\"Make prediction on single text\"\"\" cleaned_text = self.preprocess_text(text) inputs = self.tokenizer( cleaned_text, return_tensors=\"pt\", truncation=True, max_length=128, padding=True ) with torch.no_grad(): outputs = self.model(**inputs) predictions = torch.nn.functional.softmax(outputs.logits, dim=-1) predicted_class = torch.argmax(predictions, dim=-1).item() confidence = predictions[0][predicted_class].item() return { \"text\": text, \"cleaned_text\": cleaned_text, \"prediction\": self.label_map[predicted_class], \"confidence\": confidence, \"all_scores\": { self.label_map[i]: predictions[0][i].item() for i in range(len(self.label_map)) } } def predict_batch(self, texts, batch_size=32): \"\"\"Make predictions on batch of texts\"\"\" results = [] for i in range(0, len(texts), batch_size): batch_texts = texts[i:i + batch_size] cleaned_texts = [self.preprocess_text(text) for text in batch_texts] inputs = self.tokenizer( cleaned_texts, return_tensors=\"pt\", truncation=True, max_length=128, padding=True ) with torch.no_grad(): outputs = self.model(**inputs) predictions = torch.nn.functional.softmax(outputs.logits, dim=-1) predicted_classes = torch.argmax(predictions, dim=-1) for j, (text, cleaned_text) in enumerate(zip(batch_texts, cleaned_texts)): pred_class = predicted_classes[j].item() confidence = predictions[j][pred_class].item() results.append({ \"text\": text, \"cleaned_text\": cleaned_text, \"prediction\": self.label_map[pred_class], \"confidence\": confidence }) return results # Usage classifier = TextClassificationSystem() # Single prediction result = classifier.predict(\"I absolutely love this new product! It's amazing!\") print(result) # Batch prediction texts = [ \"Great service and friendly staff!\", \"Terrible experience, would not recommend.\", \"It was okay, nothing special.\" ] results = classifier.predict_batch(texts) for result in results: print(f\"{result['prediction']}: {result['text']} (confidence: {result['confidence']:.3f})\") Multi-task NLP Pipeline class MultiTaskNLPPipeline: def __init__(self): # Initialize different models for different tasks self.sentiment_analyzer = pipeline(\"sentiment-analysis\") self.ner_model = pipeline(\"ner\", aggregation_strategy=\"simple\") self.qa_model = pipeline(\"question-answering\") self.summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\") def analyze_text(self, text, tasks=[\"sentiment\", \"ner\", \"summary\"]): \"\"\"Comprehensive text analysis\"\"\" results = {\"original_text\": text} if \"sentiment\" in tasks: sentiment = self.sentiment_analyzer(text)[0] results[\"sentiment\"] = { \"label\": sentiment[\"label\"], \"confidence\": sentiment[\"score\"] } if \"ner\" in tasks: entities = self.ner_model(text) results[\"entities\"] = [ { \"text\": entity[\"word\"], \"label\": entity[\"entity_group\"], \"confidence\": entity[\"score\"] } for entity in entities ] if \"summary\" in tasks and len(text.split()) > 30: try: summary = self.summarizer(text, max_length=100, min_length=30)[0] results[\"summary\"] = summary[\"summary_text\"] except: results[\"summary\"] = \"Text too short for summarization\" return results def answer_questions(self, context, questions): \"\"\"Answer multiple questions about a context\"\"\" answers = [] for question in questions: try: answer = self.qa_model(question=question, context=context) answers.append({ \"question\": question, \"answer\": answer[\"answer\"], \"confidence\": answer[\"score\"] }) except: answers.append({ \"question\": question, \"answer\": \"Could not answer\", \"confidence\": 0.0 }) return answers # Usage nlp_pipeline = MultiTaskNLPPipeline() text = \"\"\" Apple Inc. is an American multinational technology company headquartered in Cupertino, California. Apple is the world's largest technology company by revenue and the world's most valuable company. The company was founded by Steve Jobs, Steve Wozniak, and Ronald Wayne in April 1976. Apple's products include the iPhone, iPad, Mac, Apple Watch, and Apple TV. \"\"\" # Comprehensive analysis analysis = nlp_pipeline.analyze_text(text) print(\"Analysis Results:\") print(f\"Sentiment: {analysis['sentiment']['label']} ({analysis['sentiment']['confidence']:.3f})\") print(f\"Entities: {[e['text'] for e in analysis['entities']]}\") print(f\"Summary: {analysis['summary']}\") # Question answering questions = [ \"Who founded Apple?\", \"Where is Apple headquartered?\", \"What products does Apple make?\" ] answers = nlp_pipeline.answer_questions(text, questions) for qa in answers: print(f\"Q: {qa['question']}\") print(f\"A: {qa['answer']} (confidence: {qa['confidence']:.3f})\") This comprehensive cheat sheet covers the essential aspects of the Transformers library. The library's strength lies in its unified API across different models and tasks, extensive model zoo, and seamless integration with the broader ML ecosystem. It's the go-to library for state-of-the-art NLP applications and research.","title":"Transformers (Hugging Face)"},{"location":"python/transformers/#transformers-hugging-face","text":"Transformers is Hugging Face's flagship library providing state-of-the-art machine learning models for PyTorch, TensorFlow, and JAX. It offers thousands of pretrained models to perform tasks on different domains like text, vision, and audio.","title":"Transformers (Hugging Face)"},{"location":"python/transformers/#installation","text":"# Basic installation pip install transformers # With PyTorch pip install transformers[torch] # With TensorFlow pip install transformers[tf] # With additional dependencies pip install transformers[torch,vision,audio] # Development version pip install git+https://github.com/huggingface/transformers.git # With specific backend pip install transformers torch torchvision torchaudio","title":"Installation"},{"location":"python/transformers/#basic-setup","text":"from transformers import ( AutoTokenizer, AutoModel, AutoModelForSequenceClassification, AutoModelForCausalLM, AutoModelForMaskedLM, pipeline, Trainer, TrainingArguments, BertTokenizer, BertModel, GPT2LMHeadModel, T5ForConditionalGeneration, T5Tokenizer ) import torch import numpy as np from datasets import load_dataset","title":"Basic Setup"},{"location":"python/transformers/#core-functionality","text":"","title":"Core Functionality"},{"location":"python/transformers/#pipeline-api-quickstart","text":"# Sentiment analysis classifier = pipeline(\"sentiment-analysis\") result = classifier(\"I love this product!\") print(result) # [{'label': 'POSITIVE', 'score': 0.9998}] # Text generation generator = pipeline(\"text-generation\", model=\"gpt2\") result = generator(\"The future of AI is\", max_length=50, num_return_sequences=2) print(result[0]['generated_text']) # Question answering qa_pipeline = pipeline(\"question-answering\") context = \"The capital of France is Paris. Paris is known for the Eiffel Tower.\" question = \"What is the capital of France?\" answer = qa_pipeline(question=question, context=context) print(answer) # {'answer': 'Paris', 'score': 0.9999, 'start': 23, 'end': 28} # Named Entity Recognition ner = pipeline(\"ner\", aggregation_strategy=\"simple\") text = \"My name is Wolfgang and I live in Berlin\" entities = ner(text) print(entities) # Summarization summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\") article = \"Your long article text here...\" summary = summarizer(article, max_length=130, min_length=30, do_sample=False) print(summary[0]['summary_text']) # Translation translator = pipeline(\"translation_en_to_fr\") result = translator(\"Hello, how are you?\") print(result[0]['translation_text']) # Bonjour, comment allez-vous? # Fill mask unmasker = pipeline(\"fill-mask\") result = unmasker(\"Paris is the capital of <mask>.\") print(result[0]['token_str']) # France","title":"Pipeline API (Quickstart)"},{"location":"python/transformers/#model-and-tokenizer-loading","text":"# Auto classes (recommended) model_name = \"bert-base-uncased\" tokenizer = AutoTokenizer.from_pretrained(model_name) model = AutoModel.from_pretrained(model_name) # Specific model classes tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\") model = BertModel.from_pretrained(\"bert-base-uncased\") # Loading with specific configurations from transformers import BertConfig config = BertConfig.from_pretrained(\"bert-base-uncased\") config.num_hidden_layers = 6 # Modify configuration model = BertModel.from_pretrained(\"bert-base-uncased\", config=config) # Loading from local files tokenizer = AutoTokenizer.from_pretrained(\"./my_model_directory\") model = AutoModel.from_pretrained(\"./my_model_directory\") # Loading with specific torch dtype model = AutoModel.from_pretrained( model_name, torch_dtype=torch.float16, device_map=\"auto\" )","title":"Model and Tokenizer Loading"},{"location":"python/transformers/#tokenization","text":"# Basic tokenization text = \"Hello, how are you today?\" tokens = tokenizer.tokenize(text) print(tokens) # ['hello', ',', 'how', 'are', 'you', 'today', '?'] # Encoding (text to tokens to IDs) encoding = tokenizer(text) print(encoding['input_ids']) # [101, 7592, 1010, 2129, 2024, 2017, 2651, 1029, 102] print(encoding['attention_mask']) # [1, 1, 1, 1, 1, 1, 1, 1, 1] # Batch encoding texts = [\"Hello world!\", \"How are you?\", \"Fine, thanks!\"] batch_encoding = tokenizer( texts, padding=True, truncation=True, max_length=128, return_tensors=\"pt\" # PyTorch tensors ) # Decoding (IDs back to text) decoded = tokenizer.decode(encoding['input_ids']) print(decoded) # [CLS] hello, how are you today? [SEP] # Advanced tokenization options encoding = tokenizer( text, add_special_tokens=True, # Add [CLS] and [SEP] max_length=512, # Maximum sequence length padding=\"max_length\", # Pad to max_length truncation=True, # Truncate if longer return_attention_mask=True, # Return attention masks return_token_type_ids=True, # Return token type IDs (for BERT) return_tensors=\"pt\" # Return PyTorch tensors )","title":"Tokenization"},{"location":"python/transformers/#common-use-cases","text":"","title":"Common Use Cases"},{"location":"python/transformers/#text-classification","text":"from transformers import AutoModelForSequenceClassification import torch.nn.functional as F # Load model for classification model_name = \"cardiffnlp/twitter-roberta-base-sentiment-latest\" tokenizer = AutoTokenizer.from_pretrained(model_name) model = AutoModelForSequenceClassification.from_pretrained(model_name) def classify_sentiment(text): # Tokenize inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=512) # Get predictions with torch.no_grad(): outputs = model(**inputs) predictions = F.softmax(outputs.logits, dim=-1) # Get predicted class predicted_class = torch.argmax(predictions, dim=-1).item() confidence = predictions[0][predicted_class].item() # Map to labels (model specific) labels = [\"negative\", \"neutral\", \"positive\"] return { \"label\": labels[predicted_class], \"confidence\": confidence } # Usage result = classify_sentiment(\"I love this new feature!\") print(result) # {'label': 'positive', 'confidence': 0.9234}","title":"Text Classification"},{"location":"python/transformers/#text-generation","text":"from transformers import GPT2LMHeadModel, GPT2Tokenizer # Load GPT-2 model tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\") model = GPT2LMHeadModel.from_pretrained(\"gpt2\") # Add pad token tokenizer.pad_token = tokenizer.eos_token def generate_text(prompt, max_length=100, temperature=0.7, num_return_sequences=1): # Tokenize input inputs = tokenizer.encode(prompt, return_tensors=\"pt\") # Generate with torch.no_grad(): outputs = model.generate( inputs, max_length=max_length, temperature=temperature, num_return_sequences=num_return_sequences, do_sample=True, pad_token_id=tokenizer.eos_token_id, repetition_penalty=1.2 ) # Decode results generated_texts = [] for output in outputs: text = tokenizer.decode(output, skip_special_tokens=True) generated_texts.append(text) return generated_texts # Usage texts = generate_text(\"The future of artificial intelligence\", max_length=80) for text in texts: print(text)","title":"Text Generation"},{"location":"python/transformers/#question-answering","text":"from transformers import AutoModelForQuestionAnswering # Load QA model model_name = \"distilbert-base-cased-distilled-squad\" tokenizer = AutoTokenizer.from_pretrained(model_name) model = AutoModelForQuestionAnswering.from_pretrained(model_name) def answer_question(context, question): # Tokenize inputs = tokenizer.encode_plus( question, context, add_special_tokens=True, return_tensors=\"pt\", max_length=512, truncation=True ) # Get predictions with torch.no_grad(): outputs = model(**inputs) start_scores = outputs.start_logits end_scores = outputs.end_logits # Find the best answer start_idx = torch.argmax(start_scores) end_idx = torch.argmax(end_scores) + 1 # Decode answer input_ids = inputs['input_ids'][0] answer_tokens = input_ids[start_idx:end_idx] answer = tokenizer.decode(answer_tokens, skip_special_tokens=True) # Calculate confidence confidence = (start_scores[0][start_idx] + end_scores[0][end_idx-1]).item() return { \"answer\": answer, \"confidence\": confidence, \"start\": start_idx.item(), \"end\": end_idx.item() } # Usage context = \"\"\" The Transformer architecture was introduced in the paper \"Attention Is All You Need\" by Vaswani et al. in 2017. It revolutionized natural language processing by using self-attention mechanisms instead of recurrent layers. \"\"\" question = \"When was the Transformer architecture introduced?\" result = answer_question(context, question) print(result) # {'answer': '2017', 'confidence': 15.23, ...}","title":"Question Answering"},{"location":"python/transformers/#text-summarization","text":"from transformers import T5ForConditionalGeneration, T5Tokenizer # Load T5 model for summarization model_name = \"t5-small\" tokenizer = T5Tokenizer.from_pretrained(model_name) model = T5ForConditionalGeneration.from_pretrained(model_name) def summarize_text(text, max_length=150, min_length=50): # T5 requires task prefix input_text = \"summarize: \" + text # Tokenize inputs = tokenizer.encode( input_text, return_tensors=\"pt\", max_length=512, truncation=True ) # Generate summary with torch.no_grad(): summary_ids = model.generate( inputs, max_length=max_length, min_length=min_length, length_penalty=2.0, num_beams=4, early_stopping=True ) # Decode summary summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True) return summary # Usage article = \"\"\" Artificial Intelligence (AI) has become increasingly important in modern technology. Machine learning algorithms can now process vast amounts of data and make predictions with remarkable accuracy. Deep learning, a subset of machine learning, uses neural networks with multiple layers to learn complex patterns in data. This technology powers many applications we use daily, from search engines to recommendation systems. \"\"\" summary = summarize_text(article) print(summary)","title":"Text Summarization"},{"location":"python/transformers/#advanced-features","text":"","title":"Advanced Features"},{"location":"python/transformers/#fine-tuning-models","text":"from transformers import Trainer, TrainingArguments, DataCollatorWithPadding from datasets import Dataset import torch # Prepare dataset def prepare_dataset(): # Your data preparation logic texts = [\"positive example\", \"negative example\", ...] labels = [1, 0, ...] # Binary classification return Dataset.from_dict({ \"text\": texts, \"labels\": labels }) # Tokenize dataset def tokenize_function(examples): return tokenizer( examples[\"text\"], truncation=True, padding=True, max_length=128 ) # Load model for training model = AutoModelForSequenceClassification.from_pretrained( \"bert-base-uncased\", num_labels=2 ) # Prepare data train_dataset = prepare_dataset() train_dataset = train_dataset.map(tokenize_function, batched=True) # Set training arguments training_args = TrainingArguments( output_dir=\"./results\", num_train_epochs=3, per_device_train_batch_size=16, per_device_eval_batch_size=64, warmup_steps=500, weight_decay=0.01, logging_dir=\"./logs\", logging_steps=10, evaluation_strategy=\"epoch\", save_strategy=\"epoch\", load_best_model_at_end=True, metric_for_best_model=\"accuracy\", ) # Data collator data_collator = DataCollatorWithPadding(tokenizer) # Define compute metrics function from sklearn.metrics import accuracy_score, precision_recall_fscore_support def compute_metrics(eval_pred): predictions, labels = eval_pred predictions = np.argmax(predictions, axis=1) accuracy = accuracy_score(labels, predictions) precision, recall, f1, _ = precision_recall_fscore_support(labels, predictions, average='weighted') return { 'accuracy': accuracy, 'f1': f1, 'precision': precision, 'recall': recall } # Create trainer trainer = Trainer( model=model, args=training_args, train_dataset=train_dataset, eval_dataset=train_dataset, # Use validation set in practice tokenizer=tokenizer, data_collator=data_collator, compute_metrics=compute_metrics, ) # Train the model trainer.train() # Save the model trainer.save_model(\"./fine_tuned_model\")","title":"Fine-tuning Models"},{"location":"python/transformers/#custom-model-architecture","text":"import torch.nn as nn from transformers import BertPreTrainedModel, BertModel class CustomBertClassifier(BertPreTrainedModel): def __init__(self, config, num_labels=2): super().__init__(config) self.num_labels = num_labels self.bert = BertModel(config) self.dropout = nn.Dropout(config.hidden_dropout_prob) # Custom classifier head self.classifier = nn.Sequential( nn.Linear(config.hidden_size, 256), nn.ReLU(), nn.Dropout(0.3), nn.Linear(256, num_labels) ) self.init_weights() def forward(self, input_ids=None, attention_mask=None, token_type_ids=None, labels=None): outputs = self.bert( input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids ) pooled_output = outputs[1] # [CLS] token representation pooled_output = self.dropout(pooled_output) logits = self.classifier(pooled_output) loss = None if labels is not None: loss_fct = nn.CrossEntropyLoss() loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1)) return { 'loss': loss, 'logits': logits, 'hidden_states': outputs.hidden_states, 'attentions': outputs.attentions } # Usage config = AutoConfig.from_pretrained(\"bert-base-uncased\") model = CustomBertClassifier(config, num_labels=3)","title":"Custom Model Architecture"},{"location":"python/transformers/#working-with-different-modalities","text":"# Vision-Language Models (CLIP) from transformers import CLIPProcessor, CLIPModel from PIL import Image import requests model = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\") processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\") # Load image url = \"http://images.cocodataset.org/val2017/000000039769.jpg\" image = Image.open(requests.get(url, stream=True).raw) # Process inputs inputs = processor( text=[\"a photo of a cat\", \"a photo of a dog\"], images=image, return_tensors=\"pt\", padding=True ) # Get similarities outputs = model(**inputs) logits_per_image = outputs.logits_per_image probs = logits_per_image.softmax(dim=1) print(probs) # Probability for each text description # Audio Models (Wav2Vec2) from transformers import Wav2Vec2Processor, Wav2Vec2ForCTC import librosa # Load audio model processor = Wav2Vec2Processor.from_pretrained(\"facebook/wav2vec2-base-960h\") model = Wav2Vec2ForCTC.from_pretrained(\"facebook/wav2vec2-base-960h\") # Process audio file audio, sampling_rate = librosa.load(\"path_to_audio.wav\", sr=16000) inputs = processor(audio, sampling_rate=16000, return_tensors=\"pt\", padding=True) # Get transcription with torch.no_grad(): logits = model(inputs.input_values).logits predicted_ids = torch.argmax(logits, dim=-1) transcription = processor.batch_decode(predicted_ids)[0] print(transcription)","title":"Working with Different Modalities"},{"location":"python/transformers/#integration-with-other-libraries","text":"","title":"Integration with Other Libraries"},{"location":"python/transformers/#with-datasets-library","text":"from datasets import load_dataset, Dataset, DatasetDict # Load popular datasets dataset = load_dataset(\"imdb\") # Movie reviews dataset = load_dataset(\"squad\") # Question answering dataset = load_dataset(\"glue\", \"sst2\") # Sentiment analysis # Create custom dataset data = { \"text\": [\"Great movie!\", \"Terrible film.\", \"Average story.\"], \"label\": [2, 0, 1] # positive, negative, neutral } custom_dataset = Dataset.from_dict(data) # Tokenize dataset def tokenize_data(examples): return tokenizer(examples[\"text\"], truncation=True, padding=\"max_length\", max_length=128) tokenized_dataset = custom_dataset.map(tokenize_data, batched=True) # Split dataset train_test = custom_dataset.train_test_split(test_size=0.2) dataset_dict = DatasetDict({ 'train': train_test['train'], 'test': train_test['test'] })","title":"With Datasets Library"},{"location":"python/transformers/#with-pytorch-lightning","text":"import pytorch_lightning as pl from torch.utils.data import DataLoader class TransformersLightningModule(pl.LightningModule): def __init__(self, model_name=\"bert-base-uncased\", num_labels=2, learning_rate=2e-5): super().__init__() self.save_hyperparameters() self.model = AutoModelForSequenceClassification.from_pretrained( model_name, num_labels=num_labels ) self.tokenizer = AutoTokenizer.from_pretrained(model_name) def forward(self, input_ids, attention_mask, labels=None): return self.model(input_ids=input_ids, attention_mask=attention_mask, labels=labels) def training_step(self, batch, batch_idx): outputs = self(**batch) loss = outputs.loss self.log(\"train_loss\", loss) return loss def validation_step(self, batch, batch_idx): outputs = self(**batch) loss = outputs.loss self.log(\"val_loss\", loss) return loss def configure_optimizers(self): return torch.optim.AdamW(self.parameters(), lr=self.hparams.learning_rate) # Usage model = TransformersLightningModule() trainer = pl.Trainer(max_epochs=3, gpus=1 if torch.cuda.is_available() else 0) trainer.fit(model, train_dataloader, val_dataloader)","title":"With PyTorch Lightning"},{"location":"python/transformers/#with-gradio-for-web-apps","text":"import gradio as gr from transformers import pipeline # Create sentiment analysis pipeline sentiment_pipeline = pipeline(\"sentiment-analysis\", model=\"cardiffnlp/twitter-roberta-base-sentiment-latest\") def analyze_sentiment(text): result = sentiment_pipeline(text)[0] return f\"Sentiment: {result['label']} (Confidence: {result['score']:.3f})\" # Create Gradio interface interface = gr.Interface( fn=analyze_sentiment, inputs=gr.Textbox(lines=3, placeholder=\"Enter text to analyze...\"), outputs=\"text\", title=\"Sentiment Analysis\", description=\"Analyze the sentiment of your text using RoBERTa model\" ) # Launch the app interface.launch()","title":"With Gradio for Web Apps"},{"location":"python/transformers/#best-practices","text":"","title":"Best Practices"},{"location":"python/transformers/#memory-and-performance-optimization","text":"# 1. Use appropriate model sizes model = AutoModel.from_pretrained( \"distilbert-base-uncased\", # Smaller, faster alternative to BERT torch_dtype=torch.float16, # Half precision for memory efficiency device_map=\"auto\" # Automatic device placement ) # 2. Batch processing for efficiency def batch_inference(texts, batch_size=32): results = [] for i in range(0, len(texts), batch_size): batch = texts[i:i + batch_size] batch_encoding = tokenizer( batch, truncation=True, padding=True, return_tensors=\"pt\" ) with torch.no_grad(): outputs = model(**batch_encoding) results.extend(outputs.logits.cpu().numpy()) return results # 3. Gradient checkpointing for training large models model.gradient_checkpointing_enable() # 4. Use DataLoader with multiple workers from torch.utils.data import DataLoader dataloader = DataLoader( dataset, batch_size=16, num_workers=4, pin_memory=True )","title":"Memory and Performance Optimization"},{"location":"python/transformers/#model-evaluation-and-monitoring","text":"from sklearn.metrics import classification_report, confusion_matrix import matplotlib.pyplot as plt import seaborn as sns def evaluate_model(model, tokenizer, test_texts, test_labels): predictions = [] for text in test_texts: inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=128) with torch.no_grad(): outputs = model(**inputs) pred = torch.argmax(outputs.logits, dim=-1).item() predictions.append(pred) # Classification report report = classification_report(test_labels, predictions, output_dict=True) print(classification_report(test_labels, predictions)) # Confusion matrix cm = confusion_matrix(test_labels, predictions) plt.figure(figsize=(8, 6)) sns.heatmap(cm, annot=True, fmt='d', cmap='Blues') plt.title('Confusion Matrix') plt.ylabel('True Label') plt.xlabel('Predicted Label') plt.show() return report, cm # Usage report, cm = evaluate_model(model, tokenizer, test_texts, test_labels)","title":"Model Evaluation and Monitoring"},{"location":"python/transformers/#error-handling-and-robust-inference","text":"def robust_inference(text, model, tokenizer, max_retries=3): \"\"\"Robust inference with error handling\"\"\" for attempt in range(max_retries): try: # Validate input if not isinstance(text, str) or not text.strip(): return {\"error\": \"Invalid input text\"} # Tokenize with length check inputs = tokenizer( text, return_tensors=\"pt\", truncation=True, max_length=512, padding=True ) # Check if input is too long even after truncation if inputs['input_ids'].shape[1] > 512: return {\"error\": \"Text too long even after truncation\"} # Inference with torch.no_grad(): outputs = model(**inputs) predictions = torch.nn.functional.softmax(outputs.logits, dim=-1) predicted_class = torch.argmax(predictions, dim=-1).item() confidence = predictions[0][predicted_class].item() return { \"prediction\": predicted_class, \"confidence\": confidence, \"success\": True } except Exception as e: if attempt == max_retries - 1: return {\"error\": f\"Inference failed after {max_retries} attempts: {str(e)}\"} time.sleep(0.1) # Brief pause before retry return {\"error\": \"Maximum retries exceeded\"}","title":"Error Handling and Robust Inference"},{"location":"python/transformers/#real-world-examples","text":"","title":"Real-world Examples"},{"location":"python/transformers/#complete-text-classification-system","text":"class TextClassificationSystem: def __init__(self, model_name=\"distilbert-base-uncased\", num_labels=3): self.tokenizer = AutoTokenizer.from_pretrained(model_name) self.model = AutoModelForSequenceClassification.from_pretrained( model_name, num_labels=num_labels ) self.label_map = {0: \"negative\", 1: \"neutral\", 2: \"positive\"} def preprocess_text(self, text): \"\"\"Clean and preprocess text\"\"\" import re text = re.sub(r'http\\S+', '', text) # Remove URLs text = re.sub(r'@\\w+', '', text) # Remove mentions text = re.sub(r'#\\w+', '', text) # Remove hashtags text = re.sub(r'\\s+', ' ', text) # Normalize whitespace return text.strip() def predict(self, text): \"\"\"Make prediction on single text\"\"\" cleaned_text = self.preprocess_text(text) inputs = self.tokenizer( cleaned_text, return_tensors=\"pt\", truncation=True, max_length=128, padding=True ) with torch.no_grad(): outputs = self.model(**inputs) predictions = torch.nn.functional.softmax(outputs.logits, dim=-1) predicted_class = torch.argmax(predictions, dim=-1).item() confidence = predictions[0][predicted_class].item() return { \"text\": text, \"cleaned_text\": cleaned_text, \"prediction\": self.label_map[predicted_class], \"confidence\": confidence, \"all_scores\": { self.label_map[i]: predictions[0][i].item() for i in range(len(self.label_map)) } } def predict_batch(self, texts, batch_size=32): \"\"\"Make predictions on batch of texts\"\"\" results = [] for i in range(0, len(texts), batch_size): batch_texts = texts[i:i + batch_size] cleaned_texts = [self.preprocess_text(text) for text in batch_texts] inputs = self.tokenizer( cleaned_texts, return_tensors=\"pt\", truncation=True, max_length=128, padding=True ) with torch.no_grad(): outputs = self.model(**inputs) predictions = torch.nn.functional.softmax(outputs.logits, dim=-1) predicted_classes = torch.argmax(predictions, dim=-1) for j, (text, cleaned_text) in enumerate(zip(batch_texts, cleaned_texts)): pred_class = predicted_classes[j].item() confidence = predictions[j][pred_class].item() results.append({ \"text\": text, \"cleaned_text\": cleaned_text, \"prediction\": self.label_map[pred_class], \"confidence\": confidence }) return results # Usage classifier = TextClassificationSystem() # Single prediction result = classifier.predict(\"I absolutely love this new product! It's amazing!\") print(result) # Batch prediction texts = [ \"Great service and friendly staff!\", \"Terrible experience, would not recommend.\", \"It was okay, nothing special.\" ] results = classifier.predict_batch(texts) for result in results: print(f\"{result['prediction']}: {result['text']} (confidence: {result['confidence']:.3f})\")","title":"Complete Text Classification System"},{"location":"python/transformers/#multi-task-nlp-pipeline","text":"class MultiTaskNLPPipeline: def __init__(self): # Initialize different models for different tasks self.sentiment_analyzer = pipeline(\"sentiment-analysis\") self.ner_model = pipeline(\"ner\", aggregation_strategy=\"simple\") self.qa_model = pipeline(\"question-answering\") self.summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\") def analyze_text(self, text, tasks=[\"sentiment\", \"ner\", \"summary\"]): \"\"\"Comprehensive text analysis\"\"\" results = {\"original_text\": text} if \"sentiment\" in tasks: sentiment = self.sentiment_analyzer(text)[0] results[\"sentiment\"] = { \"label\": sentiment[\"label\"], \"confidence\": sentiment[\"score\"] } if \"ner\" in tasks: entities = self.ner_model(text) results[\"entities\"] = [ { \"text\": entity[\"word\"], \"label\": entity[\"entity_group\"], \"confidence\": entity[\"score\"] } for entity in entities ] if \"summary\" in tasks and len(text.split()) > 30: try: summary = self.summarizer(text, max_length=100, min_length=30)[0] results[\"summary\"] = summary[\"summary_text\"] except: results[\"summary\"] = \"Text too short for summarization\" return results def answer_questions(self, context, questions): \"\"\"Answer multiple questions about a context\"\"\" answers = [] for question in questions: try: answer = self.qa_model(question=question, context=context) answers.append({ \"question\": question, \"answer\": answer[\"answer\"], \"confidence\": answer[\"score\"] }) except: answers.append({ \"question\": question, \"answer\": \"Could not answer\", \"confidence\": 0.0 }) return answers # Usage nlp_pipeline = MultiTaskNLPPipeline() text = \"\"\" Apple Inc. is an American multinational technology company headquartered in Cupertino, California. Apple is the world's largest technology company by revenue and the world's most valuable company. The company was founded by Steve Jobs, Steve Wozniak, and Ronald Wayne in April 1976. Apple's products include the iPhone, iPad, Mac, Apple Watch, and Apple TV. \"\"\" # Comprehensive analysis analysis = nlp_pipeline.analyze_text(text) print(\"Analysis Results:\") print(f\"Sentiment: {analysis['sentiment']['label']} ({analysis['sentiment']['confidence']:.3f})\") print(f\"Entities: {[e['text'] for e in analysis['entities']]}\") print(f\"Summary: {analysis['summary']}\") # Question answering questions = [ \"Who founded Apple?\", \"Where is Apple headquartered?\", \"What products does Apple make?\" ] answers = nlp_pipeline.answer_questions(text, questions) for qa in answers: print(f\"Q: {qa['question']}\") print(f\"A: {qa['answer']} (confidence: {qa['confidence']:.3f})\") This comprehensive cheat sheet covers the essential aspects of the Transformers library. The library's strength lies in its unified API across different models and tasks, extensive model zoo, and seamless integration with the broader ML ecosystem. It's the go-to library for state-of-the-art NLP applications and research.","title":"Multi-task NLP Pipeline"},{"location":"tools/protobuf/","text":"Protocol Buffers (protobuf) Protocol Buffers is Google's language-neutral, platform-neutral mechanism for serializing structured data. This guide covers .proto file syntax and compilation with protoc . Quick Start Installation # Install protoc compiler (Linux/Mac) # From https://github.com/protocolbuffers/protobuf/releases curl -LO https://github.com/protocolbuffers/protobuf/releases/download/v27.0/protoc-27.0-linux-x86_64.zip unzip protoc-27.0-linux-x86_64.zip -d protoc sudo cp protoc/bin/protoc /usr/local/bin/ sudo cp -r protoc/include/google /usr/local/include/ # Verify installation protoc --version Language Plugins # Go go install google.golang.org/protobuf/cmd/protoc-gen-go@latest # Python (included with protobuf library) pip install protobuf # Java/Kotlin (built into protoc) # JavaScript/TypeScript npm install -g @protobuf-ts/plugin Core Concepts .proto File Structure // File header syntax = \"proto3\"; // or \"proto2\" or edition = \"2024\" package com.example; // Imports import \"google/protobuf/timestamp.proto\"; // Options option java_package = \"com.example.proto\"; option go_package = \"./proto\"; // Message definitions message Person { string name = 1; int32 age = 2; } Message Definitions Basic Message syntax = \"proto3\"; message User { int32 id = 1; // Field number must be unique string username = 2; string email = 3; bool active = 4; } Nested Messages message Person { string name = 1; message Address { string street = 1; string city = 2; string country = 3; } Address address = 2; } Field Rules (Proto2 vs Proto3) // Proto2 syntax = \"proto2\"; message User { required string name = 1; // Must be provided optional int32 age = 2; // Can be omitted repeated string tags = 3; // Can have 0 or more values } // Proto3 (more common) syntax = \"proto3\"; message User { string name = 1; // Implicit presence optional int32 age = 2; // Explicit presence (proto3.15+) repeated string tags = 3; // 0 or more values } Scalar Types Numeric Types message NumericTypes { double price = 1; // 64-bit floating point float rating = 2; // 32-bit floating point int32 count = 3; // Variable-length encoding int64 big_count = 4; // Variable-length encoding uint32 positive = 5; // Variable-length encoding uint64 big_positive = 6; sint32 signed_val = 7; // Better for negative numbers sint64 big_signed = 8; fixed32 fixed_val = 9; // Always 4 bytes fixed64 big_fixed = 10; // Always 8 bytes sfixed32 signed_fixed = 11; // Always 4 bytes, signed sfixed64 big_signed_fixed = 12; // Always 8 bytes, signed bool enabled = 13; } String and Bytes message TextTypes { string text = 1; // UTF-8 encoded string bytes data = 2; // Arbitrary byte sequence } Complex Types Enumerations enum Status { UNKNOWN = 0; // First value must be 0 in proto3 PENDING = 1; APPROVED = 2; REJECTED = 3; } message Request { Status status = 1; } Repeated Fields message ShoppingCart { repeated string items = 1; // List of strings repeated int32 quantities = 2; // List of integers repeated Product products = 3; // List of messages } // With packed encoding (more efficient for primitives) message Measurements { repeated int32 values = 1 [packed = true]; } Maps message UserSettings { map<string, string> preferences = 1; // String to string map<int32, User> users_by_id = 2; // Integer to message map<string, bool> features = 3; // String to boolean } Oneof (Union Types) message SearchRequest { string query = 1; oneof filter { string category = 2; int32 price_max = 3; bool on_sale = 4; } } Advanced Features Any Type import \"google/protobuf/any.proto\"; message ErrorInfo { string message = 1; google.protobuf.Any details = 2; // Can contain any message type } Well-Known Types import \"google/protobuf/timestamp.proto\"; import \"google/protobuf/duration.proto\"; import \"google/protobuf/empty.proto\"; import \"google/protobuf/struct.proto\"; message Event { google.protobuf.Timestamp created_at = 1; google.protobuf.Duration timeout = 2; google.protobuf.Struct metadata = 3; } Field Options message Product { string name = 1; double price = 2 [(validate.rules).double.gt = 0]; // Custom validation string description = 3 [deprecated = true]; // Mark as deprecated } Reserved Fields message User { reserved 2, 15, 9 to 11; // Reserve field numbers reserved \"old_name\", \"legacy_id\"; // Reserve field names string name = 1; string email = 3; // Field 2 is reserved and cannot be used } Services (gRPC) Basic Service Definition syntax = \"proto3\"; service UserService { // Unary RPC rpc GetUser(GetUserRequest) returns (User); // Server streaming rpc ListUsers(ListUsersRequest) returns (stream User); // Client streaming rpc CreateUsers(stream CreateUserRequest) returns (CreateUsersResponse); // Bidirectional streaming rpc Chat(stream ChatMessage) returns (stream ChatMessage); } message GetUserRequest { int32 user_id = 1; } message ListUsersRequest { int32 page_size = 1; string page_token = 2; } message CreateUserRequest { User user = 1; } message CreateUsersResponse { repeated User users = 1; } message ChatMessage { string message = 1; string user_id = 2; } Compilation with protoc Basic Usage # Check version protoc --version # Generate code for single language protoc --python_out=./generated user.proto # Generate for multiple languages protoc --java_out=./java --python_out=./python --go_out=./go user.proto # Specify import paths protoc -I./protos -I./vendor --python_out=./generated protos/user.proto Language-Specific Generation Go # Basic Go generation protoc --go_out=. --go_opt=paths=source_relative user.proto # With gRPC protoc --go_out=. --go-grpc_out=. \\ --go_opt=paths=source_relative \\ --go-grpc_opt=paths=source_relative \\ user.proto # Custom Go package protoc --go_out=. --go_opt=Muser.proto=./internal/proto user.proto Python # Basic Python generation protoc --python_out=./generated user.proto # With type stubs (.pyi files) protoc --python_out=./generated --pyi_out=./generated user.proto # With gRPC protoc --python_out=./generated --grpc_python_out=./generated user.proto Java/Kotlin # Java protoc --java_out=./src/main/java user.proto # Java Lite (smaller runtime) protoc --java_out=lite:./src/main/java user.proto # Kotlin protoc --java_out=./src/main/java --kotlin_out=./src/main/kotlin user.proto JavaScript/TypeScript # JavaScript protoc --js_out=import_style=commonjs,binary:./generated user.proto # TypeScript with protobuf-ts protoc --ts_out=./generated user.proto C++ # C++ protoc --cpp_out=./generated user.proto # With gRPC protoc --cpp_out=./generated --grpc_out=./generated \\ --plugin=protoc-gen-grpc=grpc_cpp_plugin user.proto C # C# protoc --csharp_out=./Generated user.proto # With gRPC protoc --csharp_out=./Generated --grpc_out=./Generated \\ --plugin=protoc-gen-grpc=grpc_csharp_plugin user.proto Advanced protoc Options Multiple Files and Directories # Compile all .proto files in directory protoc --python_out=./generated protos/*.proto # Recursive compilation find ./protos -name \"*.proto\" -exec protoc --python_out=./generated {} \\; # With include paths protoc -I./protos -I./vendor -I./third_party \\ --python_out=./generated \\ protos/user.proto protos/order.proto Descriptor Sets # Generate descriptor set (for reflection) protoc --descriptor_set_out=user.desc --include_imports user.proto # Generate descriptor set with source info protoc --descriptor_set_out=user.desc \\ --include_imports --include_source_info user.proto Custom Plugins # Use custom plugin protoc --plugin=protoc-gen-custom=./my-plugin \\ --custom_out=./generated user.proto # Plugin with options protoc --plugin=protoc-gen-validate=protoc-gen-validate \\ --validate_out=\"lang=go:./generated\" user.proto Build Integration Makefile # Variables PROTO_FILES = $(wildcard protos/*.proto) GENERATED_GO = $(PROTO_FILES:protos/%.proto=generated/%.pb.go) GENERATED_PY = $(PROTO_FILES:protos/%.proto=generated/%_pb2.py) # Go generation generated/%.pb.go: protos/%.proto protoc --go_out=generated --go_opt=paths=source_relative $< # Python generation generated/%_pb2.py: protos/%.proto protoc --python_out=generated $< # Targets .PHONY: go python clean go: $(GENERATED_GO) python: $(GENERATED_PY) clean: rm -rf generated/* all: go python CMake # Find protobuf find_package(protobuf REQUIRED) # Function to compile protobuf files function(compile_proto_files) foreach(proto_file ${ARGN}) get_filename_component(proto_name ${proto_file} NAME_WE) get_filename_component(proto_dir ${proto_file} DIRECTORY) set(generated_files ${CMAKE_CURRENT_BINARY_DIR}/${proto_name}.pb.h ${CMAKE_CURRENT_BINARY_DIR}/${proto_name}.pb.cc ) add_custom_command( OUTPUT ${generated_files} COMMAND protobuf::protoc ARGS --cpp_out=${CMAKE_CURRENT_BINARY_DIR} -I${proto_dir} ${proto_file} DEPENDS ${proto_file} ) list(APPEND PROTO_GENERATED_FILES ${generated_files}) endforeach() set(PROTO_GENERATED_FILES ${PROTO_GENERATED_FILES} PARENT_SCOPE) endfunction() # Usage compile_proto_files(protos/user.proto protos/order.proto) add_executable(myapp main.cpp ${PROTO_GENERATED_FILES}) target_link_libraries(myapp protobuf::libprotobuf) Bazel # BUILD file load(\"@rules_proto//proto:defs.bzl\", \"proto_library\") load(\"@io_grpc_grpc_java//:java_grpc_library.bzl\", \"java_grpc_library\") proto_library( name = \"user_proto\", srcs = [\"user.proto\"], deps = [ \"@com_google_protobuf//:timestamp_proto\", ], ) java_proto_library( name = \"user_java_proto\", deps = [\":user_proto\"], ) java_grpc_library( name = \"user_java_grpc\", srcs = [\":user_proto\"], deps = [\":user_java_proto\"], ) Best Practices Schema Design // Good: Use clear, descriptive names message UserProfile { string full_name = 1; // Better than 'name' string email_address = 2; // Better than 'email' int64 created_timestamp = 3; // Better than 'created' } // Good: Group related fields message Address { string street_line_1 = 1; string street_line_2 = 2; string city = 3; string state = 4; string postal_code = 5; string country_code = 6; } // Good: Use enums for fixed sets of values enum UserRole { ROLE_UNSPECIFIED = 0; // Always include zero value ROLE_USER = 1; ROLE_ADMIN = 2; ROLE_MODERATOR = 3; } Field Numbering message Product { // Reserve low numbers (1-15) for frequently used fields // They use 1 byte for tag encoding string name = 1; double price = 2; bool available = 3; // Higher numbers (16+) use 2+ bytes string detailed_description = 16; repeated string tags = 17; // Reserve ranges for future use reserved 4 to 10; reserved 100 to 200; } Versioning and Evolution // Original version message User { string name = 1; string email = 2; } // Evolved version - backward compatible message User { string name = 1; string email = 2; // New optional fields don't break compatibility optional int32 age = 3; repeated string interests = 4; // Nested messages can be added optional Address address = 5; } Performance Considerations // Use appropriate field types for your data message Metrics { // Use packed repeated for primitive arrays repeated int32 values = 1 [packed = true]; // Consider fixed types for known-size data fixed64 timestamp_nanos = 2; // Better than int64 for large numbers // Use bytes for binary data bytes thumbnail = 3; // Not string for binary data // Consider string vs bytes for text string utf8_text = 4; // For valid UTF-8 bytes raw_text = 5; // For potentially invalid UTF-8 } Common Patterns Request/Response Patterns // Standard CRUD operations service UserService { rpc CreateUser(CreateUserRequest) returns (CreateUserResponse); rpc GetUser(GetUserRequest) returns (GetUserResponse); rpc UpdateUser(UpdateUserRequest) returns (UpdateUserResponse); rpc DeleteUser(DeleteUserRequest) returns (DeleteUserResponse); rpc ListUsers(ListUsersRequest) returns (ListUsersResponse); } message CreateUserRequest { User user = 1; } message CreateUserResponse { User user = 1; string message = 2; } message GetUserRequest { string user_id = 1; } message GetUserResponse { User user = 1; } // Pagination pattern message ListUsersRequest { int32 page_size = 1; string page_token = 2; string filter = 3; } message ListUsersResponse { repeated User users = 1; string next_page_token = 2; int32 total_count = 3; } Error Handling import \"google/rpc/status.proto\"; import \"google/protobuf/any.proto\"; message ErrorResponse { google.rpc.Status status = 1; // Standard error status string message = 2; // Human-readable message repeated google.protobuf.Any details = 3; // Additional error details } // Custom error details message ValidationError { repeated FieldError field_errors = 1; } message FieldError { string field = 1; string message = 2; string code = 3; } Gotchas and Common Mistakes Field Number Management // DON'T: Reuse field numbers message User { string name = 1; // string old_email = 2; // Removed field string email = 2; // DON'T reuse number 2 } // DO: Reserve removed field numbers message User { reserved 2; // or: reserved \"old_email\"; string name = 1; string email = 3; // Use new number } Default Values and Presence // Proto3: Cannot distinguish between default value and not set message User { int32 age = 1; // age=0 could mean \"not set\" or actually 0 } // Solution: Use optional or wrapper types import \"google/protobuf/wrappers.proto\"; message User { optional int32 age = 1; // Can detect presence // or google.protobuf.Int32Value age_wrapper = 2; } Package and Import Issues // File: protos/user.proto syntax = \"proto3\"; package myapp.user; // Use consistent package naming import \"protos/common.proto\"; // Use relative paths consistently // File: protos/common.proto syntax = \"proto3\"; package myapp.common; // Must match directory structure Compilation Ordering # Wrong: May fail if dependencies aren't found protoc --python_out=. user.proto # Right: Include all necessary import paths protoc -I. -I./vendor -I./third_party --python_out=. user.proto Quick Reference Essential protoc Flags Flag Purpose Example --version Show protoc version protoc --version -I, --proto_path Add import directory protoc -I./protos --python_out Generate Python code --python_out=./gen --go_out Generate Go code --go_out=. --java_out Generate Java code --java_out=./src --cpp_out Generate C++ code --cpp_out=./gen --descriptor_set_out Generate descriptor --descriptor_set_out=desc.pb --include_imports Include dependencies in descriptor Use with --descriptor_set_out Scalar Type Mapping Proto Type Go Python Java C++ JavaScript double float64 float double double number float float32 float float float number int32 int32 int int int32 number int64 int64 int long int64 string string string str String string string bool bool bool boolean bool boolean bytes []byte bytes ByteString string Uint8Array Protocol Buffers provide efficient, language-agnostic data serialization with strong schema evolution capabilities. Focus on clear field naming, proper type selection, and maintaining backward compatibility for production systems.","title":"Protocol Buffers (protobuf)"},{"location":"tools/protobuf/#protocol-buffers-protobuf","text":"Protocol Buffers is Google's language-neutral, platform-neutral mechanism for serializing structured data. This guide covers .proto file syntax and compilation with protoc .","title":"Protocol Buffers (protobuf)"},{"location":"tools/protobuf/#quick-start","text":"","title":"Quick Start"},{"location":"tools/protobuf/#installation","text":"# Install protoc compiler (Linux/Mac) # From https://github.com/protocolbuffers/protobuf/releases curl -LO https://github.com/protocolbuffers/protobuf/releases/download/v27.0/protoc-27.0-linux-x86_64.zip unzip protoc-27.0-linux-x86_64.zip -d protoc sudo cp protoc/bin/protoc /usr/local/bin/ sudo cp -r protoc/include/google /usr/local/include/ # Verify installation protoc --version","title":"Installation"},{"location":"tools/protobuf/#language-plugins","text":"# Go go install google.golang.org/protobuf/cmd/protoc-gen-go@latest # Python (included with protobuf library) pip install protobuf # Java/Kotlin (built into protoc) # JavaScript/TypeScript npm install -g @protobuf-ts/plugin","title":"Language Plugins"},{"location":"tools/protobuf/#core-concepts","text":"","title":"Core Concepts"},{"location":"tools/protobuf/#proto-file-structure","text":"// File header syntax = \"proto3\"; // or \"proto2\" or edition = \"2024\" package com.example; // Imports import \"google/protobuf/timestamp.proto\"; // Options option java_package = \"com.example.proto\"; option go_package = \"./proto\"; // Message definitions message Person { string name = 1; int32 age = 2; }","title":".proto File Structure"},{"location":"tools/protobuf/#message-definitions","text":"","title":"Message Definitions"},{"location":"tools/protobuf/#basic-message","text":"syntax = \"proto3\"; message User { int32 id = 1; // Field number must be unique string username = 2; string email = 3; bool active = 4; }","title":"Basic Message"},{"location":"tools/protobuf/#nested-messages","text":"message Person { string name = 1; message Address { string street = 1; string city = 2; string country = 3; } Address address = 2; }","title":"Nested Messages"},{"location":"tools/protobuf/#field-rules-proto2-vs-proto3","text":"// Proto2 syntax = \"proto2\"; message User { required string name = 1; // Must be provided optional int32 age = 2; // Can be omitted repeated string tags = 3; // Can have 0 or more values } // Proto3 (more common) syntax = \"proto3\"; message User { string name = 1; // Implicit presence optional int32 age = 2; // Explicit presence (proto3.15+) repeated string tags = 3; // 0 or more values }","title":"Field Rules (Proto2 vs Proto3)"},{"location":"tools/protobuf/#scalar-types","text":"","title":"Scalar Types"},{"location":"tools/protobuf/#numeric-types","text":"message NumericTypes { double price = 1; // 64-bit floating point float rating = 2; // 32-bit floating point int32 count = 3; // Variable-length encoding int64 big_count = 4; // Variable-length encoding uint32 positive = 5; // Variable-length encoding uint64 big_positive = 6; sint32 signed_val = 7; // Better for negative numbers sint64 big_signed = 8; fixed32 fixed_val = 9; // Always 4 bytes fixed64 big_fixed = 10; // Always 8 bytes sfixed32 signed_fixed = 11; // Always 4 bytes, signed sfixed64 big_signed_fixed = 12; // Always 8 bytes, signed bool enabled = 13; }","title":"Numeric Types"},{"location":"tools/protobuf/#string-and-bytes","text":"message TextTypes { string text = 1; // UTF-8 encoded string bytes data = 2; // Arbitrary byte sequence }","title":"String and Bytes"},{"location":"tools/protobuf/#complex-types","text":"","title":"Complex Types"},{"location":"tools/protobuf/#enumerations","text":"enum Status { UNKNOWN = 0; // First value must be 0 in proto3 PENDING = 1; APPROVED = 2; REJECTED = 3; } message Request { Status status = 1; }","title":"Enumerations"},{"location":"tools/protobuf/#repeated-fields","text":"message ShoppingCart { repeated string items = 1; // List of strings repeated int32 quantities = 2; // List of integers repeated Product products = 3; // List of messages } // With packed encoding (more efficient for primitives) message Measurements { repeated int32 values = 1 [packed = true]; }","title":"Repeated Fields"},{"location":"tools/protobuf/#maps","text":"message UserSettings { map<string, string> preferences = 1; // String to string map<int32, User> users_by_id = 2; // Integer to message map<string, bool> features = 3; // String to boolean }","title":"Maps"},{"location":"tools/protobuf/#oneof-union-types","text":"message SearchRequest { string query = 1; oneof filter { string category = 2; int32 price_max = 3; bool on_sale = 4; } }","title":"Oneof (Union Types)"},{"location":"tools/protobuf/#advanced-features","text":"","title":"Advanced Features"},{"location":"tools/protobuf/#any-type","text":"import \"google/protobuf/any.proto\"; message ErrorInfo { string message = 1; google.protobuf.Any details = 2; // Can contain any message type }","title":"Any Type"},{"location":"tools/protobuf/#well-known-types","text":"import \"google/protobuf/timestamp.proto\"; import \"google/protobuf/duration.proto\"; import \"google/protobuf/empty.proto\"; import \"google/protobuf/struct.proto\"; message Event { google.protobuf.Timestamp created_at = 1; google.protobuf.Duration timeout = 2; google.protobuf.Struct metadata = 3; }","title":"Well-Known Types"},{"location":"tools/protobuf/#field-options","text":"message Product { string name = 1; double price = 2 [(validate.rules).double.gt = 0]; // Custom validation string description = 3 [deprecated = true]; // Mark as deprecated }","title":"Field Options"},{"location":"tools/protobuf/#reserved-fields","text":"message User { reserved 2, 15, 9 to 11; // Reserve field numbers reserved \"old_name\", \"legacy_id\"; // Reserve field names string name = 1; string email = 3; // Field 2 is reserved and cannot be used }","title":"Reserved Fields"},{"location":"tools/protobuf/#services-grpc","text":"","title":"Services (gRPC)"},{"location":"tools/protobuf/#basic-service-definition","text":"syntax = \"proto3\"; service UserService { // Unary RPC rpc GetUser(GetUserRequest) returns (User); // Server streaming rpc ListUsers(ListUsersRequest) returns (stream User); // Client streaming rpc CreateUsers(stream CreateUserRequest) returns (CreateUsersResponse); // Bidirectional streaming rpc Chat(stream ChatMessage) returns (stream ChatMessage); } message GetUserRequest { int32 user_id = 1; } message ListUsersRequest { int32 page_size = 1; string page_token = 2; } message CreateUserRequest { User user = 1; } message CreateUsersResponse { repeated User users = 1; } message ChatMessage { string message = 1; string user_id = 2; }","title":"Basic Service Definition"},{"location":"tools/protobuf/#compilation-with-protoc","text":"","title":"Compilation with protoc"},{"location":"tools/protobuf/#basic-usage","text":"# Check version protoc --version # Generate code for single language protoc --python_out=./generated user.proto # Generate for multiple languages protoc --java_out=./java --python_out=./python --go_out=./go user.proto # Specify import paths protoc -I./protos -I./vendor --python_out=./generated protos/user.proto","title":"Basic Usage"},{"location":"tools/protobuf/#language-specific-generation","text":"","title":"Language-Specific Generation"},{"location":"tools/protobuf/#go","text":"# Basic Go generation protoc --go_out=. --go_opt=paths=source_relative user.proto # With gRPC protoc --go_out=. --go-grpc_out=. \\ --go_opt=paths=source_relative \\ --go-grpc_opt=paths=source_relative \\ user.proto # Custom Go package protoc --go_out=. --go_opt=Muser.proto=./internal/proto user.proto","title":"Go"},{"location":"tools/protobuf/#python","text":"# Basic Python generation protoc --python_out=./generated user.proto # With type stubs (.pyi files) protoc --python_out=./generated --pyi_out=./generated user.proto # With gRPC protoc --python_out=./generated --grpc_python_out=./generated user.proto","title":"Python"},{"location":"tools/protobuf/#javakotlin","text":"# Java protoc --java_out=./src/main/java user.proto # Java Lite (smaller runtime) protoc --java_out=lite:./src/main/java user.proto # Kotlin protoc --java_out=./src/main/java --kotlin_out=./src/main/kotlin user.proto","title":"Java/Kotlin"},{"location":"tools/protobuf/#javascripttypescript","text":"# JavaScript protoc --js_out=import_style=commonjs,binary:./generated user.proto # TypeScript with protobuf-ts protoc --ts_out=./generated user.proto","title":"JavaScript/TypeScript"},{"location":"tools/protobuf/#c","text":"# C++ protoc --cpp_out=./generated user.proto # With gRPC protoc --cpp_out=./generated --grpc_out=./generated \\ --plugin=protoc-gen-grpc=grpc_cpp_plugin user.proto","title":"C++"},{"location":"tools/protobuf/#c_1","text":"# C# protoc --csharp_out=./Generated user.proto # With gRPC protoc --csharp_out=./Generated --grpc_out=./Generated \\ --plugin=protoc-gen-grpc=grpc_csharp_plugin user.proto","title":"C"},{"location":"tools/protobuf/#advanced-protoc-options","text":"","title":"Advanced protoc Options"},{"location":"tools/protobuf/#multiple-files-and-directories","text":"# Compile all .proto files in directory protoc --python_out=./generated protos/*.proto # Recursive compilation find ./protos -name \"*.proto\" -exec protoc --python_out=./generated {} \\; # With include paths protoc -I./protos -I./vendor -I./third_party \\ --python_out=./generated \\ protos/user.proto protos/order.proto","title":"Multiple Files and Directories"},{"location":"tools/protobuf/#descriptor-sets","text":"# Generate descriptor set (for reflection) protoc --descriptor_set_out=user.desc --include_imports user.proto # Generate descriptor set with source info protoc --descriptor_set_out=user.desc \\ --include_imports --include_source_info user.proto","title":"Descriptor Sets"},{"location":"tools/protobuf/#custom-plugins","text":"# Use custom plugin protoc --plugin=protoc-gen-custom=./my-plugin \\ --custom_out=./generated user.proto # Plugin with options protoc --plugin=protoc-gen-validate=protoc-gen-validate \\ --validate_out=\"lang=go:./generated\" user.proto","title":"Custom Plugins"},{"location":"tools/protobuf/#build-integration","text":"","title":"Build Integration"},{"location":"tools/protobuf/#makefile","text":"# Variables PROTO_FILES = $(wildcard protos/*.proto) GENERATED_GO = $(PROTO_FILES:protos/%.proto=generated/%.pb.go) GENERATED_PY = $(PROTO_FILES:protos/%.proto=generated/%_pb2.py) # Go generation generated/%.pb.go: protos/%.proto protoc --go_out=generated --go_opt=paths=source_relative $< # Python generation generated/%_pb2.py: protos/%.proto protoc --python_out=generated $< # Targets .PHONY: go python clean go: $(GENERATED_GO) python: $(GENERATED_PY) clean: rm -rf generated/* all: go python","title":"Makefile"},{"location":"tools/protobuf/#cmake","text":"# Find protobuf find_package(protobuf REQUIRED) # Function to compile protobuf files function(compile_proto_files) foreach(proto_file ${ARGN}) get_filename_component(proto_name ${proto_file} NAME_WE) get_filename_component(proto_dir ${proto_file} DIRECTORY) set(generated_files ${CMAKE_CURRENT_BINARY_DIR}/${proto_name}.pb.h ${CMAKE_CURRENT_BINARY_DIR}/${proto_name}.pb.cc ) add_custom_command( OUTPUT ${generated_files} COMMAND protobuf::protoc ARGS --cpp_out=${CMAKE_CURRENT_BINARY_DIR} -I${proto_dir} ${proto_file} DEPENDS ${proto_file} ) list(APPEND PROTO_GENERATED_FILES ${generated_files}) endforeach() set(PROTO_GENERATED_FILES ${PROTO_GENERATED_FILES} PARENT_SCOPE) endfunction() # Usage compile_proto_files(protos/user.proto protos/order.proto) add_executable(myapp main.cpp ${PROTO_GENERATED_FILES}) target_link_libraries(myapp protobuf::libprotobuf)","title":"CMake"},{"location":"tools/protobuf/#bazel","text":"# BUILD file load(\"@rules_proto//proto:defs.bzl\", \"proto_library\") load(\"@io_grpc_grpc_java//:java_grpc_library.bzl\", \"java_grpc_library\") proto_library( name = \"user_proto\", srcs = [\"user.proto\"], deps = [ \"@com_google_protobuf//:timestamp_proto\", ], ) java_proto_library( name = \"user_java_proto\", deps = [\":user_proto\"], ) java_grpc_library( name = \"user_java_grpc\", srcs = [\":user_proto\"], deps = [\":user_java_proto\"], )","title":"Bazel"},{"location":"tools/protobuf/#best-practices","text":"","title":"Best Practices"},{"location":"tools/protobuf/#schema-design","text":"// Good: Use clear, descriptive names message UserProfile { string full_name = 1; // Better than 'name' string email_address = 2; // Better than 'email' int64 created_timestamp = 3; // Better than 'created' } // Good: Group related fields message Address { string street_line_1 = 1; string street_line_2 = 2; string city = 3; string state = 4; string postal_code = 5; string country_code = 6; } // Good: Use enums for fixed sets of values enum UserRole { ROLE_UNSPECIFIED = 0; // Always include zero value ROLE_USER = 1; ROLE_ADMIN = 2; ROLE_MODERATOR = 3; }","title":"Schema Design"},{"location":"tools/protobuf/#field-numbering","text":"message Product { // Reserve low numbers (1-15) for frequently used fields // They use 1 byte for tag encoding string name = 1; double price = 2; bool available = 3; // Higher numbers (16+) use 2+ bytes string detailed_description = 16; repeated string tags = 17; // Reserve ranges for future use reserved 4 to 10; reserved 100 to 200; }","title":"Field Numbering"},{"location":"tools/protobuf/#versioning-and-evolution","text":"// Original version message User { string name = 1; string email = 2; } // Evolved version - backward compatible message User { string name = 1; string email = 2; // New optional fields don't break compatibility optional int32 age = 3; repeated string interests = 4; // Nested messages can be added optional Address address = 5; }","title":"Versioning and Evolution"},{"location":"tools/protobuf/#performance-considerations","text":"// Use appropriate field types for your data message Metrics { // Use packed repeated for primitive arrays repeated int32 values = 1 [packed = true]; // Consider fixed types for known-size data fixed64 timestamp_nanos = 2; // Better than int64 for large numbers // Use bytes for binary data bytes thumbnail = 3; // Not string for binary data // Consider string vs bytes for text string utf8_text = 4; // For valid UTF-8 bytes raw_text = 5; // For potentially invalid UTF-8 }","title":"Performance Considerations"},{"location":"tools/protobuf/#common-patterns","text":"","title":"Common Patterns"},{"location":"tools/protobuf/#requestresponse-patterns","text":"// Standard CRUD operations service UserService { rpc CreateUser(CreateUserRequest) returns (CreateUserResponse); rpc GetUser(GetUserRequest) returns (GetUserResponse); rpc UpdateUser(UpdateUserRequest) returns (UpdateUserResponse); rpc DeleteUser(DeleteUserRequest) returns (DeleteUserResponse); rpc ListUsers(ListUsersRequest) returns (ListUsersResponse); } message CreateUserRequest { User user = 1; } message CreateUserResponse { User user = 1; string message = 2; } message GetUserRequest { string user_id = 1; } message GetUserResponse { User user = 1; } // Pagination pattern message ListUsersRequest { int32 page_size = 1; string page_token = 2; string filter = 3; } message ListUsersResponse { repeated User users = 1; string next_page_token = 2; int32 total_count = 3; }","title":"Request/Response Patterns"},{"location":"tools/protobuf/#error-handling","text":"import \"google/rpc/status.proto\"; import \"google/protobuf/any.proto\"; message ErrorResponse { google.rpc.Status status = 1; // Standard error status string message = 2; // Human-readable message repeated google.protobuf.Any details = 3; // Additional error details } // Custom error details message ValidationError { repeated FieldError field_errors = 1; } message FieldError { string field = 1; string message = 2; string code = 3; }","title":"Error Handling"},{"location":"tools/protobuf/#gotchas-and-common-mistakes","text":"","title":"Gotchas and Common Mistakes"},{"location":"tools/protobuf/#field-number-management","text":"// DON'T: Reuse field numbers message User { string name = 1; // string old_email = 2; // Removed field string email = 2; // DON'T reuse number 2 } // DO: Reserve removed field numbers message User { reserved 2; // or: reserved \"old_email\"; string name = 1; string email = 3; // Use new number }","title":"Field Number Management"},{"location":"tools/protobuf/#default-values-and-presence","text":"// Proto3: Cannot distinguish between default value and not set message User { int32 age = 1; // age=0 could mean \"not set\" or actually 0 } // Solution: Use optional or wrapper types import \"google/protobuf/wrappers.proto\"; message User { optional int32 age = 1; // Can detect presence // or google.protobuf.Int32Value age_wrapper = 2; }","title":"Default Values and Presence"},{"location":"tools/protobuf/#package-and-import-issues","text":"// File: protos/user.proto syntax = \"proto3\"; package myapp.user; // Use consistent package naming import \"protos/common.proto\"; // Use relative paths consistently // File: protos/common.proto syntax = \"proto3\"; package myapp.common; // Must match directory structure","title":"Package and Import Issues"},{"location":"tools/protobuf/#compilation-ordering","text":"# Wrong: May fail if dependencies aren't found protoc --python_out=. user.proto # Right: Include all necessary import paths protoc -I. -I./vendor -I./third_party --python_out=. user.proto","title":"Compilation Ordering"},{"location":"tools/protobuf/#quick-reference","text":"","title":"Quick Reference"},{"location":"tools/protobuf/#essential-protoc-flags","text":"Flag Purpose Example --version Show protoc version protoc --version -I, --proto_path Add import directory protoc -I./protos --python_out Generate Python code --python_out=./gen --go_out Generate Go code --go_out=. --java_out Generate Java code --java_out=./src --cpp_out Generate C++ code --cpp_out=./gen --descriptor_set_out Generate descriptor --descriptor_set_out=desc.pb --include_imports Include dependencies in descriptor Use with --descriptor_set_out","title":"Essential protoc Flags"},{"location":"tools/protobuf/#scalar-type-mapping","text":"Proto Type Go Python Java C++ JavaScript double float64 float double double number float float32 float float float number int32 int32 int int int32 number int64 int64 int long int64 string string string str String string string bool bool bool boolean bool boolean bytes []byte bytes ByteString string Uint8Array Protocol Buffers provide efficient, language-agnostic data serialization with strong schema evolution capabilities. Focus on clear field naming, proper type selection, and maintaining backward compatibility for production systems.","title":"Scalar Type Mapping"},{"location":"tools/ripgrep/","text":"Ripgrep (rg) ripgrep is a line-oriented search tool that recursively searches the current directory for a regex pattern. It's written in Rust and is significantly faster than grep, ag, and other alternatives while respecting .gitignore rules by default. Quick Start Installation # macOS (Homebrew) brew install ripgrep # Ubuntu/Debian sudo apt-get install ripgrep # Fedora sudo dnf install ripgrep # Arch Linux sudo pacman -S ripgrep # Windows (Chocolatey) choco install ripgrep # Windows (Scoop) scoop install ripgrep # From source (requires Rust) cargo install ripgrep Basic Syntax rg <pattern> [path] # Search for pattern in current directory rg \"hello world\" # Search for exact phrase rg hello README.md # Search in specific file rg hello /path/to/directory # Search in specific directory Core Concepts Default Behavior Recursive : Searches all subdirectories by default Gitignore-aware : Respects .gitignore , .ignore , and .rgignore files Binary file filtering : Skips binary files automatically Hidden file filtering : Ignores hidden files and directories Unicode support : Full Unicode support with proper handling Disable Automatic Filtering rg -uuu pattern # Disable all filtering (gitignore, hidden, binary) rg -u pattern # Disable gitignore filtering rg -uu pattern # Also search hidden files rg --no-ignore pattern # Disable gitignore filtering rg --hidden pattern # Search hidden files rg -a pattern # Search binary files as text Common Search Patterns Basic Patterns rg \"exact phrase\" # Exact phrase search rg word # Single word search rg -i case # Case-insensitive search rg -S smart # Smart case (case-insensitive unless pattern has uppercase) rg -w function # Word boundary search rg -F \"literal.string\" # Fixed string (no regex) Regular Expressions rg \"func.*main\" # Any characters between func and main rg \"^import\" # Lines starting with import rg \"error$\" # Lines ending with error rg \"\\d{3}-\\d{4}\" # Phone number pattern (XXX-XXXX) rg \"TODO|FIXME|BUG\" # Multiple patterns (OR) rg \"\\w+@\\w+\\.\\w+\" # Basic email pattern Advanced Regex Features # Use PCRE2 engine for advanced features rg -P \"(?<=func\\s)\\w+\" # Positive lookbehind rg -P \"(\\w+)\\1\" # Backreferences rg -P \"\\b\\w+(?=\\s+error)\" # Positive lookahead # Multiline patterns rg -U \"function.*\\{.*\\}\" # Multiline function pattern rg -U \"struct.*\\{[^}]*field\" # Struct with specific field File Filtering and Type Selection File Types # List all available file types rg --type-list # Search specific file types rg pattern -tpy # Python files only rg pattern -tjs # JavaScript files only rg pattern -trust # Rust files only rg pattern -tc # C files only # Exclude file types rg pattern -Trust # Exclude Rust files rg pattern -Tjs # Exclude JavaScript files rg pattern --type-not rust # Alternative syntax Glob Patterns # Include files matching pattern rg pattern -g \"*.toml\" # TOML files only rg pattern -g \"*.{py,pyx}\" # Python files rg pattern -g \"test_*.py\" # Test files # Exclude files matching pattern rg pattern -g \"!*.min.js\" # Exclude minified JS rg pattern -g \"!node_modules/*\" # Exclude node_modules rg pattern -g \"!*.log\" # Exclude log files # Multiple glob patterns rg pattern -g \"*.rs\" -g \"!target/*\" # Rust files, exclude target directory Custom File Types # Define custom file type rg pattern --type-add 'web:*.{html,css,js}' -tweb # Make persistent with alias alias rg=\"rg --type-add 'web:*.{html,css,js}'\" # Using configuration file echo \"--type-add=web:*.{html,css,js}\" >> ~/.config/ripgrep/rc export RIPGREP_CONFIG_PATH=\"$HOME/.config/ripgrep/rc\" Output Formatting and Options Basic Output Control rg pattern -n # Show line numbers (default) rg pattern -N # Don't show line numbers rg pattern -H # Show file names (default when multiple files) rg pattern --no-filename # Don't show file names rg pattern -c # Count matching lines only rg pattern --count-matches # Count individual matches Context and Surrounding Lines rg pattern -A 3 # Show 3 lines after match rg pattern -B 2 # Show 2 lines before match rg pattern -C 2 # Show 2 lines before and after rg pattern --context 2 # Alternative syntax for -C Output Modes rg pattern -l # List files with matches only rg pattern --files-with-matches # Alternative syntax rg pattern --files-without-match # List files without matches rg pattern -o # Show only matching parts rg pattern --only-matching # Alternative syntax rg pattern -v # Show non-matching lines (invert match) Column and Statistics rg pattern --column # Show column numbers rg pattern --stats # Show search statistics rg pattern --debug # Show debug information rg pattern --trace # Show trace information Text Replacement and Substitution Basic Replacement # Show what replacements would look like (no file modification) rg \"fast\" -r \"FAST\" README.md # Replace fast with FAST rg \"fast\" --replace \"FAST\" # Alternative syntax Capture Groups # Using numbered capture groups rg \"fast\\s+(\\w+)\" -r \"fast-$1\" # fast word -> fast-word # Using named capture groups rg \"fast\\s+(?P<word>\\w+)\" -r \"fast-$word\" Whole Line Replacement rg \"^.*error.*$\" -r \"ERROR LINE\" # Replace entire lines containing error File Modification (with external tools) # GNU sed (Linux) rg foo -l | xargs sed -i 's/foo/bar/g' # BSD sed (macOS) rg foo -l | xargs sed -i '' 's/foo/bar/g' # Handle filenames with spaces rg foo -l -0 | xargs -0 sed -i 's/foo/bar/g' Color and Visual Customization Color Control rg pattern --color never # Disable colors rg pattern --color always # Force colors rg pattern --color auto # Automatic (default) rg pattern --color ansi # Use ANSI colors only Custom Colors # Individual color settings rg pattern --colors 'match:fg:red' rg pattern --colors 'path:fg:green' rg pattern --colors 'line:fg:yellow' rg pattern --colors 'column:fg:blue' # Multiple color settings rg pattern \\ --colors 'match:fg:white' \\ --colors 'match:bg:blue' \\ --colors 'match:style:bold' # RGB colors rg pattern --colors 'match:fg:255,0,0' # Bright red rg pattern --colors 'match:bg:0x33,0x66,0xFF' # Hex colors # Clear default styles first (recommended) rg pattern \\ --colors 'match:none' \\ --colors 'match:fg:blue' Configuration File for Colors # ~/.config/ripgrep/rc --colors=line:fg:yellow --colors=line:style:bold --colors=path:fg:green --colors=path:style:bold --colors=match:fg:black --colors=match:bg:yellow --colors=match:style:nobold # Use configuration export RIPGREP_CONFIG_PATH=\"$HOME/.config/ripgrep/rc\" Performance Tips and Best Practices Speed Optimization # Use fixed strings when possible (faster than regex) rg -F \"exact string\" # Much faster for literal searches # Limit search scope rg pattern src/ # Search specific directory rg pattern -trs # Limit to Rust files # Use word boundaries for whole words rg -w function # Faster than \"\\\\bfunction\\\\b\" # Smart case by default rg -S pattern # Case insensitive unless uppercase in pattern Memory and Resource Control # Limit line length to prevent huge output rg pattern --max-columns 150 rg pattern --max-columns-preview # Show preview of long lines # Limit file size to search rg pattern --max-filesize 1M # Skip files larger than 1MB # Control number of threads rg pattern -j 4 # Use 4 threads rg pattern --threads 1 # Single-threaded # Memory mapping control rg pattern --mmap # Force memory mapping rg pattern --no-mmap # Disable memory mapping Large File and Binary Handling # Search compressed files rg pattern -z # Search gzip, bzip2, xz, lzma, lz4, brotli, zstd # Handle encoding rg pattern --encoding utf8 # Force UTF-8 rg pattern --encoding none # No encoding (binary search) # Binary file handling rg pattern -a # Search binary files as text rg pattern --binary # Show binary matches Advanced Features Preprocessing # Use preprocessor for special file types (e.g., PDFs) rg pattern --pre ./preprocess.sh # Conditional preprocessing with glob rg pattern --pre ./preprocess.sh --pre-glob '*.pdf' Example preprocessor script: #!/bin/sh # preprocess.sh case \"$1\" in *.pdf) if [ -s \"$1\" ]; then exec pdftotext \"$1\" - else exec cat fi ;; *) exec cat ;; esac Regular Expression Engine Control # Default engine (fast, limited features) rg pattern # Default Rust regex engine # PCRE2 engine (slower, more features) rg -P pattern # Enable lookarounds, backreferences rg -P --no-pcre2-unicode pattern # Disable Unicode for speed # Engine size limits rg pattern --regex-size-limit 1G # Increase regex compilation size rg pattern --dfa-size-limit 1G # Increase DFA cache size Multiline Search rg -U \"function.*{.*return.*}\" # Search across line boundaries rg -U --multiline-dotall \"start.*end\" # . matches newlines too Integration with Other Tools Shell Integration # Generate shell completions rg --generate complete-bash > ~/.local/share/bash-completion/completions/rg rg --generate complete-zsh > ~/.zsh/completions/_rg rg --generate complete-fish > ~/.config/fish/completions/rg.fish # Generate man page rg --generate man | man -l - Editor Integration # Vim/Neovim grepprg set grepprg=rg\\ --vimgrep\\ --no-heading\\ --smart-case # VS Code search with ripgrep \"search.useRipgrep\": true # Emacs (setq counsel-rg-base-command \"rg -i -M 120 --no-heading --line-number --color never %s\") Pipeline Usage # Find and process files rg -l \"TODO\" | head -5 # First 5 files with TODO rg -l \"pattern\" | wc -l # Count files with pattern rg -c \"error\" | sort -t: -k2 -nr # Sort by match count # Combining with other tools rg \"class.*:\" --only-matching | sort | uniq -c # Count class definitions rg \"import.*from\" -o | awk '{print $3}' | sort | uniq # List import sources Common Command Combinations Development Workflow # Find TODOs and FIXMEs in code rg \"(TODO|FIXME|BUG|HACK|XXX)\" -n # Search for functions/methods rg \"(def|function|fn)\\s+\\w+\" -tpy -tjs -trust # Find unused imports (basic) rg \"^import.*\" --only-matching | sort | uniq -c | awk '$1==1' # Search for potential security issues rg -i \"(password|secret|key|token).*=\" -tpy -tjs # Find large functions (rough estimate) rg -U \"^(def|function|fn).*\\{\" -A 50 | rg -c \"^}\" | awk -F: '$2>30' System Administration # Search log files rg \"ERROR|FATAL\" /var/log/ -tlog # Find configuration issues rg -i \"(error|fail|exception)\" /etc/ -g \"*.conf\" -g \"*.cfg\" # Process and network searches rg \":80\\b\" /etc/ -n # Find port 80 references rg \"127\\.0\\.0\\.1\" /etc/ -n # Find localhost references Data Analysis # Count occurrences rg \"pattern\" -c | awk -F: '{sum+=$2} END {print sum}' # Extract structured data rg \"\\b\\d{4}-\\d{2}-\\d{2}\\b\" -o # Extract dates rg \"\\b[\\w.-]+@[\\w.-]+\\.\\w+\\b\" -o # Extract emails rg \"\\b(?:[0-9]{1,3}\\.){3}[0-9]{1,3}\\b\" -o # Extract IP addresses Troubleshooting and Gotchas Common Issues # Pattern not found due to gitignore rg pattern --no-ignore # Disable gitignore rules # Searching binary files rg pattern -a # Force text mode # Too many matches rg pattern --max-count 10 # Limit matches per file # Permission denied errors rg pattern 2>/dev/null # Suppress error messages Performance Issues # Slow searches in large repositories rg pattern --max-filesize 1M # Skip large files rg pattern -j 1 # Use single thread rg pattern --no-mmap # Disable memory mapping # Memory issues with large files rg pattern --max-columns 100 # Limit line length rg pattern --multiline-dotall false # Disable multiline optimizations Platform-Specific Issues # Windows path issues (Cygwin) MSYS_NO_PATHCONV=1 rg \"/pattern\" # PowerShell encoding issues $OutputEncoding = [System.Text.UTF8Encoding]::new() Configuration Files Global Configuration Create ~/.config/ripgrep/rc : # Default options --smart-case --hidden --max-columns=150 --max-columns-preview # Custom file types --type-add=web:*.{html,css,js,jsx,ts,tsx} --type-add=config:*.{json,yaml,yml,toml,ini} # Color settings --colors=line:fg:yellow --colors=path:fg:green --colors=match:bg:blue --colors=match:fg:white # Exclusions --glob=!.git/* --glob=!node_modules/* --glob=!target/* Set environment variable: export RIPGREP_CONFIG_PATH=\"$HOME/.config/ripgrep/rc\" Project-specific Configuration Create .rgignore in project root: # Ignore build artifacts target/ build/ dist/ # Ignore dependencies node_modules/ vendor/ # Ignore logs *.log logs/ Quick Reference Most Useful Flags Flag Purpose -i Case insensitive -S Smart case -w Word boundaries -F Fixed strings (literal) -v Invert match -c Count matches -l List files with matches -n Line numbers -A/B/C Context lines -t<type> File type filter -g Glob pattern --hidden Search hidden files --no-ignore Ignore .gitignore -u/-uu/-uuu Reduce filtering Essential Patterns Pattern Matches \\b\\w+\\b Whole words ^\\s*$ Empty lines \\d+ Numbers [A-Z_]+ Constants https?://\\S+ URLs \\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z\\|a-z]{2,}\\b Emails This cheat sheet covers the most important ripgrep features and usage patterns. For exhaustive documentation, use rg --help or generate the man page with rg --generate man .","title":"Ripgrep (rg)"},{"location":"tools/ripgrep/#ripgrep-rg","text":"ripgrep is a line-oriented search tool that recursively searches the current directory for a regex pattern. It's written in Rust and is significantly faster than grep, ag, and other alternatives while respecting .gitignore rules by default.","title":"Ripgrep (rg)"},{"location":"tools/ripgrep/#quick-start","text":"","title":"Quick Start"},{"location":"tools/ripgrep/#installation","text":"# macOS (Homebrew) brew install ripgrep # Ubuntu/Debian sudo apt-get install ripgrep # Fedora sudo dnf install ripgrep # Arch Linux sudo pacman -S ripgrep # Windows (Chocolatey) choco install ripgrep # Windows (Scoop) scoop install ripgrep # From source (requires Rust) cargo install ripgrep","title":"Installation"},{"location":"tools/ripgrep/#basic-syntax","text":"rg <pattern> [path] # Search for pattern in current directory rg \"hello world\" # Search for exact phrase rg hello README.md # Search in specific file rg hello /path/to/directory # Search in specific directory","title":"Basic Syntax"},{"location":"tools/ripgrep/#core-concepts","text":"","title":"Core Concepts"},{"location":"tools/ripgrep/#default-behavior","text":"Recursive : Searches all subdirectories by default Gitignore-aware : Respects .gitignore , .ignore , and .rgignore files Binary file filtering : Skips binary files automatically Hidden file filtering : Ignores hidden files and directories Unicode support : Full Unicode support with proper handling","title":"Default Behavior"},{"location":"tools/ripgrep/#disable-automatic-filtering","text":"rg -uuu pattern # Disable all filtering (gitignore, hidden, binary) rg -u pattern # Disable gitignore filtering rg -uu pattern # Also search hidden files rg --no-ignore pattern # Disable gitignore filtering rg --hidden pattern # Search hidden files rg -a pattern # Search binary files as text","title":"Disable Automatic Filtering"},{"location":"tools/ripgrep/#common-search-patterns","text":"","title":"Common Search Patterns"},{"location":"tools/ripgrep/#basic-patterns","text":"rg \"exact phrase\" # Exact phrase search rg word # Single word search rg -i case # Case-insensitive search rg -S smart # Smart case (case-insensitive unless pattern has uppercase) rg -w function # Word boundary search rg -F \"literal.string\" # Fixed string (no regex)","title":"Basic Patterns"},{"location":"tools/ripgrep/#regular-expressions","text":"rg \"func.*main\" # Any characters between func and main rg \"^import\" # Lines starting with import rg \"error$\" # Lines ending with error rg \"\\d{3}-\\d{4}\" # Phone number pattern (XXX-XXXX) rg \"TODO|FIXME|BUG\" # Multiple patterns (OR) rg \"\\w+@\\w+\\.\\w+\" # Basic email pattern","title":"Regular Expressions"},{"location":"tools/ripgrep/#advanced-regex-features","text":"# Use PCRE2 engine for advanced features rg -P \"(?<=func\\s)\\w+\" # Positive lookbehind rg -P \"(\\w+)\\1\" # Backreferences rg -P \"\\b\\w+(?=\\s+error)\" # Positive lookahead # Multiline patterns rg -U \"function.*\\{.*\\}\" # Multiline function pattern rg -U \"struct.*\\{[^}]*field\" # Struct with specific field","title":"Advanced Regex Features"},{"location":"tools/ripgrep/#file-filtering-and-type-selection","text":"","title":"File Filtering and Type Selection"},{"location":"tools/ripgrep/#file-types","text":"# List all available file types rg --type-list # Search specific file types rg pattern -tpy # Python files only rg pattern -tjs # JavaScript files only rg pattern -trust # Rust files only rg pattern -tc # C files only # Exclude file types rg pattern -Trust # Exclude Rust files rg pattern -Tjs # Exclude JavaScript files rg pattern --type-not rust # Alternative syntax","title":"File Types"},{"location":"tools/ripgrep/#glob-patterns","text":"# Include files matching pattern rg pattern -g \"*.toml\" # TOML files only rg pattern -g \"*.{py,pyx}\" # Python files rg pattern -g \"test_*.py\" # Test files # Exclude files matching pattern rg pattern -g \"!*.min.js\" # Exclude minified JS rg pattern -g \"!node_modules/*\" # Exclude node_modules rg pattern -g \"!*.log\" # Exclude log files # Multiple glob patterns rg pattern -g \"*.rs\" -g \"!target/*\" # Rust files, exclude target directory","title":"Glob Patterns"},{"location":"tools/ripgrep/#custom-file-types","text":"# Define custom file type rg pattern --type-add 'web:*.{html,css,js}' -tweb # Make persistent with alias alias rg=\"rg --type-add 'web:*.{html,css,js}'\" # Using configuration file echo \"--type-add=web:*.{html,css,js}\" >> ~/.config/ripgrep/rc export RIPGREP_CONFIG_PATH=\"$HOME/.config/ripgrep/rc\"","title":"Custom File Types"},{"location":"tools/ripgrep/#output-formatting-and-options","text":"","title":"Output Formatting and Options"},{"location":"tools/ripgrep/#basic-output-control","text":"rg pattern -n # Show line numbers (default) rg pattern -N # Don't show line numbers rg pattern -H # Show file names (default when multiple files) rg pattern --no-filename # Don't show file names rg pattern -c # Count matching lines only rg pattern --count-matches # Count individual matches","title":"Basic Output Control"},{"location":"tools/ripgrep/#context-and-surrounding-lines","text":"rg pattern -A 3 # Show 3 lines after match rg pattern -B 2 # Show 2 lines before match rg pattern -C 2 # Show 2 lines before and after rg pattern --context 2 # Alternative syntax for -C","title":"Context and Surrounding Lines"},{"location":"tools/ripgrep/#output-modes","text":"rg pattern -l # List files with matches only rg pattern --files-with-matches # Alternative syntax rg pattern --files-without-match # List files without matches rg pattern -o # Show only matching parts rg pattern --only-matching # Alternative syntax rg pattern -v # Show non-matching lines (invert match)","title":"Output Modes"},{"location":"tools/ripgrep/#column-and-statistics","text":"rg pattern --column # Show column numbers rg pattern --stats # Show search statistics rg pattern --debug # Show debug information rg pattern --trace # Show trace information","title":"Column and Statistics"},{"location":"tools/ripgrep/#text-replacement-and-substitution","text":"","title":"Text Replacement and Substitution"},{"location":"tools/ripgrep/#basic-replacement","text":"# Show what replacements would look like (no file modification) rg \"fast\" -r \"FAST\" README.md # Replace fast with FAST rg \"fast\" --replace \"FAST\" # Alternative syntax","title":"Basic Replacement"},{"location":"tools/ripgrep/#capture-groups","text":"# Using numbered capture groups rg \"fast\\s+(\\w+)\" -r \"fast-$1\" # fast word -> fast-word # Using named capture groups rg \"fast\\s+(?P<word>\\w+)\" -r \"fast-$word\"","title":"Capture Groups"},{"location":"tools/ripgrep/#whole-line-replacement","text":"rg \"^.*error.*$\" -r \"ERROR LINE\" # Replace entire lines containing error","title":"Whole Line Replacement"},{"location":"tools/ripgrep/#file-modification-with-external-tools","text":"# GNU sed (Linux) rg foo -l | xargs sed -i 's/foo/bar/g' # BSD sed (macOS) rg foo -l | xargs sed -i '' 's/foo/bar/g' # Handle filenames with spaces rg foo -l -0 | xargs -0 sed -i 's/foo/bar/g'","title":"File Modification (with external tools)"},{"location":"tools/ripgrep/#color-and-visual-customization","text":"","title":"Color and Visual Customization"},{"location":"tools/ripgrep/#color-control","text":"rg pattern --color never # Disable colors rg pattern --color always # Force colors rg pattern --color auto # Automatic (default) rg pattern --color ansi # Use ANSI colors only","title":"Color Control"},{"location":"tools/ripgrep/#custom-colors","text":"# Individual color settings rg pattern --colors 'match:fg:red' rg pattern --colors 'path:fg:green' rg pattern --colors 'line:fg:yellow' rg pattern --colors 'column:fg:blue' # Multiple color settings rg pattern \\ --colors 'match:fg:white' \\ --colors 'match:bg:blue' \\ --colors 'match:style:bold' # RGB colors rg pattern --colors 'match:fg:255,0,0' # Bright red rg pattern --colors 'match:bg:0x33,0x66,0xFF' # Hex colors # Clear default styles first (recommended) rg pattern \\ --colors 'match:none' \\ --colors 'match:fg:blue'","title":"Custom Colors"},{"location":"tools/ripgrep/#configuration-file-for-colors","text":"# ~/.config/ripgrep/rc --colors=line:fg:yellow --colors=line:style:bold --colors=path:fg:green --colors=path:style:bold --colors=match:fg:black --colors=match:bg:yellow --colors=match:style:nobold # Use configuration export RIPGREP_CONFIG_PATH=\"$HOME/.config/ripgrep/rc\"","title":"Configuration File for Colors"},{"location":"tools/ripgrep/#performance-tips-and-best-practices","text":"","title":"Performance Tips and Best Practices"},{"location":"tools/ripgrep/#speed-optimization","text":"# Use fixed strings when possible (faster than regex) rg -F \"exact string\" # Much faster for literal searches # Limit search scope rg pattern src/ # Search specific directory rg pattern -trs # Limit to Rust files # Use word boundaries for whole words rg -w function # Faster than \"\\\\bfunction\\\\b\" # Smart case by default rg -S pattern # Case insensitive unless uppercase in pattern","title":"Speed Optimization"},{"location":"tools/ripgrep/#memory-and-resource-control","text":"# Limit line length to prevent huge output rg pattern --max-columns 150 rg pattern --max-columns-preview # Show preview of long lines # Limit file size to search rg pattern --max-filesize 1M # Skip files larger than 1MB # Control number of threads rg pattern -j 4 # Use 4 threads rg pattern --threads 1 # Single-threaded # Memory mapping control rg pattern --mmap # Force memory mapping rg pattern --no-mmap # Disable memory mapping","title":"Memory and Resource Control"},{"location":"tools/ripgrep/#large-file-and-binary-handling","text":"# Search compressed files rg pattern -z # Search gzip, bzip2, xz, lzma, lz4, brotli, zstd # Handle encoding rg pattern --encoding utf8 # Force UTF-8 rg pattern --encoding none # No encoding (binary search) # Binary file handling rg pattern -a # Search binary files as text rg pattern --binary # Show binary matches","title":"Large File and Binary Handling"},{"location":"tools/ripgrep/#advanced-features","text":"","title":"Advanced Features"},{"location":"tools/ripgrep/#preprocessing","text":"# Use preprocessor for special file types (e.g., PDFs) rg pattern --pre ./preprocess.sh # Conditional preprocessing with glob rg pattern --pre ./preprocess.sh --pre-glob '*.pdf'","title":"Preprocessing"},{"location":"tools/ripgrep/#example-preprocessor-script","text":"#!/bin/sh # preprocess.sh case \"$1\" in *.pdf) if [ -s \"$1\" ]; then exec pdftotext \"$1\" - else exec cat fi ;; *) exec cat ;; esac","title":"Example preprocessor script:"},{"location":"tools/ripgrep/#regular-expression-engine-control","text":"# Default engine (fast, limited features) rg pattern # Default Rust regex engine # PCRE2 engine (slower, more features) rg -P pattern # Enable lookarounds, backreferences rg -P --no-pcre2-unicode pattern # Disable Unicode for speed # Engine size limits rg pattern --regex-size-limit 1G # Increase regex compilation size rg pattern --dfa-size-limit 1G # Increase DFA cache size","title":"Regular Expression Engine Control"},{"location":"tools/ripgrep/#multiline-search","text":"rg -U \"function.*{.*return.*}\" # Search across line boundaries rg -U --multiline-dotall \"start.*end\" # . matches newlines too","title":"Multiline Search"},{"location":"tools/ripgrep/#integration-with-other-tools","text":"","title":"Integration with Other Tools"},{"location":"tools/ripgrep/#shell-integration","text":"# Generate shell completions rg --generate complete-bash > ~/.local/share/bash-completion/completions/rg rg --generate complete-zsh > ~/.zsh/completions/_rg rg --generate complete-fish > ~/.config/fish/completions/rg.fish # Generate man page rg --generate man | man -l -","title":"Shell Integration"},{"location":"tools/ripgrep/#editor-integration","text":"# Vim/Neovim grepprg set grepprg=rg\\ --vimgrep\\ --no-heading\\ --smart-case # VS Code search with ripgrep \"search.useRipgrep\": true # Emacs (setq counsel-rg-base-command \"rg -i -M 120 --no-heading --line-number --color never %s\")","title":"Editor Integration"},{"location":"tools/ripgrep/#pipeline-usage","text":"# Find and process files rg -l \"TODO\" | head -5 # First 5 files with TODO rg -l \"pattern\" | wc -l # Count files with pattern rg -c \"error\" | sort -t: -k2 -nr # Sort by match count # Combining with other tools rg \"class.*:\" --only-matching | sort | uniq -c # Count class definitions rg \"import.*from\" -o | awk '{print $3}' | sort | uniq # List import sources","title":"Pipeline Usage"},{"location":"tools/ripgrep/#common-command-combinations","text":"","title":"Common Command Combinations"},{"location":"tools/ripgrep/#development-workflow","text":"# Find TODOs and FIXMEs in code rg \"(TODO|FIXME|BUG|HACK|XXX)\" -n # Search for functions/methods rg \"(def|function|fn)\\s+\\w+\" -tpy -tjs -trust # Find unused imports (basic) rg \"^import.*\" --only-matching | sort | uniq -c | awk '$1==1' # Search for potential security issues rg -i \"(password|secret|key|token).*=\" -tpy -tjs # Find large functions (rough estimate) rg -U \"^(def|function|fn).*\\{\" -A 50 | rg -c \"^}\" | awk -F: '$2>30'","title":"Development Workflow"},{"location":"tools/ripgrep/#system-administration","text":"# Search log files rg \"ERROR|FATAL\" /var/log/ -tlog # Find configuration issues rg -i \"(error|fail|exception)\" /etc/ -g \"*.conf\" -g \"*.cfg\" # Process and network searches rg \":80\\b\" /etc/ -n # Find port 80 references rg \"127\\.0\\.0\\.1\" /etc/ -n # Find localhost references","title":"System Administration"},{"location":"tools/ripgrep/#data-analysis","text":"# Count occurrences rg \"pattern\" -c | awk -F: '{sum+=$2} END {print sum}' # Extract structured data rg \"\\b\\d{4}-\\d{2}-\\d{2}\\b\" -o # Extract dates rg \"\\b[\\w.-]+@[\\w.-]+\\.\\w+\\b\" -o # Extract emails rg \"\\b(?:[0-9]{1,3}\\.){3}[0-9]{1,3}\\b\" -o # Extract IP addresses","title":"Data Analysis"},{"location":"tools/ripgrep/#troubleshooting-and-gotchas","text":"","title":"Troubleshooting and Gotchas"},{"location":"tools/ripgrep/#common-issues","text":"# Pattern not found due to gitignore rg pattern --no-ignore # Disable gitignore rules # Searching binary files rg pattern -a # Force text mode # Too many matches rg pattern --max-count 10 # Limit matches per file # Permission denied errors rg pattern 2>/dev/null # Suppress error messages","title":"Common Issues"},{"location":"tools/ripgrep/#performance-issues","text":"# Slow searches in large repositories rg pattern --max-filesize 1M # Skip large files rg pattern -j 1 # Use single thread rg pattern --no-mmap # Disable memory mapping # Memory issues with large files rg pattern --max-columns 100 # Limit line length rg pattern --multiline-dotall false # Disable multiline optimizations","title":"Performance Issues"},{"location":"tools/ripgrep/#platform-specific-issues","text":"# Windows path issues (Cygwin) MSYS_NO_PATHCONV=1 rg \"/pattern\" # PowerShell encoding issues $OutputEncoding = [System.Text.UTF8Encoding]::new()","title":"Platform-Specific Issues"},{"location":"tools/ripgrep/#configuration-files","text":"","title":"Configuration Files"},{"location":"tools/ripgrep/#global-configuration","text":"Create ~/.config/ripgrep/rc : # Default options --smart-case --hidden --max-columns=150 --max-columns-preview # Custom file types --type-add=web:*.{html,css,js,jsx,ts,tsx} --type-add=config:*.{json,yaml,yml,toml,ini} # Color settings --colors=line:fg:yellow --colors=path:fg:green --colors=match:bg:blue --colors=match:fg:white # Exclusions --glob=!.git/* --glob=!node_modules/* --glob=!target/* Set environment variable: export RIPGREP_CONFIG_PATH=\"$HOME/.config/ripgrep/rc\"","title":"Global Configuration"},{"location":"tools/ripgrep/#project-specific-configuration","text":"Create .rgignore in project root: # Ignore build artifacts target/ build/ dist/ # Ignore dependencies node_modules/ vendor/ # Ignore logs *.log logs/","title":"Project-specific Configuration"},{"location":"tools/ripgrep/#quick-reference","text":"","title":"Quick Reference"},{"location":"tools/ripgrep/#most-useful-flags","text":"Flag Purpose -i Case insensitive -S Smart case -w Word boundaries -F Fixed strings (literal) -v Invert match -c Count matches -l List files with matches -n Line numbers -A/B/C Context lines -t<type> File type filter -g Glob pattern --hidden Search hidden files --no-ignore Ignore .gitignore -u/-uu/-uuu Reduce filtering","title":"Most Useful Flags"},{"location":"tools/ripgrep/#essential-patterns","text":"Pattern Matches \\b\\w+\\b Whole words ^\\s*$ Empty lines \\d+ Numbers [A-Z_]+ Constants https?://\\S+ URLs \\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z\\|a-z]{2,}\\b Emails This cheat sheet covers the most important ripgrep features and usage patterns. For exhaustive documentation, use rg --help or generate the man page with rg --generate man .","title":"Essential Patterns"},{"location":"tools/vim-lazyvim/","text":"Vim/Neovim with LazyVim A comprehensive reference for Vim/Neovim fundamentals and LazyVim-specific features. This cheat sheet covers essential motions, commands, and LazyVim's modern enhancements for efficient text editing. Quick Start LazyVim Installation # Backup existing config mv ~/.config/nvim ~/.config/nvim.bak mv ~/.local/share/nvim ~/.local/share/nvim.bak # Clone LazyVim starter git clone https://github.com/LazyVim/starter ~/.config/nvim rm -rf ~/.config/nvim/.git # Start Neovim (plugins install automatically) nvim Essential LazyVim Settings -- Disable animations (add to lua/config/options.lua) vim.g.snacks_animate = false -- Disable auto-formatting vim.g.autoformat = false -- Disable lazygit theme sync vim.g.lazygit_config = false -- Use basedpyright for Python (development version) vim.g.lazyvim_python_lsp = \"basedpyright\" Core Vim Concepts Modes Normal Mode : Navigation and text manipulation (default) Insert Mode : Text insertion ( i , I , a , A , o , O ) Visual Mode : Text selection ( v , V , Ctrl-v ) Command Mode : Ex commands ( : ) Mode Transitions Normal \u2192 Insert: i, I, a, A, o, O, s, S, c, C Insert \u2192 Normal: <Esc>, Ctrl-c Normal \u2192 Visual: v, V, Ctrl-v Normal \u2192 Command: :, /, ? Any Mode \u2192 Normal: <Esc> Navigation & Motions Basic Movement Key Action h Left j Down k Up l Right w Next word start W Next WORD start (space-delimited) e Next word end E Next WORD end b Previous word start B Previous WORD start ge Previous word end Line Navigation Key Action 0 Beginning of line ^ First non-blank character $ End of line g_ Last non-blank character gj Down by screen line (wrapped) gk Up by screen line (wrapped) g0 Beginning of screen line g$ End of screen line File Navigation Key Action gg Go to first line G Go to last line {number}G Go to line number :{number} Go to line number H Top of screen M Middle of screen L Bottom of screen Ctrl-u Scroll up half screen Ctrl-d Scroll down half screen Ctrl-b Scroll up full screen Ctrl-f Scroll down full screen Advanced Movement Key Action f{char} Find next character in line F{char} Find previous character in line t{char} Till next character T{char} Till previous character ; Repeat last f/F/t/T , Repeat last f/F/t/T backward * Search word under cursor forward # Search word under cursor backward % Match parentheses/brackets ( Previous sentence ) Next sentence { Previous paragraph } Next paragraph Text Objects & Selection Text Objects Key Action iw Inner word aw A word (with space) is Inner sentence as A sentence ip Inner paragraph ap A paragraph i\" Inside quotes a\" Around quotes i' Inside single quotes a' Around single quotes i( Inside parentheses a( Around parentheses i[ Inside brackets a[ Around brackets i{ Inside braces a{ Around braces it Inside tag at Around tag Visual Mode Key Action v Character-wise visual V Line-wise visual Ctrl-v Block-wise visual o Go to other end of selection gv Reselect last visual area Editing Operations Insert Mode Entry Key Action i Insert before cursor I Insert at beginning of line a Insert after cursor A Insert at end of line o Open line below O Open line above s Substitute character S Substitute line c{motion} Change text C Change to end of line Delete Operations Key Action x Delete character under cursor X Delete character before cursor d{motion} Delete text dd Delete line D Delete to end of line dw Delete word diw Delete inner word d$ Delete to end of line d0 Delete to beginning of line Copy & Paste Key Action y{motion} Yank (copy) text yy Yank line Y Yank to end of line p Put (paste) after cursor P Put before cursor \"{register}y Yank to register \"{register}p Put from register \"0p Put from yank register Undo & Redo Key Action u Undo Ctrl-r Redo U Undo all changes on line . Repeat last change Search & Replace Search Key Action /pattern Search forward ?pattern Search backward n Next match N Previous match * Search word under cursor forward # Search word under cursor backward g* Search partial word forward g# Search partial word backward Replace :s/old/new/ \" Replace first in line :s/old/new/g \" Replace all in line :%s/old/new/g \" Replace all in file :%s/old/new/gc \" Replace all with confirmation :10,20s/old/new/g \" Replace in lines 10-20 LazyVim Key Mappings Leader Key LazyVim uses <Space> as the leader key. Press <Space> to see all available mappings. File Operations Key Action <leader>ff Find files <leader>fg Live grep <leader>fb Find buffers <leader>fh Find help <leader>fr Recent files <leader>fn New file <leader>fe File explorer Buffer Management Key Action <S-h> Previous buffer <S-l> Next buffer [b Previous buffer ]b Next buffer <leader>bd Delete buffer <leader>bD Delete buffer (force) <leader>bb Switch to other buffer Window Management Key Action <Ctrl-w>h Move to left window <Ctrl-w>j Move to bottom window <Ctrl-w>k Move to top window <Ctrl-w>l Move to right window <Ctrl-w>s Split horizontally <Ctrl-w>v Split vertically <Ctrl-w>q Close window <Ctrl-w>= Equalize window sizes <Ctrl-w>_ Maximize height <Ctrl-w>| Maximize width Code Navigation Key Action gd Go to definition gD Go to declaration gi Go to implementation gy Go to type definition gr Go to references K Hover documentation <leader>ca Code actions <leader>rn Rename symbol [d Previous diagnostic ]d Next diagnostic <leader>cd Line diagnostics Git Integration Key Action <leader>gg LazyGit <leader>gb Git blame <leader>gf Git file history <leader>gs Git status ]h Next hunk [h Previous hunk <leader>ghs Stage hunk <leader>ghu Undo hunk <leader>ghp Preview hunk Terminal Key Action <Ctrl-\\> Toggle terminal <leader>ft Terminal (root dir) <leader>fT Terminal (cwd) <Ctrl-/> Terminal (root dir) Search & Navigation Key Action <leader>/ Grep (root dir) <leader>: Command history <leader><space> Find files (root dir) <leader>, Switch buffer <leader>fb Buffers <leader>fc Find config file <leader>ff Find files (root dir) <leader>fF Find files (cwd) <leader>fr Recent <leader>fR Recent (cwd) LazyVim Specific Key Action <leader>l Lazy (plugin manager) <leader>L LazyVim changelog <leader>x LazyVim extras Advanced Features Marks Key Action m{a-z} Set local mark m{A-Z} Set global mark '{mark} Jump to mark line `{mark}` Jump to mark position '' Jump to previous line `` Jump to previous position :marks List marks Registers Key Action \"{a-z} Named registers \"0 Yank register \"1-9 Delete registers \"+ System clipboard \"* Primary selection \"% Current filename \": Last command \"/ Last search \". Last inserted text Macros Key Action q{a-z} Record macro q Stop recording @{a-z} Play macro @@ Repeat last macro {number}@{a-z} Run macro n times Folding Key Action zf{motion} Create fold zd Delete fold zo Open fold zc Close fold za Toggle fold zR Open all folds zM Close all folds zj Move to next fold zk Move to previous fold Command Line & Ex Commands File Operations :w \" Save :w filename \" Save as :q \" Quit :q! \" Quit without saving :wq or :x \" Save and quit :e filename \" Edit file :e! \" Reload file :enew \" New buffer Buffer Management :ls \" List buffers :b {number} \" Switch to buffer :bn \" Next buffer :bp \" Previous buffer :bd \" Delete buffer :bufdo cmd \" Run command on all buffers Window Management :sp filename \" Horizontal split :vs filename \" Vertical split :new \" New horizontal split :vnew \" New vertical split :only \" Close all other windows :resize {n} \" Resize window height :vertical resize {n} \" Resize window width Advanced Commands :set option \" Set option :set option? \" Show option value :set option! \" Toggle option :help topic \" Get help :history \" Command history :changes \" Show change list :jumps \" Show jump list :reg \" Show registers Configuration Tips Essential LazyVim Options -- In lua/config/options.lua vim.opt.relativenumber = true -- Relative line numbers vim.opt.clipboard = \"unnamedplus\" -- System clipboard vim.opt.scrolloff = 8 -- Keep 8 lines visible vim.opt.sidescrolloff = 8 -- Keep 8 columns visible vim.opt.wrap = false -- No line wrapping vim.opt.expandtab = true -- Use spaces instead of tabs vim.opt.shiftwidth = 2 -- Indent width vim.opt.tabstop = 2 -- Tab width vim.opt.ignorecase = true -- Ignore case in search vim.opt.smartcase = true -- Case sensitive if uppercase used Custom Keymaps -- In lua/config/keymaps.lua local map = vim.keymap.set -- Better window navigation map(\"n\", \"<C-h>\", \"<C-w>h\") map(\"n\", \"<C-j>\", \"<C-w>j\") map(\"n\", \"<C-k>\", \"<C-w>k\") map(\"n\", \"<C-l>\", \"<C-w>l\") -- Stay in indent mode map(\"v\", \"<\", \"<gv\") map(\"v\", \">\", \">gv\") -- Move text up and down map(\"v\", \"J\", \":m '>+1<CR>gv=gv\") map(\"v\", \"K\", \":m '<-2<CR>gv=gv\") -- Better paste map(\"v\", \"p\", '\"_dP') Performance Tips Use relative line numbers for efficient jumping Learn text objects for precise editing Master the . command for repetition Use visual mode for complex selections Leverage marks for quick navigation Practice motions to avoid arrow keys Use LazyVim's fuzzy finding instead of file trees Learn LSP shortcuts for code navigation Use multiple cursors with visual block mode Customize based on your workflow Troubleshooting Common Issues # Check LazyVim health :checkhealth # View logs :messages # Profile startup time nvim --startuptime startup.log # Reset LazyVim rm -rf ~/.local/share/nvim rm -rf ~/.local/state/nvim rm -rf ~/.cache/nvim Plugin Management :Lazy \" Open Lazy.nvim :Lazy sync \" Update plugins :Lazy clean \" Remove unused plugins :Lazy profile \" Profile plugin loading This cheat sheet covers the essential Vim motions and LazyVim enhancements. Practice these commands daily to build muscle memory and improve your editing efficiency. Remember that Vim's power comes from combining simple commands into complex operations.","title":"Vim/Neovim with LazyVim"},{"location":"tools/vim-lazyvim/#vimneovim-with-lazyvim","text":"A comprehensive reference for Vim/Neovim fundamentals and LazyVim-specific features. This cheat sheet covers essential motions, commands, and LazyVim's modern enhancements for efficient text editing.","title":"Vim/Neovim with LazyVim"},{"location":"tools/vim-lazyvim/#quick-start","text":"","title":"Quick Start"},{"location":"tools/vim-lazyvim/#lazyvim-installation","text":"# Backup existing config mv ~/.config/nvim ~/.config/nvim.bak mv ~/.local/share/nvim ~/.local/share/nvim.bak # Clone LazyVim starter git clone https://github.com/LazyVim/starter ~/.config/nvim rm -rf ~/.config/nvim/.git # Start Neovim (plugins install automatically) nvim","title":"LazyVim Installation"},{"location":"tools/vim-lazyvim/#essential-lazyvim-settings","text":"-- Disable animations (add to lua/config/options.lua) vim.g.snacks_animate = false -- Disable auto-formatting vim.g.autoformat = false -- Disable lazygit theme sync vim.g.lazygit_config = false -- Use basedpyright for Python (development version) vim.g.lazyvim_python_lsp = \"basedpyright\"","title":"Essential LazyVim Settings"},{"location":"tools/vim-lazyvim/#core-vim-concepts","text":"","title":"Core Vim Concepts"},{"location":"tools/vim-lazyvim/#modes","text":"Normal Mode : Navigation and text manipulation (default) Insert Mode : Text insertion ( i , I , a , A , o , O ) Visual Mode : Text selection ( v , V , Ctrl-v ) Command Mode : Ex commands ( : )","title":"Modes"},{"location":"tools/vim-lazyvim/#mode-transitions","text":"Normal \u2192 Insert: i, I, a, A, o, O, s, S, c, C Insert \u2192 Normal: <Esc>, Ctrl-c Normal \u2192 Visual: v, V, Ctrl-v Normal \u2192 Command: :, /, ? Any Mode \u2192 Normal: <Esc>","title":"Mode Transitions"},{"location":"tools/vim-lazyvim/#navigation-motions","text":"","title":"Navigation &amp; Motions"},{"location":"tools/vim-lazyvim/#basic-movement","text":"Key Action h Left j Down k Up l Right w Next word start W Next WORD start (space-delimited) e Next word end E Next WORD end b Previous word start B Previous WORD start ge Previous word end","title":"Basic Movement"},{"location":"tools/vim-lazyvim/#line-navigation","text":"Key Action 0 Beginning of line ^ First non-blank character $ End of line g_ Last non-blank character gj Down by screen line (wrapped) gk Up by screen line (wrapped) g0 Beginning of screen line g$ End of screen line","title":"Line Navigation"},{"location":"tools/vim-lazyvim/#file-navigation","text":"Key Action gg Go to first line G Go to last line {number}G Go to line number :{number} Go to line number H Top of screen M Middle of screen L Bottom of screen Ctrl-u Scroll up half screen Ctrl-d Scroll down half screen Ctrl-b Scroll up full screen Ctrl-f Scroll down full screen","title":"File Navigation"},{"location":"tools/vim-lazyvim/#advanced-movement","text":"Key Action f{char} Find next character in line F{char} Find previous character in line t{char} Till next character T{char} Till previous character ; Repeat last f/F/t/T , Repeat last f/F/t/T backward * Search word under cursor forward # Search word under cursor backward % Match parentheses/brackets ( Previous sentence ) Next sentence { Previous paragraph } Next paragraph","title":"Advanced Movement"},{"location":"tools/vim-lazyvim/#text-objects-selection","text":"","title":"Text Objects &amp; Selection"},{"location":"tools/vim-lazyvim/#text-objects","text":"Key Action iw Inner word aw A word (with space) is Inner sentence as A sentence ip Inner paragraph ap A paragraph i\" Inside quotes a\" Around quotes i' Inside single quotes a' Around single quotes i( Inside parentheses a( Around parentheses i[ Inside brackets a[ Around brackets i{ Inside braces a{ Around braces it Inside tag at Around tag","title":"Text Objects"},{"location":"tools/vim-lazyvim/#visual-mode","text":"Key Action v Character-wise visual V Line-wise visual Ctrl-v Block-wise visual o Go to other end of selection gv Reselect last visual area","title":"Visual Mode"},{"location":"tools/vim-lazyvim/#editing-operations","text":"","title":"Editing Operations"},{"location":"tools/vim-lazyvim/#insert-mode-entry","text":"Key Action i Insert before cursor I Insert at beginning of line a Insert after cursor A Insert at end of line o Open line below O Open line above s Substitute character S Substitute line c{motion} Change text C Change to end of line","title":"Insert Mode Entry"},{"location":"tools/vim-lazyvim/#delete-operations","text":"Key Action x Delete character under cursor X Delete character before cursor d{motion} Delete text dd Delete line D Delete to end of line dw Delete word diw Delete inner word d$ Delete to end of line d0 Delete to beginning of line","title":"Delete Operations"},{"location":"tools/vim-lazyvim/#copy-paste","text":"Key Action y{motion} Yank (copy) text yy Yank line Y Yank to end of line p Put (paste) after cursor P Put before cursor \"{register}y Yank to register \"{register}p Put from register \"0p Put from yank register","title":"Copy &amp; Paste"},{"location":"tools/vim-lazyvim/#undo-redo","text":"Key Action u Undo Ctrl-r Redo U Undo all changes on line . Repeat last change","title":"Undo &amp; Redo"},{"location":"tools/vim-lazyvim/#search-replace","text":"","title":"Search &amp; Replace"},{"location":"tools/vim-lazyvim/#search","text":"Key Action /pattern Search forward ?pattern Search backward n Next match N Previous match * Search word under cursor forward # Search word under cursor backward g* Search partial word forward g# Search partial word backward","title":"Search"},{"location":"tools/vim-lazyvim/#replace","text":":s/old/new/ \" Replace first in line :s/old/new/g \" Replace all in line :%s/old/new/g \" Replace all in file :%s/old/new/gc \" Replace all with confirmation :10,20s/old/new/g \" Replace in lines 10-20","title":"Replace"},{"location":"tools/vim-lazyvim/#lazyvim-key-mappings","text":"","title":"LazyVim Key Mappings"},{"location":"tools/vim-lazyvim/#leader-key","text":"LazyVim uses <Space> as the leader key. Press <Space> to see all available mappings.","title":"Leader Key"},{"location":"tools/vim-lazyvim/#file-operations","text":"Key Action <leader>ff Find files <leader>fg Live grep <leader>fb Find buffers <leader>fh Find help <leader>fr Recent files <leader>fn New file <leader>fe File explorer","title":"File Operations"},{"location":"tools/vim-lazyvim/#buffer-management","text":"Key Action <S-h> Previous buffer <S-l> Next buffer [b Previous buffer ]b Next buffer <leader>bd Delete buffer <leader>bD Delete buffer (force) <leader>bb Switch to other buffer","title":"Buffer Management"},{"location":"tools/vim-lazyvim/#window-management","text":"Key Action <Ctrl-w>h Move to left window <Ctrl-w>j Move to bottom window <Ctrl-w>k Move to top window <Ctrl-w>l Move to right window <Ctrl-w>s Split horizontally <Ctrl-w>v Split vertically <Ctrl-w>q Close window <Ctrl-w>= Equalize window sizes <Ctrl-w>_ Maximize height <Ctrl-w>| Maximize width","title":"Window Management"},{"location":"tools/vim-lazyvim/#code-navigation","text":"Key Action gd Go to definition gD Go to declaration gi Go to implementation gy Go to type definition gr Go to references K Hover documentation <leader>ca Code actions <leader>rn Rename symbol [d Previous diagnostic ]d Next diagnostic <leader>cd Line diagnostics","title":"Code Navigation"},{"location":"tools/vim-lazyvim/#git-integration","text":"Key Action <leader>gg LazyGit <leader>gb Git blame <leader>gf Git file history <leader>gs Git status ]h Next hunk [h Previous hunk <leader>ghs Stage hunk <leader>ghu Undo hunk <leader>ghp Preview hunk","title":"Git Integration"},{"location":"tools/vim-lazyvim/#terminal","text":"Key Action <Ctrl-\\> Toggle terminal <leader>ft Terminal (root dir) <leader>fT Terminal (cwd) <Ctrl-/> Terminal (root dir)","title":"Terminal"},{"location":"tools/vim-lazyvim/#search-navigation","text":"Key Action <leader>/ Grep (root dir) <leader>: Command history <leader><space> Find files (root dir) <leader>, Switch buffer <leader>fb Buffers <leader>fc Find config file <leader>ff Find files (root dir) <leader>fF Find files (cwd) <leader>fr Recent <leader>fR Recent (cwd)","title":"Search &amp; Navigation"},{"location":"tools/vim-lazyvim/#lazyvim-specific","text":"Key Action <leader>l Lazy (plugin manager) <leader>L LazyVim changelog <leader>x LazyVim extras","title":"LazyVim Specific"},{"location":"tools/vim-lazyvim/#advanced-features","text":"","title":"Advanced Features"},{"location":"tools/vim-lazyvim/#marks","text":"Key Action m{a-z} Set local mark m{A-Z} Set global mark '{mark} Jump to mark line `{mark}` Jump to mark position '' Jump to previous line `` Jump to previous position :marks List marks","title":"Marks"},{"location":"tools/vim-lazyvim/#registers","text":"Key Action \"{a-z} Named registers \"0 Yank register \"1-9 Delete registers \"+ System clipboard \"* Primary selection \"% Current filename \": Last command \"/ Last search \". Last inserted text","title":"Registers"},{"location":"tools/vim-lazyvim/#macros","text":"Key Action q{a-z} Record macro q Stop recording @{a-z} Play macro @@ Repeat last macro {number}@{a-z} Run macro n times","title":"Macros"},{"location":"tools/vim-lazyvim/#folding","text":"Key Action zf{motion} Create fold zd Delete fold zo Open fold zc Close fold za Toggle fold zR Open all folds zM Close all folds zj Move to next fold zk Move to previous fold","title":"Folding"},{"location":"tools/vim-lazyvim/#command-line-ex-commands","text":"","title":"Command Line &amp; Ex Commands"},{"location":"tools/vim-lazyvim/#file-operations_1","text":":w \" Save :w filename \" Save as :q \" Quit :q! \" Quit without saving :wq or :x \" Save and quit :e filename \" Edit file :e! \" Reload file :enew \" New buffer","title":"File Operations"},{"location":"tools/vim-lazyvim/#buffer-management_1","text":":ls \" List buffers :b {number} \" Switch to buffer :bn \" Next buffer :bp \" Previous buffer :bd \" Delete buffer :bufdo cmd \" Run command on all buffers","title":"Buffer Management"},{"location":"tools/vim-lazyvim/#window-management_1","text":":sp filename \" Horizontal split :vs filename \" Vertical split :new \" New horizontal split :vnew \" New vertical split :only \" Close all other windows :resize {n} \" Resize window height :vertical resize {n} \" Resize window width","title":"Window Management"},{"location":"tools/vim-lazyvim/#advanced-commands","text":":set option \" Set option :set option? \" Show option value :set option! \" Toggle option :help topic \" Get help :history \" Command history :changes \" Show change list :jumps \" Show jump list :reg \" Show registers","title":"Advanced Commands"},{"location":"tools/vim-lazyvim/#configuration-tips","text":"","title":"Configuration Tips"},{"location":"tools/vim-lazyvim/#essential-lazyvim-options","text":"-- In lua/config/options.lua vim.opt.relativenumber = true -- Relative line numbers vim.opt.clipboard = \"unnamedplus\" -- System clipboard vim.opt.scrolloff = 8 -- Keep 8 lines visible vim.opt.sidescrolloff = 8 -- Keep 8 columns visible vim.opt.wrap = false -- No line wrapping vim.opt.expandtab = true -- Use spaces instead of tabs vim.opt.shiftwidth = 2 -- Indent width vim.opt.tabstop = 2 -- Tab width vim.opt.ignorecase = true -- Ignore case in search vim.opt.smartcase = true -- Case sensitive if uppercase used","title":"Essential LazyVim Options"},{"location":"tools/vim-lazyvim/#custom-keymaps","text":"-- In lua/config/keymaps.lua local map = vim.keymap.set -- Better window navigation map(\"n\", \"<C-h>\", \"<C-w>h\") map(\"n\", \"<C-j>\", \"<C-w>j\") map(\"n\", \"<C-k>\", \"<C-w>k\") map(\"n\", \"<C-l>\", \"<C-w>l\") -- Stay in indent mode map(\"v\", \"<\", \"<gv\") map(\"v\", \">\", \">gv\") -- Move text up and down map(\"v\", \"J\", \":m '>+1<CR>gv=gv\") map(\"v\", \"K\", \":m '<-2<CR>gv=gv\") -- Better paste map(\"v\", \"p\", '\"_dP')","title":"Custom Keymaps"},{"location":"tools/vim-lazyvim/#performance-tips","text":"Use relative line numbers for efficient jumping Learn text objects for precise editing Master the . command for repetition Use visual mode for complex selections Leverage marks for quick navigation Practice motions to avoid arrow keys Use LazyVim's fuzzy finding instead of file trees Learn LSP shortcuts for code navigation Use multiple cursors with visual block mode Customize based on your workflow","title":"Performance Tips"},{"location":"tools/vim-lazyvim/#troubleshooting","text":"","title":"Troubleshooting"},{"location":"tools/vim-lazyvim/#common-issues","text":"# Check LazyVim health :checkhealth # View logs :messages # Profile startup time nvim --startuptime startup.log # Reset LazyVim rm -rf ~/.local/share/nvim rm -rf ~/.local/state/nvim rm -rf ~/.cache/nvim","title":"Common Issues"},{"location":"tools/vim-lazyvim/#plugin-management","text":":Lazy \" Open Lazy.nvim :Lazy sync \" Update plugins :Lazy clean \" Remove unused plugins :Lazy profile \" Profile plugin loading This cheat sheet covers the essential Vim motions and LazyVim enhancements. Practice these commands daily to build muscle memory and improve your editing efficiency. Remember that Vim's power comes from combining simple commands into complex operations.","title":"Plugin Management"}]}