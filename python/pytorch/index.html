
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
      
        <link rel="prev" href="../python/">
      
      
        <link rel="next" href="../scikit-learn/">
      
      
      <link rel="icon" href="../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.5.3, mkdocs-material-9.5.17">
    
    
      
        <title>PyTorch - Cheat Sheets</title>
      
    
    
      <link rel="stylesheet" href="../../assets/stylesheets/main.bcfcd587.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
    <script>__md_scope=new URL("../..",location),__md_hash=e=>[...e].reduce((e,_)=>(e<<5)-e+_.charCodeAt(0),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    <body dir="ltr">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#pytorch" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../.." title="Cheat Sheets" class="md-header__button md-logo" aria-label="Cheat Sheets" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54Z"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2Z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            Cheat Sheets
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              PyTorch
            
          </span>
        </div>
      </div>
    </div>
    
    
      <script>var media,input,key,value,palette=__md_get("__palette");if(palette&&palette.color){"(prefers-color-scheme)"===palette.color.media&&(media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']"),palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent"));for([key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    



<nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../.." title="Cheat Sheets" class="md-nav__button md-logo" aria-label="Cheat Sheets" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54Z"/></svg>

    </a>
    Cheat Sheets
  </label>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../.." class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Cheat Sheets Collection
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../machine-learning-algorithms/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Machine Learning Algorithms
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3" >
        
          
          <label class="md-nav__link" for="__nav_3" id="__nav_3_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Gpu
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3">
            <span class="md-nav__icon md-icon"></span>
            Gpu
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../gpu/cuda/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    CUDA Programming
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4" >
        
          
          <label class="md-nav__link" for="__nav_4" id="__nav_4_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Javascript
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4">
            <span class="md-nav__icon md-icon"></span>
            Javascript
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../javascript/nextjs/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Next.js
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../javascript/react/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    React
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5" >
        
          
          <label class="md-nav__link" for="__nav_5" id="__nav_5_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Os
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_5_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5">
            <span class="md-nav__icon md-icon"></span>
            Os
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../os/bottlerocket/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Bottlerocket OS Administration
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
    
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_6" checked>
        
          
          <label class="md-nav__link" for="__nav_6" id="__nav_6_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Python
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_6_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_6">
            <span class="md-nav__icon md-icon"></span>
            Python
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../inquirer/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Python Inquirer
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../keras/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Keras
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../langchain/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    LangChain
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../langextract/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    LangExtract
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../matplotlib/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Matplotlib
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../nltk/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    NLTK (Natural Language Toolkit)
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../numpy/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    NumPy
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../pandas/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Pandas
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../pillow/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Pillow (PIL)
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../polars/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Polars
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../python/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Python
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  <span class="md-ellipsis">
    PyTorch
  </span>
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  <span class="md-ellipsis">
    PyTorch
  </span>
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#installation" class="md-nav__link">
    <span class="md-ellipsis">
      Installation
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#import-essentials" class="md-nav__link">
    <span class="md-ellipsis">
      Import Essentials
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#tensor-basics" class="md-nav__link">
    <span class="md-ellipsis">
      Tensor Basics
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Tensor Basics">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#creating-tensors" class="md-nav__link">
    <span class="md-ellipsis">
      Creating Tensors
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tensor-properties" class="md-nav__link">
    <span class="md-ellipsis">
      Tensor Properties
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tensor-operations" class="md-nav__link">
    <span class="md-ellipsis">
      Tensor Operations
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#reshaping-and-indexing" class="md-nav__link">
    <span class="md-ellipsis">
      Reshaping and Indexing
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#device-management" class="md-nav__link">
    <span class="md-ellipsis">
      Device Management
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#neural-networks" class="md-nav__link">
    <span class="md-ellipsis">
      Neural Networks
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Neural Networks">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#basic-neural-network" class="md-nav__link">
    <span class="md-ellipsis">
      Basic Neural Network
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#convolutional-neural-network" class="md-nav__link">
    <span class="md-ellipsis">
      Convolutional Neural Network
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#common-layers" class="md-nav__link">
    <span class="md-ellipsis">
      Common Layers
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#loss-functions" class="md-nav__link">
    <span class="md-ellipsis">
      Loss Functions
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#optimizers" class="md-nav__link">
    <span class="md-ellipsis">
      Optimizers
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#training-loop" class="md-nav__link">
    <span class="md-ellipsis">
      Training Loop
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#evaluation" class="md-nav__link">
    <span class="md-ellipsis">
      Evaluation
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#data-loading" class="md-nav__link">
    <span class="md-ellipsis">
      Data Loading
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Data Loading">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#custom-dataset" class="md-nav__link">
    <span class="md-ellipsis">
      Custom Dataset
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#data-transforms" class="md-nav__link">
    <span class="md-ellipsis">
      Data Transforms
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#model-saving-and-loading" class="md-nav__link">
    <span class="md-ellipsis">
      Model Saving and Loading
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#autograd-and-gradients" class="md-nav__link">
    <span class="md-ellipsis">
      Autograd and Gradients
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#mixed-precision-training" class="md-nav__link">
    <span class="md-ellipsis">
      Mixed Precision Training
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#torchcompile-pytorch-20" class="md-nav__link">
    <span class="md-ellipsis">
      torch.compile (PyTorch 2.0+)
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#model-utilities" class="md-nav__link">
    <span class="md-ellipsis">
      Model Utilities
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Model Utilities">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#parameter-counting" class="md-nav__link">
    <span class="md-ellipsis">
      Parameter Counting
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#model-summary" class="md-nav__link">
    <span class="md-ellipsis">
      Model Summary
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#transfer-learning" class="md-nav__link">
    <span class="md-ellipsis">
      Transfer Learning
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#common-patterns" class="md-nav__link">
    <span class="md-ellipsis">
      Common Patterns
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Common Patterns">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#early-stopping" class="md-nav__link">
    <span class="md-ellipsis">
      Early Stopping
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#gradient-clipping" class="md-nav__link">
    <span class="md-ellipsis">
      Gradient Clipping
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#learning-rate-finding" class="md-nav__link">
    <span class="md-ellipsis">
      Learning Rate Finding
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#debugging-tips" class="md-nav__link">
    <span class="md-ellipsis">
      Debugging Tips
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Debugging Tips">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#check-for-naninf" class="md-nav__link">
    <span class="md-ellipsis">
      Check for NaN/Inf
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#monitor-gradients" class="md-nav__link">
    <span class="md-ellipsis">
      Monitor Gradients
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#memory-usage" class="md-nav__link">
    <span class="md-ellipsis">
      Memory Usage
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#performance-tips" class="md-nav__link">
    <span class="md-ellipsis">
      Performance Tips
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../scikit-learn/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Scikit-learn
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../scipy/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    SciPy
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../seaborn/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Seaborn
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../sentence-transformers/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Sentence-Transformers (UKPLab)
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../tensorflow/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    TensorFlow
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../torchvision/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    TorchVision
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../transformers/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Transformers (Hugging Face)
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_7" >
        
          
          <label class="md-nav__link" for="__nav_7" id="__nav_7_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Tools
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_7_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_7">
            <span class="md-nav__icon md-icon"></span>
            Tools
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../tools/protobuf/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Protocol Buffers (protobuf)
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../tools/ripgrep/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Ripgrep (rg)
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../tools/vim-lazyvim/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Vim/Neovim with LazyVim
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#installation" class="md-nav__link">
    <span class="md-ellipsis">
      Installation
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#import-essentials" class="md-nav__link">
    <span class="md-ellipsis">
      Import Essentials
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#tensor-basics" class="md-nav__link">
    <span class="md-ellipsis">
      Tensor Basics
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Tensor Basics">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#creating-tensors" class="md-nav__link">
    <span class="md-ellipsis">
      Creating Tensors
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tensor-properties" class="md-nav__link">
    <span class="md-ellipsis">
      Tensor Properties
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tensor-operations" class="md-nav__link">
    <span class="md-ellipsis">
      Tensor Operations
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#reshaping-and-indexing" class="md-nav__link">
    <span class="md-ellipsis">
      Reshaping and Indexing
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#device-management" class="md-nav__link">
    <span class="md-ellipsis">
      Device Management
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#neural-networks" class="md-nav__link">
    <span class="md-ellipsis">
      Neural Networks
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Neural Networks">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#basic-neural-network" class="md-nav__link">
    <span class="md-ellipsis">
      Basic Neural Network
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#convolutional-neural-network" class="md-nav__link">
    <span class="md-ellipsis">
      Convolutional Neural Network
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#common-layers" class="md-nav__link">
    <span class="md-ellipsis">
      Common Layers
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#loss-functions" class="md-nav__link">
    <span class="md-ellipsis">
      Loss Functions
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#optimizers" class="md-nav__link">
    <span class="md-ellipsis">
      Optimizers
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#training-loop" class="md-nav__link">
    <span class="md-ellipsis">
      Training Loop
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#evaluation" class="md-nav__link">
    <span class="md-ellipsis">
      Evaluation
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#data-loading" class="md-nav__link">
    <span class="md-ellipsis">
      Data Loading
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Data Loading">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#custom-dataset" class="md-nav__link">
    <span class="md-ellipsis">
      Custom Dataset
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#data-transforms" class="md-nav__link">
    <span class="md-ellipsis">
      Data Transforms
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#model-saving-and-loading" class="md-nav__link">
    <span class="md-ellipsis">
      Model Saving and Loading
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#autograd-and-gradients" class="md-nav__link">
    <span class="md-ellipsis">
      Autograd and Gradients
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#mixed-precision-training" class="md-nav__link">
    <span class="md-ellipsis">
      Mixed Precision Training
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#torchcompile-pytorch-20" class="md-nav__link">
    <span class="md-ellipsis">
      torch.compile (PyTorch 2.0+)
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#model-utilities" class="md-nav__link">
    <span class="md-ellipsis">
      Model Utilities
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Model Utilities">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#parameter-counting" class="md-nav__link">
    <span class="md-ellipsis">
      Parameter Counting
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#model-summary" class="md-nav__link">
    <span class="md-ellipsis">
      Model Summary
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#transfer-learning" class="md-nav__link">
    <span class="md-ellipsis">
      Transfer Learning
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#common-patterns" class="md-nav__link">
    <span class="md-ellipsis">
      Common Patterns
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Common Patterns">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#early-stopping" class="md-nav__link">
    <span class="md-ellipsis">
      Early Stopping
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#gradient-clipping" class="md-nav__link">
    <span class="md-ellipsis">
      Gradient Clipping
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#learning-rate-finding" class="md-nav__link">
    <span class="md-ellipsis">
      Learning Rate Finding
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#debugging-tips" class="md-nav__link">
    <span class="md-ellipsis">
      Debugging Tips
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Debugging Tips">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#check-for-naninf" class="md-nav__link">
    <span class="md-ellipsis">
      Check for NaN/Inf
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#monitor-gradients" class="md-nav__link">
    <span class="md-ellipsis">
      Monitor Gradients
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#memory-usage" class="md-nav__link">
    <span class="md-ellipsis">
      Memory Usage
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#performance-tips" class="md-nav__link">
    <span class="md-ellipsis">
      Performance Tips
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  


<h1 id="pytorch">PyTorch</h1>
<h2 id="installation">Installation</h2>
<pre><code class="language-bash"># CPU only
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu

# CUDA (check https://pytorch.org for your CUDA version)
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121

# AMD ROCm
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/rocm5.6

# Intel GPU (XPU)
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/xpu

# Development version (nightly)
pip install --pre torch torchvision torchaudio --index-url https://download.pytorch.org/whl/nightly/cpu
</code></pre>
<h2 id="import-essentials">Import Essentials</h2>
<pre><code class="language-python">import torch
import torch.nn as nn
import torch.optim as optim
import torch.nn.functional as F
from torch.utils.data import DataLoader, Dataset
import torchvision
import torchvision.transforms as transforms
import numpy as np
</code></pre>
<h2 id="tensor-basics">Tensor Basics</h2>
<h3 id="creating-tensors">Creating Tensors</h3>
<pre><code class="language-python"># From data
x = torch.tensor([1, 2, 3])
x = torch.tensor([[1, 2], [3, 4]], dtype=torch.float32)

# Zeros and ones
x = torch.zeros(3, 4)
x = torch.ones(2, 3)
x = torch.eye(3)  # identity matrix

# Random tensors
x = torch.randn(2, 3)  # normal distribution
x = torch.rand(2, 3)   # uniform [0, 1)
x = torch.randint(0, 10, (2, 3))  # random integers

# From numpy
numpy_array = np.array([1, 2, 3])
x = torch.from_numpy(numpy_array)

# Ranges
x = torch.arange(0, 10, 2)  # [0, 2, 4, 6, 8]
x = torch.linspace(0, 1, 5) # [0, 0.25, 0.5, 0.75, 1.0]
</code></pre>
<h3 id="tensor-properties">Tensor Properties</h3>
<pre><code class="language-python">x = torch.randn(3, 4, 5)

print(x.shape)      # torch.Size([3, 4, 5])
print(x.size())     # torch.Size([3, 4, 5])
print(x.dtype)      # torch.float32
print(x.device)     # cpu or cuda:0
print(x.ndim)       # 3
print(x.numel())    # 60 (total elements)
</code></pre>
<h3 id="tensor-operations">Tensor Operations</h3>
<pre><code class="language-python"># Arithmetic
x = torch.tensor([1, 2, 3])
y = torch.tensor([4, 5, 6])

z = x + y           # or torch.add(x, y)
z = x - y           # or torch.sub(x, y)
z = x * y           # element-wise multiplication
z = x / y           # element-wise division
z = x @ y           # dot product
z = torch.matmul(x, y)  # matrix multiplication

# In-place operations (end with _)
x.add_(1)           # adds 1 to x in-place
x.mul_(2)           # multiplies x by 2 in-place
</code></pre>
<h3 id="reshaping-and-indexing">Reshaping and Indexing</h3>
<pre><code class="language-python">x = torch.randn(4, 4)

# Reshaping
x = x.view(16)      # or x.view(-1)
x = x.view(2, 8)
x = x.reshape(4, 4) # more flexible than view
x = x.squeeze()     # remove dimensions of size 1
x = x.unsqueeze(0)  # add dimension at index 0

# Indexing
x[0, 1]             # element at row 0, col 1
x[:, 1]             # all rows, column 1
x[1, :]             # row 1, all columns
x[0:2, 1:3]         # submatrix

# Advanced indexing
mask = x &gt; 0
x[mask]             # elements where mask is True
</code></pre>
<h3 id="device-management">Device Management</h3>
<pre><code class="language-python"># Check device availability
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
print(f&quot;Using device: {device}&quot;)

# Move tensors to device
x = torch.randn(3, 3)
x = x.to(device)
# or
x = x.cuda() if torch.cuda.is_available() else x

# Create tensors directly on device
x = torch.randn(3, 3, device=device)
</code></pre>
<h2 id="neural-networks">Neural Networks</h2>
<h3 id="basic-neural-network">Basic Neural Network</h3>
<pre><code class="language-python">class SimpleNet(nn.Module):
    def __init__(self, input_size, hidden_size, output_size):
        super(SimpleNet, self).__init__()
        self.fc1 = nn.Linear(input_size, hidden_size)
        self.fc2 = nn.Linear(hidden_size, output_size)
        self.relu = nn.ReLU()
        self.dropout = nn.Dropout(0.2)

    def forward(self, x):
        x = self.fc1(x)
        x = self.relu(x)
        x = self.dropout(x)
        x = self.fc2(x)
        return x

# Create model
model = SimpleNet(784, 128, 10)
print(model)
</code></pre>
<h3 id="convolutional-neural-network">Convolutional Neural Network</h3>
<pre><code class="language-python">class ConvNet(nn.Module):
    def __init__(self, num_classes=10):
        super(ConvNet, self).__init__()
        self.conv1 = nn.Conv2d(3, 16, 3, padding=1)
        self.conv2 = nn.Conv2d(16, 32, 3, padding=1)
        self.pool = nn.MaxPool2d(2, 2)
        self.fc1 = nn.Linear(32 * 8 * 8, 128)
        self.fc2 = nn.Linear(128, num_classes)
        self.dropout = nn.Dropout(0.5)

    def forward(self, x):
        x = self.pool(F.relu(self.conv1(x)))
        x = self.pool(F.relu(self.conv2(x)))
        x = x.view(-1, 32 * 8 * 8)  # flatten
        x = F.relu(self.fc1(x))
        x = self.dropout(x)
        x = self.fc2(x)
        return x
</code></pre>
<h3 id="common-layers">Common Layers</h3>
<pre><code class="language-python"># Linear layers
nn.Linear(in_features, out_features)
nn.Linear(784, 10, bias=False)

# Convolutional layers
nn.Conv1d(in_channels, out_channels, kernel_size)
nn.Conv2d(1, 32, 3, stride=1, padding=1)
nn.Conv3d(1, 16, 3)

# Pooling layers
nn.MaxPool2d(kernel_size=2)
nn.AvgPool2d(kernel_size=2, stride=2)
nn.AdaptiveAvgPool2d((1, 1))

# Normalization
nn.BatchNorm1d(num_features)
nn.BatchNorm2d(num_features)
nn.LayerNorm(normalized_shape)

# Activation functions
nn.ReLU()
nn.LeakyReLU(negative_slope=0.01)
nn.Sigmoid()
nn.Tanh()
nn.Softmax(dim=1)

# Regularization
nn.Dropout(p=0.5)
nn.Dropout2d(p=0.5)
</code></pre>
<h2 id="loss-functions">Loss Functions</h2>
<pre><code class="language-python"># Classification
criterion = nn.CrossEntropyLoss()
criterion = nn.BCELoss()  # Binary cross entropy
criterion = nn.BCEWithLogitsLoss()  # BCE with sigmoid

# Regression
criterion = nn.MSELoss()  # Mean squared error
criterion = nn.L1Loss()   # Mean absolute error
criterion = nn.SmoothL1Loss()  # Huber loss

# Custom loss example
class CustomLoss(nn.Module):
    def __init__(self):
        super(CustomLoss, self).__init__()

    def forward(self, predictions, targets):
        return torch.mean((predictions - targets) ** 2)
</code></pre>
<h2 id="optimizers">Optimizers</h2>
<pre><code class="language-python"># Common optimizers
optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9, weight_decay=1e-4)
optimizer = optim.Adam(model.parameters(), lr=0.001, betas=(0.9, 0.999))
optimizer = optim.AdamW(model.parameters(), lr=0.001, weight_decay=0.01)
optimizer = optim.RMSprop(model.parameters(), lr=0.01, alpha=0.9)

# Learning rate schedulers
scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=30, gamma=0.1)
scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=10)
scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=50)
</code></pre>
<h2 id="training-loop">Training Loop</h2>
<pre><code class="language-python">def train_model(model, train_loader, criterion, optimizer, num_epochs, device):
    model.train()
    for epoch in range(num_epochs):
        running_loss = 0.0
        for batch_idx, (data, targets) in enumerate(train_loader):
            # Move data to device
            data, targets = data.to(device), targets.to(device)

            # Zero gradients
            optimizer.zero_grad()

            # Forward pass
            outputs = model(data)
            loss = criterion(outputs, targets)

            # Backward pass
            loss.backward()
            optimizer.step()

            running_loss += loss.item()

            if batch_idx % 100 == 0:
                print(f'Epoch {epoch+1}/{num_epochs}, '
                      f'Batch {batch_idx}/{len(train_loader)}, '
                      f'Loss: {loss.item():.4f}')

        # Optional: step scheduler
        # scheduler.step()

        epoch_loss = running_loss / len(train_loader)
        print(f'Epoch {epoch+1} average loss: {epoch_loss:.4f}')

# Usage
train_model(model, train_loader, criterion, optimizer, num_epochs=10, device=device)
</code></pre>
<h2 id="evaluation">Evaluation</h2>
<pre><code class="language-python">def evaluate_model(model, test_loader, device):
    model.eval()
    correct = 0
    total = 0
    test_loss = 0

    with torch.no_grad():
        for data, targets in test_loader:
            data, targets = data.to(device), targets.to(device)
            outputs = model(data)

            test_loss += F.cross_entropy(outputs, targets, reduction='sum').item()
            _, predicted = torch.max(outputs.data, 1)
            total += targets.size(0)
            correct += (predicted == targets).sum().item()

    accuracy = 100 * correct / total
    avg_loss = test_loss / total

    print(f'Test Accuracy: {accuracy:.2f}%')
    print(f'Test Loss: {avg_loss:.4f}')

    return accuracy, avg_loss
</code></pre>
<h2 id="data-loading">Data Loading</h2>
<h3 id="custom-dataset">Custom Dataset</h3>
<pre><code class="language-python">class CustomDataset(Dataset):
    def __init__(self, data, labels, transform=None):
        self.data = data
        self.labels = labels
        self.transform = transform

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        sample = self.data[idx]
        label = self.labels[idx]

        if self.transform:
            sample = self.transform(sample)

        return sample, label

# Usage
dataset = CustomDataset(data, labels, transform=transforms.ToTensor())
dataloader = DataLoader(dataset, batch_size=32, shuffle=True, num_workers=4)
</code></pre>
<h3 id="data-transforms">Data Transforms</h3>
<pre><code class="language-python">from torchvision import transforms

# Common transforms
transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.RandomHorizontalFlip(p=0.5),
    transforms.RandomRotation(degrees=10),
    transforms.ColorJitter(brightness=0.2, contrast=0.2),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], 
                        std=[0.229, 0.224, 0.225])
])

# For evaluation (no data augmentation)
test_transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], 
                        std=[0.229, 0.224, 0.225])
])
</code></pre>
<h2 id="model-saving-and-loading">Model Saving and Loading</h2>
<pre><code class="language-python"># Save model
torch.save(model.state_dict(), 'model_weights.pth')
torch.save(model, 'complete_model.pth')

# Save checkpoint
checkpoint = {
    'epoch': epoch,
    'model_state_dict': model.state_dict(),
    'optimizer_state_dict': optimizer.state_dict(),
    'loss': loss,
}
torch.save(checkpoint, 'checkpoint.pth')

# Load model
model.load_state_dict(torch.load('model_weights.pth', map_location=device))
model = torch.load('complete_model.pth', map_location=device)

# Load checkpoint
checkpoint = torch.load('checkpoint.pth', map_location=device)
model.load_state_dict(checkpoint['model_state_dict'])
optimizer.load_state_dict(checkpoint['optimizer_state_dict'])
epoch = checkpoint['epoch']
loss = checkpoint['loss']
</code></pre>
<h2 id="autograd-and-gradients">Autograd and Gradients</h2>
<pre><code class="language-python"># Enable/disable gradients
x = torch.randn(3, requires_grad=True)

# Forward pass
y = x.sum()

# Backward pass
y.backward()
print(x.grad)

# Gradient context managers
with torch.no_grad():
    # Operations here won't track gradients
    y = model(x)

# Temporarily enable gradients
with torch.enable_grad():
    # Operations here will track gradients
    pass

# Manual gradient computation
def custom_backward(x):
    x.retain_grad()
    y = x ** 2
    y.backward(torch.ones_like(y))
    return x.grad
</code></pre>
<h2 id="mixed-precision-training">Mixed Precision Training</h2>
<pre><code class="language-python">from torch.amp import autocast, GradScaler

# Initialize scaler
scaler = GradScaler()

def train_with_amp(model, train_loader, criterion, optimizer, device):
    model.train()
    for data, targets in train_loader:
        data, targets = data.to(device), targets.to(device)

        optimizer.zero_grad()

        # Use autocast for forward pass
        with autocast(device_type='cuda'):
            outputs = model(data)
            loss = criterion(outputs, targets)

        # Scale loss and backward
        scaler.scale(loss).backward()
        scaler.step(optimizer)
        scaler.update()
</code></pre>
<h2 id="torchcompile-pytorch-20">torch.compile (PyTorch 2.0+)</h2>
<pre><code class="language-python"># Optimize model with torch.compile
model = torch.compile(model)

# With specific backend
model = torch.compile(model, backend=&quot;inductor&quot;)

# For inference only
@torch.compile
def inference_function(x):
    return torch.sin(x).cos()

# Disable compilation for debugging
model = torch.compile(model, disable=True)
</code></pre>
<h2 id="model-utilities">Model Utilities</h2>
<h3 id="parameter-counting">Parameter Counting</h3>
<pre><code class="language-python">def count_parameters(model):
    return sum(p.numel() for p in model.parameters() if p.requires_grad)

print(f&quot;Model has {count_parameters(model):,} trainable parameters&quot;)
</code></pre>
<h3 id="model-summary">Model Summary</h3>
<pre><code class="language-python">def model_summary(model, input_size):
    def register_hook(module):
        def hook(module, input, output):
            class_name = str(module.__class__).split(&quot;.&quot;)[-1].split(&quot;'&quot;)[0]
            module_idx = len(summary)

            m_key = f&quot;{class_name}-{module_idx+1}&quot;
            summary[m_key] = {
                &quot;input_shape&quot;: list(input[0].size()),
                &quot;output_shape&quot;: list(output.size()),
                &quot;nb_params&quot;: sum([param.nelement() for param in module.parameters()])
            }

        if not isinstance(module, nn.Sequential) and not isinstance(module, nn.ModuleList):
            hooks.append(module.register_forward_hook(hook))

    device = next(model.parameters()).device
    summary = {}
    hooks = []

    model.apply(register_hook)

    # Make a forward pass
    x = torch.randn(*input_size).to(device)
    model(x)

    # Remove hooks
    for h in hooks:
        h.remove()

    return summary
</code></pre>
<h2 id="transfer-learning">Transfer Learning</h2>
<pre><code class="language-python">import torchvision.models as models

# Load pretrained model
model = models.resnet18(pretrained=True)

# Freeze parameters
for param in model.parameters():
    param.requires_grad = False

# Replace final layer
num_features = model.fc.in_features
model.fc = nn.Linear(num_features, num_classes)

# Only train final layer
optimizer = optim.Adam(model.fc.parameters(), lr=0.001)

# Fine-tuning: unfreeze some layers
for param in model.layer4.parameters():
    param.requires_grad = True
</code></pre>
<h2 id="common-patterns">Common Patterns</h2>
<h3 id="early-stopping">Early Stopping</h3>
<pre><code class="language-python">class EarlyStopping:
    def __init__(self, patience=7, min_delta=0, restore_best_weights=True):
        self.patience = patience
        self.min_delta = min_delta
        self.restore_best_weights = restore_best_weights
        self.best_loss = None
        self.counter = 0
        self.best_weights = None

    def __call__(self, val_loss, model):
        if self.best_loss is None:
            self.best_loss = val_loss
            self.save_checkpoint(model)
        elif val_loss &lt; self.best_loss - self.min_delta:
            self.best_loss = val_loss
            self.counter = 0
            self.save_checkpoint(model)
        else:
            self.counter += 1

        if self.counter &gt;= self.patience:
            if self.restore_best_weights:
                model.load_state_dict(self.best_weights)
            return True
        return False

    def save_checkpoint(self, model):
        self.best_weights = model.state_dict().copy()
</code></pre>
<h3 id="gradient-clipping">Gradient Clipping</h3>
<pre><code class="language-python"># During training
loss.backward()
torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
optimizer.step()
</code></pre>
<h3 id="learning-rate-finding">Learning Rate Finding</h3>
<pre><code class="language-python">def find_lr(model, train_loader, optimizer, criterion, device):
    lrs = []
    losses = []
    lr = 1e-7

    for data, targets in train_loader:
        data, targets = data.to(device), targets.to(device)

        optimizer.param_groups[0]['lr'] = lr
        optimizer.zero_grad()

        outputs = model(data)
        loss = criterion(outputs, targets)
        loss.backward()
        optimizer.step()

        lrs.append(lr)
        losses.append(loss.item())

        lr *= 1.1
        if lr &gt; 1:
            break

    return lrs, losses
</code></pre>
<h2 id="debugging-tips">Debugging Tips</h2>
<h3 id="check-for-naninf">Check for NaN/Inf</h3>
<pre><code class="language-python">def check_for_nan(tensor, name=&quot;tensor&quot;):
    if torch.isnan(tensor).any():
        print(f&quot;NaN detected in {name}&quot;)
    if torch.isinf(tensor).any():
        print(f&quot;Inf detected in {name}&quot;)
</code></pre>
<h3 id="monitor-gradients">Monitor Gradients</h3>
<pre><code class="language-python">def monitor_gradients(model):
    for name, param in model.named_parameters():
        if param.grad is not None:
            grad_norm = param.grad.norm()
            print(f&quot;{name}: {grad_norm:.4f}&quot;)
</code></pre>
<h3 id="memory-usage">Memory Usage</h3>
<pre><code class="language-python">def print_gpu_memory():
    if torch.cuda.is_available():
        print(f&quot;GPU memory allocated: {torch.cuda.memory_allocated() / 1024**2:.1f} MB&quot;)
        print(f&quot;GPU memory cached: {torch.cuda.memory_reserved() / 1024**2:.1f} MB&quot;)
</code></pre>
<h2 id="performance-tips">Performance Tips</h2>
<ul>
<li>Use <code>torch.compile()</code> for PyTorch 2.0+ performance gains</li>
<li>Use mixed precision training with AMP for faster training</li>
<li>Set <code>torch.backends.cudnn.benchmark = True</code> for consistent input sizes</li>
<li>Use <code>pin_memory=True</code> in DataLoader for faster GPU transfer</li>
<li>Use appropriate <code>num_workers</code> in DataLoader (typically 2-4x number of GPUs)</li>
<li>Use <code>torch.no_grad()</code> during inference to save memory</li>
<li>Consider using <code>torch.jit.script()</code> for model optimization</li>
<li>Use <code>torch.utils.checkpoint</code> for memory-efficient training of large models</li>
</ul>












                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    <script id="__config" type="application/json">{"base": "../..", "features": [], "search": "../../assets/javascripts/workers/search.b8dbb3d2.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}}</script>
    
    
      <script src="../../assets/javascripts/bundle.1e8ae164.min.js"></script>
      
        <script src="../../search/main.js"></script>
      
    
  </body>
</html>