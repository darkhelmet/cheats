
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
      
        <link rel="prev" href="../matplotlib/">
      
      
        <link rel="next" href="../numpy/">
      
      
      <link rel="icon" href="../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.5.3, mkdocs-material-9.5.17">
    
    
      
        <title>NLTK (Natural Language Toolkit) - Cheat Sheets</title>
      
    
    
      <link rel="stylesheet" href="../../assets/stylesheets/main.bcfcd587.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
    <script>__md_scope=new URL("../..",location),__md_hash=e=>[...e].reduce((e,_)=>(e<<5)-e+_.charCodeAt(0),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    <body dir="ltr">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#nltk-natural-language-toolkit" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../.." title="Cheat Sheets" class="md-header__button md-logo" aria-label="Cheat Sheets" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54Z"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2Z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            Cheat Sheets
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              NLTK (Natural Language Toolkit)
            
          </span>
        </div>
      </div>
    </div>
    
    
      <script>var media,input,key,value,palette=__md_get("__palette");if(palette&&palette.color){"(prefers-color-scheme)"===palette.color.media&&(media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']"),palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent"));for([key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    



<nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../.." title="Cheat Sheets" class="md-nav__button md-logo" aria-label="Cheat Sheets" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54Z"/></svg>

    </a>
    Cheat Sheets
  </label>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../.." class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Cheat Sheets Collection
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../machine-learning-algorithms/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Machine Learning Algorithms
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3" >
        
          
          <label class="md-nav__link" for="__nav_3" id="__nav_3_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Gpu
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3">
            <span class="md-nav__icon md-icon"></span>
            Gpu
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../gpu/cuda/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    CUDA Programming
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4" >
        
          
          <label class="md-nav__link" for="__nav_4" id="__nav_4_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Javascript
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4">
            <span class="md-nav__icon md-icon"></span>
            Javascript
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../javascript/nextjs/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Next.js
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../javascript/react/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    React
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5" >
        
          
          <label class="md-nav__link" for="__nav_5" id="__nav_5_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Os
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_5_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5">
            <span class="md-nav__icon md-icon"></span>
            Os
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../os/bottlerocket/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Bottlerocket OS Administration
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
    
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_6" checked>
        
          
          <label class="md-nav__link" for="__nav_6" id="__nav_6_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Python
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_6_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_6">
            <span class="md-nav__icon md-icon"></span>
            Python
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../inquirer/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Python Inquirer
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../keras/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Keras
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../langchain/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    LangChain
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../langextract/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    LangExtract
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../matplotlib/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Matplotlib
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  <span class="md-ellipsis">
    NLTK (Natural Language Toolkit)
  </span>
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  <span class="md-ellipsis">
    NLTK (Natural Language Toolkit)
  </span>
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#installation" class="md-nav__link">
    <span class="md-ellipsis">
      Installation
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#basic-setup" class="md-nav__link">
    <span class="md-ellipsis">
      Basic Setup
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#core-functionality" class="md-nav__link">
    <span class="md-ellipsis">
      Core Functionality
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Core Functionality">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#text-tokenization" class="md-nav__link">
    <span class="md-ellipsis">
      Text Tokenization
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#stop-words-removal" class="md-nav__link">
    <span class="md-ellipsis">
      Stop Words Removal
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#stemming-and-lemmatization" class="md-nav__link">
    <span class="md-ellipsis">
      Stemming and Lemmatization
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#part-of-speech-tagging" class="md-nav__link">
    <span class="md-ellipsis">
      Part-of-Speech Tagging
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#named-entity-recognition" class="md-nav__link">
    <span class="md-ellipsis">
      Named Entity Recognition
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#common-use-cases" class="md-nav__link">
    <span class="md-ellipsis">
      Common Use Cases
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Common Use Cases">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#sentiment-analysis" class="md-nav__link">
    <span class="md-ellipsis">
      Sentiment Analysis
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#text-preprocessing-pipeline" class="md-nav__link">
    <span class="md-ellipsis">
      Text Preprocessing Pipeline
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#frequency-analysis" class="md-nav__link">
    <span class="md-ellipsis">
      Frequency Analysis
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#n-grams-and-collocations" class="md-nav__link">
    <span class="md-ellipsis">
      N-grams and Collocations
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#advanced-features" class="md-nav__link">
    <span class="md-ellipsis">
      Advanced Features
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Advanced Features">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#custom-text-classification" class="md-nav__link">
    <span class="md-ellipsis">
      Custom Text Classification
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#working-with-corpora" class="md-nav__link">
    <span class="md-ellipsis">
      Working with Corpora
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#text-parsing-and-chunking" class="md-nav__link">
    <span class="md-ellipsis">
      Text Parsing and Chunking
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#integration-with-other-libraries" class="md-nav__link">
    <span class="md-ellipsis">
      Integration with Other Libraries
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Integration with Other Libraries">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#with-pandas-for-data-analysis" class="md-nav__link">
    <span class="md-ellipsis">
      With Pandas for Data Analysis
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#with-scikit-learn-for-ml" class="md-nav__link">
    <span class="md-ellipsis">
      With Scikit-learn for ML
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#best-practices" class="md-nav__link">
    <span class="md-ellipsis">
      Best Practices
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Best Practices">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#performance-tips" class="md-nav__link">
    <span class="md-ellipsis">
      Performance Tips
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#memory-management" class="md-nav__link">
    <span class="md-ellipsis">
      Memory Management
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#error-handling" class="md-nav__link">
    <span class="md-ellipsis">
      Error Handling
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#real-world-examples" class="md-nav__link">
    <span class="md-ellipsis">
      Real-world Examples
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Real-world Examples">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#complete-sentiment-analysis-pipeline" class="md-nav__link">
    <span class="md-ellipsis">
      Complete Sentiment Analysis Pipeline
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#text-summarization-with-nltk" class="md-nav__link">
    <span class="md-ellipsis">
      Text Summarization with NLTK
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../numpy/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    NumPy
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../pandas/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Pandas
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../pillow/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Pillow (PIL)
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../polars/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Polars
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../python/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Python
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../pytorch/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    PyTorch
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../scikit-learn/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Scikit-learn
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../scipy/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    SciPy
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../seaborn/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Seaborn
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../sentence-transformers/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Sentence-Transformers (UKPLab)
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../tensorflow/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    TensorFlow
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../torchvision/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    TorchVision
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../transformers/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Transformers (Hugging Face)
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_7" >
        
          
          <label class="md-nav__link" for="__nav_7" id="__nav_7_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Tools
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_7_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_7">
            <span class="md-nav__icon md-icon"></span>
            Tools
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../tools/protobuf/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Protocol Buffers (protobuf)
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../tools/ripgrep/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Ripgrep (rg)
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../tools/vim-lazyvim/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Vim/Neovim with LazyVim
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#installation" class="md-nav__link">
    <span class="md-ellipsis">
      Installation
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#basic-setup" class="md-nav__link">
    <span class="md-ellipsis">
      Basic Setup
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#core-functionality" class="md-nav__link">
    <span class="md-ellipsis">
      Core Functionality
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Core Functionality">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#text-tokenization" class="md-nav__link">
    <span class="md-ellipsis">
      Text Tokenization
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#stop-words-removal" class="md-nav__link">
    <span class="md-ellipsis">
      Stop Words Removal
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#stemming-and-lemmatization" class="md-nav__link">
    <span class="md-ellipsis">
      Stemming and Lemmatization
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#part-of-speech-tagging" class="md-nav__link">
    <span class="md-ellipsis">
      Part-of-Speech Tagging
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#named-entity-recognition" class="md-nav__link">
    <span class="md-ellipsis">
      Named Entity Recognition
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#common-use-cases" class="md-nav__link">
    <span class="md-ellipsis">
      Common Use Cases
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Common Use Cases">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#sentiment-analysis" class="md-nav__link">
    <span class="md-ellipsis">
      Sentiment Analysis
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#text-preprocessing-pipeline" class="md-nav__link">
    <span class="md-ellipsis">
      Text Preprocessing Pipeline
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#frequency-analysis" class="md-nav__link">
    <span class="md-ellipsis">
      Frequency Analysis
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#n-grams-and-collocations" class="md-nav__link">
    <span class="md-ellipsis">
      N-grams and Collocations
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#advanced-features" class="md-nav__link">
    <span class="md-ellipsis">
      Advanced Features
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Advanced Features">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#custom-text-classification" class="md-nav__link">
    <span class="md-ellipsis">
      Custom Text Classification
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#working-with-corpora" class="md-nav__link">
    <span class="md-ellipsis">
      Working with Corpora
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#text-parsing-and-chunking" class="md-nav__link">
    <span class="md-ellipsis">
      Text Parsing and Chunking
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#integration-with-other-libraries" class="md-nav__link">
    <span class="md-ellipsis">
      Integration with Other Libraries
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Integration with Other Libraries">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#with-pandas-for-data-analysis" class="md-nav__link">
    <span class="md-ellipsis">
      With Pandas for Data Analysis
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#with-scikit-learn-for-ml" class="md-nav__link">
    <span class="md-ellipsis">
      With Scikit-learn for ML
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#best-practices" class="md-nav__link">
    <span class="md-ellipsis">
      Best Practices
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Best Practices">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#performance-tips" class="md-nav__link">
    <span class="md-ellipsis">
      Performance Tips
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#memory-management" class="md-nav__link">
    <span class="md-ellipsis">
      Memory Management
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#error-handling" class="md-nav__link">
    <span class="md-ellipsis">
      Error Handling
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#real-world-examples" class="md-nav__link">
    <span class="md-ellipsis">
      Real-world Examples
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Real-world Examples">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#complete-sentiment-analysis-pipeline" class="md-nav__link">
    <span class="md-ellipsis">
      Complete Sentiment Analysis Pipeline
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#text-summarization-with-nltk" class="md-nav__link">
    <span class="md-ellipsis">
      Text Summarization with NLTK
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  


<h1 id="nltk-natural-language-toolkit">NLTK (Natural Language Toolkit)</h1>
<p>NLTK is a leading platform for building Python programs to work with human language data. It provides easy-to-use interfaces to over 50 corpora and lexical resources such as WordNet, along with a suite of text processing libraries for classification, tokenization, stemming, tagging, parsing, and semantic reasoning.</p>
<h2 id="installation">Installation</h2>
<pre><code class="language-bash"># Basic installation
pip install nltk

# Install with datasets
pip install nltk[all]

# Download specific data
python -c &quot;import nltk; nltk.download('punkt')&quot;
python -c &quot;import nltk; nltk.download('stopwords')&quot;
python -c &quot;import nltk; nltk.download('vader_lexicon')&quot;
python -c &quot;import nltk; nltk.download('wordnet')&quot;
python -c &quot;import nltk; nltk.download('omw-1.4')&quot;

# Download all datasets (large)
python -c &quot;import nltk; nltk.download('all')&quot;
</code></pre>
<h2 id="basic-setup">Basic Setup</h2>
<pre><code class="language-python">import nltk
from nltk.tokenize import word_tokenize, sent_tokenize
from nltk.corpus import stopwords
from nltk.stem import PorterStemmer, WordNetLemmatizer
from nltk.tag import pos_tag
from nltk.chunk import ne_chunk
from nltk.sentiment import SentimentIntensityAnalyzer

# Download required data (run once)
nltk.download('punkt')
nltk.download('stopwords')
nltk.download('averaged_perceptron_tagger')
nltk.download('maxent_ne_chunker')
nltk.download('words')
nltk.download('vader_lexicon')
</code></pre>
<h2 id="core-functionality">Core Functionality</h2>
<h3 id="text-tokenization">Text Tokenization</h3>
<pre><code class="language-python"># Sentence tokenization
text = &quot;Hello world. This is NLTK. It's great for NLP!&quot;
sentences = sent_tokenize(text)
print(sentences)  # ['Hello world.', 'This is NLTK.', &quot;It's great for NLP!&quot;]

# Word tokenization
words = word_tokenize(text)
print(words)  # ['Hello', 'world', '.', 'This', 'is', 'NLTK', '.', ...]

# Custom tokenizers
from nltk.tokenize import RegexpTokenizer, WhitespaceTokenizer, LineTokenizer

# Only alphabetic tokens
tokenizer = RegexpTokenizer(r'\w+')
tokens = tokenizer.tokenize(text)

# Whitespace tokenization
ws_tokenizer = WhitespaceTokenizer()
tokens = ws_tokenizer.tokenize(text)
</code></pre>
<h3 id="stop-words-removal">Stop Words Removal</h3>
<pre><code class="language-python">from nltk.corpus import stopwords

# Get English stopwords
stop_words = set(stopwords.words('english'))

# Filter stop words
words = word_tokenize(&quot;This is a sample sentence with stop words.&quot;)
filtered_words = [w for w in words if w.lower() not in stop_words]
print(filtered_words)  # ['sample', 'sentence', 'stop', 'words', '.']

# Custom stop words
custom_stops = stop_words.union({'sample', 'example'})
</code></pre>
<h3 id="stemming-and-lemmatization">Stemming and Lemmatization</h3>
<pre><code class="language-python"># Porter Stemmer
stemmer = PorterStemmer()
words = [&quot;running&quot;, &quot;runs&quot;, &quot;ran&quot;, &quot;runner&quot;]
stems = [stemmer.stem(word) for word in words]
print(stems)  # ['run', 'run', 'ran', 'runner']

# WordNet Lemmatizer (more accurate)
lemmatizer = WordNetLemmatizer()
lemmas = [lemmatizer.lemmatize(word, pos='v') for word in words]
print(lemmas)  # ['run', 'run', 'run', 'runner']

# Lemmatize with different POS tags
word = &quot;better&quot;
print(lemmatizer.lemmatize(word, pos='a'))  # good (adjective)
print(lemmatizer.lemmatize(word, pos='r'))  # well (adverb)
</code></pre>
<h3 id="part-of-speech-tagging">Part-of-Speech Tagging</h3>
<pre><code class="language-python"># POS tagging
text = &quot;The quick brown fox jumps over the lazy dog&quot;
tokens = word_tokenize(text)
pos_tags = pos_tag(tokens)
print(pos_tags)
# [('The', 'DT'), ('quick', 'JJ'), ('brown', 'JJ'), ('fox', 'NN'), ...]

# Extract specific POS
nouns = [word for word, pos in pos_tags if pos.startswith('N')]
adjectives = [word for word, pos in pos_tags if pos.startswith('JJ')]

# Universal POS tags
from nltk.tag import pos_tag
from nltk.corpus import brown
universal_tags = pos_tag(tokens, tagset='universal')
</code></pre>
<h3 id="named-entity-recognition">Named Entity Recognition</h3>
<pre><code class="language-python"># Named entity chunking
tokens = word_tokenize(&quot;Barack Obama was the 44th President of the United States.&quot;)
pos_tags = pos_tag(tokens)
entities = ne_chunk(pos_tags)

# Extract named entities
from nltk import Tree
def extract_entities(tree):
    entities = []
    if hasattr(tree, 'label'):
        entities.append((tree.label(), [token for token, pos in tree.leaves()]))
    else:
        for child in tree:
            entities.extend(extract_entities(child))
    return entities

named_entities = extract_entities(entities)
print(named_entities)  # [('PERSON', ['Barack', 'Obama']), ...]
</code></pre>
<h2 id="common-use-cases">Common Use Cases</h2>
<h3 id="sentiment-analysis">Sentiment Analysis</h3>
<pre><code class="language-python"># VADER sentiment analyzer
sia = SentimentIntensityAnalyzer()

texts = [
    &quot;I love this product! It's amazing!&quot;,
    &quot;This is terrible. I hate it.&quot;,
    &quot;It's okay, nothing special.&quot;,
    &quot;Best purchase ever! Highly recommend!&quot;
]

for text in texts:
    scores = sia.polarity_scores(text)
    print(f&quot;Text: {text}&quot;)
    print(f&quot;Positive: {scores['pos']:.3f}&quot;)
    print(f&quot;Negative: {scores['neg']:.3f}&quot;)
    print(f&quot;Neutral: {scores['neu']:.3f}&quot;)
    print(f&quot;Compound: {scores['compound']:.3f}&quot;)
    print(&quot;-&quot; * 50)

# Simple sentiment classification
def classify_sentiment(text):
    score = sia.polarity_scores(text)['compound']
    if score &gt;= 0.05:
        return 'Positive'
    elif score &lt;= -0.05:
        return 'Negative'
    else:
        return 'Neutral'
</code></pre>
<h3 id="text-preprocessing-pipeline">Text Preprocessing Pipeline</h3>
<pre><code class="language-python">import re
import string

def preprocess_text(text, 
                   lowercase=True,
                   remove_punctuation=True,
                   remove_stopwords=True,
                   lemmatize=True):
    &quot;&quot;&quot;Complete text preprocessing pipeline&quot;&quot;&quot;

    # Convert to lowercase
    if lowercase:
        text = text.lower()

    # Remove URLs, emails, mentions
    text = re.sub(r'http\S+|www\S+|https\S+', '', text, flags=re.MULTILINE)
    text = re.sub(r'\@\w+|\#\w+', '', text)

    # Remove punctuation
    if remove_punctuation:
        text = text.translate(str.maketrans('', '', string.punctuation))

    # Tokenization
    tokens = word_tokenize(text)

    # Remove stopwords
    if remove_stopwords:
        stop_words = set(stopwords.words('english'))
        tokens = [token for token in tokens if token not in stop_words]

    # Lemmatization
    if lemmatize:
        lemmatizer = WordNetLemmatizer()
        tokens = [lemmatizer.lemmatize(token) for token in tokens]

    return tokens

# Usage
text = &quot;I'm loving this new product! Check out https://example.com #awesome @company&quot;
processed = preprocess_text(text)
print(processed)  # ['loving', 'new', 'product', 'check']
</code></pre>
<h3 id="frequency-analysis">Frequency Analysis</h3>
<pre><code class="language-python">from nltk import FreqDist
from collections import Counter

# Word frequency distribution
text = &quot;the quick brown fox jumps over the lazy dog the fox is quick&quot;
tokens = word_tokenize(text.lower())
fdist = FreqDist(tokens)

# Most common words
print(fdist.most_common(5))  # [('the', 3), ('quick', 2), ('fox', 2), ...]

# Plot frequency distribution
fdist.plot(30, cumulative=False)

# Conditional frequency distribution
from nltk import ConditionalFreqDist
from nltk.corpus import brown

# Frequency by genre
cfdist = ConditionalFreqDist(
    (genre, word)
    for genre in brown.categories()
    for word in brown.words(categories=genre)
)

# Words most common in news vs romance
cfdist['news'].most_common(10)
cfdist['romance'].most_common(10)
</code></pre>
<h3 id="n-grams-and-collocations">N-grams and Collocations</h3>
<pre><code class="language-python">from nltk import ngrams, collocations
from nltk.collocations import BigramCollocationFinder, TrigramCollocationFinder

# Generate n-grams
text = &quot;the quick brown fox jumps over the lazy dog&quot;
tokens = word_tokenize(text)

# Bigrams
bigrams = list(ngrams(tokens, 2))
print(bigrams[:5])  # [('the', 'quick'), ('quick', 'brown'), ...]

# Trigrams
trigrams = list(ngrams(tokens, 3))
print(trigrams[:3])  # [('the', 'quick', 'brown'), ...]

# Find collocations
from nltk.corpus import text1  # Moby Dick

# Bigram collocations
bigram_measures = collocations.BigramAssocMeasures()
finder = BigramCollocationFinder.from_words(text1.tokens)
finder.apply_freq_filter(3)  # Only bigrams that appear 3+ times

# Best collocations by PMI
collocations = finder.nbest(bigram_measures.pmi, 10)
print(collocations)  # [('Sperm', 'Whale'), ('Moby', 'Dick'), ...]
</code></pre>
<h2 id="advanced-features">Advanced Features</h2>
<h3 id="custom-text-classification">Custom Text Classification</h3>
<pre><code class="language-python">import random
from nltk.corpus import movie_reviews
from nltk.tokenize import word_tokenize

# Prepare movie review dataset
documents = [(list(movie_reviews.words(fileid)), category)
             for category in movie_reviews.categories()
             for fileid in movie_reviews.fileids(category)]

random.shuffle(documents)

# Feature extraction
def document_features(document):
    &quot;&quot;&quot;Extract features from document&quot;&quot;&quot;
    words = set(document)
    features = {}

    # Word presence features
    for word in word_features:
        features[f'contains({word})'] = (word in words)

    return features

# Get most informative words
all_words = nltk.FreqDist(w.lower() for w in movie_reviews.words())
word_features = list(all_words)[:2000]

# Create feature sets
featuresets = [(document_features(d), c) for (d, c) in documents]
train_set, test_set = featuresets[100:], featuresets[:100]

# Train classifier
classifier = nltk.NaiveBayesClassifier.train(train_set)

# Evaluate
accuracy = nltk.classify.accuracy(classifier, test_set)
print(f&quot;Accuracy: {accuracy:.3f}&quot;)

# Show most informative features
classifier.show_most_informative_features(5)
</code></pre>
<h3 id="working-with-corpora">Working with Corpora</h3>
<pre><code class="language-python">from nltk.corpus import gutenberg, reuters, wordnet

# Gutenberg corpus
print(gutenberg.fileids())  # List of books
emma = gutenberg.words('austen-emma.txt')
print(f&quot;Emma has {len(emma)} words&quot;)

# Reuters corpus
print(reuters.categories())  # News categories
finance_docs = reuters.fileids('money-fx')
print(f&quot;Finance articles: {len(finance_docs)}&quot;)

# WordNet (semantic dictionary)
from nltk.corpus import wordnet as wn

# Synsets (synonym sets)
dog_synsets = wn.synsets('dog')
print(dog_synsets[0].definition())  # 'a member of the genus Canis...'

# Hypernyms and hyponyms
dog = wn.synset('dog.n.01')
print(dog.hypernyms())  # More general terms
print(dog.hyponyms())   # More specific terms

# Semantic similarity
dog = wn.synset('dog.n.01')
cat = wn.synset('cat.n.01')
similarity = dog.path_similarity(cat)
print(f&quot;Dog-cat similarity: {similarity:.3f}&quot;)
</code></pre>
<h3 id="text-parsing-and-chunking">Text Parsing and Chunking</h3>
<pre><code class="language-python"># Grammar-based chunking
grammar = r&quot;&quot;&quot;
    NP: {&lt;DT|JJ|NN.*&gt;+}          # Chunk sequences of DT, JJ, NN
    PP: {&lt;IN&gt;&lt;NP&gt;}               # Chunk prepositions followed by NP
    VP: {&lt;VB.*&gt;&lt;NP|PP|CLAUSE&gt;+$} # Chunk verbs followed by NP or PP
&quot;&quot;&quot;

chunk_parser = nltk.RegexpParser(grammar)
sentence = &quot;The little yellow dog barked at the cat&quot;
tokens = word_tokenize(sentence)
pos_tags = pos_tag(tokens)
parsed = chunk_parser.parse(pos_tags)

# Draw parse tree
parsed.draw()

# Extract noun phrases
def extract_noun_phrases(tree):
    noun_phrases = []
    for subtree in tree:
        if hasattr(subtree, 'label') and subtree.label() == 'NP':
            np = ' '.join([token for token, pos in subtree.leaves()])
            noun_phrases.append(np)
    return noun_phrases

nps = extract_noun_phrases(parsed)
print(nps)  # ['The little yellow dog', 'the cat']
</code></pre>
<h2 id="integration-with-other-libraries">Integration with Other Libraries</h2>
<h3 id="with-pandas-for-data-analysis">With Pandas for Data Analysis</h3>
<pre><code class="language-python">import pandas as pd
import nltk
from nltk.sentiment import SentimentIntensityAnalyzer

# Create sample dataset
data = {
    'review': [
        &quot;This product is amazing! Love it!&quot;,
        &quot;Terrible quality. Very disappointed.&quot;,
        &quot;It's okay, nothing special.&quot;,
        &quot;Best purchase I've ever made!&quot;
    ],
    'rating': [5, 1, 3, 5]
}

df = pd.DataFrame(data)

# Add sentiment analysis
sia = SentimentIntensityAnalyzer()
df['sentiment_compound'] = df['review'].apply(
    lambda x: sia.polarity_scores(x)['compound']
)

# Add preprocessing
def preprocess_for_analysis(text):
    tokens = word_tokenize(text.lower())
    stop_words = set(stopwords.words('english'))
    tokens = [token for token in tokens if token.isalpha() and token not in stop_words]
    return ' '.join(tokens)

df['processed_text'] = df['review'].apply(preprocess_for_analysis)
df['word_count'] = df['processed_text'].apply(lambda x: len(x.split()))

print(df[['review', 'sentiment_compound', 'word_count']])
</code></pre>
<h3 id="with-scikit-learn-for-ml">With Scikit-learn for ML</h3>
<pre><code class="language-python">from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.model_selection import train_test_split
from sklearn.naive_bayes import MultinomialNB
from sklearn.pipeline import Pipeline
from sklearn.metrics import classification_report

# Custom tokenizer using NLTK
def nltk_tokenizer(text):
    tokens = word_tokenize(text.lower())
    return [lemmatizer.lemmatize(token) for token in tokens if token.isalpha()]

# Create pipeline
pipeline = Pipeline([
    ('tfidf', TfidfVectorizer(tokenizer=nltk_tokenizer, stop_words='english')),
    ('classifier', MultinomialNB())
])

# Train model (using movie reviews data)
X = [' '.join(d) for d, c in documents]
y = [c for d, c in documents]

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

pipeline.fit(X_train, y_train)
predictions = pipeline.predict(X_test)

print(classification_report(y_test, predictions))
</code></pre>
<h2 id="best-practices">Best Practices</h2>
<h3 id="performance-tips">Performance Tips</h3>
<pre><code class="language-python"># 1. Cache expensive operations
import functools

@functools.lru_cache(maxsize=1000)
def cached_lemmatize(word, pos='n'):
    return lemmatizer.lemmatize(word, pos=pos)

# 2. Use generators for large datasets
def process_large_corpus(file_path):
    with open(file_path, 'r') as f:
        for line in f:
            yield preprocess_text(line.strip())

# 3. Batch processing
def batch_sentiment_analysis(texts, batch_size=100):
    sia = SentimentIntensityAnalyzer()
    results = []

    for i in range(0, len(texts), batch_size):
        batch = texts[i:i + batch_size]
        batch_results = [sia.polarity_scores(text) for text in batch]
        results.extend(batch_results)

    return results

# 4. Efficient stopword removal
stop_words = set(stopwords.words('english'))  # Create once, reuse many times

def remove_stopwords_efficiently(tokens):
    return [token for token in tokens if token.lower() not in stop_words]
</code></pre>
<h3 id="memory-management">Memory Management</h3>
<pre><code class="language-python"># For large text processing
import gc
from collections import deque

def process_large_text_stream(text_stream, window_size=1000):
    &quot;&quot;&quot;Process large text streams efficiently&quot;&quot;&quot;
    buffer = deque(maxlen=window_size)

    for text in text_stream:
        # Process text
        processed = preprocess_text(text)
        buffer.append(processed)

        # Periodic cleanup
        if len(buffer) == window_size:
            # Do something with buffer
            yield list(buffer)
            gc.collect()  # Force garbage collection
</code></pre>
<h3 id="error-handling">Error Handling</h3>
<pre><code class="language-python">def robust_text_processing(text):
    &quot;&quot;&quot;Text processing with error handling&quot;&quot;&quot;
    try:
        # Validate input
        if not isinstance(text, str):
            text = str(text)

        if not text.strip():
            return []

        # Process with fallbacks
        try:
            tokens = word_tokenize(text)
        except:
            # Fallback to simple split
            tokens = text.split()

        # Safe POS tagging
        try:
            pos_tags = pos_tag(tokens)
        except:
            pos_tags = [(token, 'NN') for token in tokens]

        return pos_tags

    except Exception as e:
        print(f&quot;Error processing text: {e}&quot;)
        return []
</code></pre>
<h2 id="real-world-examples">Real-world Examples</h2>
<h3 id="complete-sentiment-analysis-pipeline">Complete Sentiment Analysis Pipeline</h3>
<pre><code class="language-python">class SentimentAnalyzer:
    def __init__(self):
        self.sia = SentimentIntensityAnalyzer()
        self.lemmatizer = WordNetLemmatizer()
        self.stop_words = set(stopwords.words('english'))

    def preprocess(self, text):
        &quot;&quot;&quot;Clean and preprocess text&quot;&quot;&quot;
        # Basic cleaning
        text = re.sub(r'http\S+|www\S+', '', text)
        text = re.sub(r'[^a-zA-Z\s]', '', text)

        # Tokenization and normalization
        tokens = word_tokenize(text.lower())
        tokens = [self.lemmatizer.lemmatize(token) 
                 for token in tokens 
                 if token not in self.stop_words and len(token) &gt; 2]

        return ' '.join(tokens)

    def analyze(self, text):
        &quot;&quot;&quot;Perform sentiment analysis&quot;&quot;&quot;
        # Preprocess
        clean_text = self.preprocess(text)

        # Get sentiment scores
        scores = self.sia.polarity_scores(text)  # Use original text for better accuracy

        # Classify sentiment
        compound = scores['compound']
        if compound &gt;= 0.05:
            sentiment = 'positive'
        elif compound &lt;= -0.05:
            sentiment = 'negative'
        else:
            sentiment = 'neutral'

        return {
            'sentiment': sentiment,
            'confidence': abs(compound),
            'scores': scores,
            'processed_text': clean_text
        }

# Usage
analyzer = SentimentAnalyzer()
result = analyzer.analyze(&quot;I absolutely love this new product! It's fantastic!&quot;)
print(result)
</code></pre>
<h3 id="text-summarization-with-nltk">Text Summarization with NLTK</h3>
<pre><code class="language-python">from nltk.tokenize import sent_tokenize
from collections import Counter
import math

def extractive_summarization(text, num_sentences=3):
    &quot;&quot;&quot;Simple extractive summarization using TF-IDF&quot;&quot;&quot;

    # Tokenize into sentences
    sentences = sent_tokenize(text)

    if len(sentences) &lt;= num_sentences:
        return text

    # Tokenize and preprocess
    all_words = []
    sentence_words = []

    for sentence in sentences:
        words = word_tokenize(sentence.lower())
        words = [word for word in words if word.isalpha() and word not in stop_words]
        sentence_words.append(words)
        all_words.extend(words)

    # Calculate word frequencies
    word_freq = Counter(all_words)

    # Calculate sentence scores
    sentence_scores = []
    for words in sentence_words:
        score = sum(word_freq[word] for word in words)
        sentence_scores.append(score)

    # Get top sentences
    top_indices = sorted(range(len(sentence_scores)), 
                        key=lambda i: sentence_scores[i], 
                        reverse=True)[:num_sentences]

    # Return sentences in original order
    top_indices.sort()
    summary_sentences = [sentences[i] for i in top_indices]

    return ' '.join(summary_sentences)

# Usage
long_text = &quot;&quot;&quot;
Natural language processing (NLP) is a subfield of linguistics, computer science, and artificial intelligence 
concerned with the interactions between computers and human language. In particular, it focuses on programming 
computers to process and analyze large amounts of natural language data. The result is a computer capable of 
&quot;understanding&quot; the contents of documents, including the contextual nuances of the language within them. 
The technology can then accurately extract information and insights contained in the documents as well as 
categorize and organize the documents themselves. Challenges in natural language processing frequently involve 
speech recognition, natural language understanding, and natural language generation.
&quot;&quot;&quot;

summary = extractive_summarization(long_text, num_sentences=2)
print(summary)
</code></pre>
<p>This cheat sheet covers the essential aspects of NLTK for natural language processing tasks. The library is particularly strong in academic and research contexts, providing comprehensive tools for text analysis, linguistic processing, and building NLP applications. Its extensive corpus collection and built-in algorithms make it an excellent choice for learning NLP concepts and rapid prototyping.</p>












                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    <script id="__config" type="application/json">{"base": "../..", "features": [], "search": "../../assets/javascripts/workers/search.b8dbb3d2.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}}</script>
    
    
      <script src="../../assets/javascripts/bundle.1e8ae164.min.js"></script>
      
        <script src="../../search/main.js"></script>
      
    
  </body>
</html>